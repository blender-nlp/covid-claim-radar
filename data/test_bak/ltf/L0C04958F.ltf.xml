<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="eng">
<DOC id="L0C04958F" lang="eng" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="19522" raw_text_md5="6894a1c1a6d48b6421cf1c8d18283a71">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="89">
<ORIGINAL_TEXT>Coronavirus: Institut Pasteur warns against false information circulating on social media</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="11">Coronavirus</TOKEN>
<TOKEN id="token-0-1" pos="punct" morph="none" start_char="12" end_char="12">:</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="14" end_char="21">Institut</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="23" end_char="29">Pasteur</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="31" end_char="35">warns</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="37" end_char="43">against</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="45" end_char="49">false</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="51" end_char="61">information</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="63" end_char="73">circulating</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="75" end_char="76">on</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="78" end_char="83">social</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="85" end_char="89">media</TOKEN>
</SEG>
<SEG id="segment-1" start_char="93" end_char="225">
<ORIGINAL_TEXT>As the Covid-19 outbreak continues to spread in France, multiple information are circulating on social media and messaging platforms.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="93" end_char="94">As</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="96" end_char="98">the</TOKEN>
<TOKEN id="token-1-2" pos="unknown" morph="none" start_char="100" end_char="107">Covid-19</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="109" end_char="116">outbreak</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="118" end_char="126">continues</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="128" end_char="129">to</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="131" end_char="136">spread</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="138" end_char="139">in</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="141" end_char="146">France</TOKEN>
<TOKEN id="token-1-9" pos="punct" morph="none" start_char="147" end_char="147">,</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="149" end_char="156">multiple</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="158" end_char="168">information</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="170" end_char="172">are</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="174" end_char="184">circulating</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="186" end_char="187">on</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="189" end_char="194">social</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="196" end_char="200">media</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="202" end_char="204">and</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="206" end_char="214">messaging</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="216" end_char="224">platforms</TOKEN>
<TOKEN id="token-1-20" pos="punct" morph="none" start_char="225" end_char="225">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="227" end_char="366">
<ORIGINAL_TEXT>Some of these messages contain misleading information, and some are supposedly based on the expertise of scientists at the Institut Pasteur.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="227" end_char="230">Some</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="232" end_char="233">of</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="235" end_char="239">these</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="241" end_char="248">messages</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="250" end_char="256">contain</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="258" end_char="267">misleading</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="269" end_char="279">information</TOKEN>
<TOKEN id="token-2-7" pos="punct" morph="none" start_char="280" end_char="280">,</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="282" end_char="284">and</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="286" end_char="289">some</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="291" end_char="293">are</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="295" end_char="304">supposedly</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="306" end_char="310">based</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="312" end_char="313">on</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="315" end_char="317">the</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="319" end_char="327">expertise</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="329" end_char="330">of</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="332" end_char="341">scientists</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="343" end_char="344">at</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="346" end_char="348">the</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="350" end_char="357">Institut</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="359" end_char="365">Pasteur</TOKEN>
<TOKEN id="token-2-22" pos="punct" morph="none" start_char="366" end_char="366">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="368" end_char="462">
<ORIGINAL_TEXT>The Institut Pasteur asks you not to take any notice of this information and not to pass it on.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="368" end_char="370">The</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="372" end_char="379">Institut</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="381" end_char="387">Pasteur</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="389" end_char="392">asks</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="394" end_char="396">you</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="398" end_char="400">not</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="402" end_char="403">to</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="405" end_char="408">take</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="410" end_char="412">any</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="414" end_char="419">notice</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="421" end_char="422">of</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="424" end_char="427">this</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="429" end_char="439">information</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="441" end_char="443">and</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="445" end_char="447">not</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="449" end_char="450">to</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="452" end_char="455">pass</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="457" end_char="458">it</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="460" end_char="461">on</TOKEN>
<TOKEN id="token-3-19" pos="punct" morph="none" start_char="462" end_char="462">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="465" end_char="556">
<ORIGINAL_TEXT>For official information about the research carried out at the Institut Pasteur, click here.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="465" end_char="467">For</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="469" end_char="476">official</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="478" end_char="488">information</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="490" end_char="494">about</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="496" end_char="498">the</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="500" end_char="507">research</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="509" end_char="515">carried</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="517" end_char="519">out</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="521" end_char="522">at</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="524" end_char="526">the</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="528" end_char="535">Institut</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="537" end_char="543">Pasteur</TOKEN>
<TOKEN id="token-4-12" pos="punct" morph="none" start_char="544" end_char="544">,</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="546" end_char="550">click</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="552" end_char="555">here</TOKEN>
<TOKEN id="token-4-15" pos="punct" morph="none" start_char="556" end_char="556">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="559" end_char="667">
<ORIGINAL_TEXT>You can also follow the Institut Pasteur via its official Facebook, Twitter, LinkedIn and Instagram accounts.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="559" end_char="561">You</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="563" end_char="565">can</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="567" end_char="570">also</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="572" end_char="577">follow</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="579" end_char="581">the</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="583" end_char="590">Institut</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="592" end_char="598">Pasteur</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="600" end_char="602">via</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="604" end_char="606">its</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="608" end_char="615">official</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="617" end_char="624">Facebook</TOKEN>
<TOKEN id="token-5-11" pos="punct" morph="none" start_char="625" end_char="625">,</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="627" end_char="633">Twitter</TOKEN>
<TOKEN id="token-5-13" pos="punct" morph="none" start_char="634" end_char="634">,</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="636" end_char="643">LinkedIn</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="645" end_char="647">and</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="649" end_char="657">Instagram</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="659" end_char="666">accounts</TOKEN>
<TOKEN id="token-5-18" pos="punct" morph="none" start_char="667" end_char="667">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="670" end_char="809">
<ORIGINAL_TEXT>The Institut Pasteur's scientists have been working since the early days of the Covid-19 outbreak to deal with this unprecedented situation.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="670" end_char="672">The</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="674" end_char="681">Institut</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="683" end_char="691">Pasteur's</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="693" end_char="702">scientists</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="704" end_char="707">have</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="709" end_char="712">been</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="714" end_char="720">working</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="722" end_char="726">since</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="728" end_char="730">the</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="732" end_char="736">early</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="738" end_char="741">days</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="743" end_char="744">of</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="746" end_char="748">the</TOKEN>
<TOKEN id="token-6-13" pos="unknown" morph="none" start_char="750" end_char="757">Covid-19</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="759" end_char="766">outbreak</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="768" end_char="769">to</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="771" end_char="774">deal</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="776" end_char="779">with</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="781" end_char="784">this</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="786" end_char="798">unprecedented</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="800" end_char="808">situation</TOKEN>
<TOKEN id="token-6-21" pos="punct" morph="none" start_char="809" end_char="809">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="812" end_char="835">
<ORIGINAL_TEXT>Updated December 1, 2020</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="812" end_char="818">Updated</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="820" end_char="827">December</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="829" end_char="829">1</TOKEN>
<TOKEN id="token-7-3" pos="punct" morph="none" start_char="830" end_char="830">,</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="832" end_char="835">2020</TOKEN>
</SEG>
<SEG id="segment-8" start_char="839" end_char="994">
<ORIGINAL_TEXT>NO, the Institut Pasteur did not create the SARS-CoV-2 virus and release it in the city of Wuhan to cause the pandemic and implicate the Chinese authorities</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="839" end_char="840">NO</TOKEN>
<TOKEN id="token-8-1" pos="punct" morph="none" start_char="841" end_char="841">,</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="843" end_char="845">the</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="847" end_char="854">Institut</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="856" end_char="862">Pasteur</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="864" end_char="866">did</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="868" end_char="870">not</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="872" end_char="877">create</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="879" end_char="881">the</TOKEN>
<TOKEN id="token-8-9" pos="unknown" morph="none" start_char="883" end_char="892">SARS-CoV-2</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="894" end_char="898">virus</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="900" end_char="902">and</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="904" end_char="910">release</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="912" end_char="913">it</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="915" end_char="916">in</TOKEN>
<TOKEN id="token-8-15" pos="word" morph="none" start_char="918" end_char="920">the</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="922" end_char="925">city</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="927" end_char="928">of</TOKEN>
<TOKEN id="token-8-18" pos="word" morph="none" start_char="930" end_char="934">Wuhan</TOKEN>
<TOKEN id="token-8-19" pos="word" morph="none" start_char="936" end_char="937">to</TOKEN>
<TOKEN id="token-8-20" pos="word" morph="none" start_char="939" end_char="943">cause</TOKEN>
<TOKEN id="token-8-21" pos="word" morph="none" start_char="945" end_char="947">the</TOKEN>
<TOKEN id="token-8-22" pos="word" morph="none" start_char="949" end_char="956">pandemic</TOKEN>
<TOKEN id="token-8-23" pos="word" morph="none" start_char="958" end_char="960">and</TOKEN>
<TOKEN id="token-8-24" pos="word" morph="none" start_char="962" end_char="970">implicate</TOKEN>
<TOKEN id="token-8-25" pos="word" morph="none" start_char="972" end_char="974">the</TOKEN>
<TOKEN id="token-8-26" pos="word" morph="none" start_char="976" end_char="982">Chinese</TOKEN>
<TOKEN id="token-8-27" pos="word" morph="none" start_char="984" end_char="994">authorities</TOKEN>
</SEG>
<SEG id="segment-9" start_char="997" end_char="1021">
<ORIGINAL_TEXT>Text of October 22, 2020.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="997" end_char="1000">Text</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1002" end_char="1003">of</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1005" end_char="1011">October</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1013" end_char="1014">22</TOKEN>
<TOKEN id="token-9-4" pos="punct" morph="none" start_char="1015" end_char="1015">,</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1017" end_char="1020">2020</TOKEN>
<TOKEN id="token-9-6" pos="punct" morph="none" start_char="1021" end_char="1021">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1024" end_char="1047">
<ORIGINAL_TEXT>Updated December 1, 2020</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1024" end_char="1030">Updated</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1032" end_char="1039">December</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1041" end_char="1041">1</TOKEN>
<TOKEN id="token-10-3" pos="punct" morph="none" start_char="1042" end_char="1042">,</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1044" end_char="1047">2020</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1050" end_char="1050">
<ORIGINAL_TEXT>.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="punct" morph="none" start_char="1050" end_char="1050">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1054" end_char="1241">
<ORIGINAL_TEXT>After a first defamatory video in March 2020, new videos have been circulating online since late August 2020 claiming to trace the supposedly premeditated history of the COVID-19 pandemic.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1054" end_char="1058">After</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1060" end_char="1060">a</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1062" end_char="1066">first</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1068" end_char="1077">defamatory</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1079" end_char="1083">video</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1085" end_char="1086">in</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1088" end_char="1092">March</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1094" end_char="1097">2020</TOKEN>
<TOKEN id="token-12-8" pos="punct" morph="none" start_char="1098" end_char="1098">,</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1100" end_char="1102">new</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1104" end_char="1109">videos</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1111" end_char="1114">have</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1116" end_char="1119">been</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1121" end_char="1131">circulating</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1133" end_char="1138">online</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1140" end_char="1144">since</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1146" end_char="1149">late</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1151" end_char="1156">August</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1158" end_char="1161">2020</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="1163" end_char="1170">claiming</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="1172" end_char="1173">to</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="1175" end_char="1179">trace</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="1181" end_char="1183">the</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="1185" end_char="1194">supposedly</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="1196" end_char="1207">premeditated</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="1209" end_char="1215">history</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="1217" end_char="1218">of</TOKEN>
<TOKEN id="token-12-27" pos="word" morph="none" start_char="1220" end_char="1222">the</TOKEN>
<TOKEN id="token-12-28" pos="unknown" morph="none" start_char="1224" end_char="1231">COVID-19</TOKEN>
<TOKEN id="token-12-29" pos="word" morph="none" start_char="1233" end_char="1240">pandemic</TOKEN>
<TOKEN id="token-12-30" pos="punct" morph="none" start_char="1241" end_char="1241">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1243" end_char="1323">
<ORIGINAL_TEXT>The information contained in these videos is pure conspiracy and of course false.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1243" end_char="1245">The</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1247" end_char="1257">information</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1259" end_char="1267">contained</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1269" end_char="1270">in</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1272" end_char="1276">these</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1278" end_char="1283">videos</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1285" end_char="1286">is</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1288" end_char="1291">pure</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1293" end_char="1302">conspiracy</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1304" end_char="1306">and</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1308" end_char="1309">of</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1311" end_char="1316">course</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1318" end_char="1322">false</TOKEN>
<TOKEN id="token-13-13" pos="punct" morph="none" start_char="1323" end_char="1323">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1327" end_char="1393">
<ORIGINAL_TEXT>The SARS-CoV-2 coronavirus was not created by the Institut Pasteur.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1327" end_char="1329">The</TOKEN>
<TOKEN id="token-14-1" pos="unknown" morph="none" start_char="1331" end_char="1340">SARS-CoV-2</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1342" end_char="1352">coronavirus</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1354" end_char="1356">was</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1358" end_char="1360">not</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1362" end_char="1368">created</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1370" end_char="1371">by</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1373" end_char="1375">the</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1377" end_char="1384">Institut</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1386" end_char="1392">Pasteur</TOKEN>
<TOKEN id="token-14-10" pos="punct" morph="none" start_char="1393" end_char="1393">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1399" end_char="1477">
<ORIGINAL_TEXT>The Institut Pasteur did not release any viruses in the city of Wuhan in China!</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1399" end_char="1401">The</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1403" end_char="1410">Institut</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1412" end_char="1418">Pasteur</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1420" end_char="1422">did</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1424" end_char="1426">not</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1428" end_char="1434">release</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1436" end_char="1438">any</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1440" end_char="1446">viruses</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1448" end_char="1449">in</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1451" end_char="1453">the</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="1455" end_char="1458">city</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1460" end_char="1461">of</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="1463" end_char="1467">Wuhan</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="1469" end_char="1470">in</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="1472" end_char="1476">China</TOKEN>
<TOKEN id="token-15-15" pos="punct" morph="none" start_char="1477" end_char="1477">!</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1483" end_char="1645">
<ORIGINAL_TEXT>The Institut Pasteur is not a laboratory belonging to the Sanofi pharmaceutical group or its subsidiary Sanofi-Pasteur; it is an independent non-profit foundation.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1483" end_char="1485">The</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1487" end_char="1494">Institut</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1496" end_char="1502">Pasteur</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1504" end_char="1505">is</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="1507" end_char="1509">not</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="1511" end_char="1511">a</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="1513" end_char="1522">laboratory</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="1524" end_char="1532">belonging</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="1534" end_char="1535">to</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="1537" end_char="1539">the</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="1541" end_char="1546">Sanofi</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="1548" end_char="1561">pharmaceutical</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="1563" end_char="1567">group</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="1569" end_char="1570">or</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="1572" end_char="1574">its</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="1576" end_char="1585">subsidiary</TOKEN>
<TOKEN id="token-16-16" pos="unknown" morph="none" start_char="1587" end_char="1600">Sanofi-Pasteur</TOKEN>
<TOKEN id="token-16-17" pos="punct" morph="none" start_char="1601" end_char="1601">;</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="1603" end_char="1604">it</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="1606" end_char="1607">is</TOKEN>
<TOKEN id="token-16-20" pos="word" morph="none" start_char="1609" end_char="1610">an</TOKEN>
<TOKEN id="token-16-21" pos="word" morph="none" start_char="1612" end_char="1622">independent</TOKEN>
<TOKEN id="token-16-22" pos="unknown" morph="none" start_char="1624" end_char="1633">non-profit</TOKEN>
<TOKEN id="token-16-23" pos="word" morph="none" start_char="1635" end_char="1644">foundation</TOKEN>
<TOKEN id="token-16-24" pos="punct" morph="none" start_char="1645" end_char="1645">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1651" end_char="1789">
<ORIGINAL_TEXT>Asserting that the Institut Pasteur is planning to enslave and control the global population is utterly false and devoid of all foundation.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1651" end_char="1659">Asserting</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="1661" end_char="1664">that</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="1666" end_char="1668">the</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="1670" end_char="1677">Institut</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="1679" end_char="1685">Pasteur</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="1687" end_char="1688">is</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="1690" end_char="1697">planning</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="1699" end_char="1700">to</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="1702" end_char="1708">enslave</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="1710" end_char="1712">and</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="1714" end_char="1720">control</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="1722" end_char="1724">the</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="1726" end_char="1731">global</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="1733" end_char="1742">population</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="1744" end_char="1745">is</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="1747" end_char="1753">utterly</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="1755" end_char="1759">false</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="1761" end_char="1763">and</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="1765" end_char="1770">devoid</TOKEN>
<TOKEN id="token-17-19" pos="word" morph="none" start_char="1772" end_char="1773">of</TOKEN>
<TOKEN id="token-17-20" pos="word" morph="none" start_char="1775" end_char="1777">all</TOKEN>
<TOKEN id="token-17-21" pos="word" morph="none" start_char="1779" end_char="1788">foundation</TOKEN>
<TOKEN id="token-17-22" pos="punct" morph="none" start_char="1789" end_char="1789">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="1795" end_char="1922">
<ORIGINAL_TEXT>In response to these defamatory claims, and for the first time since its inception, the Institut Pasteur has lodged a complaint.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="1795" end_char="1796">In</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="1798" end_char="1805">response</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="1807" end_char="1808">to</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="1810" end_char="1814">these</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="1816" end_char="1825">defamatory</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="1827" end_char="1832">claims</TOKEN>
<TOKEN id="token-18-6" pos="punct" morph="none" start_char="1833" end_char="1833">,</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="1835" end_char="1837">and</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="1839" end_char="1841">for</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="1843" end_char="1845">the</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="1847" end_char="1851">first</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="1853" end_char="1856">time</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="1858" end_char="1862">since</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="1864" end_char="1866">its</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="1868" end_char="1876">inception</TOKEN>
<TOKEN id="token-18-15" pos="punct" morph="none" start_char="1877" end_char="1877">,</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="1879" end_char="1881">the</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="1883" end_char="1890">Institut</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="1892" end_char="1898">Pasteur</TOKEN>
<TOKEN id="token-18-19" pos="word" morph="none" start_char="1900" end_char="1902">has</TOKEN>
<TOKEN id="token-18-20" pos="word" morph="none" start_char="1904" end_char="1909">lodged</TOKEN>
<TOKEN id="token-18-21" pos="word" morph="none" start_char="1911" end_char="1911">a</TOKEN>
<TOKEN id="token-18-22" pos="word" morph="none" start_char="1913" end_char="1921">complaint</TOKEN>
<TOKEN id="token-18-23" pos="punct" morph="none" start_char="1922" end_char="1922">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="1928" end_char="1939">
<ORIGINAL_TEXT>Explications</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="1928" end_char="1939">Explications</TOKEN>
</SEG>
<SEG id="segment-20" start_char="1943" end_char="2035">
<ORIGINAL_TEXT>1 _ The Institut Pasteur did not invent Covid-19 or the virus responsible for it, SARS-CoV-2!</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="1943" end_char="1943">1</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="1945" end_char="1945">_</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="1947" end_char="1949">The</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="1951" end_char="1958">Institut</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="1960" end_char="1966">Pasteur</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="1968" end_char="1970">did</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="1972" end_char="1974">not</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="1976" end_char="1981">invent</TOKEN>
<TOKEN id="token-20-8" pos="unknown" morph="none" start_char="1983" end_char="1990">Covid-19</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="1992" end_char="1993">or</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="1995" end_char="1997">the</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="1999" end_char="2003">virus</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="2005" end_char="2015">responsible</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="2017" end_char="2019">for</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="2021" end_char="2022">it</TOKEN>
<TOKEN id="token-20-15" pos="punct" morph="none" start_char="2023" end_char="2023">,</TOKEN>
<TOKEN id="token-20-16" pos="unknown" morph="none" start_char="2025" end_char="2034">SARS-CoV-2</TOKEN>
<TOKEN id="token-20-17" pos="punct" morph="none" start_char="2035" end_char="2035">!</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2039" end_char="2170">
<ORIGINAL_TEXT>A scientific paper published on March 17, 2020 refutes the theory that a creation by a laboratory may be behind this emerging virus.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2039" end_char="2039">A</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2041" end_char="2050">scientific</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="2052" end_char="2056">paper</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="2058" end_char="2066">published</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="2068" end_char="2069">on</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="2071" end_char="2075">March</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="2077" end_char="2078">17</TOKEN>
<TOKEN id="token-21-7" pos="punct" morph="none" start_char="2079" end_char="2079">,</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="2081" end_char="2084">2020</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="2086" end_char="2092">refutes</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="2094" end_char="2096">the</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="2098" end_char="2103">theory</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="2105" end_char="2108">that</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="2110" end_char="2110">a</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="2112" end_char="2119">creation</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="2121" end_char="2122">by</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="2124" end_char="2124">a</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="2126" end_char="2135">laboratory</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="2137" end_char="2139">may</TOKEN>
<TOKEN id="token-21-19" pos="word" morph="none" start_char="2141" end_char="2142">be</TOKEN>
<TOKEN id="token-21-20" pos="word" morph="none" start_char="2144" end_char="2149">behind</TOKEN>
<TOKEN id="token-21-21" pos="word" morph="none" start_char="2151" end_char="2154">this</TOKEN>
<TOKEN id="token-21-22" pos="word" morph="none" start_char="2156" end_char="2163">emerging</TOKEN>
<TOKEN id="token-21-23" pos="word" morph="none" start_char="2165" end_char="2169">virus</TOKEN>
<TOKEN id="token-21-24" pos="punct" morph="none" start_char="2170" end_char="2170">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2173" end_char="2255">
<ORIGINAL_TEXT>See below "There is no evidence that SARS-CoV-2 coronavirus was created by humans".</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2173" end_char="2175">See</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="2177" end_char="2181">below</TOKEN>
<TOKEN id="token-22-2" pos="punct" morph="none" start_char="2183" end_char="2183">"</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="2184" end_char="2188">There</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="2190" end_char="2191">is</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="2193" end_char="2194">no</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="2196" end_char="2203">evidence</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="2205" end_char="2208">that</TOKEN>
<TOKEN id="token-22-8" pos="unknown" morph="none" start_char="2210" end_char="2219">SARS-CoV-2</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="2221" end_char="2231">coronavirus</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="2233" end_char="2235">was</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="2237" end_char="2243">created</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="2245" end_char="2246">by</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="2248" end_char="2253">humans</TOKEN>
<TOKEN id="token-22-14" pos="punct" morph="none" start_char="2254" end_char="2255">".</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2258" end_char="2447">
<ORIGINAL_TEXT>We would remind you that the SARS-CoV-2 coronavirus, responsible for the current Covid-19 pandemic, is different from the SARS-CoV-1 virus that caused an outbreak in South-East Asia in 2003.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2258" end_char="2259">We</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="2261" end_char="2265">would</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="2267" end_char="2272">remind</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="2274" end_char="2276">you</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="2278" end_char="2281">that</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="2283" end_char="2285">the</TOKEN>
<TOKEN id="token-23-6" pos="unknown" morph="none" start_char="2287" end_char="2296">SARS-CoV-2</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="2298" end_char="2308">coronavirus</TOKEN>
<TOKEN id="token-23-8" pos="punct" morph="none" start_char="2309" end_char="2309">,</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="2311" end_char="2321">responsible</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="2323" end_char="2325">for</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="2327" end_char="2329">the</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="2331" end_char="2337">current</TOKEN>
<TOKEN id="token-23-13" pos="unknown" morph="none" start_char="2339" end_char="2346">Covid-19</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="2348" end_char="2355">pandemic</TOKEN>
<TOKEN id="token-23-15" pos="punct" morph="none" start_char="2356" end_char="2356">,</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="2358" end_char="2359">is</TOKEN>
<TOKEN id="token-23-17" pos="word" morph="none" start_char="2361" end_char="2369">different</TOKEN>
<TOKEN id="token-23-18" pos="word" morph="none" start_char="2371" end_char="2374">from</TOKEN>
<TOKEN id="token-23-19" pos="word" morph="none" start_char="2376" end_char="2378">the</TOKEN>
<TOKEN id="token-23-20" pos="unknown" morph="none" start_char="2380" end_char="2389">SARS-CoV-1</TOKEN>
<TOKEN id="token-23-21" pos="word" morph="none" start_char="2391" end_char="2395">virus</TOKEN>
<TOKEN id="token-23-22" pos="word" morph="none" start_char="2397" end_char="2400">that</TOKEN>
<TOKEN id="token-23-23" pos="word" morph="none" start_char="2402" end_char="2407">caused</TOKEN>
<TOKEN id="token-23-24" pos="word" morph="none" start_char="2409" end_char="2410">an</TOKEN>
<TOKEN id="token-23-25" pos="word" morph="none" start_char="2412" end_char="2419">outbreak</TOKEN>
<TOKEN id="token-23-26" pos="word" morph="none" start_char="2421" end_char="2422">in</TOKEN>
<TOKEN id="token-23-27" pos="unknown" morph="none" start_char="2424" end_char="2433">South-East</TOKEN>
<TOKEN id="token-23-28" pos="word" morph="none" start_char="2435" end_char="2438">Asia</TOKEN>
<TOKEN id="token-23-29" pos="word" morph="none" start_char="2440" end_char="2441">in</TOKEN>
<TOKEN id="token-23-30" pos="word" morph="none" start_char="2443" end_char="2446">2003</TOKEN>
<TOKEN id="token-23-31" pos="punct" morph="none" start_char="2447" end_char="2447">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="2449" end_char="2648">
<ORIGINAL_TEXT>It is scientifically false to say that they are genetically identical in every way or that the only difference in their sequence lies in a few elements allegedly derived from the HIV genome sequence..</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="2449" end_char="2450">It</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="2452" end_char="2453">is</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="2455" end_char="2468">scientifically</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="2470" end_char="2474">false</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="2476" end_char="2477">to</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="2479" end_char="2481">say</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="2483" end_char="2486">that</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="2488" end_char="2491">they</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="2493" end_char="2495">are</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="2497" end_char="2507">genetically</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="2509" end_char="2517">identical</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="2519" end_char="2520">in</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="2522" end_char="2526">every</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="2528" end_char="2530">way</TOKEN>
<TOKEN id="token-24-14" pos="word" morph="none" start_char="2532" end_char="2533">or</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="2535" end_char="2538">that</TOKEN>
<TOKEN id="token-24-16" pos="word" morph="none" start_char="2540" end_char="2542">the</TOKEN>
<TOKEN id="token-24-17" pos="word" morph="none" start_char="2544" end_char="2547">only</TOKEN>
<TOKEN id="token-24-18" pos="word" morph="none" start_char="2549" end_char="2558">difference</TOKEN>
<TOKEN id="token-24-19" pos="word" morph="none" start_char="2560" end_char="2561">in</TOKEN>
<TOKEN id="token-24-20" pos="word" morph="none" start_char="2563" end_char="2567">their</TOKEN>
<TOKEN id="token-24-21" pos="word" morph="none" start_char="2569" end_char="2576">sequence</TOKEN>
<TOKEN id="token-24-22" pos="word" morph="none" start_char="2578" end_char="2581">lies</TOKEN>
<TOKEN id="token-24-23" pos="word" morph="none" start_char="2583" end_char="2584">in</TOKEN>
<TOKEN id="token-24-24" pos="word" morph="none" start_char="2586" end_char="2586">a</TOKEN>
<TOKEN id="token-24-25" pos="word" morph="none" start_char="2588" end_char="2590">few</TOKEN>
<TOKEN id="token-24-26" pos="word" morph="none" start_char="2592" end_char="2599">elements</TOKEN>
<TOKEN id="token-24-27" pos="word" morph="none" start_char="2601" end_char="2609">allegedly</TOKEN>
<TOKEN id="token-24-28" pos="word" morph="none" start_char="2611" end_char="2617">derived</TOKEN>
<TOKEN id="token-24-29" pos="word" morph="none" start_char="2619" end_char="2622">from</TOKEN>
<TOKEN id="token-24-30" pos="word" morph="none" start_char="2624" end_char="2626">the</TOKEN>
<TOKEN id="token-24-31" pos="word" morph="none" start_char="2628" end_char="2630">HIV</TOKEN>
<TOKEN id="token-24-32" pos="word" morph="none" start_char="2632" end_char="2637">genome</TOKEN>
<TOKEN id="token-24-33" pos="word" morph="none" start_char="2639" end_char="2646">sequence</TOKEN>
<TOKEN id="token-24-34" pos="punct" morph="none" start_char="2647" end_char="2648">..</TOKEN>
</SEG>
<SEG id="segment-25" start_char="2651" end_char="2802">
<ORIGINAL_TEXT>These two viruses, SARS-CoV-1 and SARS-CoV-2, do both belong to the coronavirus family (which also includes other viruses) but are two separate viruses.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="2651" end_char="2655">These</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="2657" end_char="2659">two</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="2661" end_char="2667">viruses</TOKEN>
<TOKEN id="token-25-3" pos="punct" morph="none" start_char="2668" end_char="2668">,</TOKEN>
<TOKEN id="token-25-4" pos="unknown" morph="none" start_char="2670" end_char="2679">SARS-CoV-1</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="2681" end_char="2683">and</TOKEN>
<TOKEN id="token-25-6" pos="unknown" morph="none" start_char="2685" end_char="2694">SARS-CoV-2</TOKEN>
<TOKEN id="token-25-7" pos="punct" morph="none" start_char="2695" end_char="2695">,</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="2697" end_char="2698">do</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="2700" end_char="2703">both</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="2705" end_char="2710">belong</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="2712" end_char="2713">to</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="2715" end_char="2717">the</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="2719" end_char="2729">coronavirus</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="2731" end_char="2736">family</TOKEN>
<TOKEN id="token-25-15" pos="punct" morph="none" start_char="2738" end_char="2738">(</TOKEN>
<TOKEN id="token-25-16" pos="word" morph="none" start_char="2739" end_char="2743">which</TOKEN>
<TOKEN id="token-25-17" pos="word" morph="none" start_char="2745" end_char="2748">also</TOKEN>
<TOKEN id="token-25-18" pos="word" morph="none" start_char="2750" end_char="2757">includes</TOKEN>
<TOKEN id="token-25-19" pos="word" morph="none" start_char="2759" end_char="2763">other</TOKEN>
<TOKEN id="token-25-20" pos="word" morph="none" start_char="2765" end_char="2771">viruses</TOKEN>
<TOKEN id="token-25-21" pos="punct" morph="none" start_char="2772" end_char="2772">)</TOKEN>
<TOKEN id="token-25-22" pos="word" morph="none" start_char="2774" end_char="2776">but</TOKEN>
<TOKEN id="token-25-23" pos="word" morph="none" start_char="2778" end_char="2780">are</TOKEN>
<TOKEN id="token-25-24" pos="word" morph="none" start_char="2782" end_char="2784">two</TOKEN>
<TOKEN id="token-25-25" pos="word" morph="none" start_char="2786" end_char="2793">separate</TOKEN>
<TOKEN id="token-25-26" pos="word" morph="none" start_char="2795" end_char="2801">viruses</TOKEN>
<TOKEN id="token-25-27" pos="punct" morph="none" start_char="2802" end_char="2802">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="2805" end_char="2982">
<ORIGINAL_TEXT>The Institut Pasteur did not invent any viruses (neither SARS-CoV-2 nor SARS-CoV-1) but, in 2004, did invent a vaccine candidate for the previous coronavirus known as SARS-CoV-1.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="2805" end_char="2807">The</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="2809" end_char="2816">Institut</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="2818" end_char="2824">Pasteur</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="2826" end_char="2828">did</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="2830" end_char="2832">not</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="2834" end_char="2839">invent</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="2841" end_char="2843">any</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="2845" end_char="2851">viruses</TOKEN>
<TOKEN id="token-26-8" pos="punct" morph="none" start_char="2853" end_char="2853">(</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="2854" end_char="2860">neither</TOKEN>
<TOKEN id="token-26-10" pos="unknown" morph="none" start_char="2862" end_char="2871">SARS-CoV-2</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="2873" end_char="2875">nor</TOKEN>
<TOKEN id="token-26-12" pos="unknown" morph="none" start_char="2877" end_char="2886">SARS-CoV-1</TOKEN>
<TOKEN id="token-26-13" pos="punct" morph="none" start_char="2887" end_char="2887">)</TOKEN>
<TOKEN id="token-26-14" pos="word" morph="none" start_char="2889" end_char="2891">but</TOKEN>
<TOKEN id="token-26-15" pos="punct" morph="none" start_char="2892" end_char="2892">,</TOKEN>
<TOKEN id="token-26-16" pos="word" morph="none" start_char="2894" end_char="2895">in</TOKEN>
<TOKEN id="token-26-17" pos="word" morph="none" start_char="2897" end_char="2900">2004</TOKEN>
<TOKEN id="token-26-18" pos="punct" morph="none" start_char="2901" end_char="2901">,</TOKEN>
<TOKEN id="token-26-19" pos="word" morph="none" start_char="2903" end_char="2905">did</TOKEN>
<TOKEN id="token-26-20" pos="word" morph="none" start_char="2907" end_char="2912">invent</TOKEN>
<TOKEN id="token-26-21" pos="word" morph="none" start_char="2914" end_char="2914">a</TOKEN>
<TOKEN id="token-26-22" pos="word" morph="none" start_char="2916" end_char="2922">vaccine</TOKEN>
<TOKEN id="token-26-23" pos="word" morph="none" start_char="2924" end_char="2932">candidate</TOKEN>
<TOKEN id="token-26-24" pos="word" morph="none" start_char="2934" end_char="2936">for</TOKEN>
<TOKEN id="token-26-25" pos="word" morph="none" start_char="2938" end_char="2940">the</TOKEN>
<TOKEN id="token-26-26" pos="word" morph="none" start_char="2942" end_char="2949">previous</TOKEN>
<TOKEN id="token-26-27" pos="word" morph="none" start_char="2951" end_char="2961">coronavirus</TOKEN>
<TOKEN id="token-26-28" pos="word" morph="none" start_char="2963" end_char="2967">known</TOKEN>
<TOKEN id="token-26-29" pos="word" morph="none" start_char="2969" end_char="2970">as</TOKEN>
<TOKEN id="token-26-30" pos="unknown" morph="none" start_char="2972" end_char="2981">SARS-CoV-1</TOKEN>
<TOKEN id="token-26-31" pos="punct" morph="none" start_char="2982" end_char="2982">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="2985" end_char="3085">
<ORIGINAL_TEXT>See below "The Institut Pasteur did not invent Covid-19 or the virus responsible for it, SARS-CoV-2!"</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="2985" end_char="2987">See</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="2989" end_char="2993">below</TOKEN>
<TOKEN id="token-27-2" pos="punct" morph="none" start_char="2995" end_char="2995">"</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="2996" end_char="2998">The</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="3000" end_char="3007">Institut</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="3009" end_char="3015">Pasteur</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="3017" end_char="3019">did</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="3021" end_char="3023">not</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="3025" end_char="3030">invent</TOKEN>
<TOKEN id="token-27-9" pos="unknown" morph="none" start_char="3032" end_char="3039">Covid-19</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="3041" end_char="3042">or</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="3044" end_char="3046">the</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="3048" end_char="3052">virus</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="3054" end_char="3064">responsible</TOKEN>
<TOKEN id="token-27-14" pos="word" morph="none" start_char="3066" end_char="3068">for</TOKEN>
<TOKEN id="token-27-15" pos="word" morph="none" start_char="3070" end_char="3071">it</TOKEN>
<TOKEN id="token-27-16" pos="punct" morph="none" start_char="3072" end_char="3072">,</TOKEN>
<TOKEN id="token-27-17" pos="unknown" morph="none" start_char="3074" end_char="3083">SARS-CoV-2</TOKEN>
<TOKEN id="token-27-18" pos="punct" morph="none" start_char="3084" end_char="3085">!"</TOKEN>
</SEG>
<SEG id="segment-28" start_char="3088" end_char="3345">
<ORIGINAL_TEXT>This vaccine candidate for SARS-CoV-1 was the subject of a patent application filed in 2004, which mentions a particular strain of the SARS-CoV-1 virus, which was itself discovered and described in March 2003, i.e. several months before the patent was filed.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="3088" end_char="3091">This</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="3093" end_char="3099">vaccine</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="3101" end_char="3109">candidate</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="3111" end_char="3113">for</TOKEN>
<TOKEN id="token-28-4" pos="unknown" morph="none" start_char="3115" end_char="3124">SARS-CoV-1</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="3126" end_char="3128">was</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="3130" end_char="3132">the</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="3134" end_char="3140">subject</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="3142" end_char="3143">of</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="3145" end_char="3145">a</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="3147" end_char="3152">patent</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="3154" end_char="3164">application</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="3166" end_char="3170">filed</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="3172" end_char="3173">in</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="3175" end_char="3178">2004</TOKEN>
<TOKEN id="token-28-15" pos="punct" morph="none" start_char="3179" end_char="3179">,</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="3181" end_char="3185">which</TOKEN>
<TOKEN id="token-28-17" pos="word" morph="none" start_char="3187" end_char="3194">mentions</TOKEN>
<TOKEN id="token-28-18" pos="word" morph="none" start_char="3196" end_char="3196">a</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="3198" end_char="3207">particular</TOKEN>
<TOKEN id="token-28-20" pos="word" morph="none" start_char="3209" end_char="3214">strain</TOKEN>
<TOKEN id="token-28-21" pos="word" morph="none" start_char="3216" end_char="3217">of</TOKEN>
<TOKEN id="token-28-22" pos="word" morph="none" start_char="3219" end_char="3221">the</TOKEN>
<TOKEN id="token-28-23" pos="unknown" morph="none" start_char="3223" end_char="3232">SARS-CoV-1</TOKEN>
<TOKEN id="token-28-24" pos="word" morph="none" start_char="3234" end_char="3238">virus</TOKEN>
<TOKEN id="token-28-25" pos="punct" morph="none" start_char="3239" end_char="3239">,</TOKEN>
<TOKEN id="token-28-26" pos="word" morph="none" start_char="3241" end_char="3245">which</TOKEN>
<TOKEN id="token-28-27" pos="word" morph="none" start_char="3247" end_char="3249">was</TOKEN>
<TOKEN id="token-28-28" pos="word" morph="none" start_char="3251" end_char="3256">itself</TOKEN>
<TOKEN id="token-28-29" pos="word" morph="none" start_char="3258" end_char="3267">discovered</TOKEN>
<TOKEN id="token-28-30" pos="word" morph="none" start_char="3269" end_char="3271">and</TOKEN>
<TOKEN id="token-28-31" pos="word" morph="none" start_char="3273" end_char="3281">described</TOKEN>
<TOKEN id="token-28-32" pos="word" morph="none" start_char="3283" end_char="3284">in</TOKEN>
<TOKEN id="token-28-33" pos="word" morph="none" start_char="3286" end_char="3290">March</TOKEN>
<TOKEN id="token-28-34" pos="word" morph="none" start_char="3292" end_char="3295">2003</TOKEN>
<TOKEN id="token-28-35" pos="punct" morph="none" start_char="3296" end_char="3296">,</TOKEN>
<TOKEN id="token-28-36" pos="unknown" morph="none" start_char="3298" end_char="3300">i.e</TOKEN>
<TOKEN id="token-28-37" pos="punct" morph="none" start_char="3301" end_char="3301">.</TOKEN>
<TOKEN id="token-28-38" pos="word" morph="none" start_char="3303" end_char="3309">several</TOKEN>
<TOKEN id="token-28-39" pos="word" morph="none" start_char="3311" end_char="3316">months</TOKEN>
<TOKEN id="token-28-40" pos="word" morph="none" start_char="3318" end_char="3323">before</TOKEN>
<TOKEN id="token-28-41" pos="word" morph="none" start_char="3325" end_char="3327">the</TOKEN>
<TOKEN id="token-28-42" pos="word" morph="none" start_char="3329" end_char="3334">patent</TOKEN>
<TOKEN id="token-28-43" pos="word" morph="none" start_char="3336" end_char="3338">was</TOKEN>
<TOKEN id="token-28-44" pos="word" morph="none" start_char="3340" end_char="3344">filed</TOKEN>
<TOKEN id="token-28-45" pos="punct" morph="none" start_char="3345" end_char="3345">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="3347" end_char="3601">
<ORIGINAL_TEXT>At the time, the Institut Pasteur proposed several strategies that could enable development of a vaccine (those described in the patent), which included a vaccine based on the virus used in the measles vaccine and another one based on a lentiviral vector.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="3347" end_char="3348">At</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="3350" end_char="3352">the</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="3354" end_char="3357">time</TOKEN>
<TOKEN id="token-29-3" pos="punct" morph="none" start_char="3358" end_char="3358">,</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="3360" end_char="3362">the</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="3364" end_char="3371">Institut</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="3373" end_char="3379">Pasteur</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="3381" end_char="3388">proposed</TOKEN>
<TOKEN id="token-29-8" pos="word" morph="none" start_char="3390" end_char="3396">several</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="3398" end_char="3407">strategies</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="3409" end_char="3412">that</TOKEN>
<TOKEN id="token-29-11" pos="word" morph="none" start_char="3414" end_char="3418">could</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="3420" end_char="3425">enable</TOKEN>
<TOKEN id="token-29-13" pos="word" morph="none" start_char="3427" end_char="3437">development</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="3439" end_char="3440">of</TOKEN>
<TOKEN id="token-29-15" pos="word" morph="none" start_char="3442" end_char="3442">a</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="3444" end_char="3450">vaccine</TOKEN>
<TOKEN id="token-29-17" pos="punct" morph="none" start_char="3452" end_char="3452">(</TOKEN>
<TOKEN id="token-29-18" pos="word" morph="none" start_char="3453" end_char="3457">those</TOKEN>
<TOKEN id="token-29-19" pos="word" morph="none" start_char="3459" end_char="3467">described</TOKEN>
<TOKEN id="token-29-20" pos="word" morph="none" start_char="3469" end_char="3470">in</TOKEN>
<TOKEN id="token-29-21" pos="word" morph="none" start_char="3472" end_char="3474">the</TOKEN>
<TOKEN id="token-29-22" pos="word" morph="none" start_char="3476" end_char="3481">patent</TOKEN>
<TOKEN id="token-29-23" pos="punct" morph="none" start_char="3482" end_char="3483">),</TOKEN>
<TOKEN id="token-29-24" pos="word" morph="none" start_char="3485" end_char="3489">which</TOKEN>
<TOKEN id="token-29-25" pos="word" morph="none" start_char="3491" end_char="3498">included</TOKEN>
<TOKEN id="token-29-26" pos="word" morph="none" start_char="3500" end_char="3500">a</TOKEN>
<TOKEN id="token-29-27" pos="word" morph="none" start_char="3502" end_char="3508">vaccine</TOKEN>
<TOKEN id="token-29-28" pos="word" morph="none" start_char="3510" end_char="3514">based</TOKEN>
<TOKEN id="token-29-29" pos="word" morph="none" start_char="3516" end_char="3517">on</TOKEN>
<TOKEN id="token-29-30" pos="word" morph="none" start_char="3519" end_char="3521">the</TOKEN>
<TOKEN id="token-29-31" pos="word" morph="none" start_char="3523" end_char="3527">virus</TOKEN>
<TOKEN id="token-29-32" pos="word" morph="none" start_char="3529" end_char="3532">used</TOKEN>
<TOKEN id="token-29-33" pos="word" morph="none" start_char="3534" end_char="3535">in</TOKEN>
<TOKEN id="token-29-34" pos="word" morph="none" start_char="3537" end_char="3539">the</TOKEN>
<TOKEN id="token-29-35" pos="word" morph="none" start_char="3541" end_char="3547">measles</TOKEN>
<TOKEN id="token-29-36" pos="word" morph="none" start_char="3549" end_char="3555">vaccine</TOKEN>
<TOKEN id="token-29-37" pos="word" morph="none" start_char="3557" end_char="3559">and</TOKEN>
<TOKEN id="token-29-38" pos="word" morph="none" start_char="3561" end_char="3567">another</TOKEN>
<TOKEN id="token-29-39" pos="word" morph="none" start_char="3569" end_char="3571">one</TOKEN>
<TOKEN id="token-29-40" pos="word" morph="none" start_char="3573" end_char="3577">based</TOKEN>
<TOKEN id="token-29-41" pos="word" morph="none" start_char="3579" end_char="3580">on</TOKEN>
<TOKEN id="token-29-42" pos="word" morph="none" start_char="3582" end_char="3582">a</TOKEN>
<TOKEN id="token-29-43" pos="word" morph="none" start_char="3584" end_char="3593">lentiviral</TOKEN>
<TOKEN id="token-29-44" pos="word" morph="none" start_char="3595" end_char="3600">vector</TOKEN>
<TOKEN id="token-29-45" pos="punct" morph="none" start_char="3601" end_char="3601">.</TOKEN>
</SEG>
<SEG id="segment-30" start_char="3603" end_char="3906">
<ORIGINAL_TEXT>These two scientific approaches to develop a vaccine candidate, proposed for the SARS-CoV-1 virus at the time, are today the subject of new research to tackle the SARS-CoV-2 virus and the Covid-19 pandemic (new avenues measles vector-based SARS-CoV-2 vaccine; lentiviral vector-based SARS-CoV-2 vaccine).</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="3603" end_char="3607">These</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="3609" end_char="3611">two</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="3613" end_char="3622">scientific</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="3624" end_char="3633">approaches</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="3635" end_char="3636">to</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="3638" end_char="3644">develop</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="3646" end_char="3646">a</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="3648" end_char="3654">vaccine</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="3656" end_char="3664">candidate</TOKEN>
<TOKEN id="token-30-9" pos="punct" morph="none" start_char="3665" end_char="3665">,</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="3667" end_char="3674">proposed</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="3676" end_char="3678">for</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="3680" end_char="3682">the</TOKEN>
<TOKEN id="token-30-13" pos="unknown" morph="none" start_char="3684" end_char="3693">SARS-CoV-1</TOKEN>
<TOKEN id="token-30-14" pos="word" morph="none" start_char="3695" end_char="3699">virus</TOKEN>
<TOKEN id="token-30-15" pos="word" morph="none" start_char="3701" end_char="3702">at</TOKEN>
<TOKEN id="token-30-16" pos="word" morph="none" start_char="3704" end_char="3706">the</TOKEN>
<TOKEN id="token-30-17" pos="word" morph="none" start_char="3708" end_char="3711">time</TOKEN>
<TOKEN id="token-30-18" pos="punct" morph="none" start_char="3712" end_char="3712">,</TOKEN>
<TOKEN id="token-30-19" pos="word" morph="none" start_char="3714" end_char="3716">are</TOKEN>
<TOKEN id="token-30-20" pos="word" morph="none" start_char="3718" end_char="3722">today</TOKEN>
<TOKEN id="token-30-21" pos="word" morph="none" start_char="3724" end_char="3726">the</TOKEN>
<TOKEN id="token-30-22" pos="word" morph="none" start_char="3728" end_char="3734">subject</TOKEN>
<TOKEN id="token-30-23" pos="word" morph="none" start_char="3736" end_char="3737">of</TOKEN>
<TOKEN id="token-30-24" pos="word" morph="none" start_char="3739" end_char="3741">new</TOKEN>
<TOKEN id="token-30-25" pos="word" morph="none" start_char="3743" end_char="3750">research</TOKEN>
<TOKEN id="token-30-26" pos="word" morph="none" start_char="3752" end_char="3753">to</TOKEN>
<TOKEN id="token-30-27" pos="word" morph="none" start_char="3755" end_char="3760">tackle</TOKEN>
<TOKEN id="token-30-28" pos="word" morph="none" start_char="3762" end_char="3764">the</TOKEN>
<TOKEN id="token-30-29" pos="unknown" morph="none" start_char="3766" end_char="3775">SARS-CoV-2</TOKEN>
<TOKEN id="token-30-30" pos="word" morph="none" start_char="3777" end_char="3781">virus</TOKEN>
<TOKEN id="token-30-31" pos="word" morph="none" start_char="3783" end_char="3785">and</TOKEN>
<TOKEN id="token-30-32" pos="word" morph="none" start_char="3787" end_char="3789">the</TOKEN>
<TOKEN id="token-30-33" pos="unknown" morph="none" start_char="3791" end_char="3798">Covid-19</TOKEN>
<TOKEN id="token-30-34" pos="word" morph="none" start_char="3800" end_char="3807">pandemic</TOKEN>
<TOKEN id="token-30-35" pos="punct" morph="none" start_char="3809" end_char="3809">(</TOKEN>
<TOKEN id="token-30-36" pos="word" morph="none" start_char="3810" end_char="3812">new</TOKEN>
<TOKEN id="token-30-37" pos="word" morph="none" start_char="3814" end_char="3820">avenues</TOKEN>
<TOKEN id="token-30-38" pos="word" morph="none" start_char="3822" end_char="3828">measles</TOKEN>
<TOKEN id="token-30-39" pos="unknown" morph="none" start_char="3830" end_char="3841">vector-based</TOKEN>
<TOKEN id="token-30-40" pos="unknown" morph="none" start_char="3843" end_char="3852">SARS-CoV-2</TOKEN>
<TOKEN id="token-30-41" pos="word" morph="none" start_char="3854" end_char="3860">vaccine</TOKEN>
<TOKEN id="token-30-42" pos="punct" morph="none" start_char="3861" end_char="3861">;</TOKEN>
<TOKEN id="token-30-43" pos="word" morph="none" start_char="3863" end_char="3872">lentiviral</TOKEN>
<TOKEN id="token-30-44" pos="unknown" morph="none" start_char="3874" end_char="3885">vector-based</TOKEN>
<TOKEN id="token-30-45" pos="unknown" morph="none" start_char="3887" end_char="3896">SARS-CoV-2</TOKEN>
<TOKEN id="token-30-46" pos="word" morph="none" start_char="3898" end_char="3904">vaccine</TOKEN>
<TOKEN id="token-30-47" pos="punct" morph="none" start_char="3905" end_char="3906">).</TOKEN>
</SEG>
<SEG id="segment-31" start_char="3909" end_char="4102">
<ORIGINAL_TEXT>It should be noted that the vaccine candidate for SARS-CoV-1 was successfully tested on an animal model for the 2002-2003 SARS epidemics(disease caused by SARS-CoV-1 virus) outbreak at the time.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="3909" end_char="3910">It</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="3912" end_char="3917">should</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="3919" end_char="3920">be</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="3922" end_char="3926">noted</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="3928" end_char="3931">that</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="3933" end_char="3935">the</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="3937" end_char="3943">vaccine</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="3945" end_char="3953">candidate</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="3955" end_char="3957">for</TOKEN>
<TOKEN id="token-31-9" pos="unknown" morph="none" start_char="3959" end_char="3968">SARS-CoV-1</TOKEN>
<TOKEN id="token-31-10" pos="word" morph="none" start_char="3970" end_char="3972">was</TOKEN>
<TOKEN id="token-31-11" pos="word" morph="none" start_char="3974" end_char="3985">successfully</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="3987" end_char="3992">tested</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="3994" end_char="3995">on</TOKEN>
<TOKEN id="token-31-14" pos="word" morph="none" start_char="3997" end_char="3998">an</TOKEN>
<TOKEN id="token-31-15" pos="word" morph="none" start_char="4000" end_char="4005">animal</TOKEN>
<TOKEN id="token-31-16" pos="word" morph="none" start_char="4007" end_char="4011">model</TOKEN>
<TOKEN id="token-31-17" pos="word" morph="none" start_char="4013" end_char="4015">for</TOKEN>
<TOKEN id="token-31-18" pos="word" morph="none" start_char="4017" end_char="4019">the</TOKEN>
<TOKEN id="token-31-19" pos="unknown" morph="none" start_char="4021" end_char="4029">2002-2003</TOKEN>
<TOKEN id="token-31-20" pos="word" morph="none" start_char="4031" end_char="4034">SARS</TOKEN>
<TOKEN id="token-31-21" pos="unknown" morph="none" start_char="4036" end_char="4052">epidemics(disease</TOKEN>
<TOKEN id="token-31-22" pos="word" morph="none" start_char="4054" end_char="4059">caused</TOKEN>
<TOKEN id="token-31-23" pos="word" morph="none" start_char="4061" end_char="4062">by</TOKEN>
<TOKEN id="token-31-24" pos="unknown" morph="none" start_char="4064" end_char="4073">SARS-CoV-1</TOKEN>
<TOKEN id="token-31-25" pos="word" morph="none" start_char="4075" end_char="4079">virus</TOKEN>
<TOKEN id="token-31-26" pos="punct" morph="none" start_char="4080" end_char="4080">)</TOKEN>
<TOKEN id="token-31-27" pos="word" morph="none" start_char="4082" end_char="4089">outbreak</TOKEN>
<TOKEN id="token-31-28" pos="word" morph="none" start_char="4091" end_char="4092">at</TOKEN>
<TOKEN id="token-31-29" pos="word" morph="none" start_char="4094" end_char="4096">the</TOKEN>
<TOKEN id="token-31-30" pos="word" morph="none" start_char="4098" end_char="4101">time</TOKEN>
<TOKEN id="token-31-31" pos="punct" morph="none" start_char="4102" end_char="4102">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="4104" end_char="4214">
<ORIGINAL_TEXT>But this vaccine candidate was neither ever tested on humans nor marketed as the outbreak had thankfully ended.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="4104" end_char="4106">But</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="4108" end_char="4111">this</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="4113" end_char="4119">vaccine</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="4121" end_char="4129">candidate</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="4131" end_char="4133">was</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="4135" end_char="4141">neither</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="4143" end_char="4146">ever</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="4148" end_char="4153">tested</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="4155" end_char="4156">on</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="4158" end_char="4163">humans</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="4165" end_char="4167">nor</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="4169" end_char="4176">marketed</TOKEN>
<TOKEN id="token-32-12" pos="word" morph="none" start_char="4178" end_char="4179">as</TOKEN>
<TOKEN id="token-32-13" pos="word" morph="none" start_char="4181" end_char="4183">the</TOKEN>
<TOKEN id="token-32-14" pos="word" morph="none" start_char="4185" end_char="4192">outbreak</TOKEN>
<TOKEN id="token-32-15" pos="word" morph="none" start_char="4194" end_char="4196">had</TOKEN>
<TOKEN id="token-32-16" pos="word" morph="none" start_char="4198" end_char="4207">thankfully</TOKEN>
<TOKEN id="token-32-17" pos="word" morph="none" start_char="4209" end_char="4213">ended</TOKEN>
<TOKEN id="token-32-18" pos="punct" morph="none" start_char="4214" end_char="4214">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="4217" end_char="4299">
<ORIGINAL_TEXT>2 _ The Institut Pasteur did not release any viruses in the city of Wuhan in China!</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="4217" end_char="4217">2</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="4219" end_char="4219">_</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="4221" end_char="4223">The</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="4225" end_char="4232">Institut</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="4234" end_char="4240">Pasteur</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="4242" end_char="4244">did</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="4246" end_char="4248">not</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="4250" end_char="4256">release</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="4258" end_char="4260">any</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="4262" end_char="4268">viruses</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="4270" end_char="4271">in</TOKEN>
<TOKEN id="token-33-11" pos="word" morph="none" start_char="4273" end_char="4275">the</TOKEN>
<TOKEN id="token-33-12" pos="word" morph="none" start_char="4277" end_char="4280">city</TOKEN>
<TOKEN id="token-33-13" pos="word" morph="none" start_char="4282" end_char="4283">of</TOKEN>
<TOKEN id="token-33-14" pos="word" morph="none" start_char="4285" end_char="4289">Wuhan</TOKEN>
<TOKEN id="token-33-15" pos="word" morph="none" start_char="4291" end_char="4292">in</TOKEN>
<TOKEN id="token-33-16" pos="word" morph="none" start_char="4294" end_char="4298">China</TOKEN>
<TOKEN id="token-33-17" pos="punct" morph="none" start_char="4299" end_char="4299">!</TOKEN>
</SEG>
<SEG id="segment-34" start_char="4303" end_char="4420">
<ORIGINAL_TEXT>It is false and slanderous to assert that the Institut Pasteur released the coronavirus in the city of Wuhan in China.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="4303" end_char="4304">It</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="4306" end_char="4307">is</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="4309" end_char="4313">false</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="4315" end_char="4317">and</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="4319" end_char="4328">slanderous</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="4330" end_char="4331">to</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="4333" end_char="4338">assert</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="4340" end_char="4343">that</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="4345" end_char="4347">the</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="4349" end_char="4356">Institut</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="4358" end_char="4364">Pasteur</TOKEN>
<TOKEN id="token-34-11" pos="word" morph="none" start_char="4366" end_char="4373">released</TOKEN>
<TOKEN id="token-34-12" pos="word" morph="none" start_char="4375" end_char="4377">the</TOKEN>
<TOKEN id="token-34-13" pos="word" morph="none" start_char="4379" end_char="4389">coronavirus</TOKEN>
<TOKEN id="token-34-14" pos="word" morph="none" start_char="4391" end_char="4392">in</TOKEN>
<TOKEN id="token-34-15" pos="word" morph="none" start_char="4394" end_char="4396">the</TOKEN>
<TOKEN id="token-34-16" pos="word" morph="none" start_char="4398" end_char="4401">city</TOKEN>
<TOKEN id="token-34-17" pos="word" morph="none" start_char="4403" end_char="4404">of</TOKEN>
<TOKEN id="token-34-18" pos="word" morph="none" start_char="4406" end_char="4410">Wuhan</TOKEN>
<TOKEN id="token-34-19" pos="word" morph="none" start_char="4412" end_char="4413">in</TOKEN>
<TOKEN id="token-34-20" pos="word" morph="none" start_char="4415" end_char="4419">China</TOKEN>
<TOKEN id="token-34-21" pos="punct" morph="none" start_char="4420" end_char="4420">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="4423" end_char="4632">
<ORIGINAL_TEXT>The "BSL-4 laboratory" in Wuhan, which is mentioned in this video, is a research institute that strictly depends on the Chinese authorities and one with which the Institut Pasteur has no scientific interaction.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="4423" end_char="4425">The</TOKEN>
<TOKEN id="token-35-1" pos="punct" morph="none" start_char="4427" end_char="4427">"</TOKEN>
<TOKEN id="token-35-2" pos="unknown" morph="none" start_char="4428" end_char="4432">BSL-4</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="4434" end_char="4443">laboratory</TOKEN>
<TOKEN id="token-35-4" pos="punct" morph="none" start_char="4444" end_char="4444">"</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="4446" end_char="4447">in</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="4449" end_char="4453">Wuhan</TOKEN>
<TOKEN id="token-35-7" pos="punct" morph="none" start_char="4454" end_char="4454">,</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="4456" end_char="4460">which</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="4462" end_char="4463">is</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="4465" end_char="4473">mentioned</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="4475" end_char="4476">in</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="4478" end_char="4481">this</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="4483" end_char="4487">video</TOKEN>
<TOKEN id="token-35-14" pos="punct" morph="none" start_char="4488" end_char="4488">,</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="4490" end_char="4491">is</TOKEN>
<TOKEN id="token-35-16" pos="word" morph="none" start_char="4493" end_char="4493">a</TOKEN>
<TOKEN id="token-35-17" pos="word" morph="none" start_char="4495" end_char="4502">research</TOKEN>
<TOKEN id="token-35-18" pos="word" morph="none" start_char="4504" end_char="4512">institute</TOKEN>
<TOKEN id="token-35-19" pos="word" morph="none" start_char="4514" end_char="4517">that</TOKEN>
<TOKEN id="token-35-20" pos="word" morph="none" start_char="4519" end_char="4526">strictly</TOKEN>
<TOKEN id="token-35-21" pos="word" morph="none" start_char="4528" end_char="4534">depends</TOKEN>
<TOKEN id="token-35-22" pos="word" morph="none" start_char="4536" end_char="4537">on</TOKEN>
<TOKEN id="token-35-23" pos="word" morph="none" start_char="4539" end_char="4541">the</TOKEN>
<TOKEN id="token-35-24" pos="word" morph="none" start_char="4543" end_char="4549">Chinese</TOKEN>
<TOKEN id="token-35-25" pos="word" morph="none" start_char="4551" end_char="4561">authorities</TOKEN>
<TOKEN id="token-35-26" pos="word" morph="none" start_char="4563" end_char="4565">and</TOKEN>
<TOKEN id="token-35-27" pos="word" morph="none" start_char="4567" end_char="4569">one</TOKEN>
<TOKEN id="token-35-28" pos="word" morph="none" start_char="4571" end_char="4574">with</TOKEN>
<TOKEN id="token-35-29" pos="word" morph="none" start_char="4576" end_char="4580">which</TOKEN>
<TOKEN id="token-35-30" pos="word" morph="none" start_char="4582" end_char="4584">the</TOKEN>
<TOKEN id="token-35-31" pos="word" morph="none" start_char="4586" end_char="4593">Institut</TOKEN>
<TOKEN id="token-35-32" pos="word" morph="none" start_char="4595" end_char="4601">Pasteur</TOKEN>
<TOKEN id="token-35-33" pos="word" morph="none" start_char="4603" end_char="4605">has</TOKEN>
<TOKEN id="token-35-34" pos="word" morph="none" start_char="4607" end_char="4608">no</TOKEN>
<TOKEN id="token-35-35" pos="word" morph="none" start_char="4610" end_char="4619">scientific</TOKEN>
<TOKEN id="token-35-36" pos="word" morph="none" start_char="4621" end_char="4631">interaction</TOKEN>
<TOKEN id="token-35-37" pos="punct" morph="none" start_char="4632" end_char="4632">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="4635" end_char="4782">
<ORIGINAL_TEXT>See below "The Institut Pasteur of Shanghai (IPS) did not work on coronaviruses in the Wuhan BSL-4 laboratory which depends on a Chinese institute."</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="4635" end_char="4637">See</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="4639" end_char="4643">below</TOKEN>
<TOKEN id="token-36-2" pos="punct" morph="none" start_char="4645" end_char="4645">"</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="4646" end_char="4648">The</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="4650" end_char="4657">Institut</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="4659" end_char="4665">Pasteur</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="4667" end_char="4668">of</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="4670" end_char="4677">Shanghai</TOKEN>
<TOKEN id="token-36-8" pos="punct" morph="none" start_char="4679" end_char="4679">(</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="4680" end_char="4682">IPS</TOKEN>
<TOKEN id="token-36-10" pos="punct" morph="none" start_char="4683" end_char="4683">)</TOKEN>
<TOKEN id="token-36-11" pos="word" morph="none" start_char="4685" end_char="4687">did</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="4689" end_char="4691">not</TOKEN>
<TOKEN id="token-36-13" pos="word" morph="none" start_char="4693" end_char="4696">work</TOKEN>
<TOKEN id="token-36-14" pos="word" morph="none" start_char="4698" end_char="4699">on</TOKEN>
<TOKEN id="token-36-15" pos="word" morph="none" start_char="4701" end_char="4713">coronaviruses</TOKEN>
<TOKEN id="token-36-16" pos="word" morph="none" start_char="4715" end_char="4716">in</TOKEN>
<TOKEN id="token-36-17" pos="word" morph="none" start_char="4718" end_char="4720">the</TOKEN>
<TOKEN id="token-36-18" pos="word" morph="none" start_char="4722" end_char="4726">Wuhan</TOKEN>
<TOKEN id="token-36-19" pos="unknown" morph="none" start_char="4728" end_char="4732">BSL-4</TOKEN>
<TOKEN id="token-36-20" pos="word" morph="none" start_char="4734" end_char="4743">laboratory</TOKEN>
<TOKEN id="token-36-21" pos="word" morph="none" start_char="4745" end_char="4749">which</TOKEN>
<TOKEN id="token-36-22" pos="word" morph="none" start_char="4751" end_char="4757">depends</TOKEN>
<TOKEN id="token-36-23" pos="word" morph="none" start_char="4759" end_char="4760">on</TOKEN>
<TOKEN id="token-36-24" pos="word" morph="none" start_char="4762" end_char="4762">a</TOKEN>
<TOKEN id="token-36-25" pos="word" morph="none" start_char="4764" end_char="4770">Chinese</TOKEN>
<TOKEN id="token-36-26" pos="word" morph="none" start_char="4772" end_char="4780">institute</TOKEN>
<TOKEN id="token-36-27" pos="punct" morph="none" start_char="4781" end_char="4782">."</TOKEN>
</SEG>
<SEG id="segment-37" start_char="4785" end_char="4959">
<ORIGINAL_TEXT>3 _ The Institut Pasteur is an independent, non-profit foundation with recognized charitable status, and not a laboratory  or subsidiary  of the Sanofi pharmaceutical group.</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="4785" end_char="4785">3</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="4787" end_char="4787">_</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="4789" end_char="4791">The</TOKEN>
<TOKEN id="token-37-3" pos="word" morph="none" start_char="4793" end_char="4800">Institut</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="4802" end_char="4808">Pasteur</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="4810" end_char="4811">is</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="4813" end_char="4814">an</TOKEN>
<TOKEN id="token-37-7" pos="word" morph="none" start_char="4816" end_char="4826">independent</TOKEN>
<TOKEN id="token-37-8" pos="punct" morph="none" start_char="4827" end_char="4827">,</TOKEN>
<TOKEN id="token-37-9" pos="unknown" morph="none" start_char="4829" end_char="4838">non-profit</TOKEN>
<TOKEN id="token-37-10" pos="word" morph="none" start_char="4840" end_char="4849">foundation</TOKEN>
<TOKEN id="token-37-11" pos="word" morph="none" start_char="4851" end_char="4854">with</TOKEN>
<TOKEN id="token-37-12" pos="word" morph="none" start_char="4856" end_char="4865">recognized</TOKEN>
<TOKEN id="token-37-13" pos="word" morph="none" start_char="4867" end_char="4876">charitable</TOKEN>
<TOKEN id="token-37-14" pos="word" morph="none" start_char="4878" end_char="4883">status</TOKEN>
<TOKEN id="token-37-15" pos="punct" morph="none" start_char="4884" end_char="4884">,</TOKEN>
<TOKEN id="token-37-16" pos="word" morph="none" start_char="4886" end_char="4888">and</TOKEN>
<TOKEN id="token-37-17" pos="word" morph="none" start_char="4890" end_char="4892">not</TOKEN>
<TOKEN id="token-37-18" pos="word" morph="none" start_char="4894" end_char="4894">a</TOKEN>
<TOKEN id="token-37-19" pos="word" morph="none" start_char="4896" end_char="4905">laboratory</TOKEN>
<TOKEN id="token-37-20" pos="punct" morph="none" start_char="4907" end_char="4907"></TOKEN>
<TOKEN id="token-37-21" pos="word" morph="none" start_char="4909" end_char="4910">or</TOKEN>
<TOKEN id="token-37-22" pos="word" morph="none" start_char="4912" end_char="4921">subsidiary</TOKEN>
<TOKEN id="token-37-23" pos="punct" morph="none" start_char="4923" end_char="4923"></TOKEN>
<TOKEN id="token-37-24" pos="word" morph="none" start_char="4925" end_char="4926">of</TOKEN>
<TOKEN id="token-37-25" pos="word" morph="none" start_char="4928" end_char="4930">the</TOKEN>
<TOKEN id="token-37-26" pos="word" morph="none" start_char="4932" end_char="4937">Sanofi</TOKEN>
<TOKEN id="token-37-27" pos="word" morph="none" start_char="4939" end_char="4952">pharmaceutical</TOKEN>
<TOKEN id="token-37-28" pos="word" morph="none" start_char="4954" end_char="4958">group</TOKEN>
<TOKEN id="token-37-29" pos="punct" morph="none" start_char="4959" end_char="4959">.</TOKEN>
</SEG>
<SEG id="segment-38" start_char="4963" end_char="5010">
<ORIGINAL_TEXT>The Institut Pasteur is a non-profit foundation.</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="4963" end_char="4965">The</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="4967" end_char="4974">Institut</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="4976" end_char="4982">Pasteur</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="4984" end_char="4985">is</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="4987" end_char="4987">a</TOKEN>
<TOKEN id="token-38-5" pos="unknown" morph="none" start_char="4989" end_char="4998">non-profit</TOKEN>
<TOKEN id="token-38-6" pos="word" morph="none" start_char="5000" end_char="5009">foundation</TOKEN>
<TOKEN id="token-38-7" pos="punct" morph="none" start_char="5010" end_char="5010">.</TOKEN>
</SEG>
<SEG id="segment-39" start_char="5012" end_char="5156">
<ORIGINAL_TEXT>Its mission is to help prevent and treat diseases, mainly those of infectious origin, through research, education, and public health initiatives.</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="5012" end_char="5014">Its</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="5016" end_char="5022">mission</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="5024" end_char="5025">is</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="5027" end_char="5028">to</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="5030" end_char="5033">help</TOKEN>
<TOKEN id="token-39-5" pos="word" morph="none" start_char="5035" end_char="5041">prevent</TOKEN>
<TOKEN id="token-39-6" pos="word" morph="none" start_char="5043" end_char="5045">and</TOKEN>
<TOKEN id="token-39-7" pos="word" morph="none" start_char="5047" end_char="5051">treat</TOKEN>
<TOKEN id="token-39-8" pos="word" morph="none" start_char="5053" end_char="5060">diseases</TOKEN>
<TOKEN id="token-39-9" pos="punct" morph="none" start_char="5061" end_char="5061">,</TOKEN>
<TOKEN id="token-39-10" pos="word" morph="none" start_char="5063" end_char="5068">mainly</TOKEN>
<TOKEN id="token-39-11" pos="word" morph="none" start_char="5070" end_char="5074">those</TOKEN>
<TOKEN id="token-39-12" pos="word" morph="none" start_char="5076" end_char="5077">of</TOKEN>
<TOKEN id="token-39-13" pos="word" morph="none" start_char="5079" end_char="5088">infectious</TOKEN>
<TOKEN id="token-39-14" pos="word" morph="none" start_char="5090" end_char="5095">origin</TOKEN>
<TOKEN id="token-39-15" pos="punct" morph="none" start_char="5096" end_char="5096">,</TOKEN>
<TOKEN id="token-39-16" pos="word" morph="none" start_char="5098" end_char="5104">through</TOKEN>
<TOKEN id="token-39-17" pos="word" morph="none" start_char="5106" end_char="5113">research</TOKEN>
<TOKEN id="token-39-18" pos="punct" morph="none" start_char="5114" end_char="5114">,</TOKEN>
<TOKEN id="token-39-19" pos="word" morph="none" start_char="5116" end_char="5124">education</TOKEN>
<TOKEN id="token-39-20" pos="punct" morph="none" start_char="5125" end_char="5125">,</TOKEN>
<TOKEN id="token-39-21" pos="word" morph="none" start_char="5127" end_char="5129">and</TOKEN>
<TOKEN id="token-39-22" pos="word" morph="none" start_char="5131" end_char="5136">public</TOKEN>
<TOKEN id="token-39-23" pos="word" morph="none" start_char="5138" end_char="5143">health</TOKEN>
<TOKEN id="token-39-24" pos="word" morph="none" start_char="5145" end_char="5155">initiatives</TOKEN>
<TOKEN id="token-39-25" pos="punct" morph="none" start_char="5156" end_char="5156">.</TOKEN>
</SEG>
<SEG id="segment-40" start_char="5159" end_char="5430">
<ORIGINAL_TEXT>The Institut Pasteur carries out research  including in vaccinology  in a bid to improve understanding of the processes that induce immune responses and interactions between microbes and their hosts in a certain number of diseases (dengue, AIDS, yellow fever, Zika, etc.</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="5159" end_char="5161">The</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="5163" end_char="5170">Institut</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="5172" end_char="5178">Pasteur</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="5180" end_char="5186">carries</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="5188" end_char="5190">out</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="5192" end_char="5199">research</TOKEN>
<TOKEN id="token-40-6" pos="punct" morph="none" start_char="5201" end_char="5201"></TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="5203" end_char="5211">including</TOKEN>
<TOKEN id="token-40-8" pos="word" morph="none" start_char="5213" end_char="5214">in</TOKEN>
<TOKEN id="token-40-9" pos="word" morph="none" start_char="5216" end_char="5226">vaccinology</TOKEN>
<TOKEN id="token-40-10" pos="punct" morph="none" start_char="5228" end_char="5228"></TOKEN>
<TOKEN id="token-40-11" pos="word" morph="none" start_char="5230" end_char="5231">in</TOKEN>
<TOKEN id="token-40-12" pos="word" morph="none" start_char="5233" end_char="5233">a</TOKEN>
<TOKEN id="token-40-13" pos="word" morph="none" start_char="5235" end_char="5237">bid</TOKEN>
<TOKEN id="token-40-14" pos="word" morph="none" start_char="5239" end_char="5240">to</TOKEN>
<TOKEN id="token-40-15" pos="word" morph="none" start_char="5242" end_char="5248">improve</TOKEN>
<TOKEN id="token-40-16" pos="word" morph="none" start_char="5250" end_char="5262">understanding</TOKEN>
<TOKEN id="token-40-17" pos="word" morph="none" start_char="5264" end_char="5265">of</TOKEN>
<TOKEN id="token-40-18" pos="word" morph="none" start_char="5267" end_char="5269">the</TOKEN>
<TOKEN id="token-40-19" pos="word" morph="none" start_char="5271" end_char="5279">processes</TOKEN>
<TOKEN id="token-40-20" pos="word" morph="none" start_char="5281" end_char="5284">that</TOKEN>
<TOKEN id="token-40-21" pos="word" morph="none" start_char="5286" end_char="5291">induce</TOKEN>
<TOKEN id="token-40-22" pos="word" morph="none" start_char="5293" end_char="5298">immune</TOKEN>
<TOKEN id="token-40-23" pos="word" morph="none" start_char="5300" end_char="5308">responses</TOKEN>
<TOKEN id="token-40-24" pos="word" morph="none" start_char="5310" end_char="5312">and</TOKEN>
<TOKEN id="token-40-25" pos="word" morph="none" start_char="5314" end_char="5325">interactions</TOKEN>
<TOKEN id="token-40-26" pos="word" morph="none" start_char="5327" end_char="5333">between</TOKEN>
<TOKEN id="token-40-27" pos="word" morph="none" start_char="5335" end_char="5342">microbes</TOKEN>
<TOKEN id="token-40-28" pos="word" morph="none" start_char="5344" end_char="5346">and</TOKEN>
<TOKEN id="token-40-29" pos="word" morph="none" start_char="5348" end_char="5352">their</TOKEN>
<TOKEN id="token-40-30" pos="word" morph="none" start_char="5354" end_char="5358">hosts</TOKEN>
<TOKEN id="token-40-31" pos="word" morph="none" start_char="5360" end_char="5361">in</TOKEN>
<TOKEN id="token-40-32" pos="word" morph="none" start_char="5363" end_char="5363">a</TOKEN>
<TOKEN id="token-40-33" pos="word" morph="none" start_char="5365" end_char="5371">certain</TOKEN>
<TOKEN id="token-40-34" pos="word" morph="none" start_char="5373" end_char="5378">number</TOKEN>
<TOKEN id="token-40-35" pos="word" morph="none" start_char="5380" end_char="5381">of</TOKEN>
<TOKEN id="token-40-36" pos="word" morph="none" start_char="5383" end_char="5390">diseases</TOKEN>
<TOKEN id="token-40-37" pos="punct" morph="none" start_char="5392" end_char="5392">(</TOKEN>
<TOKEN id="token-40-38" pos="word" morph="none" start_char="5393" end_char="5398">dengue</TOKEN>
<TOKEN id="token-40-39" pos="punct" morph="none" start_char="5399" end_char="5399">,</TOKEN>
<TOKEN id="token-40-40" pos="word" morph="none" start_char="5401" end_char="5404">AIDS</TOKEN>
<TOKEN id="token-40-41" pos="punct" morph="none" start_char="5405" end_char="5405">,</TOKEN>
<TOKEN id="token-40-42" pos="word" morph="none" start_char="5407" end_char="5412">yellow</TOKEN>
<TOKEN id="token-40-43" pos="word" morph="none" start_char="5414" end_char="5418">fever</TOKEN>
<TOKEN id="token-40-44" pos="punct" morph="none" start_char="5419" end_char="5419">,</TOKEN>
<TOKEN id="token-40-45" pos="word" morph="none" start_char="5421" end_char="5424">Zika</TOKEN>
<TOKEN id="token-40-46" pos="punct" morph="none" start_char="5425" end_char="5425">,</TOKEN>
<TOKEN id="token-40-47" pos="word" morph="none" start_char="5427" end_char="5429">etc</TOKEN>
<TOKEN id="token-40-48" pos="punct" morph="none" start_char="5430" end_char="5430">.</TOKEN>
</SEG>
<SEG id="segment-41" start_char="5432" end_char="5624">
<ORIGINAL_TEXT>and now SARS-CoV-2/Covid-19 infection), to pave the way for the design of innovative prevention strategies and propose vaccine candidates for developments that may be produced by manufacturers.</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="5432" end_char="5434">and</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="5436" end_char="5438">now</TOKEN>
<TOKEN id="token-41-2" pos="unknown" morph="none" start_char="5440" end_char="5458">SARS-CoV-2/Covid-19</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="5460" end_char="5468">infection</TOKEN>
<TOKEN id="token-41-4" pos="punct" morph="none" start_char="5469" end_char="5470">),</TOKEN>
<TOKEN id="token-41-5" pos="word" morph="none" start_char="5472" end_char="5473">to</TOKEN>
<TOKEN id="token-41-6" pos="word" morph="none" start_char="5475" end_char="5478">pave</TOKEN>
<TOKEN id="token-41-7" pos="word" morph="none" start_char="5480" end_char="5482">the</TOKEN>
<TOKEN id="token-41-8" pos="word" morph="none" start_char="5484" end_char="5486">way</TOKEN>
<TOKEN id="token-41-9" pos="word" morph="none" start_char="5488" end_char="5490">for</TOKEN>
<TOKEN id="token-41-10" pos="word" morph="none" start_char="5492" end_char="5494">the</TOKEN>
<TOKEN id="token-41-11" pos="word" morph="none" start_char="5496" end_char="5501">design</TOKEN>
<TOKEN id="token-41-12" pos="word" morph="none" start_char="5503" end_char="5504">of</TOKEN>
<TOKEN id="token-41-13" pos="word" morph="none" start_char="5506" end_char="5515">innovative</TOKEN>
<TOKEN id="token-41-14" pos="word" morph="none" start_char="5517" end_char="5526">prevention</TOKEN>
<TOKEN id="token-41-15" pos="word" morph="none" start_char="5528" end_char="5537">strategies</TOKEN>
<TOKEN id="token-41-16" pos="word" morph="none" start_char="5539" end_char="5541">and</TOKEN>
<TOKEN id="token-41-17" pos="word" morph="none" start_char="5543" end_char="5549">propose</TOKEN>
<TOKEN id="token-41-18" pos="word" morph="none" start_char="5551" end_char="5557">vaccine</TOKEN>
<TOKEN id="token-41-19" pos="word" morph="none" start_char="5559" end_char="5568">candidates</TOKEN>
<TOKEN id="token-41-20" pos="word" morph="none" start_char="5570" end_char="5572">for</TOKEN>
<TOKEN id="token-41-21" pos="word" morph="none" start_char="5574" end_char="5585">developments</TOKEN>
<TOKEN id="token-41-22" pos="word" morph="none" start_char="5587" end_char="5590">that</TOKEN>
<TOKEN id="token-41-23" pos="word" morph="none" start_char="5592" end_char="5594">may</TOKEN>
<TOKEN id="token-41-24" pos="word" morph="none" start_char="5596" end_char="5597">be</TOKEN>
<TOKEN id="token-41-25" pos="word" morph="none" start_char="5599" end_char="5606">produced</TOKEN>
<TOKEN id="token-41-26" pos="word" morph="none" start_char="5608" end_char="5609">by</TOKEN>
<TOKEN id="token-41-27" pos="word" morph="none" start_char="5611" end_char="5623">manufacturers</TOKEN>
<TOKEN id="token-41-28" pos="punct" morph="none" start_char="5624" end_char="5624">.</TOKEN>
</SEG>
<SEG id="segment-42" start_char="5627" end_char="5703">
<ORIGINAL_TEXT>Today, the Institut Pasteur neither manufactures nor markets vaccines itself.</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="5627" end_char="5631">Today</TOKEN>
<TOKEN id="token-42-1" pos="punct" morph="none" start_char="5632" end_char="5632">,</TOKEN>
<TOKEN id="token-42-2" pos="word" morph="none" start_char="5634" end_char="5636">the</TOKEN>
<TOKEN id="token-42-3" pos="word" morph="none" start_char="5638" end_char="5645">Institut</TOKEN>
<TOKEN id="token-42-4" pos="word" morph="none" start_char="5647" end_char="5653">Pasteur</TOKEN>
<TOKEN id="token-42-5" pos="word" morph="none" start_char="5655" end_char="5661">neither</TOKEN>
<TOKEN id="token-42-6" pos="word" morph="none" start_char="5663" end_char="5674">manufactures</TOKEN>
<TOKEN id="token-42-7" pos="word" morph="none" start_char="5676" end_char="5678">nor</TOKEN>
<TOKEN id="token-42-8" pos="word" morph="none" start_char="5680" end_char="5686">markets</TOKEN>
<TOKEN id="token-42-9" pos="word" morph="none" start_char="5688" end_char="5695">vaccines</TOKEN>
<TOKEN id="token-42-10" pos="word" morph="none" start_char="5697" end_char="5702">itself</TOKEN>
<TOKEN id="token-42-11" pos="punct" morph="none" start_char="5703" end_char="5703">.</TOKEN>
</SEG>
<SEG id="segment-43" start_char="5706" end_char="5748">
<ORIGINAL_TEXT>More information about the Institut Pasteur</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="5706" end_char="5709">More</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="5711" end_char="5721">information</TOKEN>
<TOKEN id="token-43-2" pos="word" morph="none" start_char="5723" end_char="5727">about</TOKEN>
<TOKEN id="token-43-3" pos="word" morph="none" start_char="5729" end_char="5731">the</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="5733" end_char="5740">Institut</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="5742" end_char="5748">Pasteur</TOKEN>
</SEG>
<SEG id="segment-44" start_char="5751" end_char="5893">
<ORIGINAL_TEXT>4 _ Asserting that the Institut Pasteur is planning to enslave and control the global population is utterly false and devoid of all foundation.</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="word" morph="none" start_char="5751" end_char="5751">4</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="5753" end_char="5753">_</TOKEN>
<TOKEN id="token-44-2" pos="word" morph="none" start_char="5755" end_char="5763">Asserting</TOKEN>
<TOKEN id="token-44-3" pos="word" morph="none" start_char="5765" end_char="5768">that</TOKEN>
<TOKEN id="token-44-4" pos="word" morph="none" start_char="5770" end_char="5772">the</TOKEN>
<TOKEN id="token-44-5" pos="word" morph="none" start_char="5774" end_char="5781">Institut</TOKEN>
<TOKEN id="token-44-6" pos="word" morph="none" start_char="5783" end_char="5789">Pasteur</TOKEN>
<TOKEN id="token-44-7" pos="word" morph="none" start_char="5791" end_char="5792">is</TOKEN>
<TOKEN id="token-44-8" pos="word" morph="none" start_char="5794" end_char="5801">planning</TOKEN>
<TOKEN id="token-44-9" pos="word" morph="none" start_char="5803" end_char="5804">to</TOKEN>
<TOKEN id="token-44-10" pos="word" morph="none" start_char="5806" end_char="5812">enslave</TOKEN>
<TOKEN id="token-44-11" pos="word" morph="none" start_char="5814" end_char="5816">and</TOKEN>
<TOKEN id="token-44-12" pos="word" morph="none" start_char="5818" end_char="5824">control</TOKEN>
<TOKEN id="token-44-13" pos="word" morph="none" start_char="5826" end_char="5828">the</TOKEN>
<TOKEN id="token-44-14" pos="word" morph="none" start_char="5830" end_char="5835">global</TOKEN>
<TOKEN id="token-44-15" pos="word" morph="none" start_char="5837" end_char="5846">population</TOKEN>
<TOKEN id="token-44-16" pos="word" morph="none" start_char="5848" end_char="5849">is</TOKEN>
<TOKEN id="token-44-17" pos="word" morph="none" start_char="5851" end_char="5857">utterly</TOKEN>
<TOKEN id="token-44-18" pos="word" morph="none" start_char="5859" end_char="5863">false</TOKEN>
<TOKEN id="token-44-19" pos="word" morph="none" start_char="5865" end_char="5867">and</TOKEN>
<TOKEN id="token-44-20" pos="word" morph="none" start_char="5869" end_char="5874">devoid</TOKEN>
<TOKEN id="token-44-21" pos="word" morph="none" start_char="5876" end_char="5877">of</TOKEN>
<TOKEN id="token-44-22" pos="word" morph="none" start_char="5879" end_char="5881">all</TOKEN>
<TOKEN id="token-44-23" pos="word" morph="none" start_char="5883" end_char="5892">foundation</TOKEN>
<TOKEN id="token-44-24" pos="punct" morph="none" start_char="5893" end_char="5893">.</TOKEN>
</SEG>
<SEG id="segment-45" start_char="5897" end_char="6039">
<ORIGINAL_TEXT>Falsely incriminating a natural and / or legal person for deeds that they have evidently not committed constitutes a grave and serious offense.</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="5897" end_char="5903">Falsely</TOKEN>
<TOKEN id="token-45-1" pos="word" morph="none" start_char="5905" end_char="5917">incriminating</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="5919" end_char="5919">a</TOKEN>
<TOKEN id="token-45-3" pos="word" morph="none" start_char="5921" end_char="5927">natural</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="5929" end_char="5931">and</TOKEN>
<TOKEN id="token-45-5" pos="punct" morph="none" start_char="5933" end_char="5933">/</TOKEN>
<TOKEN id="token-45-6" pos="word" morph="none" start_char="5935" end_char="5936">or</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="5938" end_char="5942">legal</TOKEN>
<TOKEN id="token-45-8" pos="word" morph="none" start_char="5944" end_char="5949">person</TOKEN>
<TOKEN id="token-45-9" pos="word" morph="none" start_char="5951" end_char="5953">for</TOKEN>
<TOKEN id="token-45-10" pos="word" morph="none" start_char="5955" end_char="5959">deeds</TOKEN>
<TOKEN id="token-45-11" pos="word" morph="none" start_char="5961" end_char="5964">that</TOKEN>
<TOKEN id="token-45-12" pos="word" morph="none" start_char="5966" end_char="5969">they</TOKEN>
<TOKEN id="token-45-13" pos="word" morph="none" start_char="5971" end_char="5974">have</TOKEN>
<TOKEN id="token-45-14" pos="word" morph="none" start_char="5976" end_char="5984">evidently</TOKEN>
<TOKEN id="token-45-15" pos="word" morph="none" start_char="5986" end_char="5988">not</TOKEN>
<TOKEN id="token-45-16" pos="word" morph="none" start_char="5990" end_char="5998">committed</TOKEN>
<TOKEN id="token-45-17" pos="word" morph="none" start_char="6000" end_char="6010">constitutes</TOKEN>
<TOKEN id="token-45-18" pos="word" morph="none" start_char="6012" end_char="6012">a</TOKEN>
<TOKEN id="token-45-19" pos="word" morph="none" start_char="6014" end_char="6018">grave</TOKEN>
<TOKEN id="token-45-20" pos="word" morph="none" start_char="6020" end_char="6022">and</TOKEN>
<TOKEN id="token-45-21" pos="word" morph="none" start_char="6024" end_char="6030">serious</TOKEN>
<TOKEN id="token-45-22" pos="word" morph="none" start_char="6032" end_char="6038">offense</TOKEN>
<TOKEN id="token-45-23" pos="punct" morph="none" start_char="6039" end_char="6039">.</TOKEN>
</SEG>
<SEG id="segment-46" start_char="6041" end_char="6228">
<ORIGINAL_TEXT>These public defamations, spread on social media without any consideration and relayed with no prior analysis of, or investigation into, the facts, deliberately feed a climate of distrust.</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="word" morph="none" start_char="6041" end_char="6045">These</TOKEN>
<TOKEN id="token-46-1" pos="word" morph="none" start_char="6047" end_char="6052">public</TOKEN>
<TOKEN id="token-46-2" pos="word" morph="none" start_char="6054" end_char="6064">defamations</TOKEN>
<TOKEN id="token-46-3" pos="punct" morph="none" start_char="6065" end_char="6065">,</TOKEN>
<TOKEN id="token-46-4" pos="word" morph="none" start_char="6067" end_char="6072">spread</TOKEN>
<TOKEN id="token-46-5" pos="word" morph="none" start_char="6074" end_char="6075">on</TOKEN>
<TOKEN id="token-46-6" pos="word" morph="none" start_char="6077" end_char="6082">social</TOKEN>
<TOKEN id="token-46-7" pos="word" morph="none" start_char="6084" end_char="6088">media</TOKEN>
<TOKEN id="token-46-8" pos="word" morph="none" start_char="6090" end_char="6096">without</TOKEN>
<TOKEN id="token-46-9" pos="word" morph="none" start_char="6098" end_char="6100">any</TOKEN>
<TOKEN id="token-46-10" pos="word" morph="none" start_char="6102" end_char="6114">consideration</TOKEN>
<TOKEN id="token-46-11" pos="word" morph="none" start_char="6116" end_char="6118">and</TOKEN>
<TOKEN id="token-46-12" pos="word" morph="none" start_char="6120" end_char="6126">relayed</TOKEN>
<TOKEN id="token-46-13" pos="word" morph="none" start_char="6128" end_char="6131">with</TOKEN>
<TOKEN id="token-46-14" pos="word" morph="none" start_char="6133" end_char="6134">no</TOKEN>
<TOKEN id="token-46-15" pos="word" morph="none" start_char="6136" end_char="6140">prior</TOKEN>
<TOKEN id="token-46-16" pos="word" morph="none" start_char="6142" end_char="6149">analysis</TOKEN>
<TOKEN id="token-46-17" pos="word" morph="none" start_char="6151" end_char="6152">of</TOKEN>
<TOKEN id="token-46-18" pos="punct" morph="none" start_char="6153" end_char="6153">,</TOKEN>
<TOKEN id="token-46-19" pos="word" morph="none" start_char="6155" end_char="6156">or</TOKEN>
<TOKEN id="token-46-20" pos="word" morph="none" start_char="6158" end_char="6170">investigation</TOKEN>
<TOKEN id="token-46-21" pos="word" morph="none" start_char="6172" end_char="6175">into</TOKEN>
<TOKEN id="token-46-22" pos="punct" morph="none" start_char="6176" end_char="6176">,</TOKEN>
<TOKEN id="token-46-23" pos="word" morph="none" start_char="6178" end_char="6180">the</TOKEN>
<TOKEN id="token-46-24" pos="word" morph="none" start_char="6182" end_char="6186">facts</TOKEN>
<TOKEN id="token-46-25" pos="punct" morph="none" start_char="6187" end_char="6187">,</TOKEN>
<TOKEN id="token-46-26" pos="word" morph="none" start_char="6189" end_char="6200">deliberately</TOKEN>
<TOKEN id="token-46-27" pos="word" morph="none" start_char="6202" end_char="6205">feed</TOKEN>
<TOKEN id="token-46-28" pos="word" morph="none" start_char="6207" end_char="6207">a</TOKEN>
<TOKEN id="token-46-29" pos="word" morph="none" start_char="6209" end_char="6215">climate</TOKEN>
<TOKEN id="token-46-30" pos="word" morph="none" start_char="6217" end_char="6218">of</TOKEN>
<TOKEN id="token-46-31" pos="word" morph="none" start_char="6220" end_char="6227">distrust</TOKEN>
<TOKEN id="token-46-32" pos="punct" morph="none" start_char="6228" end_char="6228">.</TOKEN>
</SEG>
<SEG id="segment-47" start_char="6231" end_char="6348">
<ORIGINAL_TEXT>5 _ The Institut Pasteur has initiated legal proceedings for misleading and defamatory information circulating online.</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="word" morph="none" start_char="6231" end_char="6231">5</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="6233" end_char="6233">_</TOKEN>
<TOKEN id="token-47-2" pos="word" morph="none" start_char="6235" end_char="6237">The</TOKEN>
<TOKEN id="token-47-3" pos="word" morph="none" start_char="6239" end_char="6246">Institut</TOKEN>
<TOKEN id="token-47-4" pos="word" morph="none" start_char="6248" end_char="6254">Pasteur</TOKEN>
<TOKEN id="token-47-5" pos="word" morph="none" start_char="6256" end_char="6258">has</TOKEN>
<TOKEN id="token-47-6" pos="word" morph="none" start_char="6260" end_char="6268">initiated</TOKEN>
<TOKEN id="token-47-7" pos="word" morph="none" start_char="6270" end_char="6274">legal</TOKEN>
<TOKEN id="token-47-8" pos="word" morph="none" start_char="6276" end_char="6286">proceedings</TOKEN>
<TOKEN id="token-47-9" pos="word" morph="none" start_char="6288" end_char="6290">for</TOKEN>
<TOKEN id="token-47-10" pos="word" morph="none" start_char="6292" end_char="6301">misleading</TOKEN>
<TOKEN id="token-47-11" pos="word" morph="none" start_char="6303" end_char="6305">and</TOKEN>
<TOKEN id="token-47-12" pos="word" morph="none" start_char="6307" end_char="6316">defamatory</TOKEN>
<TOKEN id="token-47-13" pos="word" morph="none" start_char="6318" end_char="6328">information</TOKEN>
<TOKEN id="token-47-14" pos="word" morph="none" start_char="6330" end_char="6340">circulating</TOKEN>
<TOKEN id="token-47-15" pos="word" morph="none" start_char="6342" end_char="6347">online</TOKEN>
<TOKEN id="token-47-16" pos="punct" morph="none" start_char="6348" end_char="6348">.</TOKEN>
</SEG>
<SEG id="segment-48" start_char="6352" end_char="6465">
<ORIGINAL_TEXT>Based on a misinterpretation of a patent, several videos accuse the Institut Pasteur of creating the #Coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="word" morph="none" start_char="6352" end_char="6356">Based</TOKEN>
<TOKEN id="token-48-1" pos="word" morph="none" start_char="6358" end_char="6359">on</TOKEN>
<TOKEN id="token-48-2" pos="word" morph="none" start_char="6361" end_char="6361">a</TOKEN>
<TOKEN id="token-48-3" pos="word" morph="none" start_char="6363" end_char="6379">misinterpretation</TOKEN>
<TOKEN id="token-48-4" pos="word" morph="none" start_char="6381" end_char="6382">of</TOKEN>
<TOKEN id="token-48-5" pos="word" morph="none" start_char="6384" end_char="6384">a</TOKEN>
<TOKEN id="token-48-6" pos="word" morph="none" start_char="6386" end_char="6391">patent</TOKEN>
<TOKEN id="token-48-7" pos="punct" morph="none" start_char="6392" end_char="6392">,</TOKEN>
<TOKEN id="token-48-8" pos="word" morph="none" start_char="6394" end_char="6400">several</TOKEN>
<TOKEN id="token-48-9" pos="word" morph="none" start_char="6402" end_char="6407">videos</TOKEN>
<TOKEN id="token-48-10" pos="word" morph="none" start_char="6409" end_char="6414">accuse</TOKEN>
<TOKEN id="token-48-11" pos="word" morph="none" start_char="6416" end_char="6418">the</TOKEN>
<TOKEN id="token-48-12" pos="word" morph="none" start_char="6420" end_char="6427">Institut</TOKEN>
<TOKEN id="token-48-13" pos="word" morph="none" start_char="6429" end_char="6435">Pasteur</TOKEN>
<TOKEN id="token-48-14" pos="word" morph="none" start_char="6437" end_char="6438">of</TOKEN>
<TOKEN id="token-48-15" pos="word" morph="none" start_char="6440" end_char="6447">creating</TOKEN>
<TOKEN id="token-48-16" pos="word" morph="none" start_char="6449" end_char="6451">the</TOKEN>
<TOKEN id="token-48-17" pos="tag" morph="none" start_char="6453" end_char="6465">#Coronavirus.</TOKEN>
</SEG>
<SEG id="segment-49" start_char="6467" end_char="6652">
<ORIGINAL_TEXT>In response to these false and defamatory claims, the Institut Pasteur once again lodged a complaint for defamation with the Senior Investigating Judge at the Paris Court this September.</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="word" morph="none" start_char="6467" end_char="6468">In</TOKEN>
<TOKEN id="token-49-1" pos="word" morph="none" start_char="6470" end_char="6477">response</TOKEN>
<TOKEN id="token-49-2" pos="word" morph="none" start_char="6479" end_char="6480">to</TOKEN>
<TOKEN id="token-49-3" pos="word" morph="none" start_char="6482" end_char="6486">these</TOKEN>
<TOKEN id="token-49-4" pos="word" morph="none" start_char="6488" end_char="6492">false</TOKEN>
<TOKEN id="token-49-5" pos="word" morph="none" start_char="6494" end_char="6496">and</TOKEN>
<TOKEN id="token-49-6" pos="word" morph="none" start_char="6498" end_char="6507">defamatory</TOKEN>
<TOKEN id="token-49-7" pos="word" morph="none" start_char="6509" end_char="6514">claims</TOKEN>
<TOKEN id="token-49-8" pos="punct" morph="none" start_char="6515" end_char="6515">,</TOKEN>
<TOKEN id="token-49-9" pos="word" morph="none" start_char="6517" end_char="6519">the</TOKEN>
<TOKEN id="token-49-10" pos="word" morph="none" start_char="6521" end_char="6528">Institut</TOKEN>
<TOKEN id="token-49-11" pos="word" morph="none" start_char="6530" end_char="6536">Pasteur</TOKEN>
<TOKEN id="token-49-12" pos="word" morph="none" start_char="6538" end_char="6541">once</TOKEN>
<TOKEN id="token-49-13" pos="word" morph="none" start_char="6543" end_char="6547">again</TOKEN>
<TOKEN id="token-49-14" pos="word" morph="none" start_char="6549" end_char="6554">lodged</TOKEN>
<TOKEN id="token-49-15" pos="word" morph="none" start_char="6556" end_char="6556">a</TOKEN>
<TOKEN id="token-49-16" pos="word" morph="none" start_char="6558" end_char="6566">complaint</TOKEN>
<TOKEN id="token-49-17" pos="word" morph="none" start_char="6568" end_char="6570">for</TOKEN>
<TOKEN id="token-49-18" pos="word" morph="none" start_char="6572" end_char="6581">defamation</TOKEN>
<TOKEN id="token-49-19" pos="word" morph="none" start_char="6583" end_char="6586">with</TOKEN>
<TOKEN id="token-49-20" pos="word" morph="none" start_char="6588" end_char="6590">the</TOKEN>
<TOKEN id="token-49-21" pos="word" morph="none" start_char="6592" end_char="6597">Senior</TOKEN>
<TOKEN id="token-49-22" pos="word" morph="none" start_char="6599" end_char="6611">Investigating</TOKEN>
<TOKEN id="token-49-23" pos="word" morph="none" start_char="6613" end_char="6617">Judge</TOKEN>
<TOKEN id="token-49-24" pos="word" morph="none" start_char="6619" end_char="6620">at</TOKEN>
<TOKEN id="token-49-25" pos="word" morph="none" start_char="6622" end_char="6624">the</TOKEN>
<TOKEN id="token-49-26" pos="word" morph="none" start_char="6626" end_char="6630">Paris</TOKEN>
<TOKEN id="token-49-27" pos="word" morph="none" start_char="6632" end_char="6636">Court</TOKEN>
<TOKEN id="token-49-28" pos="word" morph="none" start_char="6638" end_char="6641">this</TOKEN>
<TOKEN id="token-49-29" pos="word" morph="none" start_char="6643" end_char="6651">September</TOKEN>
<TOKEN id="token-49-30" pos="punct" morph="none" start_char="6652" end_char="6652">.</TOKEN>
</SEG>
<SEG id="segment-50" start_char="6655" end_char="6722">
<ORIGINAL_TEXT>The accusations have already been refuted several times since March.</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="word" morph="none" start_char="6655" end_char="6657">The</TOKEN>
<TOKEN id="token-50-1" pos="word" morph="none" start_char="6659" end_char="6669">accusations</TOKEN>
<TOKEN id="token-50-2" pos="word" morph="none" start_char="6671" end_char="6674">have</TOKEN>
<TOKEN id="token-50-3" pos="word" morph="none" start_char="6676" end_char="6682">already</TOKEN>
<TOKEN id="token-50-4" pos="word" morph="none" start_char="6684" end_char="6687">been</TOKEN>
<TOKEN id="token-50-5" pos="word" morph="none" start_char="6689" end_char="6695">refuted</TOKEN>
<TOKEN id="token-50-6" pos="word" morph="none" start_char="6697" end_char="6703">several</TOKEN>
<TOKEN id="token-50-7" pos="word" morph="none" start_char="6705" end_char="6709">times</TOKEN>
<TOKEN id="token-50-8" pos="word" morph="none" start_char="6711" end_char="6715">since</TOKEN>
<TOKEN id="token-50-9" pos="word" morph="none" start_char="6717" end_char="6721">March</TOKEN>
<TOKEN id="token-50-10" pos="punct" morph="none" start_char="6722" end_char="6722">.</TOKEN>
</SEG>
<SEG id="segment-51" start_char="6724" end_char="6908">
<ORIGINAL_TEXT>Following the publication of the first defamatory video in March 2020, the court ruled in favor of the Institut Pasteur on November 2, 2020, convicting the video's author of defamation.</ORIGINAL_TEXT>
<TOKEN id="token-51-0" pos="word" morph="none" start_char="6724" end_char="6732">Following</TOKEN>
<TOKEN id="token-51-1" pos="word" morph="none" start_char="6734" end_char="6736">the</TOKEN>
<TOKEN id="token-51-2" pos="word" morph="none" start_char="6738" end_char="6748">publication</TOKEN>
<TOKEN id="token-51-3" pos="word" morph="none" start_char="6750" end_char="6751">of</TOKEN>
<TOKEN id="token-51-4" pos="word" morph="none" start_char="6753" end_char="6755">the</TOKEN>
<TOKEN id="token-51-5" pos="word" morph="none" start_char="6757" end_char="6761">first</TOKEN>
<TOKEN id="token-51-6" pos="word" morph="none" start_char="6763" end_char="6772">defamatory</TOKEN>
<TOKEN id="token-51-7" pos="word" morph="none" start_char="6774" end_char="6778">video</TOKEN>
<TOKEN id="token-51-8" pos="word" morph="none" start_char="6780" end_char="6781">in</TOKEN>
<TOKEN id="token-51-9" pos="word" morph="none" start_char="6783" end_char="6787">March</TOKEN>
<TOKEN id="token-51-10" pos="word" morph="none" start_char="6789" end_char="6792">2020</TOKEN>
<TOKEN id="token-51-11" pos="punct" morph="none" start_char="6793" end_char="6793">,</TOKEN>
<TOKEN id="token-51-12" pos="word" morph="none" start_char="6795" end_char="6797">the</TOKEN>
<TOKEN id="token-51-13" pos="word" morph="none" start_char="6799" end_char="6803">court</TOKEN>
<TOKEN id="token-51-14" pos="word" morph="none" start_char="6805" end_char="6809">ruled</TOKEN>
<TOKEN id="token-51-15" pos="word" morph="none" start_char="6811" end_char="6812">in</TOKEN>
<TOKEN id="token-51-16" pos="word" morph="none" start_char="6814" end_char="6818">favor</TOKEN>
<TOKEN id="token-51-17" pos="word" morph="none" start_char="6820" end_char="6821">of</TOKEN>
<TOKEN id="token-51-18" pos="word" morph="none" start_char="6823" end_char="6825">the</TOKEN>
<TOKEN id="token-51-19" pos="word" morph="none" start_char="6827" end_char="6834">Institut</TOKEN>
<TOKEN id="token-51-20" pos="word" morph="none" start_char="6836" end_char="6842">Pasteur</TOKEN>
<TOKEN id="token-51-21" pos="word" morph="none" start_char="6844" end_char="6845">on</TOKEN>
<TOKEN id="token-51-22" pos="word" morph="none" start_char="6847" end_char="6854">November</TOKEN>
<TOKEN id="token-51-23" pos="word" morph="none" start_char="6856" end_char="6856">2</TOKEN>
<TOKEN id="token-51-24" pos="punct" morph="none" start_char="6857" end_char="6857">,</TOKEN>
<TOKEN id="token-51-25" pos="word" morph="none" start_char="6859" end_char="6862">2020</TOKEN>
<TOKEN id="token-51-26" pos="punct" morph="none" start_char="6863" end_char="6863">,</TOKEN>
<TOKEN id="token-51-27" pos="word" morph="none" start_char="6865" end_char="6874">convicting</TOKEN>
<TOKEN id="token-51-28" pos="word" morph="none" start_char="6876" end_char="6878">the</TOKEN>
<TOKEN id="token-51-29" pos="word" morph="none" start_char="6880" end_char="6886">video's</TOKEN>
<TOKEN id="token-51-30" pos="word" morph="none" start_char="6888" end_char="6893">author</TOKEN>
<TOKEN id="token-51-31" pos="word" morph="none" start_char="6895" end_char="6896">of</TOKEN>
<TOKEN id="token-51-32" pos="word" morph="none" start_char="6898" end_char="6907">defamation</TOKEN>
<TOKEN id="token-51-33" pos="punct" morph="none" start_char="6908" end_char="6908">.</TOKEN>
</SEG>
<SEG id="segment-52" start_char="6911" end_char="7020">
<ORIGINAL_TEXT>Read the news article: COVID-19: Senlis Criminal Court convicts the author of a fake news video for defamation</ORIGINAL_TEXT>
<TOKEN id="token-52-0" pos="word" morph="none" start_char="6911" end_char="6914">Read</TOKEN>
<TOKEN id="token-52-1" pos="word" morph="none" start_char="6916" end_char="6918">the</TOKEN>
<TOKEN id="token-52-2" pos="word" morph="none" start_char="6920" end_char="6923">news</TOKEN>
<TOKEN id="token-52-3" pos="word" morph="none" start_char="6925" end_char="6931">article</TOKEN>
<TOKEN id="token-52-4" pos="punct" morph="none" start_char="6932" end_char="6932">:</TOKEN>
<TOKEN id="token-52-5" pos="unknown" morph="none" start_char="6934" end_char="6941">COVID-19</TOKEN>
<TOKEN id="token-52-6" pos="punct" morph="none" start_char="6942" end_char="6942">:</TOKEN>
<TOKEN id="token-52-7" pos="word" morph="none" start_char="6944" end_char="6949">Senlis</TOKEN>
<TOKEN id="token-52-8" pos="word" morph="none" start_char="6951" end_char="6958">Criminal</TOKEN>
<TOKEN id="token-52-9" pos="word" morph="none" start_char="6960" end_char="6964">Court</TOKEN>
<TOKEN id="token-52-10" pos="word" morph="none" start_char="6966" end_char="6973">convicts</TOKEN>
<TOKEN id="token-52-11" pos="word" morph="none" start_char="6975" end_char="6977">the</TOKEN>
<TOKEN id="token-52-12" pos="word" morph="none" start_char="6979" end_char="6984">author</TOKEN>
<TOKEN id="token-52-13" pos="word" morph="none" start_char="6986" end_char="6987">of</TOKEN>
<TOKEN id="token-52-14" pos="word" morph="none" start_char="6989" end_char="6989">a</TOKEN>
<TOKEN id="token-52-15" pos="word" morph="none" start_char="6991" end_char="6994">fake</TOKEN>
<TOKEN id="token-52-16" pos="word" morph="none" start_char="6996" end_char="6999">news</TOKEN>
<TOKEN id="token-52-17" pos="word" morph="none" start_char="7001" end_char="7005">video</TOKEN>
<TOKEN id="token-52-18" pos="word" morph="none" start_char="7007" end_char="7009">for</TOKEN>
<TOKEN id="token-52-19" pos="word" morph="none" start_char="7011" end_char="7020">defamation</TOKEN>
</SEG>
<SEG id="segment-53" start_char="7023" end_char="7314">
<ORIGINAL_TEXT>In addition to strongly refuting false allegations and clarifying the facts of the situation and the scientific basis, taking action in this way is a means of denouncing insults and threats to the Institut Pasteur's employees and scientists and preventing such incidents from happening again.</ORIGINAL_TEXT>
<TOKEN id="token-53-0" pos="word" morph="none" start_char="7023" end_char="7024">In</TOKEN>
<TOKEN id="token-53-1" pos="word" morph="none" start_char="7026" end_char="7033">addition</TOKEN>
<TOKEN id="token-53-2" pos="word" morph="none" start_char="7035" end_char="7036">to</TOKEN>
<TOKEN id="token-53-3" pos="word" morph="none" start_char="7038" end_char="7045">strongly</TOKEN>
<TOKEN id="token-53-4" pos="word" morph="none" start_char="7047" end_char="7054">refuting</TOKEN>
<TOKEN id="token-53-5" pos="word" morph="none" start_char="7056" end_char="7060">false</TOKEN>
<TOKEN id="token-53-6" pos="word" morph="none" start_char="7062" end_char="7072">allegations</TOKEN>
<TOKEN id="token-53-7" pos="word" morph="none" start_char="7074" end_char="7076">and</TOKEN>
<TOKEN id="token-53-8" pos="word" morph="none" start_char="7078" end_char="7087">clarifying</TOKEN>
<TOKEN id="token-53-9" pos="word" morph="none" start_char="7089" end_char="7091">the</TOKEN>
<TOKEN id="token-53-10" pos="word" morph="none" start_char="7093" end_char="7097">facts</TOKEN>
<TOKEN id="token-53-11" pos="word" morph="none" start_char="7099" end_char="7100">of</TOKEN>
<TOKEN id="token-53-12" pos="word" morph="none" start_char="7102" end_char="7104">the</TOKEN>
<TOKEN id="token-53-13" pos="word" morph="none" start_char="7106" end_char="7114">situation</TOKEN>
<TOKEN id="token-53-14" pos="word" morph="none" start_char="7116" end_char="7118">and</TOKEN>
<TOKEN id="token-53-15" pos="word" morph="none" start_char="7120" end_char="7122">the</TOKEN>
<TOKEN id="token-53-16" pos="word" morph="none" start_char="7124" end_char="7133">scientific</TOKEN>
<TOKEN id="token-53-17" pos="word" morph="none" start_char="7135" end_char="7139">basis</TOKEN>
<TOKEN id="token-53-18" pos="punct" morph="none" start_char="7140" end_char="7140">,</TOKEN>
<TOKEN id="token-53-19" pos="word" morph="none" start_char="7142" end_char="7147">taking</TOKEN>
<TOKEN id="token-53-20" pos="word" morph="none" start_char="7149" end_char="7154">action</TOKEN>
<TOKEN id="token-53-21" pos="word" morph="none" start_char="7156" end_char="7157">in</TOKEN>
<TOKEN id="token-53-22" pos="word" morph="none" start_char="7159" end_char="7162">this</TOKEN>
<TOKEN id="token-53-23" pos="word" morph="none" start_char="7164" end_char="7166">way</TOKEN>
<TOKEN id="token-53-24" pos="word" morph="none" start_char="7168" end_char="7169">is</TOKEN>
<TOKEN id="token-53-25" pos="word" morph="none" start_char="7171" end_char="7171">a</TOKEN>
<TOKEN id="token-53-26" pos="word" morph="none" start_char="7173" end_char="7177">means</TOKEN>
<TOKEN id="token-53-27" pos="word" morph="none" start_char="7179" end_char="7180">of</TOKEN>
<TOKEN id="token-53-28" pos="word" morph="none" start_char="7182" end_char="7191">denouncing</TOKEN>
<TOKEN id="token-53-29" pos="word" morph="none" start_char="7193" end_char="7199">insults</TOKEN>
<TOKEN id="token-53-30" pos="word" morph="none" start_char="7201" end_char="7203">and</TOKEN>
<TOKEN id="token-53-31" pos="word" morph="none" start_char="7205" end_char="7211">threats</TOKEN>
<TOKEN id="token-53-32" pos="word" morph="none" start_char="7213" end_char="7214">to</TOKEN>
<TOKEN id="token-53-33" pos="word" morph="none" start_char="7216" end_char="7218">the</TOKEN>
<TOKEN id="token-53-34" pos="word" morph="none" start_char="7220" end_char="7227">Institut</TOKEN>
<TOKEN id="token-53-35" pos="word" morph="none" start_char="7229" end_char="7237">Pasteur's</TOKEN>
<TOKEN id="token-53-36" pos="word" morph="none" start_char="7239" end_char="7247">employees</TOKEN>
<TOKEN id="token-53-37" pos="word" morph="none" start_char="7249" end_char="7251">and</TOKEN>
<TOKEN id="token-53-38" pos="word" morph="none" start_char="7253" end_char="7262">scientists</TOKEN>
<TOKEN id="token-53-39" pos="word" morph="none" start_char="7264" end_char="7266">and</TOKEN>
<TOKEN id="token-53-40" pos="word" morph="none" start_char="7268" end_char="7277">preventing</TOKEN>
<TOKEN id="token-53-41" pos="word" morph="none" start_char="7279" end_char="7282">such</TOKEN>
<TOKEN id="token-53-42" pos="word" morph="none" start_char="7284" end_char="7292">incidents</TOKEN>
<TOKEN id="token-53-43" pos="word" morph="none" start_char="7294" end_char="7297">from</TOKEN>
<TOKEN id="token-53-44" pos="word" morph="none" start_char="7299" end_char="7307">happening</TOKEN>
<TOKEN id="token-53-45" pos="word" morph="none" start_char="7309" end_char="7313">again</TOKEN>
<TOKEN id="token-53-46" pos="punct" morph="none" start_char="7314" end_char="7314">.</TOKEN>
</SEG>
<SEG id="segment-54" start_char="7317" end_char="7492">
<ORIGINAL_TEXT>If the Institut Pasteur is targeted by publicly disseminated misinformation and misleading claims, it will lodge an official complaint and do so whenever it deems it necessary.</ORIGINAL_TEXT>
<TOKEN id="token-54-0" pos="word" morph="none" start_char="7317" end_char="7318">If</TOKEN>
<TOKEN id="token-54-1" pos="word" morph="none" start_char="7320" end_char="7322">the</TOKEN>
<TOKEN id="token-54-2" pos="word" morph="none" start_char="7324" end_char="7331">Institut</TOKEN>
<TOKEN id="token-54-3" pos="word" morph="none" start_char="7333" end_char="7339">Pasteur</TOKEN>
<TOKEN id="token-54-4" pos="word" morph="none" start_char="7341" end_char="7342">is</TOKEN>
<TOKEN id="token-54-5" pos="word" morph="none" start_char="7344" end_char="7351">targeted</TOKEN>
<TOKEN id="token-54-6" pos="word" morph="none" start_char="7353" end_char="7354">by</TOKEN>
<TOKEN id="token-54-7" pos="word" morph="none" start_char="7356" end_char="7363">publicly</TOKEN>
<TOKEN id="token-54-8" pos="word" morph="none" start_char="7365" end_char="7376">disseminated</TOKEN>
<TOKEN id="token-54-9" pos="word" morph="none" start_char="7378" end_char="7391">misinformation</TOKEN>
<TOKEN id="token-54-10" pos="word" morph="none" start_char="7393" end_char="7395">and</TOKEN>
<TOKEN id="token-54-11" pos="word" morph="none" start_char="7397" end_char="7406">misleading</TOKEN>
<TOKEN id="token-54-12" pos="word" morph="none" start_char="7408" end_char="7413">claims</TOKEN>
<TOKEN id="token-54-13" pos="punct" morph="none" start_char="7414" end_char="7414">,</TOKEN>
<TOKEN id="token-54-14" pos="word" morph="none" start_char="7416" end_char="7417">it</TOKEN>
<TOKEN id="token-54-15" pos="word" morph="none" start_char="7419" end_char="7422">will</TOKEN>
<TOKEN id="token-54-16" pos="word" morph="none" start_char="7424" end_char="7428">lodge</TOKEN>
<TOKEN id="token-54-17" pos="word" morph="none" start_char="7430" end_char="7431">an</TOKEN>
<TOKEN id="token-54-18" pos="word" morph="none" start_char="7433" end_char="7440">official</TOKEN>
<TOKEN id="token-54-19" pos="word" morph="none" start_char="7442" end_char="7450">complaint</TOKEN>
<TOKEN id="token-54-20" pos="word" morph="none" start_char="7452" end_char="7454">and</TOKEN>
<TOKEN id="token-54-21" pos="word" morph="none" start_char="7456" end_char="7457">do</TOKEN>
<TOKEN id="token-54-22" pos="word" morph="none" start_char="7459" end_char="7460">so</TOKEN>
<TOKEN id="token-54-23" pos="word" morph="none" start_char="7462" end_char="7469">whenever</TOKEN>
<TOKEN id="token-54-24" pos="word" morph="none" start_char="7471" end_char="7472">it</TOKEN>
<TOKEN id="token-54-25" pos="word" morph="none" start_char="7474" end_char="7478">deems</TOKEN>
<TOKEN id="token-54-26" pos="word" morph="none" start_char="7480" end_char="7481">it</TOKEN>
<TOKEN id="token-54-27" pos="word" morph="none" start_char="7483" end_char="7491">necessary</TOKEN>
<TOKEN id="token-54-28" pos="punct" morph="none" start_char="7492" end_char="7492">.</TOKEN>
</SEG>
<SEG id="segment-55" start_char="7495" end_char="7549">
<ORIGINAL_TEXT>NO, SARS-CoV-2 wasn't created from HIV in a laboratory!</ORIGINAL_TEXT>
<TOKEN id="token-55-0" pos="word" morph="none" start_char="7495" end_char="7496">NO</TOKEN>
<TOKEN id="token-55-1" pos="punct" morph="none" start_char="7497" end_char="7497">,</TOKEN>
<TOKEN id="token-55-2" pos="unknown" morph="none" start_char="7499" end_char="7508">SARS-CoV-2</TOKEN>
<TOKEN id="token-55-3" pos="word" morph="none" start_char="7510" end_char="7515">wasn't</TOKEN>
<TOKEN id="token-55-4" pos="word" morph="none" start_char="7517" end_char="7523">created</TOKEN>
<TOKEN id="token-55-5" pos="word" morph="none" start_char="7525" end_char="7528">from</TOKEN>
<TOKEN id="token-55-6" pos="word" morph="none" start_char="7530" end_char="7532">HIV</TOKEN>
<TOKEN id="token-55-7" pos="word" morph="none" start_char="7534" end_char="7535">in</TOKEN>
<TOKEN id="token-55-8" pos="word" morph="none" start_char="7537" end_char="7537">a</TOKEN>
<TOKEN id="token-55-9" pos="word" morph="none" start_char="7539" end_char="7548">laboratory</TOKEN>
<TOKEN id="token-55-10" pos="punct" morph="none" start_char="7549" end_char="7549">!</TOKEN>
</SEG>
<SEG id="segment-56" start_char="7552" end_char="7574">
<ORIGINAL_TEXT>Text of April 18, 2020.</ORIGINAL_TEXT>
<TOKEN id="token-56-0" pos="word" morph="none" start_char="7552" end_char="7555">Text</TOKEN>
<TOKEN id="token-56-1" pos="word" morph="none" start_char="7557" end_char="7558">of</TOKEN>
<TOKEN id="token-56-2" pos="word" morph="none" start_char="7560" end_char="7564">April</TOKEN>
<TOKEN id="token-56-3" pos="word" morph="none" start_char="7566" end_char="7567">18</TOKEN>
<TOKEN id="token-56-4" pos="punct" morph="none" start_char="7568" end_char="7568">,</TOKEN>
<TOKEN id="token-56-5" pos="word" morph="none" start_char="7570" end_char="7573">2020</TOKEN>
<TOKEN id="token-56-6" pos="punct" morph="none" start_char="7574" end_char="7574">.</TOKEN>
</SEG>
<SEG id="segment-57" start_char="7577" end_char="7600">
<ORIGINAL_TEXT>Updated December 1, 2020</ORIGINAL_TEXT>
<TOKEN id="token-57-0" pos="word" morph="none" start_char="7577" end_char="7583">Updated</TOKEN>
<TOKEN id="token-57-1" pos="word" morph="none" start_char="7585" end_char="7592">December</TOKEN>
<TOKEN id="token-57-2" pos="word" morph="none" start_char="7594" end_char="7594">1</TOKEN>
<TOKEN id="token-57-3" pos="punct" morph="none" start_char="7595" end_char="7595">,</TOKEN>
<TOKEN id="token-57-4" pos="word" morph="none" start_char="7597" end_char="7600">2020</TOKEN>
</SEG>
<SEG id="segment-58" start_char="7604" end_char="7726">
<ORIGINAL_TEXT>A new controversy has emerged following claims that SARS-CoV-2 is the result of human error in a BSL-4 laboratory in Wuhan.</ORIGINAL_TEXT>
<TOKEN id="token-58-0" pos="word" morph="none" start_char="7604" end_char="7604">A</TOKEN>
<TOKEN id="token-58-1" pos="word" morph="none" start_char="7606" end_char="7608">new</TOKEN>
<TOKEN id="token-58-2" pos="word" morph="none" start_char="7610" end_char="7620">controversy</TOKEN>
<TOKEN id="token-58-3" pos="word" morph="none" start_char="7622" end_char="7624">has</TOKEN>
<TOKEN id="token-58-4" pos="word" morph="none" start_char="7626" end_char="7632">emerged</TOKEN>
<TOKEN id="token-58-5" pos="word" morph="none" start_char="7634" end_char="7642">following</TOKEN>
<TOKEN id="token-58-6" pos="word" morph="none" start_char="7644" end_char="7649">claims</TOKEN>
<TOKEN id="token-58-7" pos="word" morph="none" start_char="7651" end_char="7654">that</TOKEN>
<TOKEN id="token-58-8" pos="unknown" morph="none" start_char="7656" end_char="7665">SARS-CoV-2</TOKEN>
<TOKEN id="token-58-9" pos="word" morph="none" start_char="7667" end_char="7668">is</TOKEN>
<TOKEN id="token-58-10" pos="word" morph="none" start_char="7670" end_char="7672">the</TOKEN>
<TOKEN id="token-58-11" pos="word" morph="none" start_char="7674" end_char="7679">result</TOKEN>
<TOKEN id="token-58-12" pos="word" morph="none" start_char="7681" end_char="7682">of</TOKEN>
<TOKEN id="token-58-13" pos="word" morph="none" start_char="7684" end_char="7688">human</TOKEN>
<TOKEN id="token-58-14" pos="word" morph="none" start_char="7690" end_char="7694">error</TOKEN>
<TOKEN id="token-58-15" pos="word" morph="none" start_char="7696" end_char="7697">in</TOKEN>
<TOKEN id="token-58-16" pos="word" morph="none" start_char="7699" end_char="7699">a</TOKEN>
<TOKEN id="token-58-17" pos="unknown" morph="none" start_char="7701" end_char="7705">BSL-4</TOKEN>
<TOKEN id="token-58-18" pos="word" morph="none" start_char="7707" end_char="7716">laboratory</TOKEN>
<TOKEN id="token-58-19" pos="word" morph="none" start_char="7718" end_char="7719">in</TOKEN>
<TOKEN id="token-58-20" pos="word" morph="none" start_char="7721" end_char="7725">Wuhan</TOKEN>
<TOKEN id="token-58-21" pos="punct" morph="none" start_char="7726" end_char="7726">.</TOKEN>
</SEG>
<SEG id="segment-59" start_char="7728" end_char="7841">
<ORIGINAL_TEXT>While carrying out research on an HIV vaccine, scientists are said to have accidentally let this new virus escape.</ORIGINAL_TEXT>
<TOKEN id="token-59-0" pos="word" morph="none" start_char="7728" end_char="7732">While</TOKEN>
<TOKEN id="token-59-1" pos="word" morph="none" start_char="7734" end_char="7741">carrying</TOKEN>
<TOKEN id="token-59-2" pos="word" morph="none" start_char="7743" end_char="7745">out</TOKEN>
<TOKEN id="token-59-3" pos="word" morph="none" start_char="7747" end_char="7754">research</TOKEN>
<TOKEN id="token-59-4" pos="word" morph="none" start_char="7756" end_char="7757">on</TOKEN>
<TOKEN id="token-59-5" pos="word" morph="none" start_char="7759" end_char="7760">an</TOKEN>
<TOKEN id="token-59-6" pos="word" morph="none" start_char="7762" end_char="7764">HIV</TOKEN>
<TOKEN id="token-59-7" pos="word" morph="none" start_char="7766" end_char="7772">vaccine</TOKEN>
<TOKEN id="token-59-8" pos="punct" morph="none" start_char="7773" end_char="7773">,</TOKEN>
<TOKEN id="token-59-9" pos="word" morph="none" start_char="7775" end_char="7784">scientists</TOKEN>
<TOKEN id="token-59-10" pos="word" morph="none" start_char="7786" end_char="7788">are</TOKEN>
<TOKEN id="token-59-11" pos="word" morph="none" start_char="7790" end_char="7793">said</TOKEN>
<TOKEN id="token-59-12" pos="word" morph="none" start_char="7795" end_char="7796">to</TOKEN>
<TOKEN id="token-59-13" pos="word" morph="none" start_char="7798" end_char="7801">have</TOKEN>
<TOKEN id="token-59-14" pos="word" morph="none" start_char="7803" end_char="7814">accidentally</TOKEN>
<TOKEN id="token-59-15" pos="word" morph="none" start_char="7816" end_char="7818">let</TOKEN>
<TOKEN id="token-59-16" pos="word" morph="none" start_char="7820" end_char="7823">this</TOKEN>
<TOKEN id="token-59-17" pos="word" morph="none" start_char="7825" end_char="7827">new</TOKEN>
<TOKEN id="token-59-18" pos="word" morph="none" start_char="7829" end_char="7833">virus</TOKEN>
<TOKEN id="token-59-19" pos="word" morph="none" start_char="7835" end_char="7840">escape</TOKEN>
<TOKEN id="token-59-20" pos="punct" morph="none" start_char="7841" end_char="7841">.</TOKEN>
</SEG>
<SEG id="segment-60" start_char="7843" end_char="8052">
<ORIGINAL_TEXT>One piece of evidence held up to support the theory is that the SARS-CoV-2 genome contains sequences that correspond to HIV, a hypothesis that is said to have been validated by an Indian scientific publication.</ORIGINAL_TEXT>
<TOKEN id="token-60-0" pos="word" morph="none" start_char="7843" end_char="7845">One</TOKEN>
<TOKEN id="token-60-1" pos="word" morph="none" start_char="7847" end_char="7851">piece</TOKEN>
<TOKEN id="token-60-2" pos="word" morph="none" start_char="7853" end_char="7854">of</TOKEN>
<TOKEN id="token-60-3" pos="word" morph="none" start_char="7856" end_char="7863">evidence</TOKEN>
<TOKEN id="token-60-4" pos="word" morph="none" start_char="7865" end_char="7868">held</TOKEN>
<TOKEN id="token-60-5" pos="word" morph="none" start_char="7870" end_char="7871">up</TOKEN>
<TOKEN id="token-60-6" pos="word" morph="none" start_char="7873" end_char="7874">to</TOKEN>
<TOKEN id="token-60-7" pos="word" morph="none" start_char="7876" end_char="7882">support</TOKEN>
<TOKEN id="token-60-8" pos="word" morph="none" start_char="7884" end_char="7886">the</TOKEN>
<TOKEN id="token-60-9" pos="word" morph="none" start_char="7888" end_char="7893">theory</TOKEN>
<TOKEN id="token-60-10" pos="word" morph="none" start_char="7895" end_char="7896">is</TOKEN>
<TOKEN id="token-60-11" pos="word" morph="none" start_char="7898" end_char="7901">that</TOKEN>
<TOKEN id="token-60-12" pos="word" morph="none" start_char="7903" end_char="7905">the</TOKEN>
<TOKEN id="token-60-13" pos="unknown" morph="none" start_char="7907" end_char="7916">SARS-CoV-2</TOKEN>
<TOKEN id="token-60-14" pos="word" morph="none" start_char="7918" end_char="7923">genome</TOKEN>
<TOKEN id="token-60-15" pos="word" morph="none" start_char="7925" end_char="7932">contains</TOKEN>
<TOKEN id="token-60-16" pos="word" morph="none" start_char="7934" end_char="7942">sequences</TOKEN>
<TOKEN id="token-60-17" pos="word" morph="none" start_char="7944" end_char="7947">that</TOKEN>
<TOKEN id="token-60-18" pos="word" morph="none" start_char="7949" end_char="7958">correspond</TOKEN>
<TOKEN id="token-60-19" pos="word" morph="none" start_char="7960" end_char="7961">to</TOKEN>
<TOKEN id="token-60-20" pos="word" morph="none" start_char="7963" end_char="7965">HIV</TOKEN>
<TOKEN id="token-60-21" pos="punct" morph="none" start_char="7966" end_char="7966">,</TOKEN>
<TOKEN id="token-60-22" pos="word" morph="none" start_char="7968" end_char="7968">a</TOKEN>
<TOKEN id="token-60-23" pos="word" morph="none" start_char="7970" end_char="7979">hypothesis</TOKEN>
<TOKEN id="token-60-24" pos="word" morph="none" start_char="7981" end_char="7984">that</TOKEN>
<TOKEN id="token-60-25" pos="word" morph="none" start_char="7986" end_char="7987">is</TOKEN>
<TOKEN id="token-60-26" pos="word" morph="none" start_char="7989" end_char="7992">said</TOKEN>
<TOKEN id="token-60-27" pos="word" morph="none" start_char="7994" end_char="7995">to</TOKEN>
<TOKEN id="token-60-28" pos="word" morph="none" start_char="7997" end_char="8000">have</TOKEN>
<TOKEN id="token-60-29" pos="word" morph="none" start_char="8002" end_char="8005">been</TOKEN>
<TOKEN id="token-60-30" pos="word" morph="none" start_char="8007" end_char="8015">validated</TOKEN>
<TOKEN id="token-60-31" pos="word" morph="none" start_char="8017" end_char="8018">by</TOKEN>
<TOKEN id="token-60-32" pos="word" morph="none" start_char="8020" end_char="8021">an</TOKEN>
<TOKEN id="token-60-33" pos="word" morph="none" start_char="8023" end_char="8028">Indian</TOKEN>
<TOKEN id="token-60-34" pos="word" morph="none" start_char="8030" end_char="8039">scientific</TOKEN>
<TOKEN id="token-60-35" pos="word" morph="none" start_char="8041" end_char="8051">publication</TOKEN>
<TOKEN id="token-60-36" pos="punct" morph="none" start_char="8052" end_char="8052">.</TOKEN>
</SEG>
<SEG id="segment-61" start_char="8056" end_char="8127">
<ORIGINAL_TEXT>The homologies between the HIV and SARS-CoV-2 sequences are meaningless.</ORIGINAL_TEXT>
<TOKEN id="token-61-0" pos="word" morph="none" start_char="8056" end_char="8058">The</TOKEN>
<TOKEN id="token-61-1" pos="word" morph="none" start_char="8060" end_char="8069">homologies</TOKEN>
<TOKEN id="token-61-2" pos="word" morph="none" start_char="8071" end_char="8077">between</TOKEN>
<TOKEN id="token-61-3" pos="word" morph="none" start_char="8079" end_char="8081">the</TOKEN>
<TOKEN id="token-61-4" pos="word" morph="none" start_char="8083" end_char="8085">HIV</TOKEN>
<TOKEN id="token-61-5" pos="word" morph="none" start_char="8087" end_char="8089">and</TOKEN>
<TOKEN id="token-61-6" pos="unknown" morph="none" start_char="8091" end_char="8100">SARS-CoV-2</TOKEN>
<TOKEN id="token-61-7" pos="word" morph="none" start_char="8102" end_char="8110">sequences</TOKEN>
<TOKEN id="token-61-8" pos="word" morph="none" start_char="8112" end_char="8114">are</TOKEN>
<TOKEN id="token-61-9" pos="word" morph="none" start_char="8116" end_char="8126">meaningless</TOKEN>
<TOKEN id="token-61-10" pos="punct" morph="none" start_char="8127" end_char="8127">.</TOKEN>
</SEG>
<SEG id="segment-62" start_char="8133" end_char="8234">
<ORIGINAL_TEXT>This theory is based on a misinterpretation of an article that appeared for a short time on a website.</ORIGINAL_TEXT>
<TOKEN id="token-62-0" pos="word" morph="none" start_char="8133" end_char="8136">This</TOKEN>
<TOKEN id="token-62-1" pos="word" morph="none" start_char="8138" end_char="8143">theory</TOKEN>
<TOKEN id="token-62-2" pos="word" morph="none" start_char="8145" end_char="8146">is</TOKEN>
<TOKEN id="token-62-3" pos="word" morph="none" start_char="8148" end_char="8152">based</TOKEN>
<TOKEN id="token-62-4" pos="word" morph="none" start_char="8154" end_char="8155">on</TOKEN>
<TOKEN id="token-62-5" pos="word" morph="none" start_char="8157" end_char="8157">a</TOKEN>
<TOKEN id="token-62-6" pos="word" morph="none" start_char="8159" end_char="8175">misinterpretation</TOKEN>
<TOKEN id="token-62-7" pos="word" morph="none" start_char="8177" end_char="8178">of</TOKEN>
<TOKEN id="token-62-8" pos="word" morph="none" start_char="8180" end_char="8181">an</TOKEN>
<TOKEN id="token-62-9" pos="word" morph="none" start_char="8183" end_char="8189">article</TOKEN>
<TOKEN id="token-62-10" pos="word" morph="none" start_char="8191" end_char="8194">that</TOKEN>
<TOKEN id="token-62-11" pos="word" morph="none" start_char="8196" end_char="8203">appeared</TOKEN>
<TOKEN id="token-62-12" pos="word" morph="none" start_char="8205" end_char="8207">for</TOKEN>
<TOKEN id="token-62-13" pos="word" morph="none" start_char="8209" end_char="8209">a</TOKEN>
<TOKEN id="token-62-14" pos="word" morph="none" start_char="8211" end_char="8215">short</TOKEN>
<TOKEN id="token-62-15" pos="word" morph="none" start_char="8217" end_char="8220">time</TOKEN>
<TOKEN id="token-62-16" pos="word" morph="none" start_char="8222" end_char="8223">on</TOKEN>
<TOKEN id="token-62-17" pos="word" morph="none" start_char="8225" end_char="8225">a</TOKEN>
<TOKEN id="token-62-18" pos="word" morph="none" start_char="8227" end_char="8233">website</TOKEN>
<TOKEN id="token-62-19" pos="punct" morph="none" start_char="8234" end_char="8234">.</TOKEN>
</SEG>
<SEG id="segment-63" start_char="8236" end_char="8409">
<ORIGINAL_TEXT>The research contained multiple methodological errors and inaccuracies that were subsequently exposed by the scientific community, leading the authors to retract the article.</ORIGINAL_TEXT>
<TOKEN id="token-63-0" pos="word" morph="none" start_char="8236" end_char="8238">The</TOKEN>
<TOKEN id="token-63-1" pos="word" morph="none" start_char="8240" end_char="8247">research</TOKEN>
<TOKEN id="token-63-2" pos="word" morph="none" start_char="8249" end_char="8257">contained</TOKEN>
<TOKEN id="token-63-3" pos="word" morph="none" start_char="8259" end_char="8266">multiple</TOKEN>
<TOKEN id="token-63-4" pos="word" morph="none" start_char="8268" end_char="8281">methodological</TOKEN>
<TOKEN id="token-63-5" pos="word" morph="none" start_char="8283" end_char="8288">errors</TOKEN>
<TOKEN id="token-63-6" pos="word" morph="none" start_char="8290" end_char="8292">and</TOKEN>
<TOKEN id="token-63-7" pos="word" morph="none" start_char="8294" end_char="8305">inaccuracies</TOKEN>
<TOKEN id="token-63-8" pos="word" morph="none" start_char="8307" end_char="8310">that</TOKEN>
<TOKEN id="token-63-9" pos="word" morph="none" start_char="8312" end_char="8315">were</TOKEN>
<TOKEN id="token-63-10" pos="word" morph="none" start_char="8317" end_char="8328">subsequently</TOKEN>
<TOKEN id="token-63-11" pos="word" morph="none" start_char="8330" end_char="8336">exposed</TOKEN>
<TOKEN id="token-63-12" pos="word" morph="none" start_char="8338" end_char="8339">by</TOKEN>
<TOKEN id="token-63-13" pos="word" morph="none" start_char="8341" end_char="8343">the</TOKEN>
<TOKEN id="token-63-14" pos="word" morph="none" start_char="8345" end_char="8354">scientific</TOKEN>
<TOKEN id="token-63-15" pos="word" morph="none" start_char="8356" end_char="8364">community</TOKEN>
<TOKEN id="token-63-16" pos="punct" morph="none" start_char="8365" end_char="8365">,</TOKEN>
<TOKEN id="token-63-17" pos="word" morph="none" start_char="8367" end_char="8373">leading</TOKEN>
<TOKEN id="token-63-18" pos="word" morph="none" start_char="8375" end_char="8377">the</TOKEN>
<TOKEN id="token-63-19" pos="word" morph="none" start_char="8379" end_char="8385">authors</TOKEN>
<TOKEN id="token-63-20" pos="word" morph="none" start_char="8387" end_char="8388">to</TOKEN>
<TOKEN id="token-63-21" pos="word" morph="none" start_char="8390" end_char="8396">retract</TOKEN>
<TOKEN id="token-63-22" pos="word" morph="none" start_char="8398" end_char="8400">the</TOKEN>
<TOKEN id="token-63-23" pos="word" morph="none" start_char="8402" end_char="8408">article</TOKEN>
<TOKEN id="token-63-24" pos="punct" morph="none" start_char="8409" end_char="8409">.</TOKEN>
</SEG>
<SEG id="segment-64" start_char="8415" end_char="8485">
<ORIGINAL_TEXT>There is no evidence that SARS-CoV-2 coronavirus was created by humans.</ORIGINAL_TEXT>
<TOKEN id="token-64-0" pos="word" morph="none" start_char="8415" end_char="8419">There</TOKEN>
<TOKEN id="token-64-1" pos="word" morph="none" start_char="8421" end_char="8422">is</TOKEN>
<TOKEN id="token-64-2" pos="word" morph="none" start_char="8424" end_char="8425">no</TOKEN>
<TOKEN id="token-64-3" pos="word" morph="none" start_char="8427" end_char="8434">evidence</TOKEN>
<TOKEN id="token-64-4" pos="word" morph="none" start_char="8436" end_char="8439">that</TOKEN>
<TOKEN id="token-64-5" pos="unknown" morph="none" start_char="8441" end_char="8450">SARS-CoV-2</TOKEN>
<TOKEN id="token-64-6" pos="word" morph="none" start_char="8452" end_char="8462">coronavirus</TOKEN>
<TOKEN id="token-64-7" pos="word" morph="none" start_char="8464" end_char="8466">was</TOKEN>
<TOKEN id="token-64-8" pos="word" morph="none" start_char="8468" end_char="8474">created</TOKEN>
<TOKEN id="token-64-9" pos="word" morph="none" start_char="8476" end_char="8477">by</TOKEN>
<TOKEN id="token-64-10" pos="word" morph="none" start_char="8479" end_char="8484">humans</TOKEN>
<TOKEN id="token-64-11" pos="punct" morph="none" start_char="8485" end_char="8485">.</TOKEN>
</SEG>
<SEG id="segment-65" start_char="8491" end_char="8502">
<ORIGINAL_TEXT>Explanations</ORIGINAL_TEXT>
<TOKEN id="token-65-0" pos="word" morph="none" start_char="8491" end_char="8502">Explanations</TOKEN>
</SEG>
<SEG id="segment-66" start_char="8506" end_char="8589">
<ORIGINAL_TEXT>1 _ Any homologies that exist between the HIV and SARS-CoV-2 genomes are meaningless</ORIGINAL_TEXT>
<TOKEN id="token-66-0" pos="word" morph="none" start_char="8506" end_char="8506">1</TOKEN>
<TOKEN id="token-66-1" pos="word" morph="none" start_char="8508" end_char="8508">_</TOKEN>
<TOKEN id="token-66-2" pos="word" morph="none" start_char="8510" end_char="8512">Any</TOKEN>
<TOKEN id="token-66-3" pos="word" morph="none" start_char="8514" end_char="8523">homologies</TOKEN>
<TOKEN id="token-66-4" pos="word" morph="none" start_char="8525" end_char="8528">that</TOKEN>
<TOKEN id="token-66-5" pos="word" morph="none" start_char="8530" end_char="8534">exist</TOKEN>
<TOKEN id="token-66-6" pos="word" morph="none" start_char="8536" end_char="8542">between</TOKEN>
<TOKEN id="token-66-7" pos="word" morph="none" start_char="8544" end_char="8546">the</TOKEN>
<TOKEN id="token-66-8" pos="word" morph="none" start_char="8548" end_char="8550">HIV</TOKEN>
<TOKEN id="token-66-9" pos="word" morph="none" start_char="8552" end_char="8554">and</TOKEN>
<TOKEN id="token-66-10" pos="unknown" morph="none" start_char="8556" end_char="8565">SARS-CoV-2</TOKEN>
<TOKEN id="token-66-11" pos="word" morph="none" start_char="8567" end_char="8573">genomes</TOKEN>
<TOKEN id="token-66-12" pos="word" morph="none" start_char="8575" end_char="8577">are</TOKEN>
<TOKEN id="token-66-13" pos="word" morph="none" start_char="8579" end_char="8589">meaningless</TOKEN>
</SEG>
<SEG id="segment-67" start_char="8593" end_char="8772">
<ORIGINAL_TEXT>Although it is true that there is in the genome of the SARS-CoV-2 coronavirus, a sequence also present in the genome of HIV, this does not mean that SARS-CoV-2 is derived from HIV.</ORIGINAL_TEXT>
<TOKEN id="token-67-0" pos="word" morph="none" start_char="8593" end_char="8600">Although</TOKEN>
<TOKEN id="token-67-1" pos="word" morph="none" start_char="8602" end_char="8603">it</TOKEN>
<TOKEN id="token-67-2" pos="word" morph="none" start_char="8605" end_char="8606">is</TOKEN>
<TOKEN id="token-67-3" pos="word" morph="none" start_char="8608" end_char="8611">true</TOKEN>
<TOKEN id="token-67-4" pos="word" morph="none" start_char="8613" end_char="8616">that</TOKEN>
<TOKEN id="token-67-5" pos="word" morph="none" start_char="8618" end_char="8622">there</TOKEN>
<TOKEN id="token-67-6" pos="word" morph="none" start_char="8624" end_char="8625">is</TOKEN>
<TOKEN id="token-67-7" pos="word" morph="none" start_char="8627" end_char="8628">in</TOKEN>
<TOKEN id="token-67-8" pos="word" morph="none" start_char="8630" end_char="8632">the</TOKEN>
<TOKEN id="token-67-9" pos="word" morph="none" start_char="8634" end_char="8639">genome</TOKEN>
<TOKEN id="token-67-10" pos="word" morph="none" start_char="8641" end_char="8642">of</TOKEN>
<TOKEN id="token-67-11" pos="word" morph="none" start_char="8644" end_char="8646">the</TOKEN>
<TOKEN id="token-67-12" pos="unknown" morph="none" start_char="8648" end_char="8657">SARS-CoV-2</TOKEN>
<TOKEN id="token-67-13" pos="word" morph="none" start_char="8659" end_char="8669">coronavirus</TOKEN>
<TOKEN id="token-67-14" pos="punct" morph="none" start_char="8670" end_char="8670">,</TOKEN>
<TOKEN id="token-67-15" pos="word" morph="none" start_char="8672" end_char="8672">a</TOKEN>
<TOKEN id="token-67-16" pos="word" morph="none" start_char="8674" end_char="8681">sequence</TOKEN>
<TOKEN id="token-67-17" pos="word" morph="none" start_char="8683" end_char="8686">also</TOKEN>
<TOKEN id="token-67-18" pos="word" morph="none" start_char="8688" end_char="8694">present</TOKEN>
<TOKEN id="token-67-19" pos="word" morph="none" start_char="8696" end_char="8697">in</TOKEN>
<TOKEN id="token-67-20" pos="word" morph="none" start_char="8699" end_char="8701">the</TOKEN>
<TOKEN id="token-67-21" pos="word" morph="none" start_char="8703" end_char="8708">genome</TOKEN>
<TOKEN id="token-67-22" pos="word" morph="none" start_char="8710" end_char="8711">of</TOKEN>
<TOKEN id="token-67-23" pos="word" morph="none" start_char="8713" end_char="8715">HIV</TOKEN>
<TOKEN id="token-67-24" pos="punct" morph="none" start_char="8716" end_char="8716">,</TOKEN>
<TOKEN id="token-67-25" pos="word" morph="none" start_char="8718" end_char="8721">this</TOKEN>
<TOKEN id="token-67-26" pos="word" morph="none" start_char="8723" end_char="8726">does</TOKEN>
<TOKEN id="token-67-27" pos="word" morph="none" start_char="8728" end_char="8730">not</TOKEN>
<TOKEN id="token-67-28" pos="word" morph="none" start_char="8732" end_char="8735">mean</TOKEN>
<TOKEN id="token-67-29" pos="word" morph="none" start_char="8737" end_char="8740">that</TOKEN>
<TOKEN id="token-67-30" pos="unknown" morph="none" start_char="8742" end_char="8751">SARS-CoV-2</TOKEN>
<TOKEN id="token-67-31" pos="word" morph="none" start_char="8753" end_char="8754">is</TOKEN>
<TOKEN id="token-67-32" pos="word" morph="none" start_char="8756" end_char="8762">derived</TOKEN>
<TOKEN id="token-67-33" pos="word" morph="none" start_char="8764" end_char="8767">from</TOKEN>
<TOKEN id="token-67-34" pos="word" morph="none" start_char="8769" end_char="8771">HIV</TOKEN>
<TOKEN id="token-67-35" pos="punct" morph="none" start_char="8772" end_char="8772">.</TOKEN>
</SEG>
<SEG id="segment-68" start_char="8775" end_char="8775">
<ORIGINAL_TEXT>"</ORIGINAL_TEXT>
<TOKEN id="token-68-0" pos="punct" morph="none" start_char="8775" end_char="8775">"</TOKEN>
</SEG>
<SEG id="segment-69" start_char="8778" end_char="8831">
<ORIGINAL_TEXT>Genetic sequences are composed of a series of letters.</ORIGINAL_TEXT>
<TOKEN id="token-69-0" pos="word" morph="none" start_char="8778" end_char="8784">Genetic</TOKEN>
<TOKEN id="token-69-1" pos="word" morph="none" start_char="8786" end_char="8794">sequences</TOKEN>
<TOKEN id="token-69-2" pos="word" morph="none" start_char="8796" end_char="8798">are</TOKEN>
<TOKEN id="token-69-3" pos="word" morph="none" start_char="8800" end_char="8807">composed</TOKEN>
<TOKEN id="token-69-4" pos="word" morph="none" start_char="8809" end_char="8810">of</TOKEN>
<TOKEN id="token-69-5" pos="word" morph="none" start_char="8812" end_char="8812">a</TOKEN>
<TOKEN id="token-69-6" pos="word" morph="none" start_char="8814" end_char="8819">series</TOKEN>
<TOKEN id="token-69-7" pos="word" morph="none" start_char="8821" end_char="8822">of</TOKEN>
<TOKEN id="token-69-8" pos="word" morph="none" start_char="8824" end_char="8830">letters</TOKEN>
<TOKEN id="token-69-9" pos="punct" morph="none" start_char="8831" end_char="8831">.</TOKEN>
</SEG>
<SEG id="segment-70" start_char="8833" end_char="8999">
<ORIGINAL_TEXT>If we examine a very short series of letters taken at random in a sequence, they may resemble a small fragment of another sequence without there being any direct link.</ORIGINAL_TEXT>
<TOKEN id="token-70-0" pos="word" morph="none" start_char="8833" end_char="8834">If</TOKEN>
<TOKEN id="token-70-1" pos="word" morph="none" start_char="8836" end_char="8837">we</TOKEN>
<TOKEN id="token-70-2" pos="word" morph="none" start_char="8839" end_char="8845">examine</TOKEN>
<TOKEN id="token-70-3" pos="word" morph="none" start_char="8847" end_char="8847">a</TOKEN>
<TOKEN id="token-70-4" pos="word" morph="none" start_char="8849" end_char="8852">very</TOKEN>
<TOKEN id="token-70-5" pos="word" morph="none" start_char="8854" end_char="8858">short</TOKEN>
<TOKEN id="token-70-6" pos="word" morph="none" start_char="8860" end_char="8865">series</TOKEN>
<TOKEN id="token-70-7" pos="word" morph="none" start_char="8867" end_char="8868">of</TOKEN>
<TOKEN id="token-70-8" pos="word" morph="none" start_char="8870" end_char="8876">letters</TOKEN>
<TOKEN id="token-70-9" pos="word" morph="none" start_char="8878" end_char="8882">taken</TOKEN>
<TOKEN id="token-70-10" pos="word" morph="none" start_char="8884" end_char="8885">at</TOKEN>
<TOKEN id="token-70-11" pos="word" morph="none" start_char="8887" end_char="8892">random</TOKEN>
<TOKEN id="token-70-12" pos="word" morph="none" start_char="8894" end_char="8895">in</TOKEN>
<TOKEN id="token-70-13" pos="word" morph="none" start_char="8897" end_char="8897">a</TOKEN>
<TOKEN id="token-70-14" pos="word" morph="none" start_char="8899" end_char="8906">sequence</TOKEN>
<TOKEN id="token-70-15" pos="punct" morph="none" start_char="8907" end_char="8907">,</TOKEN>
<TOKEN id="token-70-16" pos="word" morph="none" start_char="8909" end_char="8912">they</TOKEN>
<TOKEN id="token-70-17" pos="word" morph="none" start_char="8914" end_char="8916">may</TOKEN>
<TOKEN id="token-70-18" pos="word" morph="none" start_char="8918" end_char="8925">resemble</TOKEN>
<TOKEN id="token-70-19" pos="word" morph="none" start_char="8927" end_char="8927">a</TOKEN>
<TOKEN id="token-70-20" pos="word" morph="none" start_char="8929" end_char="8933">small</TOKEN>
<TOKEN id="token-70-21" pos="word" morph="none" start_char="8935" end_char="8942">fragment</TOKEN>
<TOKEN id="token-70-22" pos="word" morph="none" start_char="8944" end_char="8945">of</TOKEN>
<TOKEN id="token-70-23" pos="word" morph="none" start_char="8947" end_char="8953">another</TOKEN>
<TOKEN id="token-70-24" pos="word" morph="none" start_char="8955" end_char="8962">sequence</TOKEN>
<TOKEN id="token-70-25" pos="word" morph="none" start_char="8964" end_char="8970">without</TOKEN>
<TOKEN id="token-70-26" pos="word" morph="none" start_char="8972" end_char="8976">there</TOKEN>
<TOKEN id="token-70-27" pos="word" morph="none" start_char="8978" end_char="8982">being</TOKEN>
<TOKEN id="token-70-28" pos="word" morph="none" start_char="8984" end_char="8986">any</TOKEN>
<TOKEN id="token-70-29" pos="word" morph="none" start_char="8988" end_char="8993">direct</TOKEN>
<TOKEN id="token-70-30" pos="word" morph="none" start_char="8995" end_char="8998">link</TOKEN>
<TOKEN id="token-70-31" pos="punct" morph="none" start_char="8999" end_char="8999">.</TOKEN>
</SEG>
<SEG id="segment-71" start_char="9001" end_char="9109">
<ORIGINAL_TEXT>Imagine taking a book and choosing a word, and then finding that the same word was also used in another book.</ORIGINAL_TEXT>
<TOKEN id="token-71-0" pos="word" morph="none" start_char="9001" end_char="9007">Imagine</TOKEN>
<TOKEN id="token-71-1" pos="word" morph="none" start_char="9009" end_char="9014">taking</TOKEN>
<TOKEN id="token-71-2" pos="word" morph="none" start_char="9016" end_char="9016">a</TOKEN>
<TOKEN id="token-71-3" pos="word" morph="none" start_char="9018" end_char="9021">book</TOKEN>
<TOKEN id="token-71-4" pos="word" morph="none" start_char="9023" end_char="9025">and</TOKEN>
<TOKEN id="token-71-5" pos="word" morph="none" start_char="9027" end_char="9034">choosing</TOKEN>
<TOKEN id="token-71-6" pos="word" morph="none" start_char="9036" end_char="9036">a</TOKEN>
<TOKEN id="token-71-7" pos="word" morph="none" start_char="9038" end_char="9041">word</TOKEN>
<TOKEN id="token-71-8" pos="punct" morph="none" start_char="9042" end_char="9042">,</TOKEN>
<TOKEN id="token-71-9" pos="word" morph="none" start_char="9044" end_char="9046">and</TOKEN>
<TOKEN id="token-71-10" pos="word" morph="none" start_char="9048" end_char="9051">then</TOKEN>
<TOKEN id="token-71-11" pos="word" morph="none" start_char="9053" end_char="9059">finding</TOKEN>
<TOKEN id="token-71-12" pos="word" morph="none" start_char="9061" end_char="9064">that</TOKEN>
<TOKEN id="token-71-13" pos="word" morph="none" start_char="9066" end_char="9068">the</TOKEN>
<TOKEN id="token-71-14" pos="word" morph="none" start_char="9070" end_char="9073">same</TOKEN>
<TOKEN id="token-71-15" pos="word" morph="none" start_char="9075" end_char="9078">word</TOKEN>
<TOKEN id="token-71-16" pos="word" morph="none" start_char="9080" end_char="9082">was</TOKEN>
<TOKEN id="token-71-17" pos="word" morph="none" start_char="9084" end_char="9087">also</TOKEN>
<TOKEN id="token-71-18" pos="word" morph="none" start_char="9089" end_char="9092">used</TOKEN>
<TOKEN id="token-71-19" pos="word" morph="none" start_char="9094" end_char="9095">in</TOKEN>
<TOKEN id="token-71-20" pos="word" morph="none" start_char="9097" end_char="9103">another</TOKEN>
<TOKEN id="token-71-21" pos="word" morph="none" start_char="9105" end_char="9108">book</TOKEN>
<TOKEN id="token-71-22" pos="punct" morph="none" start_char="9109" end_char="9109">.</TOKEN>
</SEG>
<SEG id="segment-72" start_char="9111" end_char="9161">
<ORIGINAL_TEXT>That does not mean that one book copied the other!"</ORIGINAL_TEXT>
<TOKEN id="token-72-0" pos="word" morph="none" start_char="9111" end_char="9114">That</TOKEN>
<TOKEN id="token-72-1" pos="word" morph="none" start_char="9116" end_char="9119">does</TOKEN>
<TOKEN id="token-72-2" pos="word" morph="none" start_char="9121" end_char="9123">not</TOKEN>
<TOKEN id="token-72-3" pos="word" morph="none" start_char="9125" end_char="9128">mean</TOKEN>
<TOKEN id="token-72-4" pos="word" morph="none" start_char="9130" end_char="9133">that</TOKEN>
<TOKEN id="token-72-5" pos="word" morph="none" start_char="9135" end_char="9137">one</TOKEN>
<TOKEN id="token-72-6" pos="word" morph="none" start_char="9139" end_char="9142">book</TOKEN>
<TOKEN id="token-72-7" pos="word" morph="none" start_char="9144" end_char="9149">copied</TOKEN>
<TOKEN id="token-72-8" pos="word" morph="none" start_char="9151" end_char="9153">the</TOKEN>
<TOKEN id="token-72-9" pos="word" morph="none" start_char="9155" end_char="9159">other</TOKEN>
<TOKEN id="token-72-10" pos="punct" morph="none" start_char="9160" end_char="9161">!"</TOKEN>
</SEG>
<SEG id="segment-73" start_char="9164" end_char="9284">
<ORIGINAL_TEXT>explains Etienne Simon-Lorire, Head of the Evolutionary Genomics of RNA Viruses five-year group at the Institut Pasteur.</ORIGINAL_TEXT>
<TOKEN id="token-73-0" pos="word" morph="none" start_char="9164" end_char="9171">explains</TOKEN>
<TOKEN id="token-73-1" pos="word" morph="none" start_char="9173" end_char="9179">Etienne</TOKEN>
<TOKEN id="token-73-2" pos="unknown" morph="none" start_char="9181" end_char="9193">Simon-Lorire</TOKEN>
<TOKEN id="token-73-3" pos="punct" morph="none" start_char="9194" end_char="9194">,</TOKEN>
<TOKEN id="token-73-4" pos="word" morph="none" start_char="9196" end_char="9199">Head</TOKEN>
<TOKEN id="token-73-5" pos="word" morph="none" start_char="9201" end_char="9202">of</TOKEN>
<TOKEN id="token-73-6" pos="word" morph="none" start_char="9204" end_char="9206">the</TOKEN>
<TOKEN id="token-73-7" pos="word" morph="none" start_char="9208" end_char="9219">Evolutionary</TOKEN>
<TOKEN id="token-73-8" pos="word" morph="none" start_char="9221" end_char="9228">Genomics</TOKEN>
<TOKEN id="token-73-9" pos="word" morph="none" start_char="9230" end_char="9231">of</TOKEN>
<TOKEN id="token-73-10" pos="word" morph="none" start_char="9233" end_char="9235">RNA</TOKEN>
<TOKEN id="token-73-11" pos="word" morph="none" start_char="9237" end_char="9243">Viruses</TOKEN>
<TOKEN id="token-73-12" pos="unknown" morph="none" start_char="9245" end_char="9253">five-year</TOKEN>
<TOKEN id="token-73-13" pos="word" morph="none" start_char="9255" end_char="9259">group</TOKEN>
<TOKEN id="token-73-14" pos="word" morph="none" start_char="9261" end_char="9262">at</TOKEN>
<TOKEN id="token-73-15" pos="word" morph="none" start_char="9264" end_char="9266">the</TOKEN>
<TOKEN id="token-73-16" pos="word" morph="none" start_char="9268" end_char="9275">Institut</TOKEN>
<TOKEN id="token-73-17" pos="word" morph="none" start_char="9277" end_char="9283">Pasteur</TOKEN>
<TOKEN id="token-73-18" pos="punct" morph="none" start_char="9284" end_char="9284">.</TOKEN>
</SEG>
<SEG id="segment-74" start_char="9287" end_char="9463">
<ORIGINAL_TEXT>2 _ The hypothesis is based on a misinterpretation of an article with multiple methodological errors and inaccuracies which has since been repudiated by the scientific community</ORIGINAL_TEXT>
<TOKEN id="token-74-0" pos="word" morph="none" start_char="9287" end_char="9287">2</TOKEN>
<TOKEN id="token-74-1" pos="word" morph="none" start_char="9289" end_char="9289">_</TOKEN>
<TOKEN id="token-74-2" pos="word" morph="none" start_char="9291" end_char="9293">The</TOKEN>
<TOKEN id="token-74-3" pos="word" morph="none" start_char="9295" end_char="9304">hypothesis</TOKEN>
<TOKEN id="token-74-4" pos="word" morph="none" start_char="9306" end_char="9307">is</TOKEN>
<TOKEN id="token-74-5" pos="word" morph="none" start_char="9309" end_char="9313">based</TOKEN>
<TOKEN id="token-74-6" pos="word" morph="none" start_char="9315" end_char="9316">on</TOKEN>
<TOKEN id="token-74-7" pos="word" morph="none" start_char="9318" end_char="9318">a</TOKEN>
<TOKEN id="token-74-8" pos="word" morph="none" start_char="9320" end_char="9336">misinterpretation</TOKEN>
<TOKEN id="token-74-9" pos="word" morph="none" start_char="9338" end_char="9339">of</TOKEN>
<TOKEN id="token-74-10" pos="word" morph="none" start_char="9341" end_char="9342">an</TOKEN>
<TOKEN id="token-74-11" pos="word" morph="none" start_char="9344" end_char="9350">article</TOKEN>
<TOKEN id="token-74-12" pos="word" morph="none" start_char="9352" end_char="9355">with</TOKEN>
<TOKEN id="token-74-13" pos="word" morph="none" start_char="9357" end_char="9364">multiple</TOKEN>
<TOKEN id="token-74-14" pos="word" morph="none" start_char="9366" end_char="9379">methodological</TOKEN>
<TOKEN id="token-74-15" pos="word" morph="none" start_char="9381" end_char="9386">errors</TOKEN>
<TOKEN id="token-74-16" pos="word" morph="none" start_char="9388" end_char="9390">and</TOKEN>
<TOKEN id="token-74-17" pos="word" morph="none" start_char="9392" end_char="9403">inaccuracies</TOKEN>
<TOKEN id="token-74-18" pos="word" morph="none" start_char="9405" end_char="9409">which</TOKEN>
<TOKEN id="token-74-19" pos="word" morph="none" start_char="9411" end_char="9413">has</TOKEN>
<TOKEN id="token-74-20" pos="word" morph="none" start_char="9415" end_char="9419">since</TOKEN>
<TOKEN id="token-74-21" pos="word" morph="none" start_char="9421" end_char="9424">been</TOKEN>
<TOKEN id="token-74-22" pos="word" morph="none" start_char="9426" end_char="9435">repudiated</TOKEN>
<TOKEN id="token-74-23" pos="word" morph="none" start_char="9437" end_char="9438">by</TOKEN>
<TOKEN id="token-74-24" pos="word" morph="none" start_char="9440" end_char="9442">the</TOKEN>
<TOKEN id="token-74-25" pos="word" morph="none" start_char="9444" end_char="9453">scientific</TOKEN>
<TOKEN id="token-74-26" pos="word" morph="none" start_char="9455" end_char="9463">community</TOKEN>
</SEG>
<SEG id="segment-75" start_char="9467" end_char="9625">
<ORIGINAL_TEXT>The theory that SARS-CoV-2 derives from HIV is based on an incorrect analysis of an article published by Indian scientists on the open science website bioRxiv.</ORIGINAL_TEXT>
<TOKEN id="token-75-0" pos="word" morph="none" start_char="9467" end_char="9469">The</TOKEN>
<TOKEN id="token-75-1" pos="word" morph="none" start_char="9471" end_char="9476">theory</TOKEN>
<TOKEN id="token-75-2" pos="word" morph="none" start_char="9478" end_char="9481">that</TOKEN>
<TOKEN id="token-75-3" pos="unknown" morph="none" start_char="9483" end_char="9492">SARS-CoV-2</TOKEN>
<TOKEN id="token-75-4" pos="word" morph="none" start_char="9494" end_char="9500">derives</TOKEN>
<TOKEN id="token-75-5" pos="word" morph="none" start_char="9502" end_char="9505">from</TOKEN>
<TOKEN id="token-75-6" pos="word" morph="none" start_char="9507" end_char="9509">HIV</TOKEN>
<TOKEN id="token-75-7" pos="word" morph="none" start_char="9511" end_char="9512">is</TOKEN>
<TOKEN id="token-75-8" pos="word" morph="none" start_char="9514" end_char="9518">based</TOKEN>
<TOKEN id="token-75-9" pos="word" morph="none" start_char="9520" end_char="9521">on</TOKEN>
<TOKEN id="token-75-10" pos="word" morph="none" start_char="9523" end_char="9524">an</TOKEN>
<TOKEN id="token-75-11" pos="word" morph="none" start_char="9526" end_char="9534">incorrect</TOKEN>
<TOKEN id="token-75-12" pos="word" morph="none" start_char="9536" end_char="9543">analysis</TOKEN>
<TOKEN id="token-75-13" pos="word" morph="none" start_char="9545" end_char="9546">of</TOKEN>
<TOKEN id="token-75-14" pos="word" morph="none" start_char="9548" end_char="9549">an</TOKEN>
<TOKEN id="token-75-15" pos="word" morph="none" start_char="9551" end_char="9557">article</TOKEN>
<TOKEN id="token-75-16" pos="word" morph="none" start_char="9559" end_char="9567">published</TOKEN>
<TOKEN id="token-75-17" pos="word" morph="none" start_char="9569" end_char="9570">by</TOKEN>
<TOKEN id="token-75-18" pos="word" morph="none" start_char="9572" end_char="9577">Indian</TOKEN>
<TOKEN id="token-75-19" pos="word" morph="none" start_char="9579" end_char="9588">scientists</TOKEN>
<TOKEN id="token-75-20" pos="word" morph="none" start_char="9590" end_char="9591">on</TOKEN>
<TOKEN id="token-75-21" pos="word" morph="none" start_char="9593" end_char="9595">the</TOKEN>
<TOKEN id="token-75-22" pos="word" morph="none" start_char="9597" end_char="9600">open</TOKEN>
<TOKEN id="token-75-23" pos="word" morph="none" start_char="9602" end_char="9608">science</TOKEN>
<TOKEN id="token-75-24" pos="word" morph="none" start_char="9610" end_char="9616">website</TOKEN>
<TOKEN id="token-75-25" pos="word" morph="none" start_char="9618" end_char="9624">bioRxiv</TOKEN>
<TOKEN id="token-75-26" pos="punct" morph="none" start_char="9625" end_char="9625">.</TOKEN>
</SEG>
<SEG id="segment-76" start_char="9627" end_char="9874">
<ORIGINAL_TEXT>"A scientific study was submitted to the bioRxiv website, where scientists can post results that have not been validated," confirms Olivier Schwartz, Head of the Virus and Immunity Unit at the Institut Pasteur (see also France Culture - in French).</ORIGINAL_TEXT>
<TOKEN id="token-76-0" pos="punct" morph="none" start_char="9627" end_char="9627">"</TOKEN>
<TOKEN id="token-76-1" pos="word" morph="none" start_char="9628" end_char="9628">A</TOKEN>
<TOKEN id="token-76-2" pos="word" morph="none" start_char="9630" end_char="9639">scientific</TOKEN>
<TOKEN id="token-76-3" pos="word" morph="none" start_char="9641" end_char="9645">study</TOKEN>
<TOKEN id="token-76-4" pos="word" morph="none" start_char="9647" end_char="9649">was</TOKEN>
<TOKEN id="token-76-5" pos="word" morph="none" start_char="9651" end_char="9659">submitted</TOKEN>
<TOKEN id="token-76-6" pos="word" morph="none" start_char="9661" end_char="9662">to</TOKEN>
<TOKEN id="token-76-7" pos="word" morph="none" start_char="9664" end_char="9666">the</TOKEN>
<TOKEN id="token-76-8" pos="word" morph="none" start_char="9668" end_char="9674">bioRxiv</TOKEN>
<TOKEN id="token-76-9" pos="word" morph="none" start_char="9676" end_char="9682">website</TOKEN>
<TOKEN id="token-76-10" pos="punct" morph="none" start_char="9683" end_char="9683">,</TOKEN>
<TOKEN id="token-76-11" pos="word" morph="none" start_char="9685" end_char="9689">where</TOKEN>
<TOKEN id="token-76-12" pos="word" morph="none" start_char="9691" end_char="9700">scientists</TOKEN>
<TOKEN id="token-76-13" pos="word" morph="none" start_char="9702" end_char="9704">can</TOKEN>
<TOKEN id="token-76-14" pos="word" morph="none" start_char="9706" end_char="9709">post</TOKEN>
<TOKEN id="token-76-15" pos="word" morph="none" start_char="9711" end_char="9717">results</TOKEN>
<TOKEN id="token-76-16" pos="word" morph="none" start_char="9719" end_char="9722">that</TOKEN>
<TOKEN id="token-76-17" pos="word" morph="none" start_char="9724" end_char="9727">have</TOKEN>
<TOKEN id="token-76-18" pos="word" morph="none" start_char="9729" end_char="9731">not</TOKEN>
<TOKEN id="token-76-19" pos="word" morph="none" start_char="9733" end_char="9736">been</TOKEN>
<TOKEN id="token-76-20" pos="word" morph="none" start_char="9738" end_char="9746">validated</TOKEN>
<TOKEN id="token-76-21" pos="punct" morph="none" start_char="9747" end_char="9748">,"</TOKEN>
<TOKEN id="token-76-22" pos="word" morph="none" start_char="9750" end_char="9757">confirms</TOKEN>
<TOKEN id="token-76-23" pos="word" morph="none" start_char="9759" end_char="9765">Olivier</TOKEN>
<TOKEN id="token-76-24" pos="word" morph="none" start_char="9767" end_char="9774">Schwartz</TOKEN>
<TOKEN id="token-76-25" pos="punct" morph="none" start_char="9775" end_char="9775">,</TOKEN>
<TOKEN id="token-76-26" pos="word" morph="none" start_char="9777" end_char="9780">Head</TOKEN>
<TOKEN id="token-76-27" pos="word" morph="none" start_char="9782" end_char="9783">of</TOKEN>
<TOKEN id="token-76-28" pos="word" morph="none" start_char="9785" end_char="9787">the</TOKEN>
<TOKEN id="token-76-29" pos="word" morph="none" start_char="9789" end_char="9793">Virus</TOKEN>
<TOKEN id="token-76-30" pos="word" morph="none" start_char="9795" end_char="9797">and</TOKEN>
<TOKEN id="token-76-31" pos="word" morph="none" start_char="9799" end_char="9806">Immunity</TOKEN>
<TOKEN id="token-76-32" pos="word" morph="none" start_char="9808" end_char="9811">Unit</TOKEN>
<TOKEN id="token-76-33" pos="word" morph="none" start_char="9813" end_char="9814">at</TOKEN>
<TOKEN id="token-76-34" pos="word" morph="none" start_char="9816" end_char="9818">the</TOKEN>
<TOKEN id="token-76-35" pos="word" morph="none" start_char="9820" end_char="9827">Institut</TOKEN>
<TOKEN id="token-76-36" pos="word" morph="none" start_char="9829" end_char="9835">Pasteur</TOKEN>
<TOKEN id="token-76-37" pos="punct" morph="none" start_char="9837" end_char="9837">(</TOKEN>
<TOKEN id="token-76-38" pos="word" morph="none" start_char="9838" end_char="9840">see</TOKEN>
<TOKEN id="token-76-39" pos="word" morph="none" start_char="9842" end_char="9845">also</TOKEN>
<TOKEN id="token-76-40" pos="word" morph="none" start_char="9847" end_char="9852">France</TOKEN>
<TOKEN id="token-76-41" pos="word" morph="none" start_char="9854" end_char="9860">Culture</TOKEN>
<TOKEN id="token-76-42" pos="punct" morph="none" start_char="9862" end_char="9862">-</TOKEN>
<TOKEN id="token-76-43" pos="word" morph="none" start_char="9864" end_char="9865">in</TOKEN>
<TOKEN id="token-76-44" pos="word" morph="none" start_char="9867" end_char="9872">French</TOKEN>
<TOKEN id="token-76-45" pos="punct" morph="none" start_char="9873" end_char="9874">).</TOKEN>
</SEG>
<SEG id="segment-77" start_char="9877" end_char="10195">
<ORIGINAL_TEXT>The Indian paper, initially published without peer review (as is the norm for this type of open science website), was strongly criticized by the scientific community for its approximations and subsequently withdrawn by the authors themselves because of the methodological errors that had been flagged up by their peers.</ORIGINAL_TEXT>
<TOKEN id="token-77-0" pos="word" morph="none" start_char="9877" end_char="9879">The</TOKEN>
<TOKEN id="token-77-1" pos="word" morph="none" start_char="9881" end_char="9886">Indian</TOKEN>
<TOKEN id="token-77-2" pos="word" morph="none" start_char="9888" end_char="9892">paper</TOKEN>
<TOKEN id="token-77-3" pos="punct" morph="none" start_char="9893" end_char="9893">,</TOKEN>
<TOKEN id="token-77-4" pos="word" morph="none" start_char="9895" end_char="9903">initially</TOKEN>
<TOKEN id="token-77-5" pos="word" morph="none" start_char="9905" end_char="9913">published</TOKEN>
<TOKEN id="token-77-6" pos="word" morph="none" start_char="9915" end_char="9921">without</TOKEN>
<TOKEN id="token-77-7" pos="word" morph="none" start_char="9923" end_char="9926">peer</TOKEN>
<TOKEN id="token-77-8" pos="word" morph="none" start_char="9928" end_char="9933">review</TOKEN>
<TOKEN id="token-77-9" pos="punct" morph="none" start_char="9935" end_char="9935">(</TOKEN>
<TOKEN id="token-77-10" pos="word" morph="none" start_char="9936" end_char="9937">as</TOKEN>
<TOKEN id="token-77-11" pos="word" morph="none" start_char="9939" end_char="9940">is</TOKEN>
<TOKEN id="token-77-12" pos="word" morph="none" start_char="9942" end_char="9944">the</TOKEN>
<TOKEN id="token-77-13" pos="word" morph="none" start_char="9946" end_char="9949">norm</TOKEN>
<TOKEN id="token-77-14" pos="word" morph="none" start_char="9951" end_char="9953">for</TOKEN>
<TOKEN id="token-77-15" pos="word" morph="none" start_char="9955" end_char="9958">this</TOKEN>
<TOKEN id="token-77-16" pos="word" morph="none" start_char="9960" end_char="9963">type</TOKEN>
<TOKEN id="token-77-17" pos="word" morph="none" start_char="9965" end_char="9966">of</TOKEN>
<TOKEN id="token-77-18" pos="word" morph="none" start_char="9968" end_char="9971">open</TOKEN>
<TOKEN id="token-77-19" pos="word" morph="none" start_char="9973" end_char="9979">science</TOKEN>
<TOKEN id="token-77-20" pos="word" morph="none" start_char="9981" end_char="9987">website</TOKEN>
<TOKEN id="token-77-21" pos="punct" morph="none" start_char="9988" end_char="9989">),</TOKEN>
<TOKEN id="token-77-22" pos="word" morph="none" start_char="9991" end_char="9993">was</TOKEN>
<TOKEN id="token-77-23" pos="word" morph="none" start_char="9995" end_char="10002">strongly</TOKEN>
<TOKEN id="token-77-24" pos="word" morph="none" start_char="10004" end_char="10013">criticized</TOKEN>
<TOKEN id="token-77-25" pos="word" morph="none" start_char="10015" end_char="10016">by</TOKEN>
<TOKEN id="token-77-26" pos="word" morph="none" start_char="10018" end_char="10020">the</TOKEN>
<TOKEN id="token-77-27" pos="word" morph="none" start_char="10022" end_char="10031">scientific</TOKEN>
<TOKEN id="token-77-28" pos="word" morph="none" start_char="10033" end_char="10041">community</TOKEN>
<TOKEN id="token-77-29" pos="word" morph="none" start_char="10043" end_char="10045">for</TOKEN>
<TOKEN id="token-77-30" pos="word" morph="none" start_char="10047" end_char="10049">its</TOKEN>
<TOKEN id="token-77-31" pos="word" morph="none" start_char="10051" end_char="10064">approximations</TOKEN>
<TOKEN id="token-77-32" pos="word" morph="none" start_char="10066" end_char="10068">and</TOKEN>
<TOKEN id="token-77-33" pos="word" morph="none" start_char="10070" end_char="10081">subsequently</TOKEN>
<TOKEN id="token-77-34" pos="word" morph="none" start_char="10083" end_char="10091">withdrawn</TOKEN>
<TOKEN id="token-77-35" pos="word" morph="none" start_char="10093" end_char="10094">by</TOKEN>
<TOKEN id="token-77-36" pos="word" morph="none" start_char="10096" end_char="10098">the</TOKEN>
<TOKEN id="token-77-37" pos="word" morph="none" start_char="10100" end_char="10106">authors</TOKEN>
<TOKEN id="token-77-38" pos="word" morph="none" start_char="10108" end_char="10117">themselves</TOKEN>
<TOKEN id="token-77-39" pos="word" morph="none" start_char="10119" end_char="10125">because</TOKEN>
<TOKEN id="token-77-40" pos="word" morph="none" start_char="10127" end_char="10128">of</TOKEN>
<TOKEN id="token-77-41" pos="word" morph="none" start_char="10130" end_char="10132">the</TOKEN>
<TOKEN id="token-77-42" pos="word" morph="none" start_char="10134" end_char="10147">methodological</TOKEN>
<TOKEN id="token-77-43" pos="word" morph="none" start_char="10149" end_char="10154">errors</TOKEN>
<TOKEN id="token-77-44" pos="word" morph="none" start_char="10156" end_char="10159">that</TOKEN>
<TOKEN id="token-77-45" pos="word" morph="none" start_char="10161" end_char="10163">had</TOKEN>
<TOKEN id="token-77-46" pos="word" morph="none" start_char="10165" end_char="10168">been</TOKEN>
<TOKEN id="token-77-47" pos="word" morph="none" start_char="10170" end_char="10176">flagged</TOKEN>
<TOKEN id="token-77-48" pos="word" morph="none" start_char="10178" end_char="10179">up</TOKEN>
<TOKEN id="token-77-49" pos="word" morph="none" start_char="10181" end_char="10182">by</TOKEN>
<TOKEN id="token-77-50" pos="word" morph="none" start_char="10184" end_char="10188">their</TOKEN>
<TOKEN id="token-77-51" pos="word" morph="none" start_char="10190" end_char="10194">peers</TOKEN>
<TOKEN id="token-77-52" pos="punct" morph="none" start_char="10195" end_char="10195">.</TOKEN>
</SEG>
<SEG id="segment-78" start_char="10198" end_char="10339">
<ORIGINAL_TEXT>The open science website bioRxiv now displays a banner qindicating that the articles it hosts have not been peer reviewed (see also the column</ORIGINAL_TEXT>
<TOKEN id="token-78-0" pos="word" morph="none" start_char="10198" end_char="10200">The</TOKEN>
<TOKEN id="token-78-1" pos="word" morph="none" start_char="10202" end_char="10205">open</TOKEN>
<TOKEN id="token-78-2" pos="word" morph="none" start_char="10207" end_char="10213">science</TOKEN>
<TOKEN id="token-78-3" pos="word" morph="none" start_char="10215" end_char="10221">website</TOKEN>
<TOKEN id="token-78-4" pos="word" morph="none" start_char="10223" end_char="10229">bioRxiv</TOKEN>
<TOKEN id="token-78-5" pos="word" morph="none" start_char="10231" end_char="10233">now</TOKEN>
<TOKEN id="token-78-6" pos="word" morph="none" start_char="10235" end_char="10242">displays</TOKEN>
<TOKEN id="token-78-7" pos="word" morph="none" start_char="10244" end_char="10244">a</TOKEN>
<TOKEN id="token-78-8" pos="word" morph="none" start_char="10246" end_char="10251">banner</TOKEN>
<TOKEN id="token-78-9" pos="word" morph="none" start_char="10253" end_char="10263">qindicating</TOKEN>
<TOKEN id="token-78-10" pos="word" morph="none" start_char="10265" end_char="10268">that</TOKEN>
<TOKEN id="token-78-11" pos="word" morph="none" start_char="10270" end_char="10272">the</TOKEN>
<TOKEN id="token-78-12" pos="word" morph="none" start_char="10274" end_char="10281">articles</TOKEN>
<TOKEN id="token-78-13" pos="word" morph="none" start_char="10283" end_char="10284">it</TOKEN>
<TOKEN id="token-78-14" pos="word" morph="none" start_char="10286" end_char="10290">hosts</TOKEN>
<TOKEN id="token-78-15" pos="word" morph="none" start_char="10292" end_char="10295">have</TOKEN>
<TOKEN id="token-78-16" pos="word" morph="none" start_char="10297" end_char="10299">not</TOKEN>
<TOKEN id="token-78-17" pos="word" morph="none" start_char="10301" end_char="10304">been</TOKEN>
<TOKEN id="token-78-18" pos="word" morph="none" start_char="10306" end_char="10309">peer</TOKEN>
<TOKEN id="token-78-19" pos="word" morph="none" start_char="10311" end_char="10318">reviewed</TOKEN>
<TOKEN id="token-78-20" pos="punct" morph="none" start_char="10320" end_char="10320">(</TOKEN>
<TOKEN id="token-78-21" pos="word" morph="none" start_char="10321" end_char="10323">see</TOKEN>
<TOKEN id="token-78-22" pos="word" morph="none" start_char="10325" end_char="10328">also</TOKEN>
<TOKEN id="token-78-23" pos="word" morph="none" start_char="10330" end_char="10332">the</TOKEN>
<TOKEN id="token-78-24" pos="word" morph="none" start_char="10334" end_char="10339">column</TOKEN>
</SEG>
<SEG id="segment-79" start_char="10342" end_char="10354">
<ORIGINAL_TEXT>Les Dcodeurs</ORIGINAL_TEXT>
<TOKEN id="token-79-0" pos="word" morph="none" start_char="10342" end_char="10344">Les</TOKEN>
<TOKEN id="token-79-1" pos="word" morph="none" start_char="10346" end_char="10354">Dcodeurs</TOKEN>
</SEG>
<SEG id="segment-80" start_char="10357" end_char="10383">
<ORIGINAL_TEXT>, in Le Monde - in French).</ORIGINAL_TEXT>
<TOKEN id="token-80-0" pos="punct" morph="none" start_char="10357" end_char="10357">,</TOKEN>
<TOKEN id="token-80-1" pos="word" morph="none" start_char="10359" end_char="10360">in</TOKEN>
<TOKEN id="token-80-2" pos="word" morph="none" start_char="10362" end_char="10363">Le</TOKEN>
<TOKEN id="token-80-3" pos="word" morph="none" start_char="10365" end_char="10369">Monde</TOKEN>
<TOKEN id="token-80-4" pos="punct" morph="none" start_char="10371" end_char="10371">-</TOKEN>
<TOKEN id="token-80-5" pos="word" morph="none" start_char="10373" end_char="10374">in</TOKEN>
<TOKEN id="token-80-6" pos="word" morph="none" start_char="10376" end_char="10381">French</TOKEN>
<TOKEN id="token-80-7" pos="punct" morph="none" start_char="10382" end_char="10383">).</TOKEN>
</SEG>
<SEG id="segment-81" start_char="10386" end_char="10412">
<ORIGINAL_TEXT>3 _ An article published in</ORIGINAL_TEXT>
<TOKEN id="token-81-0" pos="word" morph="none" start_char="10386" end_char="10386">3</TOKEN>
<TOKEN id="token-81-1" pos="word" morph="none" start_char="10388" end_char="10388">_</TOKEN>
<TOKEN id="token-81-2" pos="word" morph="none" start_char="10390" end_char="10391">An</TOKEN>
<TOKEN id="token-81-3" pos="word" morph="none" start_char="10393" end_char="10399">article</TOKEN>
<TOKEN id="token-81-4" pos="word" morph="none" start_char="10401" end_char="10409">published</TOKEN>
<TOKEN id="token-81-5" pos="word" morph="none" start_char="10411" end_char="10412">in</TOKEN>
</SEG>
<SEG id="segment-82" start_char="10415" end_char="10429">
<ORIGINAL_TEXT>Nature Medicine</ORIGINAL_TEXT>
<TOKEN id="token-82-0" pos="word" morph="none" start_char="10415" end_char="10420">Nature</TOKEN>
<TOKEN id="token-82-1" pos="word" morph="none" start_char="10422" end_char="10429">Medicine</TOKEN>
</SEG>
<SEG id="segment-83" start_char="10432" end_char="10542">
<ORIGINAL_TEXT>has since confirmed that there is no evidence that the SARS-CoV-2 coronavirus could have been created by humans</ORIGINAL_TEXT>
<TOKEN id="token-83-0" pos="word" morph="none" start_char="10432" end_char="10434">has</TOKEN>
<TOKEN id="token-83-1" pos="word" morph="none" start_char="10436" end_char="10440">since</TOKEN>
<TOKEN id="token-83-2" pos="word" morph="none" start_char="10442" end_char="10450">confirmed</TOKEN>
<TOKEN id="token-83-3" pos="word" morph="none" start_char="10452" end_char="10455">that</TOKEN>
<TOKEN id="token-83-4" pos="word" morph="none" start_char="10457" end_char="10461">there</TOKEN>
<TOKEN id="token-83-5" pos="word" morph="none" start_char="10463" end_char="10464">is</TOKEN>
<TOKEN id="token-83-6" pos="word" morph="none" start_char="10466" end_char="10467">no</TOKEN>
<TOKEN id="token-83-7" pos="word" morph="none" start_char="10469" end_char="10476">evidence</TOKEN>
<TOKEN id="token-83-8" pos="word" morph="none" start_char="10478" end_char="10481">that</TOKEN>
<TOKEN id="token-83-9" pos="word" morph="none" start_char="10483" end_char="10485">the</TOKEN>
<TOKEN id="token-83-10" pos="unknown" morph="none" start_char="10487" end_char="10496">SARS-CoV-2</TOKEN>
<TOKEN id="token-83-11" pos="word" morph="none" start_char="10498" end_char="10508">coronavirus</TOKEN>
<TOKEN id="token-83-12" pos="word" morph="none" start_char="10510" end_char="10514">could</TOKEN>
<TOKEN id="token-83-13" pos="word" morph="none" start_char="10516" end_char="10519">have</TOKEN>
<TOKEN id="token-83-14" pos="word" morph="none" start_char="10521" end_char="10524">been</TOKEN>
<TOKEN id="token-83-15" pos="word" morph="none" start_char="10526" end_char="10532">created</TOKEN>
<TOKEN id="token-83-16" pos="word" morph="none" start_char="10534" end_char="10535">by</TOKEN>
<TOKEN id="token-83-17" pos="word" morph="none" start_char="10537" end_char="10542">humans</TOKEN>
</SEG>
<SEG id="segment-84" start_char="10546" end_char="10732">
<ORIGINAL_TEXT>A scientific article dated March 17, 2020 refutes the idea of a laboratory-created virus (The proximal origin of SARS-CoV-2, Kristian G. Andersen, Andrew Rambaut, W. Ian Lipkin, Edward C.</ORIGINAL_TEXT>
<TOKEN id="token-84-0" pos="word" morph="none" start_char="10546" end_char="10546">A</TOKEN>
<TOKEN id="token-84-1" pos="word" morph="none" start_char="10548" end_char="10557">scientific</TOKEN>
<TOKEN id="token-84-2" pos="word" morph="none" start_char="10559" end_char="10565">article</TOKEN>
<TOKEN id="token-84-3" pos="word" morph="none" start_char="10567" end_char="10571">dated</TOKEN>
<TOKEN id="token-84-4" pos="word" morph="none" start_char="10573" end_char="10577">March</TOKEN>
<TOKEN id="token-84-5" pos="word" morph="none" start_char="10579" end_char="10580">17</TOKEN>
<TOKEN id="token-84-6" pos="punct" morph="none" start_char="10581" end_char="10581">,</TOKEN>
<TOKEN id="token-84-7" pos="word" morph="none" start_char="10583" end_char="10586">2020</TOKEN>
<TOKEN id="token-84-8" pos="word" morph="none" start_char="10588" end_char="10594">refutes</TOKEN>
<TOKEN id="token-84-9" pos="word" morph="none" start_char="10596" end_char="10598">the</TOKEN>
<TOKEN id="token-84-10" pos="word" morph="none" start_char="10600" end_char="10603">idea</TOKEN>
<TOKEN id="token-84-11" pos="word" morph="none" start_char="10605" end_char="10606">of</TOKEN>
<TOKEN id="token-84-12" pos="word" morph="none" start_char="10608" end_char="10608">a</TOKEN>
<TOKEN id="token-84-13" pos="unknown" morph="none" start_char="10610" end_char="10627">laboratory-created</TOKEN>
<TOKEN id="token-84-14" pos="word" morph="none" start_char="10629" end_char="10633">virus</TOKEN>
<TOKEN id="token-84-15" pos="punct" morph="none" start_char="10635" end_char="10635">(</TOKEN>
<TOKEN id="token-84-16" pos="word" morph="none" start_char="10636" end_char="10638">The</TOKEN>
<TOKEN id="token-84-17" pos="word" morph="none" start_char="10640" end_char="10647">proximal</TOKEN>
<TOKEN id="token-84-18" pos="word" morph="none" start_char="10649" end_char="10654">origin</TOKEN>
<TOKEN id="token-84-19" pos="word" morph="none" start_char="10656" end_char="10657">of</TOKEN>
<TOKEN id="token-84-20" pos="unknown" morph="none" start_char="10659" end_char="10668">SARS-CoV-2</TOKEN>
<TOKEN id="token-84-21" pos="punct" morph="none" start_char="10669" end_char="10669">,</TOKEN>
<TOKEN id="token-84-22" pos="word" morph="none" start_char="10671" end_char="10678">Kristian</TOKEN>
<TOKEN id="token-84-23" pos="word" morph="none" start_char="10680" end_char="10680">G</TOKEN>
<TOKEN id="token-84-24" pos="punct" morph="none" start_char="10681" end_char="10681">.</TOKEN>
<TOKEN id="token-84-25" pos="word" morph="none" start_char="10683" end_char="10690">Andersen</TOKEN>
<TOKEN id="token-84-26" pos="punct" morph="none" start_char="10691" end_char="10691">,</TOKEN>
<TOKEN id="token-84-27" pos="word" morph="none" start_char="10693" end_char="10698">Andrew</TOKEN>
<TOKEN id="token-84-28" pos="word" morph="none" start_char="10700" end_char="10706">Rambaut</TOKEN>
<TOKEN id="token-84-29" pos="punct" morph="none" start_char="10707" end_char="10707">,</TOKEN>
<TOKEN id="token-84-30" pos="word" morph="none" start_char="10709" end_char="10709">W</TOKEN>
<TOKEN id="token-84-31" pos="punct" morph="none" start_char="10710" end_char="10710">.</TOKEN>
<TOKEN id="token-84-32" pos="word" morph="none" start_char="10712" end_char="10714">Ian</TOKEN>
<TOKEN id="token-84-33" pos="word" morph="none" start_char="10716" end_char="10721">Lipkin</TOKEN>
<TOKEN id="token-84-34" pos="punct" morph="none" start_char="10722" end_char="10722">,</TOKEN>
<TOKEN id="token-84-35" pos="word" morph="none" start_char="10724" end_char="10729">Edward</TOKEN>
<TOKEN id="token-84-36" pos="word" morph="none" start_char="10731" end_char="10731">C</TOKEN>
<TOKEN id="token-84-37" pos="punct" morph="none" start_char="10732" end_char="10732">.</TOKEN>
</SEG>
<SEG id="segment-85" start_char="10734" end_char="10749">
<ORIGINAL_TEXT>Holmes Robert F.</ORIGINAL_TEXT>
<TOKEN id="token-85-0" pos="word" morph="none" start_char="10734" end_char="10739">Holmes</TOKEN>
<TOKEN id="token-85-1" pos="word" morph="none" start_char="10741" end_char="10746">Robert</TOKEN>
<TOKEN id="token-85-2" pos="word" morph="none" start_char="10748" end_char="10748">F</TOKEN>
<TOKEN id="token-85-3" pos="punct" morph="none" start_char="10749" end_char="10749">.</TOKEN>
</SEG>
<SEG id="segment-86" start_char="10751" end_char="10756">
<ORIGINAL_TEXT>Garry.</ORIGINAL_TEXT>
<TOKEN id="token-86-0" pos="word" morph="none" start_char="10751" end_char="10755">Garry</TOKEN>
<TOKEN id="token-86-1" pos="punct" morph="none" start_char="10756" end_char="10756">.</TOKEN>
</SEG>
<SEG id="segment-87" start_char="10759" end_char="10773">
<ORIGINAL_TEXT>Nature Medicine</ORIGINAL_TEXT>
<TOKEN id="token-87-0" pos="word" morph="none" start_char="10759" end_char="10764">Nature</TOKEN>
<TOKEN id="token-87-1" pos="word" morph="none" start_char="10766" end_char="10773">Medicine</TOKEN>
</SEG>
<SEG id="segment-88" start_char="10776" end_char="10783">
<ORIGINAL_TEXT>- 2020).</ORIGINAL_TEXT>
<TOKEN id="token-88-0" pos="punct" morph="none" start_char="10776" end_char="10776">-</TOKEN>
<TOKEN id="token-88-1" pos="word" morph="none" start_char="10778" end_char="10781">2020</TOKEN>
<TOKEN id="token-88-2" pos="punct" morph="none" start_char="10782" end_char="10783">).</TOKEN>
</SEG>
<SEG id="segment-89" start_char="10786" end_char="10873">
<ORIGINAL_TEXT>See also below "There is no evidence that SARS-CoV-2 coronavirus was created by humans".</ORIGINAL_TEXT>
<TOKEN id="token-89-0" pos="word" morph="none" start_char="10786" end_char="10788">See</TOKEN>
<TOKEN id="token-89-1" pos="word" morph="none" start_char="10790" end_char="10793">also</TOKEN>
<TOKEN id="token-89-2" pos="word" morph="none" start_char="10795" end_char="10799">below</TOKEN>
<TOKEN id="token-89-3" pos="punct" morph="none" start_char="10801" end_char="10801">"</TOKEN>
<TOKEN id="token-89-4" pos="word" morph="none" start_char="10802" end_char="10806">There</TOKEN>
<TOKEN id="token-89-5" pos="word" morph="none" start_char="10808" end_char="10809">is</TOKEN>
<TOKEN id="token-89-6" pos="word" morph="none" start_char="10811" end_char="10812">no</TOKEN>
<TOKEN id="token-89-7" pos="word" morph="none" start_char="10814" end_char="10821">evidence</TOKEN>
<TOKEN id="token-89-8" pos="word" morph="none" start_char="10823" end_char="10826">that</TOKEN>
<TOKEN id="token-89-9" pos="unknown" morph="none" start_char="10828" end_char="10837">SARS-CoV-2</TOKEN>
<TOKEN id="token-89-10" pos="word" morph="none" start_char="10839" end_char="10849">coronavirus</TOKEN>
<TOKEN id="token-89-11" pos="word" morph="none" start_char="10851" end_char="10853">was</TOKEN>
<TOKEN id="token-89-12" pos="word" morph="none" start_char="10855" end_char="10861">created</TOKEN>
<TOKEN id="token-89-13" pos="word" morph="none" start_char="10863" end_char="10864">by</TOKEN>
<TOKEN id="token-89-14" pos="word" morph="none" start_char="10866" end_char="10871">humans</TOKEN>
<TOKEN id="token-89-15" pos="punct" morph="none" start_char="10872" end_char="10873">".</TOKEN>
</SEG>
<SEG id="segment-90" start_char="10876" end_char="10957">
<ORIGINAL_TEXT>NO, nothing proves that the coronavirus would have been created in the laboratory!</ORIGINAL_TEXT>
<TOKEN id="token-90-0" pos="word" morph="none" start_char="10876" end_char="10877">NO</TOKEN>
<TOKEN id="token-90-1" pos="punct" morph="none" start_char="10878" end_char="10878">,</TOKEN>
<TOKEN id="token-90-2" pos="word" morph="none" start_char="10880" end_char="10886">nothing</TOKEN>
<TOKEN id="token-90-3" pos="word" morph="none" start_char="10888" end_char="10893">proves</TOKEN>
<TOKEN id="token-90-4" pos="word" morph="none" start_char="10895" end_char="10898">that</TOKEN>
<TOKEN id="token-90-5" pos="word" morph="none" start_char="10900" end_char="10902">the</TOKEN>
<TOKEN id="token-90-6" pos="word" morph="none" start_char="10904" end_char="10914">coronavirus</TOKEN>
<TOKEN id="token-90-7" pos="word" morph="none" start_char="10916" end_char="10920">would</TOKEN>
<TOKEN id="token-90-8" pos="word" morph="none" start_char="10922" end_char="10925">have</TOKEN>
<TOKEN id="token-90-9" pos="word" morph="none" start_char="10927" end_char="10930">been</TOKEN>
<TOKEN id="token-90-10" pos="word" morph="none" start_char="10932" end_char="10938">created</TOKEN>
<TOKEN id="token-90-11" pos="word" morph="none" start_char="10940" end_char="10941">in</TOKEN>
<TOKEN id="token-90-12" pos="word" morph="none" start_char="10943" end_char="10945">the</TOKEN>
<TOKEN id="token-90-13" pos="word" morph="none" start_char="10947" end_char="10956">laboratory</TOKEN>
<TOKEN id="token-90-14" pos="punct" morph="none" start_char="10957" end_char="10957">!</TOKEN>
</SEG>
<SEG id="segment-91" start_char="10960" end_char="10988">
<ORIGINAL_TEXT>Disclaimer of March 23, 2020.</ORIGINAL_TEXT>
<TOKEN id="token-91-0" pos="word" morph="none" start_char="10960" end_char="10969">Disclaimer</TOKEN>
<TOKEN id="token-91-1" pos="word" morph="none" start_char="10971" end_char="10972">of</TOKEN>
<TOKEN id="token-91-2" pos="word" morph="none" start_char="10974" end_char="10978">March</TOKEN>
<TOKEN id="token-91-3" pos="word" morph="none" start_char="10980" end_char="10981">23</TOKEN>
<TOKEN id="token-91-4" pos="punct" morph="none" start_char="10982" end_char="10982">,</TOKEN>
<TOKEN id="token-91-5" pos="word" morph="none" start_char="10984" end_char="10987">2020</TOKEN>
<TOKEN id="token-91-6" pos="punct" morph="none" start_char="10988" end_char="10988">.</TOKEN>
</SEG>
<SEG id="segment-92" start_char="10991" end_char="11014">
<ORIGINAL_TEXT>Updated December 1, 2020</ORIGINAL_TEXT>
<TOKEN id="token-92-0" pos="word" morph="none" start_char="10991" end_char="10997">Updated</TOKEN>
<TOKEN id="token-92-1" pos="word" morph="none" start_char="10999" end_char="11006">December</TOKEN>
<TOKEN id="token-92-2" pos="word" morph="none" start_char="11008" end_char="11008">1</TOKEN>
<TOKEN id="token-92-3" pos="punct" morph="none" start_char="11009" end_char="11009">,</TOKEN>
<TOKEN id="token-92-4" pos="word" morph="none" start_char="11011" end_char="11014">2020</TOKEN>
</SEG>
<SEG id="segment-93" start_char="11018" end_char="11200">
<ORIGINAL_TEXT>A recurring suspicion about the SARS-CoV-2 virus, held by conspiracy groups, is that it is linked to the presence of a P4 laboratory in Wuhan, the city where the virus first appeared.</ORIGINAL_TEXT>
<TOKEN id="token-93-0" pos="word" morph="none" start_char="11018" end_char="11018">A</TOKEN>
<TOKEN id="token-93-1" pos="word" morph="none" start_char="11020" end_char="11028">recurring</TOKEN>
<TOKEN id="token-93-2" pos="word" morph="none" start_char="11030" end_char="11038">suspicion</TOKEN>
<TOKEN id="token-93-3" pos="word" morph="none" start_char="11040" end_char="11044">about</TOKEN>
<TOKEN id="token-93-4" pos="word" morph="none" start_char="11046" end_char="11048">the</TOKEN>
<TOKEN id="token-93-5" pos="unknown" morph="none" start_char="11050" end_char="11059">SARS-CoV-2</TOKEN>
<TOKEN id="token-93-6" pos="word" morph="none" start_char="11061" end_char="11065">virus</TOKEN>
<TOKEN id="token-93-7" pos="punct" morph="none" start_char="11066" end_char="11066">,</TOKEN>
<TOKEN id="token-93-8" pos="word" morph="none" start_char="11068" end_char="11071">held</TOKEN>
<TOKEN id="token-93-9" pos="word" morph="none" start_char="11073" end_char="11074">by</TOKEN>
<TOKEN id="token-93-10" pos="word" morph="none" start_char="11076" end_char="11085">conspiracy</TOKEN>
<TOKEN id="token-93-11" pos="word" morph="none" start_char="11087" end_char="11092">groups</TOKEN>
<TOKEN id="token-93-12" pos="punct" morph="none" start_char="11093" end_char="11093">,</TOKEN>
<TOKEN id="token-93-13" pos="word" morph="none" start_char="11095" end_char="11096">is</TOKEN>
<TOKEN id="token-93-14" pos="word" morph="none" start_char="11098" end_char="11101">that</TOKEN>
<TOKEN id="token-93-15" pos="word" morph="none" start_char="11103" end_char="11104">it</TOKEN>
<TOKEN id="token-93-16" pos="word" morph="none" start_char="11106" end_char="11107">is</TOKEN>
<TOKEN id="token-93-17" pos="word" morph="none" start_char="11109" end_char="11114">linked</TOKEN>
<TOKEN id="token-93-18" pos="word" morph="none" start_char="11116" end_char="11117">to</TOKEN>
<TOKEN id="token-93-19" pos="word" morph="none" start_char="11119" end_char="11121">the</TOKEN>
<TOKEN id="token-93-20" pos="word" morph="none" start_char="11123" end_char="11130">presence</TOKEN>
<TOKEN id="token-93-21" pos="word" morph="none" start_char="11132" end_char="11133">of</TOKEN>
<TOKEN id="token-93-22" pos="word" morph="none" start_char="11135" end_char="11135">a</TOKEN>
<TOKEN id="token-93-23" pos="word" morph="none" start_char="11137" end_char="11138">P4</TOKEN>
<TOKEN id="token-93-24" pos="word" morph="none" start_char="11140" end_char="11149">laboratory</TOKEN>
<TOKEN id="token-93-25" pos="word" morph="none" start_char="11151" end_char="11152">in</TOKEN>
<TOKEN id="token-93-26" pos="word" morph="none" start_char="11154" end_char="11158">Wuhan</TOKEN>
<TOKEN id="token-93-27" pos="punct" morph="none" start_char="11159" end_char="11159">,</TOKEN>
<TOKEN id="token-93-28" pos="word" morph="none" start_char="11161" end_char="11163">the</TOKEN>
<TOKEN id="token-93-29" pos="word" morph="none" start_char="11165" end_char="11168">city</TOKEN>
<TOKEN id="token-93-30" pos="word" morph="none" start_char="11170" end_char="11174">where</TOKEN>
<TOKEN id="token-93-31" pos="word" morph="none" start_char="11176" end_char="11178">the</TOKEN>
<TOKEN id="token-93-32" pos="word" morph="none" start_char="11180" end_char="11184">virus</TOKEN>
<TOKEN id="token-93-33" pos="word" morph="none" start_char="11186" end_char="11190">first</TOKEN>
<TOKEN id="token-93-34" pos="word" morph="none" start_char="11192" end_char="11199">appeared</TOKEN>
<TOKEN id="token-93-35" pos="punct" morph="none" start_char="11200" end_char="11200">.</TOKEN>
</SEG>
<SEG id="segment-94" start_char="11202" end_char="11355">
<ORIGINAL_TEXT>According to conspiracy groups, SARS-CoV-2 was spread when a bat, on which tests had been performed, escaped, and the Institut Pasteur was linked to this.</ORIGINAL_TEXT>
<TOKEN id="token-94-0" pos="word" morph="none" start_char="11202" end_char="11210">According</TOKEN>
<TOKEN id="token-94-1" pos="word" morph="none" start_char="11212" end_char="11213">to</TOKEN>
<TOKEN id="token-94-2" pos="word" morph="none" start_char="11215" end_char="11224">conspiracy</TOKEN>
<TOKEN id="token-94-3" pos="word" morph="none" start_char="11226" end_char="11231">groups</TOKEN>
<TOKEN id="token-94-4" pos="punct" morph="none" start_char="11232" end_char="11232">,</TOKEN>
<TOKEN id="token-94-5" pos="unknown" morph="none" start_char="11234" end_char="11243">SARS-CoV-2</TOKEN>
<TOKEN id="token-94-6" pos="word" morph="none" start_char="11245" end_char="11247">was</TOKEN>
<TOKEN id="token-94-7" pos="word" morph="none" start_char="11249" end_char="11254">spread</TOKEN>
<TOKEN id="token-94-8" pos="word" morph="none" start_char="11256" end_char="11259">when</TOKEN>
<TOKEN id="token-94-9" pos="word" morph="none" start_char="11261" end_char="11261">a</TOKEN>
<TOKEN id="token-94-10" pos="word" morph="none" start_char="11263" end_char="11265">bat</TOKEN>
<TOKEN id="token-94-11" pos="punct" morph="none" start_char="11266" end_char="11266">,</TOKEN>
<TOKEN id="token-94-12" pos="word" morph="none" start_char="11268" end_char="11269">on</TOKEN>
<TOKEN id="token-94-13" pos="word" morph="none" start_char="11271" end_char="11275">which</TOKEN>
<TOKEN id="token-94-14" pos="word" morph="none" start_char="11277" end_char="11281">tests</TOKEN>
<TOKEN id="token-94-15" pos="word" morph="none" start_char="11283" end_char="11285">had</TOKEN>
<TOKEN id="token-94-16" pos="word" morph="none" start_char="11287" end_char="11290">been</TOKEN>
<TOKEN id="token-94-17" pos="word" morph="none" start_char="11292" end_char="11300">performed</TOKEN>
<TOKEN id="token-94-18" pos="punct" morph="none" start_char="11301" end_char="11301">,</TOKEN>
<TOKEN id="token-94-19" pos="word" morph="none" start_char="11303" end_char="11309">escaped</TOKEN>
<TOKEN id="token-94-20" pos="punct" morph="none" start_char="11310" end_char="11310">,</TOKEN>
<TOKEN id="token-94-21" pos="word" morph="none" start_char="11312" end_char="11314">and</TOKEN>
<TOKEN id="token-94-22" pos="word" morph="none" start_char="11316" end_char="11318">the</TOKEN>
<TOKEN id="token-94-23" pos="word" morph="none" start_char="11320" end_char="11327">Institut</TOKEN>
<TOKEN id="token-94-24" pos="word" morph="none" start_char="11329" end_char="11335">Pasteur</TOKEN>
<TOKEN id="token-94-25" pos="word" morph="none" start_char="11337" end_char="11339">was</TOKEN>
<TOKEN id="token-94-26" pos="word" morph="none" start_char="11341" end_char="11346">linked</TOKEN>
<TOKEN id="token-94-27" pos="word" morph="none" start_char="11348" end_char="11349">to</TOKEN>
<TOKEN id="token-94-28" pos="word" morph="none" start_char="11351" end_char="11354">this</TOKEN>
<TOKEN id="token-94-29" pos="punct" morph="none" start_char="11355" end_char="11355">.</TOKEN>
</SEG>
<SEG id="segment-95" start_char="11357" end_char="11381">
<ORIGINAL_TEXT>This is completely false.</ORIGINAL_TEXT>
<TOKEN id="token-95-0" pos="word" morph="none" start_char="11357" end_char="11360">This</TOKEN>
<TOKEN id="token-95-1" pos="word" morph="none" start_char="11362" end_char="11363">is</TOKEN>
<TOKEN id="token-95-2" pos="word" morph="none" start_char="11365" end_char="11374">completely</TOKEN>
<TOKEN id="token-95-3" pos="word" morph="none" start_char="11376" end_char="11380">false</TOKEN>
<TOKEN id="token-95-4" pos="punct" morph="none" start_char="11381" end_char="11381">.</TOKEN>
</SEG>
<SEG id="segment-96" start_char="11383" end_char="11416">
<ORIGINAL_TEXT>There are four things to remember:</ORIGINAL_TEXT>
<TOKEN id="token-96-0" pos="word" morph="none" start_char="11383" end_char="11387">There</TOKEN>
<TOKEN id="token-96-1" pos="word" morph="none" start_char="11389" end_char="11391">are</TOKEN>
<TOKEN id="token-96-2" pos="word" morph="none" start_char="11393" end_char="11396">four</TOKEN>
<TOKEN id="token-96-3" pos="word" morph="none" start_char="11398" end_char="11403">things</TOKEN>
<TOKEN id="token-96-4" pos="word" morph="none" start_char="11405" end_char="11406">to</TOKEN>
<TOKEN id="token-96-5" pos="word" morph="none" start_char="11408" end_char="11415">remember</TOKEN>
<TOKEN id="token-96-6" pos="punct" morph="none" start_char="11416" end_char="11416">:</TOKEN>
</SEG>
<SEG id="segment-97" start_char="11420" end_char="11490">
<ORIGINAL_TEXT>There is no evidence that SARS-CoV-2 coronavirus was created by humans.</ORIGINAL_TEXT>
<TOKEN id="token-97-0" pos="word" morph="none" start_char="11420" end_char="11424">There</TOKEN>
<TOKEN id="token-97-1" pos="word" morph="none" start_char="11426" end_char="11427">is</TOKEN>
<TOKEN id="token-97-2" pos="word" morph="none" start_char="11429" end_char="11430">no</TOKEN>
<TOKEN id="token-97-3" pos="word" morph="none" start_char="11432" end_char="11439">evidence</TOKEN>
<TOKEN id="token-97-4" pos="word" morph="none" start_char="11441" end_char="11444">that</TOKEN>
<TOKEN id="token-97-5" pos="unknown" morph="none" start_char="11446" end_char="11455">SARS-CoV-2</TOKEN>
<TOKEN id="token-97-6" pos="word" morph="none" start_char="11457" end_char="11467">coronavirus</TOKEN>
<TOKEN id="token-97-7" pos="word" morph="none" start_char="11469" end_char="11471">was</TOKEN>
<TOKEN id="token-97-8" pos="word" morph="none" start_char="11473" end_char="11479">created</TOKEN>
<TOKEN id="token-97-9" pos="word" morph="none" start_char="11481" end_char="11482">by</TOKEN>
<TOKEN id="token-97-10" pos="word" morph="none" start_char="11484" end_char="11489">humans</TOKEN>
<TOKEN id="token-97-11" pos="punct" morph="none" start_char="11490" end_char="11490">.</TOKEN>
</SEG>
<SEG id="segment-98" start_char="11496" end_char="11640">
<ORIGINAL_TEXT>The P4 laboratory in the city of Wuhan, where the virus SARS-CoV-2 first appeared, has nothing to do with the Institut Pasteur of Shanghai (IPS).</ORIGINAL_TEXT>
<TOKEN id="token-98-0" pos="word" morph="none" start_char="11496" end_char="11498">The</TOKEN>
<TOKEN id="token-98-1" pos="word" morph="none" start_char="11500" end_char="11501">P4</TOKEN>
<TOKEN id="token-98-2" pos="word" morph="none" start_char="11503" end_char="11512">laboratory</TOKEN>
<TOKEN id="token-98-3" pos="word" morph="none" start_char="11514" end_char="11515">in</TOKEN>
<TOKEN id="token-98-4" pos="word" morph="none" start_char="11517" end_char="11519">the</TOKEN>
<TOKEN id="token-98-5" pos="word" morph="none" start_char="11521" end_char="11524">city</TOKEN>
<TOKEN id="token-98-6" pos="word" morph="none" start_char="11526" end_char="11527">of</TOKEN>
<TOKEN id="token-98-7" pos="word" morph="none" start_char="11529" end_char="11533">Wuhan</TOKEN>
<TOKEN id="token-98-8" pos="punct" morph="none" start_char="11534" end_char="11534">,</TOKEN>
<TOKEN id="token-98-9" pos="word" morph="none" start_char="11536" end_char="11540">where</TOKEN>
<TOKEN id="token-98-10" pos="word" morph="none" start_char="11542" end_char="11544">the</TOKEN>
<TOKEN id="token-98-11" pos="word" morph="none" start_char="11546" end_char="11550">virus</TOKEN>
<TOKEN id="token-98-12" pos="unknown" morph="none" start_char="11552" end_char="11561">SARS-CoV-2</TOKEN>
<TOKEN id="token-98-13" pos="word" morph="none" start_char="11563" end_char="11567">first</TOKEN>
<TOKEN id="token-98-14" pos="word" morph="none" start_char="11569" end_char="11576">appeared</TOKEN>
<TOKEN id="token-98-15" pos="punct" morph="none" start_char="11577" end_char="11577">,</TOKEN>
<TOKEN id="token-98-16" pos="word" morph="none" start_char="11579" end_char="11581">has</TOKEN>
<TOKEN id="token-98-17" pos="word" morph="none" start_char="11583" end_char="11589">nothing</TOKEN>
<TOKEN id="token-98-18" pos="word" morph="none" start_char="11591" end_char="11592">to</TOKEN>
<TOKEN id="token-98-19" pos="word" morph="none" start_char="11594" end_char="11595">do</TOKEN>
<TOKEN id="token-98-20" pos="word" morph="none" start_char="11597" end_char="11600">with</TOKEN>
<TOKEN id="token-98-21" pos="word" morph="none" start_char="11602" end_char="11604">the</TOKEN>
<TOKEN id="token-98-22" pos="word" morph="none" start_char="11606" end_char="11613">Institut</TOKEN>
<TOKEN id="token-98-23" pos="word" morph="none" start_char="11615" end_char="11621">Pasteur</TOKEN>
<TOKEN id="token-98-24" pos="word" morph="none" start_char="11623" end_char="11624">of</TOKEN>
<TOKEN id="token-98-25" pos="word" morph="none" start_char="11626" end_char="11633">Shanghai</TOKEN>
<TOKEN id="token-98-26" pos="punct" morph="none" start_char="11635" end_char="11635">(</TOKEN>
<TOKEN id="token-98-27" pos="word" morph="none" start_char="11636" end_char="11638">IPS</TOKEN>
<TOKEN id="token-98-28" pos="punct" morph="none" start_char="11639" end_char="11640">).</TOKEN>
</SEG>
<SEG id="segment-99" start_char="11646" end_char="11792">
<ORIGINAL_TEXT>This hearsay has no link with the previous work of the Institut Pasteur (Paris) on SARS-CoV-1, the coronavirus that appeared in China in 2002-2003.</ORIGINAL_TEXT>
<TOKEN id="token-99-0" pos="word" morph="none" start_char="11646" end_char="11649">This</TOKEN>
<TOKEN id="token-99-1" pos="word" morph="none" start_char="11651" end_char="11657">hearsay</TOKEN>
<TOKEN id="token-99-2" pos="word" morph="none" start_char="11659" end_char="11661">has</TOKEN>
<TOKEN id="token-99-3" pos="word" morph="none" start_char="11663" end_char="11664">no</TOKEN>
<TOKEN id="token-99-4" pos="word" morph="none" start_char="11666" end_char="11669">link</TOKEN>
<TOKEN id="token-99-5" pos="word" morph="none" start_char="11671" end_char="11674">with</TOKEN>
<TOKEN id="token-99-6" pos="word" morph="none" start_char="11676" end_char="11678">the</TOKEN>
<TOKEN id="token-99-7" pos="word" morph="none" start_char="11680" end_char="11687">previous</TOKEN>
<TOKEN id="token-99-8" pos="word" morph="none" start_char="11689" end_char="11692">work</TOKEN>
<TOKEN id="token-99-9" pos="word" morph="none" start_char="11694" end_char="11695">of</TOKEN>
<TOKEN id="token-99-10" pos="word" morph="none" start_char="11697" end_char="11699">the</TOKEN>
<TOKEN id="token-99-11" pos="word" morph="none" start_char="11701" end_char="11708">Institut</TOKEN>
<TOKEN id="token-99-12" pos="word" morph="none" start_char="11710" end_char="11716">Pasteur</TOKEN>
<TOKEN id="token-99-13" pos="punct" morph="none" start_char="11718" end_char="11718">(</TOKEN>
<TOKEN id="token-99-14" pos="word" morph="none" start_char="11719" end_char="11723">Paris</TOKEN>
<TOKEN id="token-99-15" pos="punct" morph="none" start_char="11724" end_char="11724">)</TOKEN>
<TOKEN id="token-99-16" pos="word" morph="none" start_char="11726" end_char="11727">on</TOKEN>
<TOKEN id="token-99-17" pos="unknown" morph="none" start_char="11729" end_char="11738">SARS-CoV-1</TOKEN>
<TOKEN id="token-99-18" pos="punct" morph="none" start_char="11739" end_char="11739">,</TOKEN>
<TOKEN id="token-99-19" pos="word" morph="none" start_char="11741" end_char="11743">the</TOKEN>
<TOKEN id="token-99-20" pos="word" morph="none" start_char="11745" end_char="11755">coronavirus</TOKEN>
<TOKEN id="token-99-21" pos="word" morph="none" start_char="11757" end_char="11760">that</TOKEN>
<TOKEN id="token-99-22" pos="word" morph="none" start_char="11762" end_char="11769">appeared</TOKEN>
<TOKEN id="token-99-23" pos="word" morph="none" start_char="11771" end_char="11772">in</TOKEN>
<TOKEN id="token-99-24" pos="word" morph="none" start_char="11774" end_char="11778">China</TOKEN>
<TOKEN id="token-99-25" pos="word" morph="none" start_char="11780" end_char="11781">in</TOKEN>
<TOKEN id="token-99-26" pos="unknown" morph="none" start_char="11783" end_char="11791">2002-2003</TOKEN>
<TOKEN id="token-99-27" pos="punct" morph="none" start_char="11792" end_char="11792">.</TOKEN>
</SEG>
<SEG id="segment-100" start_char="11798" end_char="11906">
<ORIGINAL_TEXT>The videos based on this conspiracy theory, which are currently circulating on the web, are completely false.</ORIGINAL_TEXT>
<TOKEN id="token-100-0" pos="word" morph="none" start_char="11798" end_char="11800">The</TOKEN>
<TOKEN id="token-100-1" pos="word" morph="none" start_char="11802" end_char="11807">videos</TOKEN>
<TOKEN id="token-100-2" pos="word" morph="none" start_char="11809" end_char="11813">based</TOKEN>
<TOKEN id="token-100-3" pos="word" morph="none" start_char="11815" end_char="11816">on</TOKEN>
<TOKEN id="token-100-4" pos="word" morph="none" start_char="11818" end_char="11821">this</TOKEN>
<TOKEN id="token-100-5" pos="word" morph="none" start_char="11823" end_char="11832">conspiracy</TOKEN>
<TOKEN id="token-100-6" pos="word" morph="none" start_char="11834" end_char="11839">theory</TOKEN>
<TOKEN id="token-100-7" pos="punct" morph="none" start_char="11840" end_char="11840">,</TOKEN>
<TOKEN id="token-100-8" pos="word" morph="none" start_char="11842" end_char="11846">which</TOKEN>
<TOKEN id="token-100-9" pos="word" morph="none" start_char="11848" end_char="11850">are</TOKEN>
<TOKEN id="token-100-10" pos="word" morph="none" start_char="11852" end_char="11860">currently</TOKEN>
<TOKEN id="token-100-11" pos="word" morph="none" start_char="11862" end_char="11872">circulating</TOKEN>
<TOKEN id="token-100-12" pos="word" morph="none" start_char="11874" end_char="11875">on</TOKEN>
<TOKEN id="token-100-13" pos="word" morph="none" start_char="11877" end_char="11879">the</TOKEN>
<TOKEN id="token-100-14" pos="word" morph="none" start_char="11881" end_char="11883">web</TOKEN>
<TOKEN id="token-100-15" pos="punct" morph="none" start_char="11884" end_char="11884">,</TOKEN>
<TOKEN id="token-100-16" pos="word" morph="none" start_char="11886" end_char="11888">are</TOKEN>
<TOKEN id="token-100-17" pos="word" morph="none" start_char="11890" end_char="11899">completely</TOKEN>
<TOKEN id="token-100-18" pos="word" morph="none" start_char="11901" end_char="11905">false</TOKEN>
<TOKEN id="token-100-19" pos="punct" morph="none" start_char="11906" end_char="11906">.</TOKEN>
</SEG>
<SEG id="segment-101" start_char="11912" end_char="11923">
<ORIGINAL_TEXT>Explanations</ORIGINAL_TEXT>
<TOKEN id="token-101-0" pos="word" morph="none" start_char="11912" end_char="11923">Explanations</TOKEN>
</SEG>
<SEG id="segment-102" start_char="11927" end_char="12001">
<ORIGINAL_TEXT>1 _ There is no evidence that SARS-CoV-2 coronavirus was created by humans.</ORIGINAL_TEXT>
<TOKEN id="token-102-0" pos="word" morph="none" start_char="11927" end_char="11927">1</TOKEN>
<TOKEN id="token-102-1" pos="word" morph="none" start_char="11929" end_char="11929">_</TOKEN>
<TOKEN id="token-102-2" pos="word" morph="none" start_char="11931" end_char="11935">There</TOKEN>
<TOKEN id="token-102-3" pos="word" morph="none" start_char="11937" end_char="11938">is</TOKEN>
<TOKEN id="token-102-4" pos="word" morph="none" start_char="11940" end_char="11941">no</TOKEN>
<TOKEN id="token-102-5" pos="word" morph="none" start_char="11943" end_char="11950">evidence</TOKEN>
<TOKEN id="token-102-6" pos="word" morph="none" start_char="11952" end_char="11955">that</TOKEN>
<TOKEN id="token-102-7" pos="unknown" morph="none" start_char="11957" end_char="11966">SARS-CoV-2</TOKEN>
<TOKEN id="token-102-8" pos="word" morph="none" start_char="11968" end_char="11978">coronavirus</TOKEN>
<TOKEN id="token-102-9" pos="word" morph="none" start_char="11980" end_char="11982">was</TOKEN>
<TOKEN id="token-102-10" pos="word" morph="none" start_char="11984" end_char="11990">created</TOKEN>
<TOKEN id="token-102-11" pos="word" morph="none" start_char="11992" end_char="11993">by</TOKEN>
<TOKEN id="token-102-12" pos="word" morph="none" start_char="11995" end_char="12000">humans</TOKEN>
<TOKEN id="token-102-13" pos="punct" morph="none" start_char="12001" end_char="12001">.</TOKEN>
</SEG>
<SEG id="segment-103" start_char="12005" end_char="12124">
<ORIGINAL_TEXT>A scientific article published on March 17, 2020 disproved the idea that this virus resulted from a laboratory creation.</ORIGINAL_TEXT>
<TOKEN id="token-103-0" pos="word" morph="none" start_char="12005" end_char="12005">A</TOKEN>
<TOKEN id="token-103-1" pos="word" morph="none" start_char="12007" end_char="12016">scientific</TOKEN>
<TOKEN id="token-103-2" pos="word" morph="none" start_char="12018" end_char="12024">article</TOKEN>
<TOKEN id="token-103-3" pos="word" morph="none" start_char="12026" end_char="12034">published</TOKEN>
<TOKEN id="token-103-4" pos="word" morph="none" start_char="12036" end_char="12037">on</TOKEN>
<TOKEN id="token-103-5" pos="word" morph="none" start_char="12039" end_char="12043">March</TOKEN>
<TOKEN id="token-103-6" pos="word" morph="none" start_char="12045" end_char="12046">17</TOKEN>
<TOKEN id="token-103-7" pos="punct" morph="none" start_char="12047" end_char="12047">,</TOKEN>
<TOKEN id="token-103-8" pos="word" morph="none" start_char="12049" end_char="12052">2020</TOKEN>
<TOKEN id="token-103-9" pos="word" morph="none" start_char="12054" end_char="12062">disproved</TOKEN>
<TOKEN id="token-103-10" pos="word" morph="none" start_char="12064" end_char="12066">the</TOKEN>
<TOKEN id="token-103-11" pos="word" morph="none" start_char="12068" end_char="12071">idea</TOKEN>
<TOKEN id="token-103-12" pos="word" morph="none" start_char="12073" end_char="12076">that</TOKEN>
<TOKEN id="token-103-13" pos="word" morph="none" start_char="12078" end_char="12081">this</TOKEN>
<TOKEN id="token-103-14" pos="word" morph="none" start_char="12083" end_char="12087">virus</TOKEN>
<TOKEN id="token-103-15" pos="word" morph="none" start_char="12089" end_char="12096">resulted</TOKEN>
<TOKEN id="token-103-16" pos="word" morph="none" start_char="12098" end_char="12101">from</TOKEN>
<TOKEN id="token-103-17" pos="word" morph="none" start_char="12103" end_char="12103">a</TOKEN>
<TOKEN id="token-103-18" pos="word" morph="none" start_char="12105" end_char="12114">laboratory</TOKEN>
<TOKEN id="token-103-19" pos="word" morph="none" start_char="12116" end_char="12123">creation</TOKEN>
<TOKEN id="token-103-20" pos="punct" morph="none" start_char="12124" end_char="12124">.</TOKEN>
</SEG>
<SEG id="segment-104" start_char="12126" end_char="12261">
<ORIGINAL_TEXT>In the study, the researchers examined what could be deduced from the origin of SARS-CoV-2, from a comparative analysis of genetic data.</ORIGINAL_TEXT>
<TOKEN id="token-104-0" pos="word" morph="none" start_char="12126" end_char="12127">In</TOKEN>
<TOKEN id="token-104-1" pos="word" morph="none" start_char="12129" end_char="12131">the</TOKEN>
<TOKEN id="token-104-2" pos="word" morph="none" start_char="12133" end_char="12137">study</TOKEN>
<TOKEN id="token-104-3" pos="punct" morph="none" start_char="12138" end_char="12138">,</TOKEN>
<TOKEN id="token-104-4" pos="word" morph="none" start_char="12140" end_char="12142">the</TOKEN>
<TOKEN id="token-104-5" pos="word" morph="none" start_char="12144" end_char="12154">researchers</TOKEN>
<TOKEN id="token-104-6" pos="word" morph="none" start_char="12156" end_char="12163">examined</TOKEN>
<TOKEN id="token-104-7" pos="word" morph="none" start_char="12165" end_char="12168">what</TOKEN>
<TOKEN id="token-104-8" pos="word" morph="none" start_char="12170" end_char="12174">could</TOKEN>
<TOKEN id="token-104-9" pos="word" morph="none" start_char="12176" end_char="12177">be</TOKEN>
<TOKEN id="token-104-10" pos="word" morph="none" start_char="12179" end_char="12185">deduced</TOKEN>
<TOKEN id="token-104-11" pos="word" morph="none" start_char="12187" end_char="12190">from</TOKEN>
<TOKEN id="token-104-12" pos="word" morph="none" start_char="12192" end_char="12194">the</TOKEN>
<TOKEN id="token-104-13" pos="word" morph="none" start_char="12196" end_char="12201">origin</TOKEN>
<TOKEN id="token-104-14" pos="word" morph="none" start_char="12203" end_char="12204">of</TOKEN>
<TOKEN id="token-104-15" pos="unknown" morph="none" start_char="12206" end_char="12215">SARS-CoV-2</TOKEN>
<TOKEN id="token-104-16" pos="punct" morph="none" start_char="12216" end_char="12216">,</TOKEN>
<TOKEN id="token-104-17" pos="word" morph="none" start_char="12218" end_char="12221">from</TOKEN>
<TOKEN id="token-104-18" pos="word" morph="none" start_char="12223" end_char="12223">a</TOKEN>
<TOKEN id="token-104-19" pos="word" morph="none" start_char="12225" end_char="12235">comparative</TOKEN>
<TOKEN id="token-104-20" pos="word" morph="none" start_char="12237" end_char="12244">analysis</TOKEN>
<TOKEN id="token-104-21" pos="word" morph="none" start_char="12246" end_char="12247">of</TOKEN>
<TOKEN id="token-104-22" pos="word" morph="none" start_char="12249" end_char="12255">genetic</TOKEN>
<TOKEN id="token-104-23" pos="word" morph="none" start_char="12257" end_char="12260">data</TOKEN>
<TOKEN id="token-104-24" pos="punct" morph="none" start_char="12261" end_char="12261">.</TOKEN>
</SEG>
<SEG id="segment-105" start_char="12263" end_char="12392">
<ORIGINAL_TEXT>In the article, they describe the notable characteristics of its genome and discuss the scenarios in which it could have occurred.</ORIGINAL_TEXT>
<TOKEN id="token-105-0" pos="word" morph="none" start_char="12263" end_char="12264">In</TOKEN>
<TOKEN id="token-105-1" pos="word" morph="none" start_char="12266" end_char="12268">the</TOKEN>
<TOKEN id="token-105-2" pos="word" morph="none" start_char="12270" end_char="12276">article</TOKEN>
<TOKEN id="token-105-3" pos="punct" morph="none" start_char="12277" end_char="12277">,</TOKEN>
<TOKEN id="token-105-4" pos="word" morph="none" start_char="12279" end_char="12282">they</TOKEN>
<TOKEN id="token-105-5" pos="word" morph="none" start_char="12284" end_char="12291">describe</TOKEN>
<TOKEN id="token-105-6" pos="word" morph="none" start_char="12293" end_char="12295">the</TOKEN>
<TOKEN id="token-105-7" pos="word" morph="none" start_char="12297" end_char="12303">notable</TOKEN>
<TOKEN id="token-105-8" pos="word" morph="none" start_char="12305" end_char="12319">characteristics</TOKEN>
<TOKEN id="token-105-9" pos="word" morph="none" start_char="12321" end_char="12322">of</TOKEN>
<TOKEN id="token-105-10" pos="word" morph="none" start_char="12324" end_char="12326">its</TOKEN>
<TOKEN id="token-105-11" pos="word" morph="none" start_char="12328" end_char="12333">genome</TOKEN>
<TOKEN id="token-105-12" pos="word" morph="none" start_char="12335" end_char="12337">and</TOKEN>
<TOKEN id="token-105-13" pos="word" morph="none" start_char="12339" end_char="12345">discuss</TOKEN>
<TOKEN id="token-105-14" pos="word" morph="none" start_char="12347" end_char="12349">the</TOKEN>
<TOKEN id="token-105-15" pos="word" morph="none" start_char="12351" end_char="12359">scenarios</TOKEN>
<TOKEN id="token-105-16" pos="word" morph="none" start_char="12361" end_char="12362">in</TOKEN>
<TOKEN id="token-105-17" pos="word" morph="none" start_char="12364" end_char="12368">which</TOKEN>
<TOKEN id="token-105-18" pos="word" morph="none" start_char="12370" end_char="12371">it</TOKEN>
<TOKEN id="token-105-19" pos="word" morph="none" start_char="12373" end_char="12377">could</TOKEN>
<TOKEN id="token-105-20" pos="word" morph="none" start_char="12379" end_char="12382">have</TOKEN>
<TOKEN id="token-105-21" pos="word" morph="none" start_char="12384" end_char="12391">occurred</TOKEN>
<TOKEN id="token-105-22" pos="punct" morph="none" start_char="12392" end_char="12392">.</TOKEN>
</SEG>
<SEG id="segment-106" start_char="12394" end_char="12490">
<ORIGINAL_TEXT>Their analyses clearly show that there is no indication that SARS-CoV-2 could be a lab construct.</ORIGINAL_TEXT>
<TOKEN id="token-106-0" pos="word" morph="none" start_char="12394" end_char="12398">Their</TOKEN>
<TOKEN id="token-106-1" pos="word" morph="none" start_char="12400" end_char="12407">analyses</TOKEN>
<TOKEN id="token-106-2" pos="word" morph="none" start_char="12409" end_char="12415">clearly</TOKEN>
<TOKEN id="token-106-3" pos="word" morph="none" start_char="12417" end_char="12420">show</TOKEN>
<TOKEN id="token-106-4" pos="word" morph="none" start_char="12422" end_char="12425">that</TOKEN>
<TOKEN id="token-106-5" pos="word" morph="none" start_char="12427" end_char="12431">there</TOKEN>
<TOKEN id="token-106-6" pos="word" morph="none" start_char="12433" end_char="12434">is</TOKEN>
<TOKEN id="token-106-7" pos="word" morph="none" start_char="12436" end_char="12437">no</TOKEN>
<TOKEN id="token-106-8" pos="word" morph="none" start_char="12439" end_char="12448">indication</TOKEN>
<TOKEN id="token-106-9" pos="word" morph="none" start_char="12450" end_char="12453">that</TOKEN>
<TOKEN id="token-106-10" pos="unknown" morph="none" start_char="12455" end_char="12464">SARS-CoV-2</TOKEN>
<TOKEN id="token-106-11" pos="word" morph="none" start_char="12466" end_char="12470">could</TOKEN>
<TOKEN id="token-106-12" pos="word" morph="none" start_char="12472" end_char="12473">be</TOKEN>
<TOKEN id="token-106-13" pos="word" morph="none" start_char="12475" end_char="12475">a</TOKEN>
<TOKEN id="token-106-14" pos="word" morph="none" start_char="12477" end_char="12479">lab</TOKEN>
<TOKEN id="token-106-15" pos="word" morph="none" start_char="12481" end_char="12489">construct</TOKEN>
<TOKEN id="token-106-16" pos="punct" morph="none" start_char="12490" end_char="12490">.</TOKEN>
</SEG>
<SEG id="segment-107" start_char="12493" end_char="12589">
<ORIGINAL_TEXT>The proximal origin of SARS-CoV-2, Kristian G. Andersen, Andrew Rambaut, W. Ian Lipkin, Edward C.</ORIGINAL_TEXT>
<TOKEN id="token-107-0" pos="word" morph="none" start_char="12493" end_char="12495">The</TOKEN>
<TOKEN id="token-107-1" pos="word" morph="none" start_char="12497" end_char="12504">proximal</TOKEN>
<TOKEN id="token-107-2" pos="word" morph="none" start_char="12506" end_char="12511">origin</TOKEN>
<TOKEN id="token-107-3" pos="word" morph="none" start_char="12513" end_char="12514">of</TOKEN>
<TOKEN id="token-107-4" pos="unknown" morph="none" start_char="12516" end_char="12525">SARS-CoV-2</TOKEN>
<TOKEN id="token-107-5" pos="punct" morph="none" start_char="12526" end_char="12526">,</TOKEN>
<TOKEN id="token-107-6" pos="word" morph="none" start_char="12528" end_char="12535">Kristian</TOKEN>
<TOKEN id="token-107-7" pos="word" morph="none" start_char="12537" end_char="12537">G</TOKEN>
<TOKEN id="token-107-8" pos="punct" morph="none" start_char="12538" end_char="12538">.</TOKEN>
<TOKEN id="token-107-9" pos="word" morph="none" start_char="12540" end_char="12547">Andersen</TOKEN>
<TOKEN id="token-107-10" pos="punct" morph="none" start_char="12548" end_char="12548">,</TOKEN>
<TOKEN id="token-107-11" pos="word" morph="none" start_char="12550" end_char="12555">Andrew</TOKEN>
<TOKEN id="token-107-12" pos="word" morph="none" start_char="12557" end_char="12563">Rambaut</TOKEN>
<TOKEN id="token-107-13" pos="punct" morph="none" start_char="12564" end_char="12564">,</TOKEN>
<TOKEN id="token-107-14" pos="word" morph="none" start_char="12566" end_char="12566">W</TOKEN>
<TOKEN id="token-107-15" pos="punct" morph="none" start_char="12567" end_char="12567">.</TOKEN>
<TOKEN id="token-107-16" pos="word" morph="none" start_char="12569" end_char="12571">Ian</TOKEN>
<TOKEN id="token-107-17" pos="word" morph="none" start_char="12573" end_char="12578">Lipkin</TOKEN>
<TOKEN id="token-107-18" pos="punct" morph="none" start_char="12579" end_char="12579">,</TOKEN>
<TOKEN id="token-107-19" pos="word" morph="none" start_char="12581" end_char="12586">Edward</TOKEN>
<TOKEN id="token-107-20" pos="word" morph="none" start_char="12588" end_char="12588">C</TOKEN>
<TOKEN id="token-107-21" pos="punct" morph="none" start_char="12589" end_char="12589">.</TOKEN>
</SEG>
<SEG id="segment-108" start_char="12591" end_char="12606">
<ORIGINAL_TEXT>Holmes Robert F.</ORIGINAL_TEXT>
<TOKEN id="token-108-0" pos="word" morph="none" start_char="12591" end_char="12596">Holmes</TOKEN>
<TOKEN id="token-108-1" pos="word" morph="none" start_char="12598" end_char="12603">Robert</TOKEN>
<TOKEN id="token-108-2" pos="word" morph="none" start_char="12605" end_char="12605">F</TOKEN>
<TOKEN id="token-108-3" pos="punct" morph="none" start_char="12606" end_char="12606">.</TOKEN>
</SEG>
<SEG id="segment-109" start_char="12608" end_char="12613">
<ORIGINAL_TEXT>Garry.</ORIGINAL_TEXT>
<TOKEN id="token-109-0" pos="word" morph="none" start_char="12608" end_char="12612">Garry</TOKEN>
<TOKEN id="token-109-1" pos="punct" morph="none" start_char="12613" end_char="12613">.</TOKEN>
</SEG>
<SEG id="segment-110" start_char="12616" end_char="12630">
<ORIGINAL_TEXT>Nature Medicine</ORIGINAL_TEXT>
<TOKEN id="token-110-0" pos="word" morph="none" start_char="12616" end_char="12621">Nature</TOKEN>
<TOKEN id="token-110-1" pos="word" morph="none" start_char="12623" end_char="12630">Medicine</TOKEN>
</SEG>
<SEG id="segment-111" start_char="12633" end_char="12638">
<ORIGINAL_TEXT>(2020)</ORIGINAL_TEXT>
<TOKEN id="token-111-0" pos="punct" morph="none" start_char="12633" end_char="12633">(</TOKEN>
<TOKEN id="token-111-1" pos="word" morph="none" start_char="12634" end_char="12637">2020</TOKEN>
<TOKEN id="token-111-2" pos="punct" morph="none" start_char="12638" end_char="12638">)</TOKEN>
</SEG>
<SEG id="segment-112" start_char="12641" end_char="12659">
<ORIGINAL_TEXT>Decryption by Prof.</ORIGINAL_TEXT>
<TOKEN id="token-112-0" pos="word" morph="none" start_char="12641" end_char="12650">Decryption</TOKEN>
<TOKEN id="token-112-1" pos="word" morph="none" start_char="12652" end_char="12653">by</TOKEN>
<TOKEN id="token-112-2" pos="word" morph="none" start_char="12655" end_char="12658">Prof</TOKEN>
<TOKEN id="token-112-3" pos="punct" morph="none" start_char="12659" end_char="12659">.</TOKEN>
</SEG>
<SEG id="segment-113" start_char="12661" end_char="12790">
<ORIGINAL_TEXT>Olivier Schwartz, former Scientific director of the Institut Pasteur (https://twitter.com/MinSoliSante/status/1240239777925881856)</ORIGINAL_TEXT>
<TOKEN id="token-113-0" pos="word" morph="none" start_char="12661" end_char="12667">Olivier</TOKEN>
<TOKEN id="token-113-1" pos="word" morph="none" start_char="12669" end_char="12676">Schwartz</TOKEN>
<TOKEN id="token-113-2" pos="punct" morph="none" start_char="12677" end_char="12677">,</TOKEN>
<TOKEN id="token-113-3" pos="word" morph="none" start_char="12679" end_char="12684">former</TOKEN>
<TOKEN id="token-113-4" pos="word" morph="none" start_char="12686" end_char="12695">Scientific</TOKEN>
<TOKEN id="token-113-5" pos="word" morph="none" start_char="12697" end_char="12704">director</TOKEN>
<TOKEN id="token-113-6" pos="word" morph="none" start_char="12706" end_char="12707">of</TOKEN>
<TOKEN id="token-113-7" pos="word" morph="none" start_char="12709" end_char="12711">the</TOKEN>
<TOKEN id="token-113-8" pos="word" morph="none" start_char="12713" end_char="12720">Institut</TOKEN>
<TOKEN id="token-113-9" pos="word" morph="none" start_char="12722" end_char="12728">Pasteur</TOKEN>
<TOKEN id="token-113-10" pos="punct" morph="none" start_char="12730" end_char="12730">(</TOKEN>
<TOKEN id="token-113-11" pos="unknown" morph="none" start_char="12731" end_char="12789">https://twitter.com/MinSoliSante/status/1240239777925881856</TOKEN>
<TOKEN id="token-113-12" pos="punct" morph="none" start_char="12790" end_char="12790">)</TOKEN>
</SEG>
<SEG id="segment-114" start_char="12793" end_char="12941">
<ORIGINAL_TEXT>2 _ The Institut Pasteur of Shanghai (IPS) did not work on coronaviruses in the P4 laboratory in Wuhan, which is associated with a Chinese institute.</ORIGINAL_TEXT>
<TOKEN id="token-114-0" pos="word" morph="none" start_char="12793" end_char="12793">2</TOKEN>
<TOKEN id="token-114-1" pos="word" morph="none" start_char="12795" end_char="12795">_</TOKEN>
<TOKEN id="token-114-2" pos="word" morph="none" start_char="12797" end_char="12799">The</TOKEN>
<TOKEN id="token-114-3" pos="word" morph="none" start_char="12801" end_char="12808">Institut</TOKEN>
<TOKEN id="token-114-4" pos="word" morph="none" start_char="12810" end_char="12816">Pasteur</TOKEN>
<TOKEN id="token-114-5" pos="word" morph="none" start_char="12818" end_char="12819">of</TOKEN>
<TOKEN id="token-114-6" pos="word" morph="none" start_char="12821" end_char="12828">Shanghai</TOKEN>
<TOKEN id="token-114-7" pos="punct" morph="none" start_char="12830" end_char="12830">(</TOKEN>
<TOKEN id="token-114-8" pos="word" morph="none" start_char="12831" end_char="12833">IPS</TOKEN>
<TOKEN id="token-114-9" pos="punct" morph="none" start_char="12834" end_char="12834">)</TOKEN>
<TOKEN id="token-114-10" pos="word" morph="none" start_char="12836" end_char="12838">did</TOKEN>
<TOKEN id="token-114-11" pos="word" morph="none" start_char="12840" end_char="12842">not</TOKEN>
<TOKEN id="token-114-12" pos="word" morph="none" start_char="12844" end_char="12847">work</TOKEN>
<TOKEN id="token-114-13" pos="word" morph="none" start_char="12849" end_char="12850">on</TOKEN>
<TOKEN id="token-114-14" pos="word" morph="none" start_char="12852" end_char="12864">coronaviruses</TOKEN>
<TOKEN id="token-114-15" pos="word" morph="none" start_char="12866" end_char="12867">in</TOKEN>
<TOKEN id="token-114-16" pos="word" morph="none" start_char="12869" end_char="12871">the</TOKEN>
<TOKEN id="token-114-17" pos="word" morph="none" start_char="12873" end_char="12874">P4</TOKEN>
<TOKEN id="token-114-18" pos="word" morph="none" start_char="12876" end_char="12885">laboratory</TOKEN>
<TOKEN id="token-114-19" pos="word" morph="none" start_char="12887" end_char="12888">in</TOKEN>
<TOKEN id="token-114-20" pos="word" morph="none" start_char="12890" end_char="12894">Wuhan</TOKEN>
<TOKEN id="token-114-21" pos="punct" morph="none" start_char="12895" end_char="12895">,</TOKEN>
<TOKEN id="token-114-22" pos="word" morph="none" start_char="12897" end_char="12901">which</TOKEN>
<TOKEN id="token-114-23" pos="word" morph="none" start_char="12903" end_char="12904">is</TOKEN>
<TOKEN id="token-114-24" pos="word" morph="none" start_char="12906" end_char="12915">associated</TOKEN>
<TOKEN id="token-114-25" pos="word" morph="none" start_char="12917" end_char="12920">with</TOKEN>
<TOKEN id="token-114-26" pos="word" morph="none" start_char="12922" end_char="12922">a</TOKEN>
<TOKEN id="token-114-27" pos="word" morph="none" start_char="12924" end_char="12930">Chinese</TOKEN>
<TOKEN id="token-114-28" pos="word" morph="none" start_char="12932" end_char="12940">institute</TOKEN>
<TOKEN id="token-114-29" pos="punct" morph="none" start_char="12941" end_char="12941">.</TOKEN>
</SEG>
<SEG id="segment-115" start_char="12945" end_char="13326">
<ORIGINAL_TEXT>Scientific collaboration with China, on the most dangerous pathogens (referred to as "class 4," denoting pathogens that can only be the object of research in extremely secure laboratories, designated as "P4"), and on emerging viruses, fits into the context of a French-Chinese agreement for preventing and combatting emerging infectious viruses, signed in Peking on October 9, 2004.</ORIGINAL_TEXT>
<TOKEN id="token-115-0" pos="word" morph="none" start_char="12945" end_char="12954">Scientific</TOKEN>
<TOKEN id="token-115-1" pos="word" morph="none" start_char="12956" end_char="12968">collaboration</TOKEN>
<TOKEN id="token-115-2" pos="word" morph="none" start_char="12970" end_char="12973">with</TOKEN>
<TOKEN id="token-115-3" pos="word" morph="none" start_char="12975" end_char="12979">China</TOKEN>
<TOKEN id="token-115-4" pos="punct" morph="none" start_char="12980" end_char="12980">,</TOKEN>
<TOKEN id="token-115-5" pos="word" morph="none" start_char="12982" end_char="12983">on</TOKEN>
<TOKEN id="token-115-6" pos="word" morph="none" start_char="12985" end_char="12987">the</TOKEN>
<TOKEN id="token-115-7" pos="word" morph="none" start_char="12989" end_char="12992">most</TOKEN>
<TOKEN id="token-115-8" pos="word" morph="none" start_char="12994" end_char="13002">dangerous</TOKEN>
<TOKEN id="token-115-9" pos="word" morph="none" start_char="13004" end_char="13012">pathogens</TOKEN>
<TOKEN id="token-115-10" pos="punct" morph="none" start_char="13014" end_char="13014">(</TOKEN>
<TOKEN id="token-115-11" pos="word" morph="none" start_char="13015" end_char="13022">referred</TOKEN>
<TOKEN id="token-115-12" pos="word" morph="none" start_char="13024" end_char="13025">to</TOKEN>
<TOKEN id="token-115-13" pos="word" morph="none" start_char="13027" end_char="13028">as</TOKEN>
<TOKEN id="token-115-14" pos="punct" morph="none" start_char="13030" end_char="13030">"</TOKEN>
<TOKEN id="token-115-15" pos="word" morph="none" start_char="13031" end_char="13035">class</TOKEN>
<TOKEN id="token-115-16" pos="word" morph="none" start_char="13037" end_char="13037">4</TOKEN>
<TOKEN id="token-115-17" pos="punct" morph="none" start_char="13038" end_char="13039">,"</TOKEN>
<TOKEN id="token-115-18" pos="word" morph="none" start_char="13041" end_char="13048">denoting</TOKEN>
<TOKEN id="token-115-19" pos="word" morph="none" start_char="13050" end_char="13058">pathogens</TOKEN>
<TOKEN id="token-115-20" pos="word" morph="none" start_char="13060" end_char="13063">that</TOKEN>
<TOKEN id="token-115-21" pos="word" morph="none" start_char="13065" end_char="13067">can</TOKEN>
<TOKEN id="token-115-22" pos="word" morph="none" start_char="13069" end_char="13072">only</TOKEN>
<TOKEN id="token-115-23" pos="word" morph="none" start_char="13074" end_char="13075">be</TOKEN>
<TOKEN id="token-115-24" pos="word" morph="none" start_char="13077" end_char="13079">the</TOKEN>
<TOKEN id="token-115-25" pos="word" morph="none" start_char="13081" end_char="13086">object</TOKEN>
<TOKEN id="token-115-26" pos="word" morph="none" start_char="13088" end_char="13089">of</TOKEN>
<TOKEN id="token-115-27" pos="word" morph="none" start_char="13091" end_char="13098">research</TOKEN>
<TOKEN id="token-115-28" pos="word" morph="none" start_char="13100" end_char="13101">in</TOKEN>
<TOKEN id="token-115-29" pos="word" morph="none" start_char="13103" end_char="13111">extremely</TOKEN>
<TOKEN id="token-115-30" pos="word" morph="none" start_char="13113" end_char="13118">secure</TOKEN>
<TOKEN id="token-115-31" pos="word" morph="none" start_char="13120" end_char="13131">laboratories</TOKEN>
<TOKEN id="token-115-32" pos="punct" morph="none" start_char="13132" end_char="13132">,</TOKEN>
<TOKEN id="token-115-33" pos="word" morph="none" start_char="13134" end_char="13143">designated</TOKEN>
<TOKEN id="token-115-34" pos="word" morph="none" start_char="13145" end_char="13146">as</TOKEN>
<TOKEN id="token-115-35" pos="punct" morph="none" start_char="13148" end_char="13148">"</TOKEN>
<TOKEN id="token-115-36" pos="word" morph="none" start_char="13149" end_char="13150">P4</TOKEN>
<TOKEN id="token-115-37" pos="punct" morph="none" start_char="13151" end_char="13153">"),</TOKEN>
<TOKEN id="token-115-38" pos="word" morph="none" start_char="13155" end_char="13157">and</TOKEN>
<TOKEN id="token-115-39" pos="word" morph="none" start_char="13159" end_char="13160">on</TOKEN>
<TOKEN id="token-115-40" pos="word" morph="none" start_char="13162" end_char="13169">emerging</TOKEN>
<TOKEN id="token-115-41" pos="word" morph="none" start_char="13171" end_char="13177">viruses</TOKEN>
<TOKEN id="token-115-42" pos="punct" morph="none" start_char="13178" end_char="13178">,</TOKEN>
<TOKEN id="token-115-43" pos="word" morph="none" start_char="13180" end_char="13183">fits</TOKEN>
<TOKEN id="token-115-44" pos="word" morph="none" start_char="13185" end_char="13188">into</TOKEN>
<TOKEN id="token-115-45" pos="word" morph="none" start_char="13190" end_char="13192">the</TOKEN>
<TOKEN id="token-115-46" pos="word" morph="none" start_char="13194" end_char="13200">context</TOKEN>
<TOKEN id="token-115-47" pos="word" morph="none" start_char="13202" end_char="13203">of</TOKEN>
<TOKEN id="token-115-48" pos="word" morph="none" start_char="13205" end_char="13205">a</TOKEN>
<TOKEN id="token-115-49" pos="unknown" morph="none" start_char="13207" end_char="13220">French-Chinese</TOKEN>
<TOKEN id="token-115-50" pos="word" morph="none" start_char="13222" end_char="13230">agreement</TOKEN>
<TOKEN id="token-115-51" pos="word" morph="none" start_char="13232" end_char="13234">for</TOKEN>
<TOKEN id="token-115-52" pos="word" morph="none" start_char="13236" end_char="13245">preventing</TOKEN>
<TOKEN id="token-115-53" pos="word" morph="none" start_char="13247" end_char="13249">and</TOKEN>
<TOKEN id="token-115-54" pos="word" morph="none" start_char="13251" end_char="13260">combatting</TOKEN>
<TOKEN id="token-115-55" pos="word" morph="none" start_char="13262" end_char="13269">emerging</TOKEN>
<TOKEN id="token-115-56" pos="word" morph="none" start_char="13271" end_char="13280">infectious</TOKEN>
<TOKEN id="token-115-57" pos="word" morph="none" start_char="13282" end_char="13288">viruses</TOKEN>
<TOKEN id="token-115-58" pos="punct" morph="none" start_char="13289" end_char="13289">,</TOKEN>
<TOKEN id="token-115-59" pos="word" morph="none" start_char="13291" end_char="13296">signed</TOKEN>
<TOKEN id="token-115-60" pos="word" morph="none" start_char="13298" end_char="13299">in</TOKEN>
<TOKEN id="token-115-61" pos="word" morph="none" start_char="13301" end_char="13306">Peking</TOKEN>
<TOKEN id="token-115-62" pos="word" morph="none" start_char="13308" end_char="13309">on</TOKEN>
<TOKEN id="token-115-63" pos="word" morph="none" start_char="13311" end_char="13317">October</TOKEN>
<TOKEN id="token-115-64" pos="word" morph="none" start_char="13319" end_char="13319">9</TOKEN>
<TOKEN id="token-115-65" pos="punct" morph="none" start_char="13320" end_char="13320">,</TOKEN>
<TOKEN id="token-115-66" pos="word" morph="none" start_char="13322" end_char="13325">2004</TOKEN>
<TOKEN id="token-115-67" pos="punct" morph="none" start_char="13326" end_char="13326">.</TOKEN>
</SEG>
<SEG id="segment-116" start_char="13329" end_char="13547">
<ORIGINAL_TEXT>It also fits into the context of the International Health Regulations of 2005, which entered into affect after the agreement, that uphold the principle of containment at source in the battle against infectious diseases.</ORIGINAL_TEXT>
<TOKEN id="token-116-0" pos="word" morph="none" start_char="13329" end_char="13330">It</TOKEN>
<TOKEN id="token-116-1" pos="word" morph="none" start_char="13332" end_char="13335">also</TOKEN>
<TOKEN id="token-116-2" pos="word" morph="none" start_char="13337" end_char="13340">fits</TOKEN>
<TOKEN id="token-116-3" pos="word" morph="none" start_char="13342" end_char="13345">into</TOKEN>
<TOKEN id="token-116-4" pos="word" morph="none" start_char="13347" end_char="13349">the</TOKEN>
<TOKEN id="token-116-5" pos="word" morph="none" start_char="13351" end_char="13357">context</TOKEN>
<TOKEN id="token-116-6" pos="word" morph="none" start_char="13359" end_char="13360">of</TOKEN>
<TOKEN id="token-116-7" pos="word" morph="none" start_char="13362" end_char="13364">the</TOKEN>
<TOKEN id="token-116-8" pos="word" morph="none" start_char="13366" end_char="13378">International</TOKEN>
<TOKEN id="token-116-9" pos="word" morph="none" start_char="13380" end_char="13385">Health</TOKEN>
<TOKEN id="token-116-10" pos="word" morph="none" start_char="13387" end_char="13397">Regulations</TOKEN>
<TOKEN id="token-116-11" pos="word" morph="none" start_char="13399" end_char="13400">of</TOKEN>
<TOKEN id="token-116-12" pos="word" morph="none" start_char="13402" end_char="13405">2005</TOKEN>
<TOKEN id="token-116-13" pos="punct" morph="none" start_char="13406" end_char="13406">,</TOKEN>
<TOKEN id="token-116-14" pos="word" morph="none" start_char="13408" end_char="13412">which</TOKEN>
<TOKEN id="token-116-15" pos="word" morph="none" start_char="13414" end_char="13420">entered</TOKEN>
<TOKEN id="token-116-16" pos="word" morph="none" start_char="13422" end_char="13425">into</TOKEN>
<TOKEN id="token-116-17" pos="word" morph="none" start_char="13427" end_char="13432">affect</TOKEN>
<TOKEN id="token-116-18" pos="word" morph="none" start_char="13434" end_char="13438">after</TOKEN>
<TOKEN id="token-116-19" pos="word" morph="none" start_char="13440" end_char="13442">the</TOKEN>
<TOKEN id="token-116-20" pos="word" morph="none" start_char="13444" end_char="13452">agreement</TOKEN>
<TOKEN id="token-116-21" pos="punct" morph="none" start_char="13453" end_char="13453">,</TOKEN>
<TOKEN id="token-116-22" pos="word" morph="none" start_char="13455" end_char="13458">that</TOKEN>
<TOKEN id="token-116-23" pos="word" morph="none" start_char="13460" end_char="13465">uphold</TOKEN>
<TOKEN id="token-116-24" pos="word" morph="none" start_char="13467" end_char="13469">the</TOKEN>
<TOKEN id="token-116-25" pos="word" morph="none" start_char="13471" end_char="13479">principle</TOKEN>
<TOKEN id="token-116-26" pos="word" morph="none" start_char="13481" end_char="13482">of</TOKEN>
<TOKEN id="token-116-27" pos="word" morph="none" start_char="13484" end_char="13494">containment</TOKEN>
<TOKEN id="token-116-28" pos="word" morph="none" start_char="13496" end_char="13497">at</TOKEN>
<TOKEN id="token-116-29" pos="word" morph="none" start_char="13499" end_char="13504">source</TOKEN>
<TOKEN id="token-116-30" pos="word" morph="none" start_char="13506" end_char="13507">in</TOKEN>
<TOKEN id="token-116-31" pos="word" morph="none" start_char="13509" end_char="13511">the</TOKEN>
<TOKEN id="token-116-32" pos="word" morph="none" start_char="13513" end_char="13518">battle</TOKEN>
<TOKEN id="token-116-33" pos="word" morph="none" start_char="13520" end_char="13526">against</TOKEN>
<TOKEN id="token-116-34" pos="word" morph="none" start_char="13528" end_char="13537">infectious</TOKEN>
<TOKEN id="token-116-35" pos="word" morph="none" start_char="13539" end_char="13546">diseases</TOKEN>
<TOKEN id="token-116-36" pos="punct" morph="none" start_char="13547" end_char="13547">.</TOKEN>
</SEG>
<SEG id="segment-117" start_char="13550" end_char="13595">
<ORIGINAL_TEXT>This intergovernmental collaboration directed:</ORIGINAL_TEXT>
<TOKEN id="token-117-0" pos="word" morph="none" start_char="13550" end_char="13553">This</TOKEN>
<TOKEN id="token-117-1" pos="word" morph="none" start_char="13555" end_char="13571">intergovernmental</TOKEN>
<TOKEN id="token-117-2" pos="word" morph="none" start_char="13573" end_char="13585">collaboration</TOKEN>
<TOKEN id="token-117-3" pos="word" morph="none" start_char="13587" end_char="13594">directed</TOKEN>
<TOKEN id="token-117-4" pos="punct" morph="none" start_char="13595" end_char="13595">:</TOKEN>
</SEG>
<SEG id="segment-118" start_char="13598" end_char="13999">
<ORIGINAL_TEXT>Firstly, the construction of the National laboratory of high-security biological containment (a P4 laboratory), in Wuhan on the campus of the Virology Institut of Wuhan (VIW).Under the authority of a Franco-Chinese steering committee, of which the Institut Pasteur is not a member, the activities of this P4 laboratory are the responsibility of a Chinese director, appointed by the Chinese authorities.</ORIGINAL_TEXT>
<TOKEN id="token-118-0" pos="word" morph="none" start_char="13598" end_char="13604">Firstly</TOKEN>
<TOKEN id="token-118-1" pos="punct" morph="none" start_char="13605" end_char="13605">,</TOKEN>
<TOKEN id="token-118-2" pos="word" morph="none" start_char="13607" end_char="13609">the</TOKEN>
<TOKEN id="token-118-3" pos="word" morph="none" start_char="13611" end_char="13622">construction</TOKEN>
<TOKEN id="token-118-4" pos="word" morph="none" start_char="13624" end_char="13625">of</TOKEN>
<TOKEN id="token-118-5" pos="word" morph="none" start_char="13627" end_char="13629">the</TOKEN>
<TOKEN id="token-118-6" pos="word" morph="none" start_char="13631" end_char="13638">National</TOKEN>
<TOKEN id="token-118-7" pos="word" morph="none" start_char="13640" end_char="13649">laboratory</TOKEN>
<TOKEN id="token-118-8" pos="word" morph="none" start_char="13651" end_char="13652">of</TOKEN>
<TOKEN id="token-118-9" pos="unknown" morph="none" start_char="13654" end_char="13666">high-security</TOKEN>
<TOKEN id="token-118-10" pos="word" morph="none" start_char="13668" end_char="13677">biological</TOKEN>
<TOKEN id="token-118-11" pos="word" morph="none" start_char="13679" end_char="13689">containment</TOKEN>
<TOKEN id="token-118-12" pos="punct" morph="none" start_char="13691" end_char="13691">(</TOKEN>
<TOKEN id="token-118-13" pos="word" morph="none" start_char="13692" end_char="13692">a</TOKEN>
<TOKEN id="token-118-14" pos="word" morph="none" start_char="13694" end_char="13695">P4</TOKEN>
<TOKEN id="token-118-15" pos="word" morph="none" start_char="13697" end_char="13706">laboratory</TOKEN>
<TOKEN id="token-118-16" pos="punct" morph="none" start_char="13707" end_char="13708">),</TOKEN>
<TOKEN id="token-118-17" pos="word" morph="none" start_char="13710" end_char="13711">in</TOKEN>
<TOKEN id="token-118-18" pos="word" morph="none" start_char="13713" end_char="13717">Wuhan</TOKEN>
<TOKEN id="token-118-19" pos="word" morph="none" start_char="13719" end_char="13720">on</TOKEN>
<TOKEN id="token-118-20" pos="word" morph="none" start_char="13722" end_char="13724">the</TOKEN>
<TOKEN id="token-118-21" pos="word" morph="none" start_char="13726" end_char="13731">campus</TOKEN>
<TOKEN id="token-118-22" pos="word" morph="none" start_char="13733" end_char="13734">of</TOKEN>
<TOKEN id="token-118-23" pos="word" morph="none" start_char="13736" end_char="13738">the</TOKEN>
<TOKEN id="token-118-24" pos="word" morph="none" start_char="13740" end_char="13747">Virology</TOKEN>
<TOKEN id="token-118-25" pos="word" morph="none" start_char="13749" end_char="13756">Institut</TOKEN>
<TOKEN id="token-118-26" pos="word" morph="none" start_char="13758" end_char="13759">of</TOKEN>
<TOKEN id="token-118-27" pos="word" morph="none" start_char="13761" end_char="13765">Wuhan</TOKEN>
<TOKEN id="token-118-28" pos="punct" morph="none" start_char="13767" end_char="13767">(</TOKEN>
<TOKEN id="token-118-29" pos="unknown" morph="none" start_char="13768" end_char="13777">VIW).Under</TOKEN>
<TOKEN id="token-118-30" pos="word" morph="none" start_char="13779" end_char="13781">the</TOKEN>
<TOKEN id="token-118-31" pos="word" morph="none" start_char="13783" end_char="13791">authority</TOKEN>
<TOKEN id="token-118-32" pos="word" morph="none" start_char="13793" end_char="13794">of</TOKEN>
<TOKEN id="token-118-33" pos="word" morph="none" start_char="13796" end_char="13796">a</TOKEN>
<TOKEN id="token-118-34" pos="unknown" morph="none" start_char="13798" end_char="13811">Franco-Chinese</TOKEN>
<TOKEN id="token-118-35" pos="word" morph="none" start_char="13813" end_char="13820">steering</TOKEN>
<TOKEN id="token-118-36" pos="word" morph="none" start_char="13822" end_char="13830">committee</TOKEN>
<TOKEN id="token-118-37" pos="punct" morph="none" start_char="13831" end_char="13831">,</TOKEN>
<TOKEN id="token-118-38" pos="word" morph="none" start_char="13833" end_char="13834">of</TOKEN>
<TOKEN id="token-118-39" pos="word" morph="none" start_char="13836" end_char="13840">which</TOKEN>
<TOKEN id="token-118-40" pos="word" morph="none" start_char="13842" end_char="13844">the</TOKEN>
<TOKEN id="token-118-41" pos="word" morph="none" start_char="13846" end_char="13853">Institut</TOKEN>
<TOKEN id="token-118-42" pos="word" morph="none" start_char="13855" end_char="13861">Pasteur</TOKEN>
<TOKEN id="token-118-43" pos="word" morph="none" start_char="13863" end_char="13864">is</TOKEN>
<TOKEN id="token-118-44" pos="word" morph="none" start_char="13866" end_char="13868">not</TOKEN>
<TOKEN id="token-118-45" pos="word" morph="none" start_char="13870" end_char="13870">a</TOKEN>
<TOKEN id="token-118-46" pos="word" morph="none" start_char="13872" end_char="13877">member</TOKEN>
<TOKEN id="token-118-47" pos="punct" morph="none" start_char="13878" end_char="13878">,</TOKEN>
<TOKEN id="token-118-48" pos="word" morph="none" start_char="13880" end_char="13882">the</TOKEN>
<TOKEN id="token-118-49" pos="word" morph="none" start_char="13884" end_char="13893">activities</TOKEN>
<TOKEN id="token-118-50" pos="word" morph="none" start_char="13895" end_char="13896">of</TOKEN>
<TOKEN id="token-118-51" pos="word" morph="none" start_char="13898" end_char="13901">this</TOKEN>
<TOKEN id="token-118-52" pos="word" morph="none" start_char="13903" end_char="13904">P4</TOKEN>
<TOKEN id="token-118-53" pos="word" morph="none" start_char="13906" end_char="13915">laboratory</TOKEN>
<TOKEN id="token-118-54" pos="word" morph="none" start_char="13917" end_char="13919">are</TOKEN>
<TOKEN id="token-118-55" pos="word" morph="none" start_char="13921" end_char="13923">the</TOKEN>
<TOKEN id="token-118-56" pos="word" morph="none" start_char="13925" end_char="13938">responsibility</TOKEN>
<TOKEN id="token-118-57" pos="word" morph="none" start_char="13940" end_char="13941">of</TOKEN>
<TOKEN id="token-118-58" pos="word" morph="none" start_char="13943" end_char="13943">a</TOKEN>
<TOKEN id="token-118-59" pos="word" morph="none" start_char="13945" end_char="13951">Chinese</TOKEN>
<TOKEN id="token-118-60" pos="word" morph="none" start_char="13953" end_char="13960">director</TOKEN>
<TOKEN id="token-118-61" pos="punct" morph="none" start_char="13961" end_char="13961">,</TOKEN>
<TOKEN id="token-118-62" pos="word" morph="none" start_char="13963" end_char="13971">appointed</TOKEN>
<TOKEN id="token-118-63" pos="word" morph="none" start_char="13973" end_char="13974">by</TOKEN>
<TOKEN id="token-118-64" pos="word" morph="none" start_char="13976" end_char="13978">the</TOKEN>
<TOKEN id="token-118-65" pos="word" morph="none" start_char="13980" end_char="13986">Chinese</TOKEN>
<TOKEN id="token-118-66" pos="word" morph="none" start_char="13988" end_char="13998">authorities</TOKEN>
<TOKEN id="token-118-67" pos="punct" morph="none" start_char="13999" end_char="13999">.</TOKEN>
</SEG>
<SEG id="segment-119" start_char="14002" end_char="14442">
<ORIGINAL_TEXT>Secondly, the creation of the Institut Pasteur of Shanghai (IPS), a research center that holds special status within the Academy of sciences in China (IPS-CAS).The IPS has a governing system based on a board of directors and a joint scientific committee, the former co-led by the President of the Institut Pasteur and the latter led by Mr. Kourilsky, honorary professor of the College de France, and former President of the Institut Pasteur.</ORIGINAL_TEXT>
<TOKEN id="token-119-0" pos="word" morph="none" start_char="14002" end_char="14009">Secondly</TOKEN>
<TOKEN id="token-119-1" pos="punct" morph="none" start_char="14010" end_char="14010">,</TOKEN>
<TOKEN id="token-119-2" pos="word" morph="none" start_char="14012" end_char="14014">the</TOKEN>
<TOKEN id="token-119-3" pos="word" morph="none" start_char="14016" end_char="14023">creation</TOKEN>
<TOKEN id="token-119-4" pos="word" morph="none" start_char="14025" end_char="14026">of</TOKEN>
<TOKEN id="token-119-5" pos="word" morph="none" start_char="14028" end_char="14030">the</TOKEN>
<TOKEN id="token-119-6" pos="word" morph="none" start_char="14032" end_char="14039">Institut</TOKEN>
<TOKEN id="token-119-7" pos="word" morph="none" start_char="14041" end_char="14047">Pasteur</TOKEN>
<TOKEN id="token-119-8" pos="word" morph="none" start_char="14049" end_char="14050">of</TOKEN>
<TOKEN id="token-119-9" pos="word" morph="none" start_char="14052" end_char="14059">Shanghai</TOKEN>
<TOKEN id="token-119-10" pos="punct" morph="none" start_char="14061" end_char="14061">(</TOKEN>
<TOKEN id="token-119-11" pos="word" morph="none" start_char="14062" end_char="14064">IPS</TOKEN>
<TOKEN id="token-119-12" pos="punct" morph="none" start_char="14065" end_char="14066">),</TOKEN>
<TOKEN id="token-119-13" pos="word" morph="none" start_char="14068" end_char="14068">a</TOKEN>
<TOKEN id="token-119-14" pos="word" morph="none" start_char="14070" end_char="14077">research</TOKEN>
<TOKEN id="token-119-15" pos="word" morph="none" start_char="14079" end_char="14084">center</TOKEN>
<TOKEN id="token-119-16" pos="word" morph="none" start_char="14086" end_char="14089">that</TOKEN>
<TOKEN id="token-119-17" pos="word" morph="none" start_char="14091" end_char="14095">holds</TOKEN>
<TOKEN id="token-119-18" pos="word" morph="none" start_char="14097" end_char="14103">special</TOKEN>
<TOKEN id="token-119-19" pos="word" morph="none" start_char="14105" end_char="14110">status</TOKEN>
<TOKEN id="token-119-20" pos="word" morph="none" start_char="14112" end_char="14117">within</TOKEN>
<TOKEN id="token-119-21" pos="word" morph="none" start_char="14119" end_char="14121">the</TOKEN>
<TOKEN id="token-119-22" pos="word" morph="none" start_char="14123" end_char="14129">Academy</TOKEN>
<TOKEN id="token-119-23" pos="word" morph="none" start_char="14131" end_char="14132">of</TOKEN>
<TOKEN id="token-119-24" pos="word" morph="none" start_char="14134" end_char="14141">sciences</TOKEN>
<TOKEN id="token-119-25" pos="word" morph="none" start_char="14143" end_char="14144">in</TOKEN>
<TOKEN id="token-119-26" pos="word" morph="none" start_char="14146" end_char="14150">China</TOKEN>
<TOKEN id="token-119-27" pos="punct" morph="none" start_char="14152" end_char="14152">(</TOKEN>
<TOKEN id="token-119-28" pos="unknown" morph="none" start_char="14153" end_char="14164">IPS-CAS).The</TOKEN>
<TOKEN id="token-119-29" pos="word" morph="none" start_char="14166" end_char="14168">IPS</TOKEN>
<TOKEN id="token-119-30" pos="word" morph="none" start_char="14170" end_char="14172">has</TOKEN>
<TOKEN id="token-119-31" pos="word" morph="none" start_char="14174" end_char="14174">a</TOKEN>
<TOKEN id="token-119-32" pos="word" morph="none" start_char="14176" end_char="14184">governing</TOKEN>
<TOKEN id="token-119-33" pos="word" morph="none" start_char="14186" end_char="14191">system</TOKEN>
<TOKEN id="token-119-34" pos="word" morph="none" start_char="14193" end_char="14197">based</TOKEN>
<TOKEN id="token-119-35" pos="word" morph="none" start_char="14199" end_char="14200">on</TOKEN>
<TOKEN id="token-119-36" pos="word" morph="none" start_char="14202" end_char="14202">a</TOKEN>
<TOKEN id="token-119-37" pos="word" morph="none" start_char="14204" end_char="14208">board</TOKEN>
<TOKEN id="token-119-38" pos="word" morph="none" start_char="14210" end_char="14211">of</TOKEN>
<TOKEN id="token-119-39" pos="word" morph="none" start_char="14213" end_char="14221">directors</TOKEN>
<TOKEN id="token-119-40" pos="word" morph="none" start_char="14223" end_char="14225">and</TOKEN>
<TOKEN id="token-119-41" pos="word" morph="none" start_char="14227" end_char="14227">a</TOKEN>
<TOKEN id="token-119-42" pos="word" morph="none" start_char="14229" end_char="14233">joint</TOKEN>
<TOKEN id="token-119-43" pos="word" morph="none" start_char="14235" end_char="14244">scientific</TOKEN>
<TOKEN id="token-119-44" pos="word" morph="none" start_char="14246" end_char="14254">committee</TOKEN>
<TOKEN id="token-119-45" pos="punct" morph="none" start_char="14255" end_char="14255">,</TOKEN>
<TOKEN id="token-119-46" pos="word" morph="none" start_char="14257" end_char="14259">the</TOKEN>
<TOKEN id="token-119-47" pos="word" morph="none" start_char="14261" end_char="14266">former</TOKEN>
<TOKEN id="token-119-48" pos="unknown" morph="none" start_char="14268" end_char="14273">co-led</TOKEN>
<TOKEN id="token-119-49" pos="word" morph="none" start_char="14275" end_char="14276">by</TOKEN>
<TOKEN id="token-119-50" pos="word" morph="none" start_char="14278" end_char="14280">the</TOKEN>
<TOKEN id="token-119-51" pos="word" morph="none" start_char="14282" end_char="14290">President</TOKEN>
<TOKEN id="token-119-52" pos="word" morph="none" start_char="14292" end_char="14293">of</TOKEN>
<TOKEN id="token-119-53" pos="word" morph="none" start_char="14295" end_char="14297">the</TOKEN>
<TOKEN id="token-119-54" pos="word" morph="none" start_char="14299" end_char="14306">Institut</TOKEN>
<TOKEN id="token-119-55" pos="word" morph="none" start_char="14308" end_char="14314">Pasteur</TOKEN>
<TOKEN id="token-119-56" pos="word" morph="none" start_char="14316" end_char="14318">and</TOKEN>
<TOKEN id="token-119-57" pos="word" morph="none" start_char="14320" end_char="14322">the</TOKEN>
<TOKEN id="token-119-58" pos="word" morph="none" start_char="14324" end_char="14329">latter</TOKEN>
<TOKEN id="token-119-59" pos="word" morph="none" start_char="14331" end_char="14333">led</TOKEN>
<TOKEN id="token-119-60" pos="word" morph="none" start_char="14335" end_char="14336">by</TOKEN>
<TOKEN id="token-119-61" pos="word" morph="none" start_char="14338" end_char="14339">Mr</TOKEN>
<TOKEN id="token-119-62" pos="punct" morph="none" start_char="14340" end_char="14340">.</TOKEN>
<TOKEN id="token-119-63" pos="word" morph="none" start_char="14342" end_char="14350">Kourilsky</TOKEN>
<TOKEN id="token-119-64" pos="punct" morph="none" start_char="14351" end_char="14351">,</TOKEN>
<TOKEN id="token-119-65" pos="word" morph="none" start_char="14353" end_char="14360">honorary</TOKEN>
<TOKEN id="token-119-66" pos="word" morph="none" start_char="14362" end_char="14370">professor</TOKEN>
<TOKEN id="token-119-67" pos="word" morph="none" start_char="14372" end_char="14373">of</TOKEN>
<TOKEN id="token-119-68" pos="word" morph="none" start_char="14375" end_char="14377">the</TOKEN>
<TOKEN id="token-119-69" pos="word" morph="none" start_char="14379" end_char="14385">College</TOKEN>
<TOKEN id="token-119-70" pos="word" morph="none" start_char="14387" end_char="14388">de</TOKEN>
<TOKEN id="token-119-71" pos="word" morph="none" start_char="14390" end_char="14395">France</TOKEN>
<TOKEN id="token-119-72" pos="punct" morph="none" start_char="14396" end_char="14396">,</TOKEN>
<TOKEN id="token-119-73" pos="word" morph="none" start_char="14398" end_char="14400">and</TOKEN>
<TOKEN id="token-119-74" pos="word" morph="none" start_char="14402" end_char="14407">former</TOKEN>
<TOKEN id="token-119-75" pos="word" morph="none" start_char="14409" end_char="14417">President</TOKEN>
<TOKEN id="token-119-76" pos="word" morph="none" start_char="14419" end_char="14420">of</TOKEN>
<TOKEN id="token-119-77" pos="word" morph="none" start_char="14422" end_char="14424">the</TOKEN>
<TOKEN id="token-119-78" pos="word" morph="none" start_char="14426" end_char="14433">Institut</TOKEN>
<TOKEN id="token-119-79" pos="word" morph="none" start_char="14435" end_char="14441">Pasteur</TOKEN>
<TOKEN id="token-119-80" pos="punct" morph="none" start_char="14442" end_char="14442">.</TOKEN>
</SEG>
<SEG id="segment-120" start_char="14446" end_char="14575">
<ORIGINAL_TEXT>The P4 laboratory was indeed planned and constructed with the help of France, in the context of the cooperation agreement of 2004.</ORIGINAL_TEXT>
<TOKEN id="token-120-0" pos="word" morph="none" start_char="14446" end_char="14448">The</TOKEN>
<TOKEN id="token-120-1" pos="word" morph="none" start_char="14450" end_char="14451">P4</TOKEN>
<TOKEN id="token-120-2" pos="word" morph="none" start_char="14453" end_char="14462">laboratory</TOKEN>
<TOKEN id="token-120-3" pos="word" morph="none" start_char="14464" end_char="14466">was</TOKEN>
<TOKEN id="token-120-4" pos="word" morph="none" start_char="14468" end_char="14473">indeed</TOKEN>
<TOKEN id="token-120-5" pos="word" morph="none" start_char="14475" end_char="14481">planned</TOKEN>
<TOKEN id="token-120-6" pos="word" morph="none" start_char="14483" end_char="14485">and</TOKEN>
<TOKEN id="token-120-7" pos="word" morph="none" start_char="14487" end_char="14497">constructed</TOKEN>
<TOKEN id="token-120-8" pos="word" morph="none" start_char="14499" end_char="14502">with</TOKEN>
<TOKEN id="token-120-9" pos="word" morph="none" start_char="14504" end_char="14506">the</TOKEN>
<TOKEN id="token-120-10" pos="word" morph="none" start_char="14508" end_char="14511">help</TOKEN>
<TOKEN id="token-120-11" pos="word" morph="none" start_char="14513" end_char="14514">of</TOKEN>
<TOKEN id="token-120-12" pos="word" morph="none" start_char="14516" end_char="14521">France</TOKEN>
<TOKEN id="token-120-13" pos="punct" morph="none" start_char="14522" end_char="14522">,</TOKEN>
<TOKEN id="token-120-14" pos="word" morph="none" start_char="14524" end_char="14525">in</TOKEN>
<TOKEN id="token-120-15" pos="word" morph="none" start_char="14527" end_char="14529">the</TOKEN>
<TOKEN id="token-120-16" pos="word" morph="none" start_char="14531" end_char="14537">context</TOKEN>
<TOKEN id="token-120-17" pos="word" morph="none" start_char="14539" end_char="14540">of</TOKEN>
<TOKEN id="token-120-18" pos="word" morph="none" start_char="14542" end_char="14544">the</TOKEN>
<TOKEN id="token-120-19" pos="word" morph="none" start_char="14546" end_char="14556">cooperation</TOKEN>
<TOKEN id="token-120-20" pos="word" morph="none" start_char="14558" end_char="14566">agreement</TOKEN>
<TOKEN id="token-120-21" pos="word" morph="none" start_char="14568" end_char="14569">of</TOKEN>
<TOKEN id="token-120-22" pos="word" morph="none" start_char="14571" end_char="14574">2004</TOKEN>
<TOKEN id="token-120-23" pos="punct" morph="none" start_char="14575" end_char="14575">.</TOKEN>
</SEG>
<SEG id="segment-121" start_char="14577" end_char="14690">
<ORIGINAL_TEXT>However, the Institut Pasteur of Shanghai (IPS) is absolutely an independent and distinct Franco-Chinese institut</ORIGINAL_TEXT>
<TOKEN id="token-121-0" pos="word" morph="none" start_char="14577" end_char="14583">However</TOKEN>
<TOKEN id="token-121-1" pos="punct" morph="none" start_char="14584" end_char="14584">,</TOKEN>
<TOKEN id="token-121-2" pos="word" morph="none" start_char="14586" end_char="14588">the</TOKEN>
<TOKEN id="token-121-3" pos="word" morph="none" start_char="14590" end_char="14597">Institut</TOKEN>
<TOKEN id="token-121-4" pos="word" morph="none" start_char="14599" end_char="14605">Pasteur</TOKEN>
<TOKEN id="token-121-5" pos="word" morph="none" start_char="14607" end_char="14608">of</TOKEN>
<TOKEN id="token-121-6" pos="word" morph="none" start_char="14610" end_char="14617">Shanghai</TOKEN>
<TOKEN id="token-121-7" pos="punct" morph="none" start_char="14619" end_char="14619">(</TOKEN>
<TOKEN id="token-121-8" pos="word" morph="none" start_char="14620" end_char="14622">IPS</TOKEN>
<TOKEN id="token-121-9" pos="punct" morph="none" start_char="14623" end_char="14623">)</TOKEN>
<TOKEN id="token-121-10" pos="word" morph="none" start_char="14625" end_char="14626">is</TOKEN>
<TOKEN id="token-121-11" pos="word" morph="none" start_char="14628" end_char="14637">absolutely</TOKEN>
<TOKEN id="token-121-12" pos="word" morph="none" start_char="14639" end_char="14640">an</TOKEN>
<TOKEN id="token-121-13" pos="word" morph="none" start_char="14642" end_char="14652">independent</TOKEN>
<TOKEN id="token-121-14" pos="word" morph="none" start_char="14654" end_char="14656">and</TOKEN>
<TOKEN id="token-121-15" pos="word" morph="none" start_char="14658" end_char="14665">distinct</TOKEN>
<TOKEN id="token-121-16" pos="unknown" morph="none" start_char="14667" end_char="14680">Franco-Chinese</TOKEN>
<TOKEN id="token-121-17" pos="unknown" morph="none" start_char="14682" end_char="14690">institut</TOKEN>
</SEG>
<SEG id="segment-122" start_char="14693" end_char="14777">
<ORIGINAL_TEXT>Regarding the alleged work of the Shanghai Pasteur Institute (IPS) on the coronavirus</ORIGINAL_TEXT>
<TOKEN id="token-122-0" pos="word" morph="none" start_char="14693" end_char="14701">Regarding</TOKEN>
<TOKEN id="token-122-1" pos="word" morph="none" start_char="14703" end_char="14705">the</TOKEN>
<TOKEN id="token-122-2" pos="word" morph="none" start_char="14707" end_char="14713">alleged</TOKEN>
<TOKEN id="token-122-3" pos="word" morph="none" start_char="14715" end_char="14718">work</TOKEN>
<TOKEN id="token-122-4" pos="word" morph="none" start_char="14720" end_char="14721">of</TOKEN>
<TOKEN id="token-122-5" pos="word" morph="none" start_char="14723" end_char="14725">the</TOKEN>
<TOKEN id="token-122-6" pos="word" morph="none" start_char="14727" end_char="14734">Shanghai</TOKEN>
<TOKEN id="token-122-7" pos="word" morph="none" start_char="14736" end_char="14742">Pasteur</TOKEN>
<TOKEN id="token-122-8" pos="word" morph="none" start_char="14744" end_char="14752">Institute</TOKEN>
<TOKEN id="token-122-9" pos="punct" morph="none" start_char="14754" end_char="14754">(</TOKEN>
<TOKEN id="token-122-10" pos="word" morph="none" start_char="14755" end_char="14757">IPS</TOKEN>
<TOKEN id="token-122-11" pos="punct" morph="none" start_char="14758" end_char="14758">)</TOKEN>
<TOKEN id="token-122-12" pos="word" morph="none" start_char="14760" end_char="14761">on</TOKEN>
<TOKEN id="token-122-13" pos="word" morph="none" start_char="14763" end_char="14765">the</TOKEN>
<TOKEN id="token-122-14" pos="word" morph="none" start_char="14767" end_char="14777">coronavirus</TOKEN>
</SEG>
<SEG id="segment-123" start_char="14781" end_char="15033">
<ORIGINAL_TEXT>Since the emergence of the nouvel coronavirus in Wuhan, the Institut Pasteur of Shanghai (IPS), in line with its mandate, fulfilled its role as a cooperative Franco-Chinese platform, facilitating a better understanding of the evolution of the new virus.</ORIGINAL_TEXT>
<TOKEN id="token-123-0" pos="word" morph="none" start_char="14781" end_char="14785">Since</TOKEN>
<TOKEN id="token-123-1" pos="word" morph="none" start_char="14787" end_char="14789">the</TOKEN>
<TOKEN id="token-123-2" pos="word" morph="none" start_char="14791" end_char="14799">emergence</TOKEN>
<TOKEN id="token-123-3" pos="word" morph="none" start_char="14801" end_char="14802">of</TOKEN>
<TOKEN id="token-123-4" pos="word" morph="none" start_char="14804" end_char="14806">the</TOKEN>
<TOKEN id="token-123-5" pos="word" morph="none" start_char="14808" end_char="14813">nouvel</TOKEN>
<TOKEN id="token-123-6" pos="word" morph="none" start_char="14815" end_char="14825">coronavirus</TOKEN>
<TOKEN id="token-123-7" pos="word" morph="none" start_char="14827" end_char="14828">in</TOKEN>
<TOKEN id="token-123-8" pos="word" morph="none" start_char="14830" end_char="14834">Wuhan</TOKEN>
<TOKEN id="token-123-9" pos="punct" morph="none" start_char="14835" end_char="14835">,</TOKEN>
<TOKEN id="token-123-10" pos="word" morph="none" start_char="14837" end_char="14839">the</TOKEN>
<TOKEN id="token-123-11" pos="word" morph="none" start_char="14841" end_char="14848">Institut</TOKEN>
<TOKEN id="token-123-12" pos="word" morph="none" start_char="14850" end_char="14856">Pasteur</TOKEN>
<TOKEN id="token-123-13" pos="word" morph="none" start_char="14858" end_char="14859">of</TOKEN>
<TOKEN id="token-123-14" pos="word" morph="none" start_char="14861" end_char="14868">Shanghai</TOKEN>
<TOKEN id="token-123-15" pos="punct" morph="none" start_char="14870" end_char="14870">(</TOKEN>
<TOKEN id="token-123-16" pos="word" morph="none" start_char="14871" end_char="14873">IPS</TOKEN>
<TOKEN id="token-123-17" pos="punct" morph="none" start_char="14874" end_char="14875">),</TOKEN>
<TOKEN id="token-123-18" pos="word" morph="none" start_char="14877" end_char="14878">in</TOKEN>
<TOKEN id="token-123-19" pos="word" morph="none" start_char="14880" end_char="14883">line</TOKEN>
<TOKEN id="token-123-20" pos="word" morph="none" start_char="14885" end_char="14888">with</TOKEN>
<TOKEN id="token-123-21" pos="word" morph="none" start_char="14890" end_char="14892">its</TOKEN>
<TOKEN id="token-123-22" pos="word" morph="none" start_char="14894" end_char="14900">mandate</TOKEN>
<TOKEN id="token-123-23" pos="punct" morph="none" start_char="14901" end_char="14901">,</TOKEN>
<TOKEN id="token-123-24" pos="word" morph="none" start_char="14903" end_char="14911">fulfilled</TOKEN>
<TOKEN id="token-123-25" pos="word" morph="none" start_char="14913" end_char="14915">its</TOKEN>
<TOKEN id="token-123-26" pos="word" morph="none" start_char="14917" end_char="14920">role</TOKEN>
<TOKEN id="token-123-27" pos="word" morph="none" start_char="14922" end_char="14923">as</TOKEN>
<TOKEN id="token-123-28" pos="word" morph="none" start_char="14925" end_char="14925">a</TOKEN>
<TOKEN id="token-123-29" pos="word" morph="none" start_char="14927" end_char="14937">cooperative</TOKEN>
<TOKEN id="token-123-30" pos="unknown" morph="none" start_char="14939" end_char="14952">Franco-Chinese</TOKEN>
<TOKEN id="token-123-31" pos="word" morph="none" start_char="14954" end_char="14961">platform</TOKEN>
<TOKEN id="token-123-32" pos="punct" morph="none" start_char="14962" end_char="14962">,</TOKEN>
<TOKEN id="token-123-33" pos="word" morph="none" start_char="14964" end_char="14975">facilitating</TOKEN>
<TOKEN id="token-123-34" pos="word" morph="none" start_char="14977" end_char="14977">a</TOKEN>
<TOKEN id="token-123-35" pos="word" morph="none" start_char="14979" end_char="14984">better</TOKEN>
<TOKEN id="token-123-36" pos="word" morph="none" start_char="14986" end_char="14998">understanding</TOKEN>
<TOKEN id="token-123-37" pos="word" morph="none" start_char="15000" end_char="15001">of</TOKEN>
<TOKEN id="token-123-38" pos="word" morph="none" start_char="15003" end_char="15005">the</TOKEN>
<TOKEN id="token-123-39" pos="word" morph="none" start_char="15007" end_char="15015">evolution</TOKEN>
<TOKEN id="token-123-40" pos="word" morph="none" start_char="15017" end_char="15018">of</TOKEN>
<TOKEN id="token-123-41" pos="word" morph="none" start_char="15020" end_char="15022">the</TOKEN>
<TOKEN id="token-123-42" pos="word" morph="none" start_char="15024" end_char="15026">new</TOKEN>
<TOKEN id="token-123-43" pos="word" morph="none" start_char="15028" end_char="15032">virus</TOKEN>
<TOKEN id="token-123-44" pos="punct" morph="none" start_char="15033" end_char="15033">.</TOKEN>
</SEG>
<SEG id="segment-124" start_char="15035" end_char="15139">
<ORIGINAL_TEXT>It published, as early as the first weeks, an article about the three-dimensional structure of the virus.</ORIGINAL_TEXT>
<TOKEN id="token-124-0" pos="word" morph="none" start_char="15035" end_char="15036">It</TOKEN>
<TOKEN id="token-124-1" pos="word" morph="none" start_char="15038" end_char="15046">published</TOKEN>
<TOKEN id="token-124-2" pos="punct" morph="none" start_char="15047" end_char="15047">,</TOKEN>
<TOKEN id="token-124-3" pos="word" morph="none" start_char="15049" end_char="15050">as</TOKEN>
<TOKEN id="token-124-4" pos="word" morph="none" start_char="15052" end_char="15056">early</TOKEN>
<TOKEN id="token-124-5" pos="word" morph="none" start_char="15058" end_char="15059">as</TOKEN>
<TOKEN id="token-124-6" pos="word" morph="none" start_char="15061" end_char="15063">the</TOKEN>
<TOKEN id="token-124-7" pos="word" morph="none" start_char="15065" end_char="15069">first</TOKEN>
<TOKEN id="token-124-8" pos="word" morph="none" start_char="15071" end_char="15075">weeks</TOKEN>
<TOKEN id="token-124-9" pos="punct" morph="none" start_char="15076" end_char="15076">,</TOKEN>
<TOKEN id="token-124-10" pos="word" morph="none" start_char="15078" end_char="15079">an</TOKEN>
<TOKEN id="token-124-11" pos="word" morph="none" start_char="15081" end_char="15087">article</TOKEN>
<TOKEN id="token-124-12" pos="word" morph="none" start_char="15089" end_char="15093">about</TOKEN>
<TOKEN id="token-124-13" pos="word" morph="none" start_char="15095" end_char="15097">the</TOKEN>
<TOKEN id="token-124-14" pos="unknown" morph="none" start_char="15099" end_char="15115">three-dimensional</TOKEN>
<TOKEN id="token-124-15" pos="word" morph="none" start_char="15117" end_char="15125">structure</TOKEN>
<TOKEN id="token-124-16" pos="word" morph="none" start_char="15127" end_char="15128">of</TOKEN>
<TOKEN id="token-124-17" pos="word" morph="none" start_char="15130" end_char="15132">the</TOKEN>
<TOKEN id="token-124-18" pos="word" morph="none" start_char="15134" end_char="15138">virus</TOKEN>
<TOKEN id="token-124-19" pos="punct" morph="none" start_char="15139" end_char="15139">.</TOKEN>
</SEG>
<SEG id="segment-125" start_char="15141" end_char="15356">
<ORIGINAL_TEXT>Its scientific experts furthermore proposed their services to the Chinese Center for Disease Control and Prevention, as well as the Virology Institut of Wuhan, to help the on-site staff, but they were not contacted.</ORIGINAL_TEXT>
<TOKEN id="token-125-0" pos="word" morph="none" start_char="15141" end_char="15143">Its</TOKEN>
<TOKEN id="token-125-1" pos="word" morph="none" start_char="15145" end_char="15154">scientific</TOKEN>
<TOKEN id="token-125-2" pos="word" morph="none" start_char="15156" end_char="15162">experts</TOKEN>
<TOKEN id="token-125-3" pos="word" morph="none" start_char="15164" end_char="15174">furthermore</TOKEN>
<TOKEN id="token-125-4" pos="word" morph="none" start_char="15176" end_char="15183">proposed</TOKEN>
<TOKEN id="token-125-5" pos="word" morph="none" start_char="15185" end_char="15189">their</TOKEN>
<TOKEN id="token-125-6" pos="word" morph="none" start_char="15191" end_char="15198">services</TOKEN>
<TOKEN id="token-125-7" pos="word" morph="none" start_char="15200" end_char="15201">to</TOKEN>
<TOKEN id="token-125-8" pos="word" morph="none" start_char="15203" end_char="15205">the</TOKEN>
<TOKEN id="token-125-9" pos="word" morph="none" start_char="15207" end_char="15213">Chinese</TOKEN>
<TOKEN id="token-125-10" pos="word" morph="none" start_char="15215" end_char="15220">Center</TOKEN>
<TOKEN id="token-125-11" pos="word" morph="none" start_char="15222" end_char="15224">for</TOKEN>
<TOKEN id="token-125-12" pos="word" morph="none" start_char="15226" end_char="15232">Disease</TOKEN>
<TOKEN id="token-125-13" pos="word" morph="none" start_char="15234" end_char="15240">Control</TOKEN>
<TOKEN id="token-125-14" pos="word" morph="none" start_char="15242" end_char="15244">and</TOKEN>
<TOKEN id="token-125-15" pos="word" morph="none" start_char="15246" end_char="15255">Prevention</TOKEN>
<TOKEN id="token-125-16" pos="punct" morph="none" start_char="15256" end_char="15256">,</TOKEN>
<TOKEN id="token-125-17" pos="word" morph="none" start_char="15258" end_char="15259">as</TOKEN>
<TOKEN id="token-125-18" pos="word" morph="none" start_char="15261" end_char="15264">well</TOKEN>
<TOKEN id="token-125-19" pos="word" morph="none" start_char="15266" end_char="15267">as</TOKEN>
<TOKEN id="token-125-20" pos="word" morph="none" start_char="15269" end_char="15271">the</TOKEN>
<TOKEN id="token-125-21" pos="word" morph="none" start_char="15273" end_char="15280">Virology</TOKEN>
<TOKEN id="token-125-22" pos="word" morph="none" start_char="15282" end_char="15289">Institut</TOKEN>
<TOKEN id="token-125-23" pos="word" morph="none" start_char="15291" end_char="15292">of</TOKEN>
<TOKEN id="token-125-24" pos="word" morph="none" start_char="15294" end_char="15298">Wuhan</TOKEN>
<TOKEN id="token-125-25" pos="punct" morph="none" start_char="15299" end_char="15299">,</TOKEN>
<TOKEN id="token-125-26" pos="word" morph="none" start_char="15301" end_char="15302">to</TOKEN>
<TOKEN id="token-125-27" pos="word" morph="none" start_char="15304" end_char="15307">help</TOKEN>
<TOKEN id="token-125-28" pos="word" morph="none" start_char="15309" end_char="15311">the</TOKEN>
<TOKEN id="token-125-29" pos="unknown" morph="none" start_char="15313" end_char="15319">on-site</TOKEN>
<TOKEN id="token-125-30" pos="word" morph="none" start_char="15321" end_char="15325">staff</TOKEN>
<TOKEN id="token-125-31" pos="punct" morph="none" start_char="15326" end_char="15326">,</TOKEN>
<TOKEN id="token-125-32" pos="word" morph="none" start_char="15328" end_char="15330">but</TOKEN>
<TOKEN id="token-125-33" pos="word" morph="none" start_char="15332" end_char="15335">they</TOKEN>
<TOKEN id="token-125-34" pos="word" morph="none" start_char="15337" end_char="15340">were</TOKEN>
<TOKEN id="token-125-35" pos="word" morph="none" start_char="15342" end_char="15344">not</TOKEN>
<TOKEN id="token-125-36" pos="unknown" morph="none" start_char="15346" end_char="15356">contacted.</TOKEN>
</SEG>
<SEG id="segment-126" start_char="15359" end_char="15487">
<ORIGINAL_TEXT>The IPS has neither active projects inside the P4 laboratory in Wuhan, nor active projets in any of the P3 laboratories in Wuhan.</ORIGINAL_TEXT>
<TOKEN id="token-126-0" pos="word" morph="none" start_char="15359" end_char="15361">The</TOKEN>
<TOKEN id="token-126-1" pos="word" morph="none" start_char="15363" end_char="15365">IPS</TOKEN>
<TOKEN id="token-126-2" pos="word" morph="none" start_char="15367" end_char="15369">has</TOKEN>
<TOKEN id="token-126-3" pos="word" morph="none" start_char="15371" end_char="15377">neither</TOKEN>
<TOKEN id="token-126-4" pos="word" morph="none" start_char="15379" end_char="15384">active</TOKEN>
<TOKEN id="token-126-5" pos="word" morph="none" start_char="15386" end_char="15393">projects</TOKEN>
<TOKEN id="token-126-6" pos="word" morph="none" start_char="15395" end_char="15400">inside</TOKEN>
<TOKEN id="token-126-7" pos="word" morph="none" start_char="15402" end_char="15404">the</TOKEN>
<TOKEN id="token-126-8" pos="word" morph="none" start_char="15406" end_char="15407">P4</TOKEN>
<TOKEN id="token-126-9" pos="word" morph="none" start_char="15409" end_char="15418">laboratory</TOKEN>
<TOKEN id="token-126-10" pos="word" morph="none" start_char="15420" end_char="15421">in</TOKEN>
<TOKEN id="token-126-11" pos="word" morph="none" start_char="15423" end_char="15427">Wuhan</TOKEN>
<TOKEN id="token-126-12" pos="punct" morph="none" start_char="15428" end_char="15428">,</TOKEN>
<TOKEN id="token-126-13" pos="word" morph="none" start_char="15430" end_char="15432">nor</TOKEN>
<TOKEN id="token-126-14" pos="word" morph="none" start_char="15434" end_char="15439">active</TOKEN>
<TOKEN id="token-126-15" pos="word" morph="none" start_char="15441" end_char="15447">projets</TOKEN>
<TOKEN id="token-126-16" pos="word" morph="none" start_char="15449" end_char="15450">in</TOKEN>
<TOKEN id="token-126-17" pos="word" morph="none" start_char="15452" end_char="15454">any</TOKEN>
<TOKEN id="token-126-18" pos="word" morph="none" start_char="15456" end_char="15457">of</TOKEN>
<TOKEN id="token-126-19" pos="word" morph="none" start_char="15459" end_char="15461">the</TOKEN>
<TOKEN id="token-126-20" pos="word" morph="none" start_char="15463" end_char="15464">P3</TOKEN>
<TOKEN id="token-126-21" pos="word" morph="none" start_char="15466" end_char="15477">laboratories</TOKEN>
<TOKEN id="token-126-22" pos="word" morph="none" start_char="15479" end_char="15480">in</TOKEN>
<TOKEN id="token-126-23" pos="word" morph="none" start_char="15482" end_char="15486">Wuhan</TOKEN>
<TOKEN id="token-126-24" pos="punct" morph="none" start_char="15487" end_char="15487">.</TOKEN>
</SEG>
<SEG id="segment-127" start_char="15490" end_char="15717">
<ORIGINAL_TEXT>The IPS thus brought its active support to other institutes in the Asia region (Hong Kong, Laos, and Cambodia, primarily) and mobilized itself to help preparations in the most vulnerable countries (including African institutes.)</ORIGINAL_TEXT>
<TOKEN id="token-127-0" pos="word" morph="none" start_char="15490" end_char="15492">The</TOKEN>
<TOKEN id="token-127-1" pos="word" morph="none" start_char="15494" end_char="15496">IPS</TOKEN>
<TOKEN id="token-127-2" pos="word" morph="none" start_char="15498" end_char="15501">thus</TOKEN>
<TOKEN id="token-127-3" pos="word" morph="none" start_char="15503" end_char="15509">brought</TOKEN>
<TOKEN id="token-127-4" pos="word" morph="none" start_char="15511" end_char="15513">its</TOKEN>
<TOKEN id="token-127-5" pos="word" morph="none" start_char="15515" end_char="15520">active</TOKEN>
<TOKEN id="token-127-6" pos="word" morph="none" start_char="15522" end_char="15528">support</TOKEN>
<TOKEN id="token-127-7" pos="word" morph="none" start_char="15530" end_char="15531">to</TOKEN>
<TOKEN id="token-127-8" pos="word" morph="none" start_char="15533" end_char="15537">other</TOKEN>
<TOKEN id="token-127-9" pos="word" morph="none" start_char="15539" end_char="15548">institutes</TOKEN>
<TOKEN id="token-127-10" pos="word" morph="none" start_char="15550" end_char="15551">in</TOKEN>
<TOKEN id="token-127-11" pos="word" morph="none" start_char="15553" end_char="15555">the</TOKEN>
<TOKEN id="token-127-12" pos="word" morph="none" start_char="15557" end_char="15560">Asia</TOKEN>
<TOKEN id="token-127-13" pos="word" morph="none" start_char="15562" end_char="15567">region</TOKEN>
<TOKEN id="token-127-14" pos="punct" morph="none" start_char="15569" end_char="15569">(</TOKEN>
<TOKEN id="token-127-15" pos="word" morph="none" start_char="15570" end_char="15573">Hong</TOKEN>
<TOKEN id="token-127-16" pos="word" morph="none" start_char="15575" end_char="15578">Kong</TOKEN>
<TOKEN id="token-127-17" pos="punct" morph="none" start_char="15579" end_char="15579">,</TOKEN>
<TOKEN id="token-127-18" pos="word" morph="none" start_char="15581" end_char="15584">Laos</TOKEN>
<TOKEN id="token-127-19" pos="punct" morph="none" start_char="15585" end_char="15585">,</TOKEN>
<TOKEN id="token-127-20" pos="word" morph="none" start_char="15587" end_char="15589">and</TOKEN>
<TOKEN id="token-127-21" pos="word" morph="none" start_char="15591" end_char="15598">Cambodia</TOKEN>
<TOKEN id="token-127-22" pos="punct" morph="none" start_char="15599" end_char="15599">,</TOKEN>
<TOKEN id="token-127-23" pos="word" morph="none" start_char="15601" end_char="15609">primarily</TOKEN>
<TOKEN id="token-127-24" pos="punct" morph="none" start_char="15610" end_char="15610">)</TOKEN>
<TOKEN id="token-127-25" pos="word" morph="none" start_char="15612" end_char="15614">and</TOKEN>
<TOKEN id="token-127-26" pos="word" morph="none" start_char="15616" end_char="15624">mobilized</TOKEN>
<TOKEN id="token-127-27" pos="word" morph="none" start_char="15626" end_char="15631">itself</TOKEN>
<TOKEN id="token-127-28" pos="word" morph="none" start_char="15633" end_char="15634">to</TOKEN>
<TOKEN id="token-127-29" pos="word" morph="none" start_char="15636" end_char="15639">help</TOKEN>
<TOKEN id="token-127-30" pos="word" morph="none" start_char="15641" end_char="15652">preparations</TOKEN>
<TOKEN id="token-127-31" pos="word" morph="none" start_char="15654" end_char="15655">in</TOKEN>
<TOKEN id="token-127-32" pos="word" morph="none" start_char="15657" end_char="15659">the</TOKEN>
<TOKEN id="token-127-33" pos="word" morph="none" start_char="15661" end_char="15664">most</TOKEN>
<TOKEN id="token-127-34" pos="word" morph="none" start_char="15666" end_char="15675">vulnerable</TOKEN>
<TOKEN id="token-127-35" pos="word" morph="none" start_char="15677" end_char="15685">countries</TOKEN>
<TOKEN id="token-127-36" pos="punct" morph="none" start_char="15687" end_char="15687">(</TOKEN>
<TOKEN id="token-127-37" pos="word" morph="none" start_char="15688" end_char="15696">including</TOKEN>
<TOKEN id="token-127-38" pos="word" morph="none" start_char="15698" end_char="15704">African</TOKEN>
<TOKEN id="token-127-39" pos="word" morph="none" start_char="15706" end_char="15715">institutes</TOKEN>
<TOKEN id="token-127-40" pos="punct" morph="none" start_char="15716" end_char="15717">.)</TOKEN>
</SEG>
<SEG id="segment-128" start_char="15720" end_char="15891">
<ORIGINAL_TEXT>3 _ The Institut Pasteur (Paris) indeed conducted research in France on a previous coronavirus (SARS-CoV-1), which has nothing to do with SARS-CoV-2, which causes Covid-19.</ORIGINAL_TEXT>
<TOKEN id="token-128-0" pos="word" morph="none" start_char="15720" end_char="15720">3</TOKEN>
<TOKEN id="token-128-1" pos="word" morph="none" start_char="15722" end_char="15722">_</TOKEN>
<TOKEN id="token-128-2" pos="word" morph="none" start_char="15724" end_char="15726">The</TOKEN>
<TOKEN id="token-128-3" pos="word" morph="none" start_char="15728" end_char="15735">Institut</TOKEN>
<TOKEN id="token-128-4" pos="word" morph="none" start_char="15737" end_char="15743">Pasteur</TOKEN>
<TOKEN id="token-128-5" pos="punct" morph="none" start_char="15745" end_char="15745">(</TOKEN>
<TOKEN id="token-128-6" pos="word" morph="none" start_char="15746" end_char="15750">Paris</TOKEN>
<TOKEN id="token-128-7" pos="punct" morph="none" start_char="15751" end_char="15751">)</TOKEN>
<TOKEN id="token-128-8" pos="word" morph="none" start_char="15753" end_char="15758">indeed</TOKEN>
<TOKEN id="token-128-9" pos="word" morph="none" start_char="15760" end_char="15768">conducted</TOKEN>
<TOKEN id="token-128-10" pos="word" morph="none" start_char="15770" end_char="15777">research</TOKEN>
<TOKEN id="token-128-11" pos="word" morph="none" start_char="15779" end_char="15780">in</TOKEN>
<TOKEN id="token-128-12" pos="word" morph="none" start_char="15782" end_char="15787">France</TOKEN>
<TOKEN id="token-128-13" pos="word" morph="none" start_char="15789" end_char="15790">on</TOKEN>
<TOKEN id="token-128-14" pos="word" morph="none" start_char="15792" end_char="15792">a</TOKEN>
<TOKEN id="token-128-15" pos="word" morph="none" start_char="15794" end_char="15801">previous</TOKEN>
<TOKEN id="token-128-16" pos="word" morph="none" start_char="15803" end_char="15813">coronavirus</TOKEN>
<TOKEN id="token-128-17" pos="punct" morph="none" start_char="15815" end_char="15815">(</TOKEN>
<TOKEN id="token-128-18" pos="unknown" morph="none" start_char="15816" end_char="15825">SARS-CoV-1</TOKEN>
<TOKEN id="token-128-19" pos="punct" morph="none" start_char="15826" end_char="15827">),</TOKEN>
<TOKEN id="token-128-20" pos="word" morph="none" start_char="15829" end_char="15833">which</TOKEN>
<TOKEN id="token-128-21" pos="word" morph="none" start_char="15835" end_char="15837">has</TOKEN>
<TOKEN id="token-128-22" pos="word" morph="none" start_char="15839" end_char="15845">nothing</TOKEN>
<TOKEN id="token-128-23" pos="word" morph="none" start_char="15847" end_char="15848">to</TOKEN>
<TOKEN id="token-128-24" pos="word" morph="none" start_char="15850" end_char="15851">do</TOKEN>
<TOKEN id="token-128-25" pos="word" morph="none" start_char="15853" end_char="15856">with</TOKEN>
<TOKEN id="token-128-26" pos="unknown" morph="none" start_char="15858" end_char="15867">SARS-CoV-2</TOKEN>
<TOKEN id="token-128-27" pos="punct" morph="none" start_char="15868" end_char="15868">,</TOKEN>
<TOKEN id="token-128-28" pos="word" morph="none" start_char="15870" end_char="15874">which</TOKEN>
<TOKEN id="token-128-29" pos="word" morph="none" start_char="15876" end_char="15881">causes</TOKEN>
<TOKEN id="token-128-30" pos="unknown" morph="none" start_char="15883" end_char="15890">Covid-19</TOKEN>
<TOKEN id="token-128-31" pos="punct" morph="none" start_char="15891" end_char="15891">.</TOKEN>
</SEG>
<SEG id="segment-129" start_char="15895" end_char="16064">
<ORIGINAL_TEXT>The Institut Pasteur (Paris) indeed conducted research in France, between 2002 and 2004, on a preceding coronavirus (SARS-CoV-1) which was the cause of the 2003 epidemic.</ORIGINAL_TEXT>
<TOKEN id="token-129-0" pos="word" morph="none" start_char="15895" end_char="15897">The</TOKEN>
<TOKEN id="token-129-1" pos="word" morph="none" start_char="15899" end_char="15906">Institut</TOKEN>
<TOKEN id="token-129-2" pos="word" morph="none" start_char="15908" end_char="15914">Pasteur</TOKEN>
<TOKEN id="token-129-3" pos="punct" morph="none" start_char="15916" end_char="15916">(</TOKEN>
<TOKEN id="token-129-4" pos="word" morph="none" start_char="15917" end_char="15921">Paris</TOKEN>
<TOKEN id="token-129-5" pos="punct" morph="none" start_char="15922" end_char="15922">)</TOKEN>
<TOKEN id="token-129-6" pos="word" morph="none" start_char="15924" end_char="15929">indeed</TOKEN>
<TOKEN id="token-129-7" pos="word" morph="none" start_char="15931" end_char="15939">conducted</TOKEN>
<TOKEN id="token-129-8" pos="word" morph="none" start_char="15941" end_char="15948">research</TOKEN>
<TOKEN id="token-129-9" pos="word" morph="none" start_char="15950" end_char="15951">in</TOKEN>
<TOKEN id="token-129-10" pos="word" morph="none" start_char="15953" end_char="15958">France</TOKEN>
<TOKEN id="token-129-11" pos="punct" morph="none" start_char="15959" end_char="15959">,</TOKEN>
<TOKEN id="token-129-12" pos="word" morph="none" start_char="15961" end_char="15967">between</TOKEN>
<TOKEN id="token-129-13" pos="word" morph="none" start_char="15969" end_char="15972">2002</TOKEN>
<TOKEN id="token-129-14" pos="word" morph="none" start_char="15974" end_char="15976">and</TOKEN>
<TOKEN id="token-129-15" pos="word" morph="none" start_char="15978" end_char="15981">2004</TOKEN>
<TOKEN id="token-129-16" pos="punct" morph="none" start_char="15982" end_char="15982">,</TOKEN>
<TOKEN id="token-129-17" pos="word" morph="none" start_char="15984" end_char="15985">on</TOKEN>
<TOKEN id="token-129-18" pos="word" morph="none" start_char="15987" end_char="15987">a</TOKEN>
<TOKEN id="token-129-19" pos="word" morph="none" start_char="15989" end_char="15997">preceding</TOKEN>
<TOKEN id="token-129-20" pos="word" morph="none" start_char="15999" end_char="16009">coronavirus</TOKEN>
<TOKEN id="token-129-21" pos="punct" morph="none" start_char="16011" end_char="16011">(</TOKEN>
<TOKEN id="token-129-22" pos="unknown" morph="none" start_char="16012" end_char="16021">SARS-CoV-1</TOKEN>
<TOKEN id="token-129-23" pos="punct" morph="none" start_char="16022" end_char="16022">)</TOKEN>
<TOKEN id="token-129-24" pos="word" morph="none" start_char="16024" end_char="16028">which</TOKEN>
<TOKEN id="token-129-25" pos="word" morph="none" start_char="16030" end_char="16032">was</TOKEN>
<TOKEN id="token-129-26" pos="word" morph="none" start_char="16034" end_char="16036">the</TOKEN>
<TOKEN id="token-129-27" pos="word" morph="none" start_char="16038" end_char="16042">cause</TOKEN>
<TOKEN id="token-129-28" pos="word" morph="none" start_char="16044" end_char="16045">of</TOKEN>
<TOKEN id="token-129-29" pos="word" morph="none" start_char="16047" end_char="16049">the</TOKEN>
<TOKEN id="token-129-30" pos="word" morph="none" start_char="16051" end_char="16054">2003</TOKEN>
<TOKEN id="token-129-31" pos="word" morph="none" start_char="16056" end_char="16063">epidemic</TOKEN>
<TOKEN id="token-129-32" pos="punct" morph="none" start_char="16064" end_char="16064">.</TOKEN>
</SEG>
<SEG id="segment-130" start_char="16066" end_char="16142">
<ORIGINAL_TEXT>Furthermore, in 2004 the Institut created a vaccine candidate for SARS-CoV-1.</ORIGINAL_TEXT>
<TOKEN id="token-130-0" pos="word" morph="none" start_char="16066" end_char="16076">Furthermore</TOKEN>
<TOKEN id="token-130-1" pos="punct" morph="none" start_char="16077" end_char="16077">,</TOKEN>
<TOKEN id="token-130-2" pos="word" morph="none" start_char="16079" end_char="16080">in</TOKEN>
<TOKEN id="token-130-3" pos="word" morph="none" start_char="16082" end_char="16085">2004</TOKEN>
<TOKEN id="token-130-4" pos="word" morph="none" start_char="16087" end_char="16089">the</TOKEN>
<TOKEN id="token-130-5" pos="word" morph="none" start_char="16091" end_char="16098">Institut</TOKEN>
<TOKEN id="token-130-6" pos="word" morph="none" start_char="16100" end_char="16106">created</TOKEN>
<TOKEN id="token-130-7" pos="word" morph="none" start_char="16108" end_char="16108">a</TOKEN>
<TOKEN id="token-130-8" pos="word" morph="none" start_char="16110" end_char="16116">vaccine</TOKEN>
<TOKEN id="token-130-9" pos="word" morph="none" start_char="16118" end_char="16126">candidate</TOKEN>
<TOKEN id="token-130-10" pos="word" morph="none" start_char="16128" end_char="16130">for</TOKEN>
<TOKEN id="token-130-11" pos="unknown" morph="none" start_char="16132" end_char="16141">SARS-CoV-1</TOKEN>
<TOKEN id="token-130-12" pos="punct" morph="none" start_char="16142" end_char="16142">.</TOKEN>
</SEG>
<SEG id="segment-131" start_char="16145" end_char="16355">
<ORIGINAL_TEXT>The construction of the P4 laboratory of Wuhan began in 2011 and was inaugurated in 2017, which is to say, a dozen years after the invention disclosure that was touted as evidence in the conspiracy theory video.</ORIGINAL_TEXT>
<TOKEN id="token-131-0" pos="word" morph="none" start_char="16145" end_char="16147">The</TOKEN>
<TOKEN id="token-131-1" pos="word" morph="none" start_char="16149" end_char="16160">construction</TOKEN>
<TOKEN id="token-131-2" pos="word" morph="none" start_char="16162" end_char="16163">of</TOKEN>
<TOKEN id="token-131-3" pos="word" morph="none" start_char="16165" end_char="16167">the</TOKEN>
<TOKEN id="token-131-4" pos="word" morph="none" start_char="16169" end_char="16170">P4</TOKEN>
<TOKEN id="token-131-5" pos="word" morph="none" start_char="16172" end_char="16181">laboratory</TOKEN>
<TOKEN id="token-131-6" pos="word" morph="none" start_char="16183" end_char="16184">of</TOKEN>
<TOKEN id="token-131-7" pos="word" morph="none" start_char="16186" end_char="16190">Wuhan</TOKEN>
<TOKEN id="token-131-8" pos="word" morph="none" start_char="16192" end_char="16196">began</TOKEN>
<TOKEN id="token-131-9" pos="word" morph="none" start_char="16198" end_char="16199">in</TOKEN>
<TOKEN id="token-131-10" pos="word" morph="none" start_char="16201" end_char="16204">2011</TOKEN>
<TOKEN id="token-131-11" pos="word" morph="none" start_char="16206" end_char="16208">and</TOKEN>
<TOKEN id="token-131-12" pos="word" morph="none" start_char="16210" end_char="16212">was</TOKEN>
<TOKEN id="token-131-13" pos="word" morph="none" start_char="16214" end_char="16224">inaugurated</TOKEN>
<TOKEN id="token-131-14" pos="word" morph="none" start_char="16226" end_char="16227">in</TOKEN>
<TOKEN id="token-131-15" pos="word" morph="none" start_char="16229" end_char="16232">2017</TOKEN>
<TOKEN id="token-131-16" pos="punct" morph="none" start_char="16233" end_char="16233">,</TOKEN>
<TOKEN id="token-131-17" pos="word" morph="none" start_char="16235" end_char="16239">which</TOKEN>
<TOKEN id="token-131-18" pos="word" morph="none" start_char="16241" end_char="16242">is</TOKEN>
<TOKEN id="token-131-19" pos="word" morph="none" start_char="16244" end_char="16245">to</TOKEN>
<TOKEN id="token-131-20" pos="word" morph="none" start_char="16247" end_char="16249">say</TOKEN>
<TOKEN id="token-131-21" pos="punct" morph="none" start_char="16250" end_char="16250">,</TOKEN>
<TOKEN id="token-131-22" pos="word" morph="none" start_char="16252" end_char="16252">a</TOKEN>
<TOKEN id="token-131-23" pos="word" morph="none" start_char="16254" end_char="16258">dozen</TOKEN>
<TOKEN id="token-131-24" pos="word" morph="none" start_char="16260" end_char="16264">years</TOKEN>
<TOKEN id="token-131-25" pos="word" morph="none" start_char="16266" end_char="16270">after</TOKEN>
<TOKEN id="token-131-26" pos="word" morph="none" start_char="16272" end_char="16274">the</TOKEN>
<TOKEN id="token-131-27" pos="word" morph="none" start_char="16276" end_char="16284">invention</TOKEN>
<TOKEN id="token-131-28" pos="word" morph="none" start_char="16286" end_char="16295">disclosure</TOKEN>
<TOKEN id="token-131-29" pos="word" morph="none" start_char="16297" end_char="16300">that</TOKEN>
<TOKEN id="token-131-30" pos="word" morph="none" start_char="16302" end_char="16304">was</TOKEN>
<TOKEN id="token-131-31" pos="word" morph="none" start_char="16306" end_char="16311">touted</TOKEN>
<TOKEN id="token-131-32" pos="word" morph="none" start_char="16313" end_char="16314">as</TOKEN>
<TOKEN id="token-131-33" pos="word" morph="none" start_char="16316" end_char="16323">evidence</TOKEN>
<TOKEN id="token-131-34" pos="word" morph="none" start_char="16325" end_char="16326">in</TOKEN>
<TOKEN id="token-131-35" pos="word" morph="none" start_char="16328" end_char="16330">the</TOKEN>
<TOKEN id="token-131-36" pos="word" morph="none" start_char="16332" end_char="16341">conspiracy</TOKEN>
<TOKEN id="token-131-37" pos="word" morph="none" start_char="16343" end_char="16348">theory</TOKEN>
<TOKEN id="token-131-38" pos="word" morph="none" start_char="16350" end_char="16354">video</TOKEN>
<TOKEN id="token-131-39" pos="punct" morph="none" start_char="16355" end_char="16355">.</TOKEN>
</SEG>
<SEG id="segment-132" start_char="16358" end_char="16450">
<ORIGINAL_TEXT>NO, the Institut Pasteur did not invent Covid-19 or the virus responsible for it, SARS-CoV-2!</ORIGINAL_TEXT>
<TOKEN id="token-132-0" pos="word" morph="none" start_char="16358" end_char="16359">NO</TOKEN>
<TOKEN id="token-132-1" pos="punct" morph="none" start_char="16360" end_char="16360">,</TOKEN>
<TOKEN id="token-132-2" pos="word" morph="none" start_char="16362" end_char="16364">the</TOKEN>
<TOKEN id="token-132-3" pos="word" morph="none" start_char="16366" end_char="16373">Institut</TOKEN>
<TOKEN id="token-132-4" pos="word" morph="none" start_char="16375" end_char="16381">Pasteur</TOKEN>
<TOKEN id="token-132-5" pos="word" morph="none" start_char="16383" end_char="16385">did</TOKEN>
<TOKEN id="token-132-6" pos="word" morph="none" start_char="16387" end_char="16389">not</TOKEN>
<TOKEN id="token-132-7" pos="word" morph="none" start_char="16391" end_char="16396">invent</TOKEN>
<TOKEN id="token-132-8" pos="unknown" morph="none" start_char="16398" end_char="16405">Covid-19</TOKEN>
<TOKEN id="token-132-9" pos="word" morph="none" start_char="16407" end_char="16408">or</TOKEN>
<TOKEN id="token-132-10" pos="word" morph="none" start_char="16410" end_char="16412">the</TOKEN>
<TOKEN id="token-132-11" pos="word" morph="none" start_char="16414" end_char="16418">virus</TOKEN>
<TOKEN id="token-132-12" pos="word" morph="none" start_char="16420" end_char="16430">responsible</TOKEN>
<TOKEN id="token-132-13" pos="word" morph="none" start_char="16432" end_char="16434">for</TOKEN>
<TOKEN id="token-132-14" pos="word" morph="none" start_char="16436" end_char="16437">it</TOKEN>
<TOKEN id="token-132-15" pos="punct" morph="none" start_char="16438" end_char="16438">,</TOKEN>
<TOKEN id="token-132-16" pos="unknown" morph="none" start_char="16440" end_char="16449">SARS-CoV-2</TOKEN>
<TOKEN id="token-132-17" pos="punct" morph="none" start_char="16450" end_char="16450">!</TOKEN>
</SEG>
<SEG id="segment-133" start_char="16453" end_char="16475">
<ORIGINAL_TEXT>Text of March 18, 2020.</ORIGINAL_TEXT>
<TOKEN id="token-133-0" pos="word" morph="none" start_char="16453" end_char="16456">Text</TOKEN>
<TOKEN id="token-133-1" pos="word" morph="none" start_char="16458" end_char="16459">of</TOKEN>
<TOKEN id="token-133-2" pos="word" morph="none" start_char="16461" end_char="16465">March</TOKEN>
<TOKEN id="token-133-3" pos="word" morph="none" start_char="16467" end_char="16468">18</TOKEN>
<TOKEN id="token-133-4" pos="punct" morph="none" start_char="16469" end_char="16469">,</TOKEN>
<TOKEN id="token-133-5" pos="word" morph="none" start_char="16471" end_char="16474">2020</TOKEN>
<TOKEN id="token-133-6" pos="punct" morph="none" start_char="16475" end_char="16475">.</TOKEN>
</SEG>
<SEG id="segment-134" start_char="16477" end_char="16501">
<ORIGINAL_TEXT>Updated November 4, 2020.</ORIGINAL_TEXT>
<TOKEN id="token-134-0" pos="word" morph="none" start_char="16477" end_char="16483">Updated</TOKEN>
<TOKEN id="token-134-1" pos="word" morph="none" start_char="16485" end_char="16492">November</TOKEN>
<TOKEN id="token-134-2" pos="word" morph="none" start_char="16494" end_char="16494">4</TOKEN>
<TOKEN id="token-134-3" pos="punct" morph="none" start_char="16495" end_char="16495">,</TOKEN>
<TOKEN id="token-134-4" pos="word" morph="none" start_char="16497" end_char="16500">2020</TOKEN>
<TOKEN id="token-134-5" pos="punct" morph="none" start_char="16501" end_char="16501">.</TOKEN>
</SEG>
<SEG id="segment-135" start_char="16505" end_char="16705">
<ORIGINAL_TEXT>A video posted on March 17, 2020, of a conspiratorial nature, claims - on a misinterpretation of a patent filed in 2004 - that the Institut Pasteur would have invented Covid-19 for commercial purposes.</ORIGINAL_TEXT>
<TOKEN id="token-135-0" pos="word" morph="none" start_char="16505" end_char="16505">A</TOKEN>
<TOKEN id="token-135-1" pos="word" morph="none" start_char="16507" end_char="16511">video</TOKEN>
<TOKEN id="token-135-2" pos="word" morph="none" start_char="16513" end_char="16518">posted</TOKEN>
<TOKEN id="token-135-3" pos="word" morph="none" start_char="16520" end_char="16521">on</TOKEN>
<TOKEN id="token-135-4" pos="word" morph="none" start_char="16523" end_char="16527">March</TOKEN>
<TOKEN id="token-135-5" pos="word" morph="none" start_char="16529" end_char="16530">17</TOKEN>
<TOKEN id="token-135-6" pos="punct" morph="none" start_char="16531" end_char="16531">,</TOKEN>
<TOKEN id="token-135-7" pos="word" morph="none" start_char="16533" end_char="16536">2020</TOKEN>
<TOKEN id="token-135-8" pos="punct" morph="none" start_char="16537" end_char="16537">,</TOKEN>
<TOKEN id="token-135-9" pos="word" morph="none" start_char="16539" end_char="16540">of</TOKEN>
<TOKEN id="token-135-10" pos="word" morph="none" start_char="16542" end_char="16542">a</TOKEN>
<TOKEN id="token-135-11" pos="word" morph="none" start_char="16544" end_char="16557">conspiratorial</TOKEN>
<TOKEN id="token-135-12" pos="word" morph="none" start_char="16559" end_char="16564">nature</TOKEN>
<TOKEN id="token-135-13" pos="punct" morph="none" start_char="16565" end_char="16565">,</TOKEN>
<TOKEN id="token-135-14" pos="word" morph="none" start_char="16567" end_char="16572">claims</TOKEN>
<TOKEN id="token-135-15" pos="punct" morph="none" start_char="16574" end_char="16574">-</TOKEN>
<TOKEN id="token-135-16" pos="word" morph="none" start_char="16576" end_char="16577">on</TOKEN>
<TOKEN id="token-135-17" pos="word" morph="none" start_char="16579" end_char="16579">a</TOKEN>
<TOKEN id="token-135-18" pos="word" morph="none" start_char="16581" end_char="16597">misinterpretation</TOKEN>
<TOKEN id="token-135-19" pos="word" morph="none" start_char="16599" end_char="16600">of</TOKEN>
<TOKEN id="token-135-20" pos="word" morph="none" start_char="16602" end_char="16602">a</TOKEN>
<TOKEN id="token-135-21" pos="word" morph="none" start_char="16604" end_char="16609">patent</TOKEN>
<TOKEN id="token-135-22" pos="word" morph="none" start_char="16611" end_char="16615">filed</TOKEN>
<TOKEN id="token-135-23" pos="word" morph="none" start_char="16617" end_char="16618">in</TOKEN>
<TOKEN id="token-135-24" pos="word" morph="none" start_char="16620" end_char="16623">2004</TOKEN>
<TOKEN id="token-135-25" pos="punct" morph="none" start_char="16625" end_char="16625">-</TOKEN>
<TOKEN id="token-135-26" pos="word" morph="none" start_char="16627" end_char="16630">that</TOKEN>
<TOKEN id="token-135-27" pos="word" morph="none" start_char="16632" end_char="16634">the</TOKEN>
<TOKEN id="token-135-28" pos="word" morph="none" start_char="16636" end_char="16643">Institut</TOKEN>
<TOKEN id="token-135-29" pos="word" morph="none" start_char="16645" end_char="16651">Pasteur</TOKEN>
<TOKEN id="token-135-30" pos="word" morph="none" start_char="16653" end_char="16657">would</TOKEN>
<TOKEN id="token-135-31" pos="word" morph="none" start_char="16659" end_char="16662">have</TOKEN>
<TOKEN id="token-135-32" pos="word" morph="none" start_char="16664" end_char="16671">invented</TOKEN>
<TOKEN id="token-135-33" pos="unknown" morph="none" start_char="16673" end_char="16680">Covid-19</TOKEN>
<TOKEN id="token-135-34" pos="word" morph="none" start_char="16682" end_char="16684">for</TOKEN>
<TOKEN id="token-135-35" pos="word" morph="none" start_char="16686" end_char="16695">commercial</TOKEN>
<TOKEN id="token-135-36" pos="word" morph="none" start_char="16697" end_char="16704">purposes</TOKEN>
<TOKEN id="token-135-37" pos="punct" morph="none" start_char="16705" end_char="16705">.</TOKEN>
</SEG>
<SEG id="segment-136" start_char="16707" end_char="16745">
<ORIGINAL_TEXT>It is false and without any foundation.</ORIGINAL_TEXT>
<TOKEN id="token-136-0" pos="word" morph="none" start_char="16707" end_char="16708">It</TOKEN>
<TOKEN id="token-136-1" pos="word" morph="none" start_char="16710" end_char="16711">is</TOKEN>
<TOKEN id="token-136-2" pos="word" morph="none" start_char="16713" end_char="16717">false</TOKEN>
<TOKEN id="token-136-3" pos="word" morph="none" start_char="16719" end_char="16721">and</TOKEN>
<TOKEN id="token-136-4" pos="word" morph="none" start_char="16723" end_char="16729">without</TOKEN>
<TOKEN id="token-136-5" pos="word" morph="none" start_char="16731" end_char="16733">any</TOKEN>
<TOKEN id="token-136-6" pos="word" morph="none" start_char="16735" end_char="16744">foundation</TOKEN>
<TOKEN id="token-136-7" pos="punct" morph="none" start_char="16745" end_char="16745">.</TOKEN>
</SEG>
<SEG id="segment-137" start_char="16747" end_char="16822">
<ORIGINAL_TEXT>These comments are defamatory of the Institut Pasteur and its collaborators.</ORIGINAL_TEXT>
<TOKEN id="token-137-0" pos="word" morph="none" start_char="16747" end_char="16751">These</TOKEN>
<TOKEN id="token-137-1" pos="word" morph="none" start_char="16753" end_char="16760">comments</TOKEN>
<TOKEN id="token-137-2" pos="word" morph="none" start_char="16762" end_char="16764">are</TOKEN>
<TOKEN id="token-137-3" pos="word" morph="none" start_char="16766" end_char="16775">defamatory</TOKEN>
<TOKEN id="token-137-4" pos="word" morph="none" start_char="16777" end_char="16778">of</TOKEN>
<TOKEN id="token-137-5" pos="word" morph="none" start_char="16780" end_char="16782">the</TOKEN>
<TOKEN id="token-137-6" pos="word" morph="none" start_char="16784" end_char="16791">Institut</TOKEN>
<TOKEN id="token-137-7" pos="word" morph="none" start_char="16793" end_char="16799">Pasteur</TOKEN>
<TOKEN id="token-137-8" pos="word" morph="none" start_char="16801" end_char="16803">and</TOKEN>
<TOKEN id="token-137-9" pos="word" morph="none" start_char="16805" end_char="16807">its</TOKEN>
<TOKEN id="token-137-10" pos="word" morph="none" start_char="16809" end_char="16821">collaborators</TOKEN>
<TOKEN id="token-137-11" pos="punct" morph="none" start_char="16822" end_char="16822">.</TOKEN>
</SEG>
<SEG id="segment-138" start_char="16826" end_char="16930">
<ORIGINAL_TEXT>The Institut Pasteur invented a vaccine candidate in 2004 for a previous coronavirus known as SARS-CoV-1.</ORIGINAL_TEXT>
<TOKEN id="token-138-0" pos="word" morph="none" start_char="16826" end_char="16828">The</TOKEN>
<TOKEN id="token-138-1" pos="word" morph="none" start_char="16830" end_char="16837">Institut</TOKEN>
<TOKEN id="token-138-2" pos="word" morph="none" start_char="16839" end_char="16845">Pasteur</TOKEN>
<TOKEN id="token-138-3" pos="word" morph="none" start_char="16847" end_char="16854">invented</TOKEN>
<TOKEN id="token-138-4" pos="word" morph="none" start_char="16856" end_char="16856">a</TOKEN>
<TOKEN id="token-138-5" pos="word" morph="none" start_char="16858" end_char="16864">vaccine</TOKEN>
<TOKEN id="token-138-6" pos="word" morph="none" start_char="16866" end_char="16874">candidate</TOKEN>
<TOKEN id="token-138-7" pos="word" morph="none" start_char="16876" end_char="16877">in</TOKEN>
<TOKEN id="token-138-8" pos="word" morph="none" start_char="16879" end_char="16882">2004</TOKEN>
<TOKEN id="token-138-9" pos="word" morph="none" start_char="16884" end_char="16886">for</TOKEN>
<TOKEN id="token-138-10" pos="word" morph="none" start_char="16888" end_char="16888">a</TOKEN>
<TOKEN id="token-138-11" pos="word" morph="none" start_char="16890" end_char="16897">previous</TOKEN>
<TOKEN id="token-138-12" pos="word" morph="none" start_char="16899" end_char="16909">coronavirus</TOKEN>
<TOKEN id="token-138-13" pos="word" morph="none" start_char="16911" end_char="16915">known</TOKEN>
<TOKEN id="token-138-14" pos="word" morph="none" start_char="16917" end_char="16918">as</TOKEN>
<TOKEN id="token-138-15" pos="unknown" morph="none" start_char="16920" end_char="16929">SARS-CoV-1</TOKEN>
<TOKEN id="token-138-16" pos="punct" morph="none" start_char="16930" end_char="16930">.</TOKEN>
</SEG>
<SEG id="segment-139" start_char="16936" end_char="17019">
<ORIGINAL_TEXT>The conspiracy theory video currently doing the rounds on the Web is entirely false.</ORIGINAL_TEXT>
<TOKEN id="token-139-0" pos="word" morph="none" start_char="16936" end_char="16938">The</TOKEN>
<TOKEN id="token-139-1" pos="word" morph="none" start_char="16940" end_char="16949">conspiracy</TOKEN>
<TOKEN id="token-139-2" pos="word" morph="none" start_char="16951" end_char="16956">theory</TOKEN>
<TOKEN id="token-139-3" pos="word" morph="none" start_char="16958" end_char="16962">video</TOKEN>
<TOKEN id="token-139-4" pos="word" morph="none" start_char="16964" end_char="16972">currently</TOKEN>
<TOKEN id="token-139-5" pos="word" morph="none" start_char="16974" end_char="16978">doing</TOKEN>
<TOKEN id="token-139-6" pos="word" morph="none" start_char="16980" end_char="16982">the</TOKEN>
<TOKEN id="token-139-7" pos="word" morph="none" start_char="16984" end_char="16989">rounds</TOKEN>
<TOKEN id="token-139-8" pos="word" morph="none" start_char="16991" end_char="16992">on</TOKEN>
<TOKEN id="token-139-9" pos="word" morph="none" start_char="16994" end_char="16996">the</TOKEN>
<TOKEN id="token-139-10" pos="word" morph="none" start_char="16998" end_char="17000">Web</TOKEN>
<TOKEN id="token-139-11" pos="word" morph="none" start_char="17002" end_char="17003">is</TOKEN>
<TOKEN id="token-139-12" pos="word" morph="none" start_char="17005" end_char="17012">entirely</TOKEN>
<TOKEN id="token-139-13" pos="word" morph="none" start_char="17014" end_char="17018">false</TOKEN>
<TOKEN id="token-139-14" pos="punct" morph="none" start_char="17019" end_char="17019">.</TOKEN>
</SEG>
<SEG id="segment-140" start_char="17025" end_char="17036">
<ORIGINAL_TEXT>Explanations</ORIGINAL_TEXT>
<TOKEN id="token-140-0" pos="word" morph="none" start_char="17025" end_char="17036">Explanations</TOKEN>
</SEG>
<SEG id="segment-141" start_char="17040" end_char="17138">
<ORIGINAL_TEXT>One of the Institut Pasteur's missions is to work on all emerging viruses, including coronaviruses.</ORIGINAL_TEXT>
<TOKEN id="token-141-0" pos="word" morph="none" start_char="17040" end_char="17042">One</TOKEN>
<TOKEN id="token-141-1" pos="word" morph="none" start_char="17044" end_char="17045">of</TOKEN>
<TOKEN id="token-141-2" pos="word" morph="none" start_char="17047" end_char="17049">the</TOKEN>
<TOKEN id="token-141-3" pos="word" morph="none" start_char="17051" end_char="17058">Institut</TOKEN>
<TOKEN id="token-141-4" pos="word" morph="none" start_char="17060" end_char="17068">Pasteur's</TOKEN>
<TOKEN id="token-141-5" pos="word" morph="none" start_char="17070" end_char="17077">missions</TOKEN>
<TOKEN id="token-141-6" pos="word" morph="none" start_char="17079" end_char="17080">is</TOKEN>
<TOKEN id="token-141-7" pos="word" morph="none" start_char="17082" end_char="17083">to</TOKEN>
<TOKEN id="token-141-8" pos="word" morph="none" start_char="17085" end_char="17088">work</TOKEN>
<TOKEN id="token-141-9" pos="word" morph="none" start_char="17090" end_char="17091">on</TOKEN>
<TOKEN id="token-141-10" pos="word" morph="none" start_char="17093" end_char="17095">all</TOKEN>
<TOKEN id="token-141-11" pos="word" morph="none" start_char="17097" end_char="17104">emerging</TOKEN>
<TOKEN id="token-141-12" pos="word" morph="none" start_char="17106" end_char="17112">viruses</TOKEN>
<TOKEN id="token-141-13" pos="punct" morph="none" start_char="17113" end_char="17113">,</TOKEN>
<TOKEN id="token-141-14" pos="word" morph="none" start_char="17115" end_char="17123">including</TOKEN>
<TOKEN id="token-141-15" pos="word" morph="none" start_char="17125" end_char="17137">coronaviruses</TOKEN>
<TOKEN id="token-141-16" pos="punct" morph="none" start_char="17138" end_char="17138">.</TOKEN>
</SEG>
<SEG id="segment-142" start_char="17140" end_char="17192">
<ORIGINAL_TEXT>And there are several different types of coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-142-0" pos="word" morph="none" start_char="17140" end_char="17142">And</TOKEN>
<TOKEN id="token-142-1" pos="word" morph="none" start_char="17144" end_char="17148">there</TOKEN>
<TOKEN id="token-142-2" pos="word" morph="none" start_char="17150" end_char="17152">are</TOKEN>
<TOKEN id="token-142-3" pos="word" morph="none" start_char="17154" end_char="17160">several</TOKEN>
<TOKEN id="token-142-4" pos="word" morph="none" start_char="17162" end_char="17170">different</TOKEN>
<TOKEN id="token-142-5" pos="word" morph="none" start_char="17172" end_char="17176">types</TOKEN>
<TOKEN id="token-142-6" pos="word" morph="none" start_char="17178" end_char="17179">of</TOKEN>
<TOKEN id="token-142-7" pos="word" morph="none" start_char="17181" end_char="17191">coronavirus</TOKEN>
<TOKEN id="token-142-8" pos="punct" morph="none" start_char="17192" end_char="17192">.</TOKEN>
</SEG>
<SEG id="segment-143" start_char="17195" end_char="17318">
<ORIGINAL_TEXT>In 2002, a first coronavirus, SARS-CoV-1, emerged in China, causing an outbreak of severe acute respiratory syndrome (SARS).</ORIGINAL_TEXT>
<TOKEN id="token-143-0" pos="word" morph="none" start_char="17195" end_char="17196">In</TOKEN>
<TOKEN id="token-143-1" pos="word" morph="none" start_char="17198" end_char="17201">2002</TOKEN>
<TOKEN id="token-143-2" pos="punct" morph="none" start_char="17202" end_char="17202">,</TOKEN>
<TOKEN id="token-143-3" pos="word" morph="none" start_char="17204" end_char="17204">a</TOKEN>
<TOKEN id="token-143-4" pos="word" morph="none" start_char="17206" end_char="17210">first</TOKEN>
<TOKEN id="token-143-5" pos="word" morph="none" start_char="17212" end_char="17222">coronavirus</TOKEN>
<TOKEN id="token-143-6" pos="punct" morph="none" start_char="17223" end_char="17223">,</TOKEN>
<TOKEN id="token-143-7" pos="unknown" morph="none" start_char="17225" end_char="17234">SARS-CoV-1</TOKEN>
<TOKEN id="token-143-8" pos="punct" morph="none" start_char="17235" end_char="17235">,</TOKEN>
<TOKEN id="token-143-9" pos="word" morph="none" start_char="17237" end_char="17243">emerged</TOKEN>
<TOKEN id="token-143-10" pos="word" morph="none" start_char="17245" end_char="17246">in</TOKEN>
<TOKEN id="token-143-11" pos="word" morph="none" start_char="17248" end_char="17252">China</TOKEN>
<TOKEN id="token-143-12" pos="punct" morph="none" start_char="17253" end_char="17253">,</TOKEN>
<TOKEN id="token-143-13" pos="word" morph="none" start_char="17255" end_char="17261">causing</TOKEN>
<TOKEN id="token-143-14" pos="word" morph="none" start_char="17263" end_char="17264">an</TOKEN>
<TOKEN id="token-143-15" pos="word" morph="none" start_char="17266" end_char="17273">outbreak</TOKEN>
<TOKEN id="token-143-16" pos="word" morph="none" start_char="17275" end_char="17276">of</TOKEN>
<TOKEN id="token-143-17" pos="word" morph="none" start_char="17278" end_char="17283">severe</TOKEN>
<TOKEN id="token-143-18" pos="word" morph="none" start_char="17285" end_char="17289">acute</TOKEN>
<TOKEN id="token-143-19" pos="word" morph="none" start_char="17291" end_char="17301">respiratory</TOKEN>
<TOKEN id="token-143-20" pos="word" morph="none" start_char="17303" end_char="17310">syndrome</TOKEN>
<TOKEN id="token-143-21" pos="punct" morph="none" start_char="17312" end_char="17312">(</TOKEN>
<TOKEN id="token-143-22" pos="word" morph="none" start_char="17313" end_char="17316">SARS</TOKEN>
<TOKEN id="token-143-23" pos="punct" morph="none" start_char="17317" end_char="17318">).</TOKEN>
</SEG>
<SEG id="segment-144" start_char="17322" end_char="17388">
<ORIGINAL_TEXT>In 2003, this outbreak spread to several countries and continents.</ORIGINAL_TEXT>
<TOKEN id="token-144-0" pos="unknown" morph="none" start_char="17322" end_char="17324">In</TOKEN>
<TOKEN id="token-144-1" pos="word" morph="none" start_char="17326" end_char="17329">2003</TOKEN>
<TOKEN id="token-144-2" pos="punct" morph="none" start_char="17330" end_char="17330">,</TOKEN>
<TOKEN id="token-144-3" pos="word" morph="none" start_char="17332" end_char="17335">this</TOKEN>
<TOKEN id="token-144-4" pos="word" morph="none" start_char="17337" end_char="17344">outbreak</TOKEN>
<TOKEN id="token-144-5" pos="word" morph="none" start_char="17346" end_char="17351">spread</TOKEN>
<TOKEN id="token-144-6" pos="word" morph="none" start_char="17353" end_char="17354">to</TOKEN>
<TOKEN id="token-144-7" pos="word" morph="none" start_char="17356" end_char="17362">several</TOKEN>
<TOKEN id="token-144-8" pos="word" morph="none" start_char="17364" end_char="17372">countries</TOKEN>
<TOKEN id="token-144-9" pos="word" morph="none" start_char="17374" end_char="17376">and</TOKEN>
<TOKEN id="token-144-10" pos="word" morph="none" start_char="17378" end_char="17387">continents</TOKEN>
<TOKEN id="token-144-11" pos="punct" morph="none" start_char="17388" end_char="17388">.</TOKEN>
</SEG>
<SEG id="segment-145" start_char="17392" end_char="17718">
<ORIGINAL_TEXT>At the time, the Institut Pasteur's teams responded to the outbreak by proposing a number of vaccine strategies, including a vaccine candidate based on the measles virus vaccine platform (the measles vaccine can be recombined and used as a means of inducing an immune response against other pathogens, in this case SARS-CoV-1).</ORIGINAL_TEXT>
<TOKEN id="token-145-0" pos="word" morph="none" start_char="17392" end_char="17393">At</TOKEN>
<TOKEN id="token-145-1" pos="word" morph="none" start_char="17395" end_char="17397">the</TOKEN>
<TOKEN id="token-145-2" pos="word" morph="none" start_char="17399" end_char="17402">time</TOKEN>
<TOKEN id="token-145-3" pos="punct" morph="none" start_char="17403" end_char="17403">,</TOKEN>
<TOKEN id="token-145-4" pos="word" morph="none" start_char="17405" end_char="17407">the</TOKEN>
<TOKEN id="token-145-5" pos="word" morph="none" start_char="17409" end_char="17416">Institut</TOKEN>
<TOKEN id="token-145-6" pos="word" morph="none" start_char="17418" end_char="17426">Pasteur's</TOKEN>
<TOKEN id="token-145-7" pos="word" morph="none" start_char="17428" end_char="17432">teams</TOKEN>
<TOKEN id="token-145-8" pos="word" morph="none" start_char="17434" end_char="17442">responded</TOKEN>
<TOKEN id="token-145-9" pos="word" morph="none" start_char="17444" end_char="17445">to</TOKEN>
<TOKEN id="token-145-10" pos="word" morph="none" start_char="17447" end_char="17449">the</TOKEN>
<TOKEN id="token-145-11" pos="word" morph="none" start_char="17451" end_char="17458">outbreak</TOKEN>
<TOKEN id="token-145-12" pos="word" morph="none" start_char="17460" end_char="17461">by</TOKEN>
<TOKEN id="token-145-13" pos="word" morph="none" start_char="17463" end_char="17471">proposing</TOKEN>
<TOKEN id="token-145-14" pos="word" morph="none" start_char="17473" end_char="17473">a</TOKEN>
<TOKEN id="token-145-15" pos="word" morph="none" start_char="17475" end_char="17480">number</TOKEN>
<TOKEN id="token-145-16" pos="word" morph="none" start_char="17482" end_char="17483">of</TOKEN>
<TOKEN id="token-145-17" pos="word" morph="none" start_char="17485" end_char="17491">vaccine</TOKEN>
<TOKEN id="token-145-18" pos="word" morph="none" start_char="17493" end_char="17502">strategies</TOKEN>
<TOKEN id="token-145-19" pos="punct" morph="none" start_char="17503" end_char="17503">,</TOKEN>
<TOKEN id="token-145-20" pos="word" morph="none" start_char="17505" end_char="17513">including</TOKEN>
<TOKEN id="token-145-21" pos="word" morph="none" start_char="17515" end_char="17515">a</TOKEN>
<TOKEN id="token-145-22" pos="word" morph="none" start_char="17517" end_char="17523">vaccine</TOKEN>
<TOKEN id="token-145-23" pos="word" morph="none" start_char="17525" end_char="17533">candidate</TOKEN>
<TOKEN id="token-145-24" pos="word" morph="none" start_char="17535" end_char="17539">based</TOKEN>
<TOKEN id="token-145-25" pos="word" morph="none" start_char="17541" end_char="17542">on</TOKEN>
<TOKEN id="token-145-26" pos="word" morph="none" start_char="17544" end_char="17546">the</TOKEN>
<TOKEN id="token-145-27" pos="word" morph="none" start_char="17548" end_char="17554">measles</TOKEN>
<TOKEN id="token-145-28" pos="word" morph="none" start_char="17556" end_char="17560">virus</TOKEN>
<TOKEN id="token-145-29" pos="word" morph="none" start_char="17562" end_char="17568">vaccine</TOKEN>
<TOKEN id="token-145-30" pos="word" morph="none" start_char="17570" end_char="17577">platform</TOKEN>
<TOKEN id="token-145-31" pos="punct" morph="none" start_char="17579" end_char="17579">(</TOKEN>
<TOKEN id="token-145-32" pos="word" morph="none" start_char="17580" end_char="17582">the</TOKEN>
<TOKEN id="token-145-33" pos="word" morph="none" start_char="17584" end_char="17590">measles</TOKEN>
<TOKEN id="token-145-34" pos="word" morph="none" start_char="17592" end_char="17598">vaccine</TOKEN>
<TOKEN id="token-145-35" pos="word" morph="none" start_char="17600" end_char="17602">can</TOKEN>
<TOKEN id="token-145-36" pos="word" morph="none" start_char="17604" end_char="17605">be</TOKEN>
<TOKEN id="token-145-37" pos="word" morph="none" start_char="17607" end_char="17616">recombined</TOKEN>
<TOKEN id="token-145-38" pos="word" morph="none" start_char="17618" end_char="17620">and</TOKEN>
<TOKEN id="token-145-39" pos="word" morph="none" start_char="17622" end_char="17625">used</TOKEN>
<TOKEN id="token-145-40" pos="word" morph="none" start_char="17627" end_char="17628">as</TOKEN>
<TOKEN id="token-145-41" pos="word" morph="none" start_char="17630" end_char="17630">a</TOKEN>
<TOKEN id="token-145-42" pos="word" morph="none" start_char="17632" end_char="17636">means</TOKEN>
<TOKEN id="token-145-43" pos="word" morph="none" start_char="17638" end_char="17639">of</TOKEN>
<TOKEN id="token-145-44" pos="word" morph="none" start_char="17641" end_char="17648">inducing</TOKEN>
<TOKEN id="token-145-45" pos="word" morph="none" start_char="17650" end_char="17651">an</TOKEN>
<TOKEN id="token-145-46" pos="word" morph="none" start_char="17653" end_char="17658">immune</TOKEN>
<TOKEN id="token-145-47" pos="word" morph="none" start_char="17660" end_char="17667">response</TOKEN>
<TOKEN id="token-145-48" pos="word" morph="none" start_char="17669" end_char="17675">against</TOKEN>
<TOKEN id="token-145-49" pos="word" morph="none" start_char="17677" end_char="17681">other</TOKEN>
<TOKEN id="token-145-50" pos="word" morph="none" start_char="17683" end_char="17691">pathogens</TOKEN>
<TOKEN id="token-145-51" pos="punct" morph="none" start_char="17692" end_char="17692">,</TOKEN>
<TOKEN id="token-145-52" pos="word" morph="none" start_char="17694" end_char="17695">in</TOKEN>
<TOKEN id="token-145-53" pos="word" morph="none" start_char="17697" end_char="17700">this</TOKEN>
<TOKEN id="token-145-54" pos="word" morph="none" start_char="17702" end_char="17705">case</TOKEN>
<TOKEN id="token-145-55" pos="unknown" morph="none" start_char="17707" end_char="17716">SARS-CoV-1</TOKEN>
<TOKEN id="token-145-56" pos="punct" morph="none" start_char="17717" end_char="17718">).</TOKEN>
</SEG>
<SEG id="segment-146" start_char="17722" end_char="18000">
<ORIGINAL_TEXT>In 2004, an invention disclosure was filed for the vaccine candidate for SARS-CoV-1.The patent filed was for SARS-CoV-1 (responsible for the illness known as SARS in 2002-2003), which is very different from SARS-CoV-2 (responsible for the illness known as Covid-19 in 2019-2020).</ORIGINAL_TEXT>
<TOKEN id="token-146-0" pos="word" morph="none" start_char="17722" end_char="17723">In</TOKEN>
<TOKEN id="token-146-1" pos="word" morph="none" start_char="17725" end_char="17728">2004</TOKEN>
<TOKEN id="token-146-2" pos="punct" morph="none" start_char="17729" end_char="17729">,</TOKEN>
<TOKEN id="token-146-3" pos="word" morph="none" start_char="17731" end_char="17732">an</TOKEN>
<TOKEN id="token-146-4" pos="word" morph="none" start_char="17734" end_char="17742">invention</TOKEN>
<TOKEN id="token-146-5" pos="word" morph="none" start_char="17744" end_char="17753">disclosure</TOKEN>
<TOKEN id="token-146-6" pos="word" morph="none" start_char="17755" end_char="17757">was</TOKEN>
<TOKEN id="token-146-7" pos="word" morph="none" start_char="17759" end_char="17763">filed</TOKEN>
<TOKEN id="token-146-8" pos="word" morph="none" start_char="17765" end_char="17767">for</TOKEN>
<TOKEN id="token-146-9" pos="word" morph="none" start_char="17769" end_char="17771">the</TOKEN>
<TOKEN id="token-146-10" pos="word" morph="none" start_char="17773" end_char="17779">vaccine</TOKEN>
<TOKEN id="token-146-11" pos="word" morph="none" start_char="17781" end_char="17789">candidate</TOKEN>
<TOKEN id="token-146-12" pos="word" morph="none" start_char="17791" end_char="17793">for</TOKEN>
<TOKEN id="token-146-13" pos="unknown" morph="none" start_char="17795" end_char="17808">SARS-CoV-1.The</TOKEN>
<TOKEN id="token-146-14" pos="word" morph="none" start_char="17810" end_char="17815">patent</TOKEN>
<TOKEN id="token-146-15" pos="word" morph="none" start_char="17817" end_char="17821">filed</TOKEN>
<TOKEN id="token-146-16" pos="word" morph="none" start_char="17823" end_char="17825">was</TOKEN>
<TOKEN id="token-146-17" pos="word" morph="none" start_char="17827" end_char="17829">for</TOKEN>
<TOKEN id="token-146-18" pos="unknown" morph="none" start_char="17831" end_char="17840">SARS-CoV-1</TOKEN>
<TOKEN id="token-146-19" pos="punct" morph="none" start_char="17842" end_char="17842">(</TOKEN>
<TOKEN id="token-146-20" pos="word" morph="none" start_char="17843" end_char="17853">responsible</TOKEN>
<TOKEN id="token-146-21" pos="word" morph="none" start_char="17855" end_char="17857">for</TOKEN>
<TOKEN id="token-146-22" pos="word" morph="none" start_char="17859" end_char="17861">the</TOKEN>
<TOKEN id="token-146-23" pos="word" morph="none" start_char="17863" end_char="17869">illness</TOKEN>
<TOKEN id="token-146-24" pos="word" morph="none" start_char="17871" end_char="17875">known</TOKEN>
<TOKEN id="token-146-25" pos="word" morph="none" start_char="17877" end_char="17878">as</TOKEN>
<TOKEN id="token-146-26" pos="word" morph="none" start_char="17880" end_char="17883">SARS</TOKEN>
<TOKEN id="token-146-27" pos="word" morph="none" start_char="17885" end_char="17886">in</TOKEN>
<TOKEN id="token-146-28" pos="unknown" morph="none" start_char="17888" end_char="17896">2002-2003</TOKEN>
<TOKEN id="token-146-29" pos="punct" morph="none" start_char="17897" end_char="17898">),</TOKEN>
<TOKEN id="token-146-30" pos="word" morph="none" start_char="17900" end_char="17904">which</TOKEN>
<TOKEN id="token-146-31" pos="word" morph="none" start_char="17906" end_char="17907">is</TOKEN>
<TOKEN id="token-146-32" pos="word" morph="none" start_char="17909" end_char="17912">very</TOKEN>
<TOKEN id="token-146-33" pos="word" morph="none" start_char="17914" end_char="17922">different</TOKEN>
<TOKEN id="token-146-34" pos="word" morph="none" start_char="17924" end_char="17927">from</TOKEN>
<TOKEN id="token-146-35" pos="unknown" morph="none" start_char="17929" end_char="17938">SARS-CoV-2</TOKEN>
<TOKEN id="token-146-36" pos="punct" morph="none" start_char="17940" end_char="17940">(</TOKEN>
<TOKEN id="token-146-37" pos="word" morph="none" start_char="17941" end_char="17951">responsible</TOKEN>
<TOKEN id="token-146-38" pos="word" morph="none" start_char="17953" end_char="17955">for</TOKEN>
<TOKEN id="token-146-39" pos="word" morph="none" start_char="17957" end_char="17959">the</TOKEN>
<TOKEN id="token-146-40" pos="word" morph="none" start_char="17961" end_char="17967">illness</TOKEN>
<TOKEN id="token-146-41" pos="word" morph="none" start_char="17969" end_char="17973">known</TOKEN>
<TOKEN id="token-146-42" pos="word" morph="none" start_char="17975" end_char="17976">as</TOKEN>
<TOKEN id="token-146-43" pos="unknown" morph="none" start_char="17978" end_char="17985">Covid-19</TOKEN>
<TOKEN id="token-146-44" pos="word" morph="none" start_char="17987" end_char="17988">in</TOKEN>
<TOKEN id="token-146-45" pos="unknown" morph="none" start_char="17990" end_char="17998">2019-2020</TOKEN>
<TOKEN id="token-146-46" pos="punct" morph="none" start_char="17999" end_char="18000">).</TOKEN>
</SEG>
<SEG id="segment-147" start_char="18003" end_char="18168">
<ORIGINAL_TEXT>The 2004 patent described the discovery of the virus and the subsequent invention of a vaccine strategy against the virus  and NOT the invention of the virus itself!</ORIGINAL_TEXT>
<TOKEN id="token-147-0" pos="word" morph="none" start_char="18003" end_char="18005">The</TOKEN>
<TOKEN id="token-147-1" pos="word" morph="none" start_char="18007" end_char="18010">2004</TOKEN>
<TOKEN id="token-147-2" pos="word" morph="none" start_char="18012" end_char="18017">patent</TOKEN>
<TOKEN id="token-147-3" pos="word" morph="none" start_char="18019" end_char="18027">described</TOKEN>
<TOKEN id="token-147-4" pos="word" morph="none" start_char="18029" end_char="18031">the</TOKEN>
<TOKEN id="token-147-5" pos="word" morph="none" start_char="18033" end_char="18041">discovery</TOKEN>
<TOKEN id="token-147-6" pos="word" morph="none" start_char="18043" end_char="18044">of</TOKEN>
<TOKEN id="token-147-7" pos="word" morph="none" start_char="18046" end_char="18048">the</TOKEN>
<TOKEN id="token-147-8" pos="word" morph="none" start_char="18050" end_char="18054">virus</TOKEN>
<TOKEN id="token-147-9" pos="word" morph="none" start_char="18056" end_char="18058">and</TOKEN>
<TOKEN id="token-147-10" pos="word" morph="none" start_char="18060" end_char="18062">the</TOKEN>
<TOKEN id="token-147-11" pos="word" morph="none" start_char="18064" end_char="18073">subsequent</TOKEN>
<TOKEN id="token-147-12" pos="word" morph="none" start_char="18075" end_char="18083">invention</TOKEN>
<TOKEN id="token-147-13" pos="word" morph="none" start_char="18085" end_char="18086">of</TOKEN>
<TOKEN id="token-147-14" pos="word" morph="none" start_char="18088" end_char="18088">a</TOKEN>
<TOKEN id="token-147-15" pos="word" morph="none" start_char="18090" end_char="18096">vaccine</TOKEN>
<TOKEN id="token-147-16" pos="word" morph="none" start_char="18098" end_char="18105">strategy</TOKEN>
<TOKEN id="token-147-17" pos="word" morph="none" start_char="18107" end_char="18113">against</TOKEN>
<TOKEN id="token-147-18" pos="word" morph="none" start_char="18115" end_char="18117">the</TOKEN>
<TOKEN id="token-147-19" pos="word" morph="none" start_char="18119" end_char="18123">virus</TOKEN>
<TOKEN id="token-147-20" pos="punct" morph="none" start_char="18125" end_char="18125"></TOKEN>
<TOKEN id="token-147-21" pos="word" morph="none" start_char="18127" end_char="18129">and</TOKEN>
<TOKEN id="token-147-22" pos="word" morph="none" start_char="18131" end_char="18133">NOT</TOKEN>
<TOKEN id="token-147-23" pos="word" morph="none" start_char="18135" end_char="18137">the</TOKEN>
<TOKEN id="token-147-24" pos="word" morph="none" start_char="18139" end_char="18147">invention</TOKEN>
<TOKEN id="token-147-25" pos="word" morph="none" start_char="18149" end_char="18150">of</TOKEN>
<TOKEN id="token-147-26" pos="word" morph="none" start_char="18152" end_char="18154">the</TOKEN>
<TOKEN id="token-147-27" pos="word" morph="none" start_char="18156" end_char="18160">virus</TOKEN>
<TOKEN id="token-147-28" pos="word" morph="none" start_char="18162" end_char="18167">itself</TOKEN>
<TOKEN id="token-147-29" pos="punct" morph="none" start_char="18168" end_char="18168">!</TOKEN>
</SEG>
<SEG id="segment-148" start_char="18172" end_char="18358">
<ORIGINAL_TEXT>The vaccine candidate for SARS-CoV-1 was not tested on humans because, by the time it was ready, the outbreak had fortunately come to an end and there were no more patients to test it on.</ORIGINAL_TEXT>
<TOKEN id="token-148-0" pos="word" morph="none" start_char="18172" end_char="18174">The</TOKEN>
<TOKEN id="token-148-1" pos="word" morph="none" start_char="18176" end_char="18182">vaccine</TOKEN>
<TOKEN id="token-148-2" pos="word" morph="none" start_char="18184" end_char="18192">candidate</TOKEN>
<TOKEN id="token-148-3" pos="word" morph="none" start_char="18194" end_char="18196">for</TOKEN>
<TOKEN id="token-148-4" pos="unknown" morph="none" start_char="18198" end_char="18207">SARS-CoV-1</TOKEN>
<TOKEN id="token-148-5" pos="word" morph="none" start_char="18209" end_char="18211">was</TOKEN>
<TOKEN id="token-148-6" pos="word" morph="none" start_char="18213" end_char="18215">not</TOKEN>
<TOKEN id="token-148-7" pos="word" morph="none" start_char="18217" end_char="18222">tested</TOKEN>
<TOKEN id="token-148-8" pos="word" morph="none" start_char="18224" end_char="18225">on</TOKEN>
<TOKEN id="token-148-9" pos="word" morph="none" start_char="18227" end_char="18232">humans</TOKEN>
<TOKEN id="token-148-10" pos="word" morph="none" start_char="18234" end_char="18240">because</TOKEN>
<TOKEN id="token-148-11" pos="punct" morph="none" start_char="18241" end_char="18241">,</TOKEN>
<TOKEN id="token-148-12" pos="word" morph="none" start_char="18243" end_char="18244">by</TOKEN>
<TOKEN id="token-148-13" pos="word" morph="none" start_char="18246" end_char="18248">the</TOKEN>
<TOKEN id="token-148-14" pos="word" morph="none" start_char="18250" end_char="18253">time</TOKEN>
<TOKEN id="token-148-15" pos="word" morph="none" start_char="18255" end_char="18256">it</TOKEN>
<TOKEN id="token-148-16" pos="word" morph="none" start_char="18258" end_char="18260">was</TOKEN>
<TOKEN id="token-148-17" pos="word" morph="none" start_char="18262" end_char="18266">ready</TOKEN>
<TOKEN id="token-148-18" pos="punct" morph="none" start_char="18267" end_char="18267">,</TOKEN>
<TOKEN id="token-148-19" pos="word" morph="none" start_char="18269" end_char="18271">the</TOKEN>
<TOKEN id="token-148-20" pos="word" morph="none" start_char="18273" end_char="18280">outbreak</TOKEN>
<TOKEN id="token-148-21" pos="word" morph="none" start_char="18282" end_char="18284">had</TOKEN>
<TOKEN id="token-148-22" pos="word" morph="none" start_char="18286" end_char="18296">fortunately</TOKEN>
<TOKEN id="token-148-23" pos="word" morph="none" start_char="18298" end_char="18301">come</TOKEN>
<TOKEN id="token-148-24" pos="word" morph="none" start_char="18303" end_char="18304">to</TOKEN>
<TOKEN id="token-148-25" pos="word" morph="none" start_char="18306" end_char="18307">an</TOKEN>
<TOKEN id="token-148-26" pos="word" morph="none" start_char="18309" end_char="18311">end</TOKEN>
<TOKEN id="token-148-27" pos="word" morph="none" start_char="18313" end_char="18315">and</TOKEN>
<TOKEN id="token-148-28" pos="word" morph="none" start_char="18317" end_char="18321">there</TOKEN>
<TOKEN id="token-148-29" pos="word" morph="none" start_char="18323" end_char="18326">were</TOKEN>
<TOKEN id="token-148-30" pos="word" morph="none" start_char="18328" end_char="18329">no</TOKEN>
<TOKEN id="token-148-31" pos="word" morph="none" start_char="18331" end_char="18334">more</TOKEN>
<TOKEN id="token-148-32" pos="word" morph="none" start_char="18336" end_char="18343">patients</TOKEN>
<TOKEN id="token-148-33" pos="word" morph="none" start_char="18345" end_char="18346">to</TOKEN>
<TOKEN id="token-148-34" pos="word" morph="none" start_char="18348" end_char="18351">test</TOKEN>
<TOKEN id="token-148-35" pos="word" morph="none" start_char="18353" end_char="18354">it</TOKEN>
<TOKEN id="token-148-36" pos="word" morph="none" start_char="18356" end_char="18357">on</TOKEN>
<TOKEN id="token-148-37" pos="punct" morph="none" start_char="18358" end_char="18358">.</TOKEN>
</SEG>
<SEG id="segment-149" start_char="18362" end_char="18440">
<ORIGINAL_TEXT>In the coronavirus family, SARS-CoV-2 is one of a group of "SARS-like" viruses.</ORIGINAL_TEXT>
<TOKEN id="token-149-0" pos="word" morph="none" start_char="18362" end_char="18363">In</TOKEN>
<TOKEN id="token-149-1" pos="word" morph="none" start_char="18365" end_char="18367">the</TOKEN>
<TOKEN id="token-149-2" pos="word" morph="none" start_char="18369" end_char="18379">coronavirus</TOKEN>
<TOKEN id="token-149-3" pos="word" morph="none" start_char="18381" end_char="18386">family</TOKEN>
<TOKEN id="token-149-4" pos="punct" morph="none" start_char="18387" end_char="18387">,</TOKEN>
<TOKEN id="token-149-5" pos="unknown" morph="none" start_char="18389" end_char="18398">SARS-CoV-2</TOKEN>
<TOKEN id="token-149-6" pos="word" morph="none" start_char="18400" end_char="18401">is</TOKEN>
<TOKEN id="token-149-7" pos="word" morph="none" start_char="18403" end_char="18405">one</TOKEN>
<TOKEN id="token-149-8" pos="word" morph="none" start_char="18407" end_char="18408">of</TOKEN>
<TOKEN id="token-149-9" pos="word" morph="none" start_char="18410" end_char="18410">a</TOKEN>
<TOKEN id="token-149-10" pos="word" morph="none" start_char="18412" end_char="18416">group</TOKEN>
<TOKEN id="token-149-11" pos="word" morph="none" start_char="18418" end_char="18419">of</TOKEN>
<TOKEN id="token-149-12" pos="punct" morph="none" start_char="18421" end_char="18421">"</TOKEN>
<TOKEN id="token-149-13" pos="unknown" morph="none" start_char="18422" end_char="18430">SARS-like</TOKEN>
<TOKEN id="token-149-14" pos="punct" morph="none" start_char="18431" end_char="18431">"</TOKEN>
<TOKEN id="token-149-15" pos="word" morph="none" start_char="18433" end_char="18439">viruses</TOKEN>
<TOKEN id="token-149-16" pos="punct" morph="none" start_char="18440" end_char="18440">.</TOKEN>
</SEG>
<SEG id="segment-150" start_char="18444" end_char="18722">
<ORIGINAL_TEXT>The expertise developed in 2003 for SARS-CoV-1, and the vaccine candidate patented in 2004, are currently being put to use by the Institut Pasteur's scientists for the development of a potential vaccine for SARS-CoV-2 (responsible for Covid-19), again using the measles platform.</ORIGINAL_TEXT>
<TOKEN id="token-150-0" pos="word" morph="none" start_char="18444" end_char="18446">The</TOKEN>
<TOKEN id="token-150-1" pos="word" morph="none" start_char="18448" end_char="18456">expertise</TOKEN>
<TOKEN id="token-150-2" pos="word" morph="none" start_char="18458" end_char="18466">developed</TOKEN>
<TOKEN id="token-150-3" pos="word" morph="none" start_char="18468" end_char="18469">in</TOKEN>
<TOKEN id="token-150-4" pos="word" morph="none" start_char="18471" end_char="18474">2003</TOKEN>
<TOKEN id="token-150-5" pos="word" morph="none" start_char="18476" end_char="18478">for</TOKEN>
<TOKEN id="token-150-6" pos="unknown" morph="none" start_char="18480" end_char="18489">SARS-CoV-1</TOKEN>
<TOKEN id="token-150-7" pos="punct" morph="none" start_char="18490" end_char="18490">,</TOKEN>
<TOKEN id="token-150-8" pos="word" morph="none" start_char="18492" end_char="18494">and</TOKEN>
<TOKEN id="token-150-9" pos="word" morph="none" start_char="18496" end_char="18498">the</TOKEN>
<TOKEN id="token-150-10" pos="word" morph="none" start_char="18500" end_char="18506">vaccine</TOKEN>
<TOKEN id="token-150-11" pos="word" morph="none" start_char="18508" end_char="18516">candidate</TOKEN>
<TOKEN id="token-150-12" pos="word" morph="none" start_char="18518" end_char="18525">patented</TOKEN>
<TOKEN id="token-150-13" pos="word" morph="none" start_char="18527" end_char="18528">in</TOKEN>
<TOKEN id="token-150-14" pos="word" morph="none" start_char="18530" end_char="18533">2004</TOKEN>
<TOKEN id="token-150-15" pos="punct" morph="none" start_char="18534" end_char="18534">,</TOKEN>
<TOKEN id="token-150-16" pos="word" morph="none" start_char="18536" end_char="18538">are</TOKEN>
<TOKEN id="token-150-17" pos="word" morph="none" start_char="18540" end_char="18548">currently</TOKEN>
<TOKEN id="token-150-18" pos="word" morph="none" start_char="18550" end_char="18554">being</TOKEN>
<TOKEN id="token-150-19" pos="word" morph="none" start_char="18556" end_char="18558">put</TOKEN>
<TOKEN id="token-150-20" pos="word" morph="none" start_char="18560" end_char="18561">to</TOKEN>
<TOKEN id="token-150-21" pos="word" morph="none" start_char="18563" end_char="18565">use</TOKEN>
<TOKEN id="token-150-22" pos="word" morph="none" start_char="18567" end_char="18568">by</TOKEN>
<TOKEN id="token-150-23" pos="word" morph="none" start_char="18570" end_char="18572">the</TOKEN>
<TOKEN id="token-150-24" pos="word" morph="none" start_char="18574" end_char="18581">Institut</TOKEN>
<TOKEN id="token-150-25" pos="word" morph="none" start_char="18583" end_char="18591">Pasteur's</TOKEN>
<TOKEN id="token-150-26" pos="word" morph="none" start_char="18593" end_char="18602">scientists</TOKEN>
<TOKEN id="token-150-27" pos="word" morph="none" start_char="18604" end_char="18606">for</TOKEN>
<TOKEN id="token-150-28" pos="word" morph="none" start_char="18608" end_char="18610">the</TOKEN>
<TOKEN id="token-150-29" pos="word" morph="none" start_char="18612" end_char="18622">development</TOKEN>
<TOKEN id="token-150-30" pos="word" morph="none" start_char="18624" end_char="18625">of</TOKEN>
<TOKEN id="token-150-31" pos="word" morph="none" start_char="18627" end_char="18627">a</TOKEN>
<TOKEN id="token-150-32" pos="word" morph="none" start_char="18629" end_char="18637">potential</TOKEN>
<TOKEN id="token-150-33" pos="word" morph="none" start_char="18639" end_char="18645">vaccine</TOKEN>
<TOKEN id="token-150-34" pos="word" morph="none" start_char="18647" end_char="18649">for</TOKEN>
<TOKEN id="token-150-35" pos="unknown" morph="none" start_char="18651" end_char="18660">SARS-CoV-2</TOKEN>
<TOKEN id="token-150-36" pos="punct" morph="none" start_char="18662" end_char="18662">(</TOKEN>
<TOKEN id="token-150-37" pos="word" morph="none" start_char="18663" end_char="18673">responsible</TOKEN>
<TOKEN id="token-150-38" pos="word" morph="none" start_char="18675" end_char="18677">for</TOKEN>
<TOKEN id="token-150-39" pos="unknown" morph="none" start_char="18679" end_char="18686">Covid-19</TOKEN>
<TOKEN id="token-150-40" pos="punct" morph="none" start_char="18687" end_char="18688">),</TOKEN>
<TOKEN id="token-150-41" pos="word" morph="none" start_char="18690" end_char="18694">again</TOKEN>
<TOKEN id="token-150-42" pos="word" morph="none" start_char="18696" end_char="18700">using</TOKEN>
<TOKEN id="token-150-43" pos="word" morph="none" start_char="18702" end_char="18704">the</TOKEN>
<TOKEN id="token-150-44" pos="word" morph="none" start_char="18706" end_char="18712">measles</TOKEN>
<TOKEN id="token-150-45" pos="word" morph="none" start_char="18714" end_char="18721">platform</TOKEN>
<TOKEN id="token-150-46" pos="punct" morph="none" start_char="18722" end_char="18722">.</TOKEN>
</SEG>
<SEG id="segment-151" start_char="18727" end_char="18935">
<ORIGINAL_TEXT>In view of the various threats and violence following the broadcast of this video of March 2020, the Institut Pasteur was forced for the first time in its existence (since 1887) to file a defamation complaint.</ORIGINAL_TEXT>
<TOKEN id="token-151-0" pos="word" morph="none" start_char="18727" end_char="18728">In</TOKEN>
<TOKEN id="token-151-1" pos="word" morph="none" start_char="18730" end_char="18733">view</TOKEN>
<TOKEN id="token-151-2" pos="word" morph="none" start_char="18735" end_char="18736">of</TOKEN>
<TOKEN id="token-151-3" pos="word" morph="none" start_char="18738" end_char="18740">the</TOKEN>
<TOKEN id="token-151-4" pos="word" morph="none" start_char="18742" end_char="18748">various</TOKEN>
<TOKEN id="token-151-5" pos="word" morph="none" start_char="18750" end_char="18756">threats</TOKEN>
<TOKEN id="token-151-6" pos="word" morph="none" start_char="18758" end_char="18760">and</TOKEN>
<TOKEN id="token-151-7" pos="word" morph="none" start_char="18762" end_char="18769">violence</TOKEN>
<TOKEN id="token-151-8" pos="word" morph="none" start_char="18771" end_char="18779">following</TOKEN>
<TOKEN id="token-151-9" pos="word" morph="none" start_char="18781" end_char="18783">the</TOKEN>
<TOKEN id="token-151-10" pos="word" morph="none" start_char="18785" end_char="18793">broadcast</TOKEN>
<TOKEN id="token-151-11" pos="word" morph="none" start_char="18795" end_char="18796">of</TOKEN>
<TOKEN id="token-151-12" pos="word" morph="none" start_char="18798" end_char="18801">this</TOKEN>
<TOKEN id="token-151-13" pos="word" morph="none" start_char="18803" end_char="18807">video</TOKEN>
<TOKEN id="token-151-14" pos="word" morph="none" start_char="18809" end_char="18810">of</TOKEN>
<TOKEN id="token-151-15" pos="word" morph="none" start_char="18812" end_char="18816">March</TOKEN>
<TOKEN id="token-151-16" pos="word" morph="none" start_char="18818" end_char="18821">2020</TOKEN>
<TOKEN id="token-151-17" pos="punct" morph="none" start_char="18822" end_char="18822">,</TOKEN>
<TOKEN id="token-151-18" pos="word" morph="none" start_char="18824" end_char="18826">the</TOKEN>
<TOKEN id="token-151-19" pos="word" morph="none" start_char="18828" end_char="18835">Institut</TOKEN>
<TOKEN id="token-151-20" pos="word" morph="none" start_char="18837" end_char="18843">Pasteur</TOKEN>
<TOKEN id="token-151-21" pos="word" morph="none" start_char="18845" end_char="18847">was</TOKEN>
<TOKEN id="token-151-22" pos="word" morph="none" start_char="18849" end_char="18854">forced</TOKEN>
<TOKEN id="token-151-23" pos="word" morph="none" start_char="18856" end_char="18858">for</TOKEN>
<TOKEN id="token-151-24" pos="word" morph="none" start_char="18860" end_char="18862">the</TOKEN>
<TOKEN id="token-151-25" pos="word" morph="none" start_char="18864" end_char="18868">first</TOKEN>
<TOKEN id="token-151-26" pos="word" morph="none" start_char="18870" end_char="18873">time</TOKEN>
<TOKEN id="token-151-27" pos="word" morph="none" start_char="18875" end_char="18876">in</TOKEN>
<TOKEN id="token-151-28" pos="word" morph="none" start_char="18878" end_char="18880">its</TOKEN>
<TOKEN id="token-151-29" pos="word" morph="none" start_char="18882" end_char="18890">existence</TOKEN>
<TOKEN id="token-151-30" pos="punct" morph="none" start_char="18892" end_char="18892">(</TOKEN>
<TOKEN id="token-151-31" pos="word" morph="none" start_char="18893" end_char="18897">since</TOKEN>
<TOKEN id="token-151-32" pos="word" morph="none" start_char="18899" end_char="18902">1887</TOKEN>
<TOKEN id="token-151-33" pos="punct" morph="none" start_char="18903" end_char="18903">)</TOKEN>
<TOKEN id="token-151-34" pos="word" morph="none" start_char="18905" end_char="18906">to</TOKEN>
<TOKEN id="token-151-35" pos="word" morph="none" start_char="18908" end_char="18911">file</TOKEN>
<TOKEN id="token-151-36" pos="word" morph="none" start_char="18913" end_char="18913">a</TOKEN>
<TOKEN id="token-151-37" pos="word" morph="none" start_char="18915" end_char="18924">defamation</TOKEN>
<TOKEN id="token-151-38" pos="word" morph="none" start_char="18926" end_char="18934">complaint</TOKEN>
<TOKEN id="token-151-39" pos="punct" morph="none" start_char="18935" end_char="18935">.</TOKEN>
</SEG>
<SEG id="segment-152" start_char="18938" end_char="18974">
<ORIGINAL_TEXT>(paragraph added on November 4, 2020)</ORIGINAL_TEXT>
<TOKEN id="token-152-0" pos="punct" morph="none" start_char="18938" end_char="18938">(</TOKEN>
<TOKEN id="token-152-1" pos="word" morph="none" start_char="18939" end_char="18947">paragraph</TOKEN>
<TOKEN id="token-152-2" pos="word" morph="none" start_char="18949" end_char="18953">added</TOKEN>
<TOKEN id="token-152-3" pos="word" morph="none" start_char="18955" end_char="18956">on</TOKEN>
<TOKEN id="token-152-4" pos="word" morph="none" start_char="18958" end_char="18965">November</TOKEN>
<TOKEN id="token-152-5" pos="word" morph="none" start_char="18967" end_char="18967">4</TOKEN>
<TOKEN id="token-152-6" pos="punct" morph="none" start_char="18968" end_char="18968">,</TOKEN>
<TOKEN id="token-152-7" pos="word" morph="none" start_char="18970" end_char="18973">2020</TOKEN>
<TOKEN id="token-152-8" pos="punct" morph="none" start_char="18974" end_char="18974">)</TOKEN>
</SEG>
<SEG id="segment-153" start_char="18978" end_char="19085">
<ORIGINAL_TEXT>Read (in French) "Covid-19: Senlis Criminal Court condemns the author of a 'fake news' video for defamation"</ORIGINAL_TEXT>
<TOKEN id="token-153-0" pos="word" morph="none" start_char="18978" end_char="18981">Read</TOKEN>
<TOKEN id="token-153-1" pos="punct" morph="none" start_char="18983" end_char="18983">(</TOKEN>
<TOKEN id="token-153-2" pos="word" morph="none" start_char="18984" end_char="18985">in</TOKEN>
<TOKEN id="token-153-3" pos="word" morph="none" start_char="18987" end_char="18992">French</TOKEN>
<TOKEN id="token-153-4" pos="punct" morph="none" start_char="18993" end_char="18993">)</TOKEN>
<TOKEN id="token-153-5" pos="punct" morph="none" start_char="18995" end_char="18995">"</TOKEN>
<TOKEN id="token-153-6" pos="unknown" morph="none" start_char="18996" end_char="19003">Covid-19</TOKEN>
<TOKEN id="token-153-7" pos="punct" morph="none" start_char="19004" end_char="19004">:</TOKEN>
<TOKEN id="token-153-8" pos="word" morph="none" start_char="19006" end_char="19011">Senlis</TOKEN>
<TOKEN id="token-153-9" pos="word" morph="none" start_char="19013" end_char="19020">Criminal</TOKEN>
<TOKEN id="token-153-10" pos="word" morph="none" start_char="19022" end_char="19026">Court</TOKEN>
<TOKEN id="token-153-11" pos="word" morph="none" start_char="19028" end_char="19035">condemns</TOKEN>
<TOKEN id="token-153-12" pos="word" morph="none" start_char="19037" end_char="19039">the</TOKEN>
<TOKEN id="token-153-13" pos="word" morph="none" start_char="19041" end_char="19046">author</TOKEN>
<TOKEN id="token-153-14" pos="word" morph="none" start_char="19048" end_char="19049">of</TOKEN>
<TOKEN id="token-153-15" pos="word" morph="none" start_char="19051" end_char="19051">a</TOKEN>
<TOKEN id="token-153-16" pos="punct" morph="none" start_char="19053" end_char="19053">'</TOKEN>
<TOKEN id="token-153-17" pos="word" morph="none" start_char="19054" end_char="19057">fake</TOKEN>
<TOKEN id="token-153-18" pos="word" morph="none" start_char="19059" end_char="19062">news</TOKEN>
<TOKEN id="token-153-19" pos="punct" morph="none" start_char="19063" end_char="19063">'</TOKEN>
<TOKEN id="token-153-20" pos="word" morph="none" start_char="19065" end_char="19069">video</TOKEN>
<TOKEN id="token-153-21" pos="word" morph="none" start_char="19071" end_char="19073">for</TOKEN>
<TOKEN id="token-153-22" pos="word" morph="none" start_char="19075" end_char="19084">defamation</TOKEN>
<TOKEN id="token-153-23" pos="punct" morph="none" start_char="19085" end_char="19085">"</TOKEN>
</SEG>
<SEG id="segment-154" start_char="19088" end_char="19201">
<ORIGINAL_TEXT>NO, the Institut Pasteur does not have knowledge of the leak of a bacterial weapon intended for a third world war.</ORIGINAL_TEXT>
<TOKEN id="token-154-0" pos="word" morph="none" start_char="19088" end_char="19089">NO</TOKEN>
<TOKEN id="token-154-1" pos="punct" morph="none" start_char="19090" end_char="19090">,</TOKEN>
<TOKEN id="token-154-2" pos="word" morph="none" start_char="19092" end_char="19094">the</TOKEN>
<TOKEN id="token-154-3" pos="word" morph="none" start_char="19096" end_char="19103">Institut</TOKEN>
<TOKEN id="token-154-4" pos="word" morph="none" start_char="19105" end_char="19111">Pasteur</TOKEN>
<TOKEN id="token-154-5" pos="word" morph="none" start_char="19113" end_char="19116">does</TOKEN>
<TOKEN id="token-154-6" pos="word" morph="none" start_char="19118" end_char="19120">not</TOKEN>
<TOKEN id="token-154-7" pos="word" morph="none" start_char="19122" end_char="19125">have</TOKEN>
<TOKEN id="token-154-8" pos="word" morph="none" start_char="19127" end_char="19135">knowledge</TOKEN>
<TOKEN id="token-154-9" pos="word" morph="none" start_char="19137" end_char="19138">of</TOKEN>
<TOKEN id="token-154-10" pos="word" morph="none" start_char="19140" end_char="19142">the</TOKEN>
<TOKEN id="token-154-11" pos="word" morph="none" start_char="19144" end_char="19147">leak</TOKEN>
<TOKEN id="token-154-12" pos="word" morph="none" start_char="19149" end_char="19150">of</TOKEN>
<TOKEN id="token-154-13" pos="word" morph="none" start_char="19152" end_char="19152">a</TOKEN>
<TOKEN id="token-154-14" pos="word" morph="none" start_char="19154" end_char="19162">bacterial</TOKEN>
<TOKEN id="token-154-15" pos="word" morph="none" start_char="19164" end_char="19169">weapon</TOKEN>
<TOKEN id="token-154-16" pos="word" morph="none" start_char="19171" end_char="19178">intended</TOKEN>
<TOKEN id="token-154-17" pos="word" morph="none" start_char="19180" end_char="19182">for</TOKEN>
<TOKEN id="token-154-18" pos="word" morph="none" start_char="19184" end_char="19184">a</TOKEN>
<TOKEN id="token-154-19" pos="word" morph="none" start_char="19186" end_char="19190">third</TOKEN>
<TOKEN id="token-154-20" pos="word" morph="none" start_char="19192" end_char="19196">world</TOKEN>
<TOKEN id="token-154-21" pos="word" morph="none" start_char="19198" end_char="19200">war</TOKEN>
<TOKEN id="token-154-22" pos="punct" morph="none" start_char="19201" end_char="19201">.</TOKEN>
</SEG>
<SEG id="segment-155" start_char="19204" end_char="19226">
<ORIGINAL_TEXT>Text of March 20, 2020.</ORIGINAL_TEXT>
<TOKEN id="token-155-0" pos="word" morph="none" start_char="19204" end_char="19207">Text</TOKEN>
<TOKEN id="token-155-1" pos="word" morph="none" start_char="19209" end_char="19210">of</TOKEN>
<TOKEN id="token-155-2" pos="word" morph="none" start_char="19212" end_char="19216">March</TOKEN>
<TOKEN id="token-155-3" pos="word" morph="none" start_char="19218" end_char="19219">20</TOKEN>
<TOKEN id="token-155-4" pos="punct" morph="none" start_char="19220" end_char="19220">,</TOKEN>
<TOKEN id="token-155-5" pos="word" morph="none" start_char="19222" end_char="19225">2020</TOKEN>
<TOKEN id="token-155-6" pos="punct" morph="none" start_char="19226" end_char="19226">.</TOKEN>
</SEG>
<SEG id="segment-156" start_char="19231" end_char="19358">
<ORIGINAL_TEXT>An audio message disseminated widely on social networks evoked a "third world war" and the "leak" of a Chinese bacterial weapon.</ORIGINAL_TEXT>
<TOKEN id="token-156-0" pos="word" morph="none" start_char="19231" end_char="19232">An</TOKEN>
<TOKEN id="token-156-1" pos="word" morph="none" start_char="19234" end_char="19238">audio</TOKEN>
<TOKEN id="token-156-2" pos="word" morph="none" start_char="19240" end_char="19246">message</TOKEN>
<TOKEN id="token-156-3" pos="word" morph="none" start_char="19248" end_char="19259">disseminated</TOKEN>
<TOKEN id="token-156-4" pos="word" morph="none" start_char="19261" end_char="19266">widely</TOKEN>
<TOKEN id="token-156-5" pos="word" morph="none" start_char="19268" end_char="19269">on</TOKEN>
<TOKEN id="token-156-6" pos="word" morph="none" start_char="19271" end_char="19276">social</TOKEN>
<TOKEN id="token-156-7" pos="word" morph="none" start_char="19278" end_char="19285">networks</TOKEN>
<TOKEN id="token-156-8" pos="word" morph="none" start_char="19287" end_char="19292">evoked</TOKEN>
<TOKEN id="token-156-9" pos="word" morph="none" start_char="19294" end_char="19294">a</TOKEN>
<TOKEN id="token-156-10" pos="punct" morph="none" start_char="19296" end_char="19296">"</TOKEN>
<TOKEN id="token-156-11" pos="word" morph="none" start_char="19297" end_char="19301">third</TOKEN>
<TOKEN id="token-156-12" pos="word" morph="none" start_char="19303" end_char="19307">world</TOKEN>
<TOKEN id="token-156-13" pos="word" morph="none" start_char="19309" end_char="19311">war</TOKEN>
<TOKEN id="token-156-14" pos="punct" morph="none" start_char="19312" end_char="19312">"</TOKEN>
<TOKEN id="token-156-15" pos="word" morph="none" start_char="19314" end_char="19316">and</TOKEN>
<TOKEN id="token-156-16" pos="word" morph="none" start_char="19318" end_char="19320">the</TOKEN>
<TOKEN id="token-156-17" pos="punct" morph="none" start_char="19322" end_char="19322">"</TOKEN>
<TOKEN id="token-156-18" pos="word" morph="none" start_char="19323" end_char="19326">leak</TOKEN>
<TOKEN id="token-156-19" pos="punct" morph="none" start_char="19327" end_char="19327">"</TOKEN>
<TOKEN id="token-156-20" pos="word" morph="none" start_char="19329" end_char="19330">of</TOKEN>
<TOKEN id="token-156-21" pos="word" morph="none" start_char="19332" end_char="19332">a</TOKEN>
<TOKEN id="token-156-22" pos="word" morph="none" start_char="19334" end_char="19340">Chinese</TOKEN>
<TOKEN id="token-156-23" pos="word" morph="none" start_char="19342" end_char="19350">bacterial</TOKEN>
<TOKEN id="token-156-24" pos="word" morph="none" start_char="19352" end_char="19357">weapon</TOKEN>
<TOKEN id="token-156-25" pos="punct" morph="none" start_char="19358" end_char="19358">.</TOKEN>
</SEG>
<SEG id="segment-157" start_char="19360" end_char="19479">
<ORIGINAL_TEXT>The information is presented as originating from "the mother of my wife, her best friend works at the Institut Pasteur".</ORIGINAL_TEXT>
<TOKEN id="token-157-0" pos="word" morph="none" start_char="19360" end_char="19362">The</TOKEN>
<TOKEN id="token-157-1" pos="word" morph="none" start_char="19364" end_char="19374">information</TOKEN>
<TOKEN id="token-157-2" pos="word" morph="none" start_char="19376" end_char="19377">is</TOKEN>
<TOKEN id="token-157-3" pos="word" morph="none" start_char="19379" end_char="19387">presented</TOKEN>
<TOKEN id="token-157-4" pos="word" morph="none" start_char="19389" end_char="19390">as</TOKEN>
<TOKEN id="token-157-5" pos="word" morph="none" start_char="19392" end_char="19402">originating</TOKEN>
<TOKEN id="token-157-6" pos="word" morph="none" start_char="19404" end_char="19407">from</TOKEN>
<TOKEN id="token-157-7" pos="punct" morph="none" start_char="19409" end_char="19409">"</TOKEN>
<TOKEN id="token-157-8" pos="word" morph="none" start_char="19410" end_char="19412">the</TOKEN>
<TOKEN id="token-157-9" pos="word" morph="none" start_char="19414" end_char="19419">mother</TOKEN>
<TOKEN id="token-157-10" pos="word" morph="none" start_char="19421" end_char="19422">of</TOKEN>
<TOKEN id="token-157-11" pos="word" morph="none" start_char="19424" end_char="19425">my</TOKEN>
<TOKEN id="token-157-12" pos="word" morph="none" start_char="19427" end_char="19430">wife</TOKEN>
<TOKEN id="token-157-13" pos="punct" morph="none" start_char="19431" end_char="19431">,</TOKEN>
<TOKEN id="token-157-14" pos="word" morph="none" start_char="19433" end_char="19435">her</TOKEN>
<TOKEN id="token-157-15" pos="word" morph="none" start_char="19437" end_char="19440">best</TOKEN>
<TOKEN id="token-157-16" pos="word" morph="none" start_char="19442" end_char="19447">friend</TOKEN>
<TOKEN id="token-157-17" pos="word" morph="none" start_char="19449" end_char="19453">works</TOKEN>
<TOKEN id="token-157-18" pos="word" morph="none" start_char="19455" end_char="19456">at</TOKEN>
<TOKEN id="token-157-19" pos="word" morph="none" start_char="19458" end_char="19460">the</TOKEN>
<TOKEN id="token-157-20" pos="word" morph="none" start_char="19462" end_char="19469">Institut</TOKEN>
<TOKEN id="token-157-21" pos="word" morph="none" start_char="19471" end_char="19477">Pasteur</TOKEN>
<TOKEN id="token-157-22" pos="punct" morph="none" start_char="19478" end_char="19479">".</TOKEN>
</SEG>
<SEG id="segment-158" start_char="19481" end_char="19516">
<ORIGINAL_TEXT>This information is of course false.</ORIGINAL_TEXT>
<TOKEN id="token-158-0" pos="word" morph="none" start_char="19481" end_char="19484">This</TOKEN>
<TOKEN id="token-158-1" pos="word" morph="none" start_char="19486" end_char="19496">information</TOKEN>
<TOKEN id="token-158-2" pos="word" morph="none" start_char="19498" end_char="19499">is</TOKEN>
<TOKEN id="token-158-3" pos="word" morph="none" start_char="19501" end_char="19502">of</TOKEN>
<TOKEN id="token-158-4" pos="word" morph="none" start_char="19504" end_char="19509">course</TOKEN>
<TOKEN id="token-158-5" pos="word" morph="none" start_char="19511" end_char="19515">false</TOKEN>
<TOKEN id="token-158-6" pos="punct" morph="none" start_char="19516" end_char="19516">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>

<LCTL_TEXT lang="eng">
<DOC grammar="none" id="L0C049DZX" lang="eng" raw_text_char_length="10202" raw_text_md5="e54865f2cb9713f274b0648a612ab368" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="64" id="segment-0" start_char="1">
<ORIGINAL_TEXT>New evidence ties COVID-19 creation to research funded by Fauci?</ORIGINAL_TEXT>
<TOKEN end_char="3" id="token-0-0" morph="none" pos="word" start_char="1">New</TOKEN>
<TOKEN end_char="12" id="token-0-1" morph="none" pos="word" start_char="5">evidence</TOKEN>
<TOKEN end_char="17" id="token-0-2" morph="none" pos="word" start_char="14">ties</TOKEN>
<TOKEN end_char="26" id="token-0-3" morph="none" pos="unknown" start_char="19">COVID-19</TOKEN>
<TOKEN end_char="35" id="token-0-4" morph="none" pos="word" start_char="28">creation</TOKEN>
<TOKEN end_char="38" id="token-0-5" morph="none" pos="word" start_char="37">to</TOKEN>
<TOKEN end_char="47" id="token-0-6" morph="none" pos="word" start_char="40">research</TOKEN>
<TOKEN end_char="54" id="token-0-7" morph="none" pos="word" start_char="49">funded</TOKEN>
<TOKEN end_char="57" id="token-0-8" morph="none" pos="word" start_char="56">by</TOKEN>
<TOKEN end_char="63" id="token-0-9" morph="none" pos="word" start_char="59">Fauci</TOKEN>
<TOKEN end_char="64" id="token-0-10" morph="none" pos="punct" start_char="64">?</TOKEN>
</SEG>
<SEG end_char="70" id="segment-1" start_char="68">
<ORIGINAL_TEXT>Dr.</ORIGINAL_TEXT>
<TOKEN end_char="69" id="token-1-0" morph="none" pos="word" start_char="68">Dr</TOKEN>
<TOKEN end_char="70" id="token-1-1" morph="none" pos="punct" start_char="70">.</TOKEN>
<TRANSLATED_TEXT>dr.</TRANSLATED_TEXT><DETECTED_LANGUAGE>de</DETECTED_LANGUAGE></SEG>
<SEG end_char="345" id="segment-2" start_char="72">
<ORIGINAL_TEXT>Anthony Fauci, Director of National Institute of Allergy and Infectious Diseases, addresses his remarks at a roundtable on donating plasma Thursday, July 30, 2020, at the American Red Cross-National Headquarters in Washington, D.C. (Official White House photo by Tia Dufour)</ORIGINAL_TEXT>
<TOKEN end_char="78" id="token-2-0" morph="none" pos="word" start_char="72">Anthony</TOKEN>
<TOKEN end_char="84" id="token-2-1" morph="none" pos="word" start_char="80">Fauci</TOKEN>
<TOKEN end_char="85" id="token-2-2" morph="none" pos="punct" start_char="85">,</TOKEN>
<TOKEN end_char="94" id="token-2-3" morph="none" pos="word" start_char="87">Director</TOKEN>
<TOKEN end_char="97" id="token-2-4" morph="none" pos="word" start_char="96">of</TOKEN>
<TOKEN end_char="106" id="token-2-5" morph="none" pos="word" start_char="99">National</TOKEN>
<TOKEN end_char="116" id="token-2-6" morph="none" pos="word" start_char="108">Institute</TOKEN>
<TOKEN end_char="119" id="token-2-7" morph="none" pos="word" start_char="118">of</TOKEN>
<TOKEN end_char="127" id="token-2-8" morph="none" pos="word" start_char="121">Allergy</TOKEN>
<TOKEN end_char="131" id="token-2-9" morph="none" pos="word" start_char="129">and</TOKEN>
<TOKEN end_char="142" id="token-2-10" morph="none" pos="word" start_char="133">Infectious</TOKEN>
<TOKEN end_char="151" id="token-2-11" morph="none" pos="word" start_char="144">Diseases</TOKEN>
<TOKEN end_char="152" id="token-2-12" morph="none" pos="punct" start_char="152">,</TOKEN>
<TOKEN end_char="162" id="token-2-13" morph="none" pos="word" start_char="154">addresses</TOKEN>
<TOKEN end_char="166" id="token-2-14" morph="none" pos="word" start_char="164">his</TOKEN>
<TOKEN end_char="174" id="token-2-15" morph="none" pos="word" start_char="168">remarks</TOKEN>
<TOKEN end_char="177" id="token-2-16" morph="none" pos="word" start_char="176">at</TOKEN>
<TOKEN end_char="179" id="token-2-17" morph="none" pos="word" start_char="179">a</TOKEN>
<TOKEN end_char="190" id="token-2-18" morph="none" pos="word" start_char="181">roundtable</TOKEN>
<TOKEN end_char="193" id="token-2-19" morph="none" pos="word" start_char="192">on</TOKEN>
<TOKEN end_char="202" id="token-2-20" morph="none" pos="word" start_char="195">donating</TOKEN>
<TOKEN end_char="209" id="token-2-21" morph="none" pos="word" start_char="204">plasma</TOKEN>
<TOKEN end_char="218" id="token-2-22" morph="none" pos="word" start_char="211">Thursday</TOKEN>
<TOKEN end_char="219" id="token-2-23" morph="none" pos="punct" start_char="219">,</TOKEN>
<TOKEN end_char="224" id="token-2-24" morph="none" pos="word" start_char="221">July</TOKEN>
<TOKEN end_char="227" id="token-2-25" morph="none" pos="word" start_char="226">30</TOKEN>
<TOKEN end_char="228" id="token-2-26" morph="none" pos="punct" start_char="228">,</TOKEN>
<TOKEN end_char="233" id="token-2-27" morph="none" pos="word" start_char="230">2020</TOKEN>
<TOKEN end_char="234" id="token-2-28" morph="none" pos="punct" start_char="234">,</TOKEN>
<TOKEN end_char="237" id="token-2-29" morph="none" pos="word" start_char="236">at</TOKEN>
<TOKEN end_char="241" id="token-2-30" morph="none" pos="word" start_char="239">the</TOKEN>
<TOKEN end_char="250" id="token-2-31" morph="none" pos="word" start_char="243">American</TOKEN>
<TOKEN end_char="254" id="token-2-32" morph="none" pos="word" start_char="252">Red</TOKEN>
<TOKEN end_char="269" id="token-2-33" morph="none" pos="unknown" start_char="256">Cross-National</TOKEN>
<TOKEN end_char="282" id="token-2-34" morph="none" pos="word" start_char="271">Headquarters</TOKEN>
<TOKEN end_char="285" id="token-2-35" morph="none" pos="word" start_char="284">in</TOKEN>
<TOKEN end_char="296" id="token-2-36" morph="none" pos="word" start_char="287">Washington</TOKEN>
<TOKEN end_char="297" id="token-2-37" morph="none" pos="punct" start_char="297">,</TOKEN>
<TOKEN end_char="301" id="token-2-38" morph="none" pos="unknown" start_char="299">D.C</TOKEN>
<TOKEN end_char="302" id="token-2-39" morph="none" pos="punct" start_char="302">.</TOKEN>
<TOKEN end_char="304" id="token-2-40" morph="none" pos="punct" start_char="304">(</TOKEN>
<TOKEN end_char="312" id="token-2-41" morph="none" pos="word" start_char="305">Official</TOKEN>
<TOKEN end_char="318" id="token-2-42" morph="none" pos="word" start_char="314">White</TOKEN>
<TOKEN end_char="324" id="token-2-43" morph="none" pos="word" start_char="320">House</TOKEN>
<TOKEN end_char="330" id="token-2-44" morph="none" pos="word" start_char="326">photo</TOKEN>
<TOKEN end_char="333" id="token-2-45" morph="none" pos="word" start_char="332">by</TOKEN>
<TOKEN end_char="337" id="token-2-46" morph="none" pos="word" start_char="335">Tia</TOKEN>
<TOKEN end_char="344" id="token-2-47" morph="none" pos="word" start_char="339">Dufour</TOKEN>
<TOKEN end_char="345" id="token-2-48" morph="none" pos="punct" start_char="345">)</TOKEN>
</SEG>
<SEG end_char="359" id="segment-3" start_char="348">
<ORIGINAL_TEXT>UPDATED Feb.</ORIGINAL_TEXT>
<TOKEN end_char="354" id="token-3-0" morph="none" pos="word" start_char="348">UPDATED</TOKEN>
<TOKEN end_char="358" id="token-3-1" morph="none" pos="word" start_char="356">Feb</TOKEN>
<TOKEN end_char="359" id="token-3-2" morph="none" pos="punct" start_char="359">.</TOKEN>
<TRANSLATED_TEXT>FEBRUARY</TRANSLATED_TEXT><DETECTED_LANGUAGE>de</DETECTED_LANGUAGE></SEG>
<SEG end_char="509" id="segment-4" start_char="361">
<ORIGINAL_TEXT>8, 2021: A fact check by USA Today from March and April 2020 indicated the coronavirus is not man-made or engineered, but its origin remains unclear.</ORIGINAL_TEXT>
<TOKEN end_char="361" id="token-4-0" morph="none" pos="word" start_char="361">8</TOKEN>
<TOKEN end_char="362" id="token-4-1" morph="none" pos="punct" start_char="362">,</TOKEN>
<TOKEN end_char="367" id="token-4-2" morph="none" pos="word" start_char="364">2021</TOKEN>
<TOKEN end_char="368" id="token-4-3" morph="none" pos="punct" start_char="368">:</TOKEN>
<TOKEN end_char="370" id="token-4-4" morph="none" pos="word" start_char="370">A</TOKEN>
<TOKEN end_char="375" id="token-4-5" morph="none" pos="word" start_char="372">fact</TOKEN>
<TOKEN end_char="381" id="token-4-6" morph="none" pos="word" start_char="377">check</TOKEN>
<TOKEN end_char="384" id="token-4-7" morph="none" pos="word" start_char="383">by</TOKEN>
<TOKEN end_char="388" id="token-4-8" morph="none" pos="word" start_char="386">USA</TOKEN>
<TOKEN end_char="394" id="token-4-9" morph="none" pos="word" start_char="390">Today</TOKEN>
<TOKEN end_char="399" id="token-4-10" morph="none" pos="word" start_char="396">from</TOKEN>
<TOKEN end_char="405" id="token-4-11" morph="none" pos="word" start_char="401">March</TOKEN>
<TOKEN end_char="409" id="token-4-12" morph="none" pos="word" start_char="407">and</TOKEN>
<TOKEN end_char="415" id="token-4-13" morph="none" pos="word" start_char="411">April</TOKEN>
<TOKEN end_char="420" id="token-4-14" morph="none" pos="word" start_char="417">2020</TOKEN>
<TOKEN end_char="430" id="token-4-15" morph="none" pos="word" start_char="422">indicated</TOKEN>
<TOKEN end_char="434" id="token-4-16" morph="none" pos="word" start_char="432">the</TOKEN>
<TOKEN end_char="446" id="token-4-17" morph="none" pos="word" start_char="436">coronavirus</TOKEN>
<TOKEN end_char="449" id="token-4-18" morph="none" pos="word" start_char="448">is</TOKEN>
<TOKEN end_char="453" id="token-4-19" morph="none" pos="word" start_char="451">not</TOKEN>
<TOKEN end_char="462" id="token-4-20" morph="none" pos="unknown" start_char="455">man-made</TOKEN>
<TOKEN end_char="465" id="token-4-21" morph="none" pos="word" start_char="464">or</TOKEN>
<TOKEN end_char="476" id="token-4-22" morph="none" pos="word" start_char="467">engineered</TOKEN>
<TOKEN end_char="477" id="token-4-23" morph="none" pos="punct" start_char="477">,</TOKEN>
<TOKEN end_char="481" id="token-4-24" morph="none" pos="word" start_char="479">but</TOKEN>
<TOKEN end_char="485" id="token-4-25" morph="none" pos="word" start_char="483">its</TOKEN>
<TOKEN end_char="492" id="token-4-26" morph="none" pos="word" start_char="487">origin</TOKEN>
<TOKEN end_char="500" id="token-4-27" morph="none" pos="word" start_char="494">remains</TOKEN>
<TOKEN end_char="508" id="token-4-28" morph="none" pos="word" start_char="502">unclear</TOKEN>
<TOKEN end_char="509" id="token-4-29" morph="none" pos="punct" start_char="509">.</TOKEN>
</SEG>
<SEG end_char="605" id="segment-5" start_char="511">
<ORIGINAL_TEXT>It said, "There is no evidence to suggest that the virus was created in a Chinese laboratory. "</ORIGINAL_TEXT>
<TOKEN end_char="512" id="token-5-0" morph="none" pos="word" start_char="511">It</TOKEN>
<TOKEN end_char="517" id="token-5-1" morph="none" pos="word" start_char="514">said</TOKEN>
<TOKEN end_char="518" id="token-5-2" morph="none" pos="punct" start_char="518">,</TOKEN>
<TOKEN end_char="520" id="token-5-3" morph="none" pos="punct" start_char="520">"</TOKEN>
<TOKEN end_char="525" id="token-5-4" morph="none" pos="word" start_char="521">There</TOKEN>
<TOKEN end_char="528" id="token-5-5" morph="none" pos="word" start_char="527">is</TOKEN>
<TOKEN end_char="531" id="token-5-6" morph="none" pos="word" start_char="530">no</TOKEN>
<TOKEN end_char="540" id="token-5-7" morph="none" pos="word" start_char="533">evidence</TOKEN>
<TOKEN end_char="543" id="token-5-8" morph="none" pos="word" start_char="542">to</TOKEN>
<TOKEN end_char="551" id="token-5-9" morph="none" pos="word" start_char="545">suggest</TOKEN>
<TOKEN end_char="556" id="token-5-10" morph="none" pos="word" start_char="553">that</TOKEN>
<TOKEN end_char="560" id="token-5-11" morph="none" pos="word" start_char="558">the</TOKEN>
<TOKEN end_char="566" id="token-5-12" morph="none" pos="word" start_char="562">virus</TOKEN>
<TOKEN end_char="570" id="token-5-13" morph="none" pos="word" start_char="568">was</TOKEN>
<TOKEN end_char="578" id="token-5-14" morph="none" pos="word" start_char="572">created</TOKEN>
<TOKEN end_char="581" id="token-5-15" morph="none" pos="word" start_char="580">in</TOKEN>
<TOKEN end_char="583" id="token-5-16" morph="none" pos="word" start_char="583">a</TOKEN>
<TOKEN end_char="591" id="token-5-17" morph="none" pos="word" start_char="585">Chinese</TOKEN>
<TOKEN end_char="602" id="token-5-18" morph="none" pos="word" start_char="593">laboratory</TOKEN>
<TOKEN end_char="603" id="token-5-19" morph="none" pos="punct" start_char="603">.</TOKEN>
<TOKEN end_char="605" id="token-5-20" morph="none" pos="punct" start_char="605">"</TOKEN>
</SEG>
<SEG end_char="702" id="segment-6" start_char="608">
<ORIGINAL_TEXT>It is probable, likely, that the virus is of animal origin," WHO spokeswoman Fadela Chaib said.</ORIGINAL_TEXT>
<TOKEN end_char="609" id="token-6-0" morph="none" pos="word" start_char="608">It</TOKEN>
<TOKEN end_char="612" id="token-6-1" morph="none" pos="word" start_char="611">is</TOKEN>
<TOKEN end_char="621" id="token-6-2" morph="none" pos="word" start_char="614">probable</TOKEN>
<TOKEN end_char="622" id="token-6-3" morph="none" pos="punct" start_char="622">,</TOKEN>
<TOKEN end_char="629" id="token-6-4" morph="none" pos="word" start_char="624">likely</TOKEN>
<TOKEN end_char="630" id="token-6-5" morph="none" pos="punct" start_char="630">,</TOKEN>
<TOKEN end_char="635" id="token-6-6" morph="none" pos="word" start_char="632">that</TOKEN>
<TOKEN end_char="639" id="token-6-7" morph="none" pos="word" start_char="637">the</TOKEN>
<TOKEN end_char="645" id="token-6-8" morph="none" pos="word" start_char="641">virus</TOKEN>
<TOKEN end_char="648" id="token-6-9" morph="none" pos="word" start_char="647">is</TOKEN>
<TOKEN end_char="651" id="token-6-10" morph="none" pos="word" start_char="650">of</TOKEN>
<TOKEN end_char="658" id="token-6-11" morph="none" pos="word" start_char="653">animal</TOKEN>
<TOKEN end_char="665" id="token-6-12" morph="none" pos="word" start_char="660">origin</TOKEN>
<TOKEN end_char="667" id="token-6-13" morph="none" pos="punct" start_char="666">,"</TOKEN>
<TOKEN end_char="671" id="token-6-14" morph="none" pos="word" start_char="669">WHO</TOKEN>
<TOKEN end_char="683" id="token-6-15" morph="none" pos="word" start_char="673">spokeswoman</TOKEN>
<TOKEN end_char="690" id="token-6-16" morph="none" pos="word" start_char="685">Fadela</TOKEN>
<TOKEN end_char="696" id="token-6-17" morph="none" pos="word" start_char="692">Chaib</TOKEN>
<TOKEN end_char="701" id="token-6-18" morph="none" pos="word" start_char="698">said</TOKEN>
<TOKEN end_char="702" id="token-6-19" morph="none" pos="punct" start_char="702">.</TOKEN>
</SEG>
<SEG end_char="804" id="segment-7" start_char="705">
<ORIGINAL_TEXT>The Scripps Research Institute released a study that rejects the notion that the virus was man-made.</ORIGINAL_TEXT>
<TOKEN end_char="707" id="token-7-0" morph="none" pos="word" start_char="705">The</TOKEN>
<TOKEN end_char="715" id="token-7-1" morph="none" pos="word" start_char="709">Scripps</TOKEN>
<TOKEN end_char="724" id="token-7-2" morph="none" pos="word" start_char="717">Research</TOKEN>
<TOKEN end_char="734" id="token-7-3" morph="none" pos="word" start_char="726">Institute</TOKEN>
<TOKEN end_char="743" id="token-7-4" morph="none" pos="word" start_char="736">released</TOKEN>
<TOKEN end_char="745" id="token-7-5" morph="none" pos="word" start_char="745">a</TOKEN>
<TOKEN end_char="751" id="token-7-6" morph="none" pos="word" start_char="747">study</TOKEN>
<TOKEN end_char="756" id="token-7-7" morph="none" pos="word" start_char="753">that</TOKEN>
<TOKEN end_char="764" id="token-7-8" morph="none" pos="word" start_char="758">rejects</TOKEN>
<TOKEN end_char="768" id="token-7-9" morph="none" pos="word" start_char="766">the</TOKEN>
<TOKEN end_char="775" id="token-7-10" morph="none" pos="word" start_char="770">notion</TOKEN>
<TOKEN end_char="780" id="token-7-11" morph="none" pos="word" start_char="777">that</TOKEN>
<TOKEN end_char="784" id="token-7-12" morph="none" pos="word" start_char="782">the</TOKEN>
<TOKEN end_char="790" id="token-7-13" morph="none" pos="word" start_char="786">virus</TOKEN>
<TOKEN end_char="794" id="token-7-14" morph="none" pos="word" start_char="792">was</TOKEN>
<TOKEN end_char="803" id="token-7-15" morph="none" pos="unknown" start_char="796">man-made</TOKEN>
<TOKEN end_char="804" id="token-7-16" morph="none" pos="punct" start_char="804">.</TOKEN>
</SEG>
<SEG end_char="963" id="segment-8" start_char="806">
<ORIGINAL_TEXT>Researchers concluded that if the virus were engineered, its genome sequence would more closely resemble earlier and more serious versions of the coronavirus.</ORIGINAL_TEXT>
<TOKEN end_char="816" id="token-8-0" morph="none" pos="word" start_char="806">Researchers</TOKEN>
<TOKEN end_char="826" id="token-8-1" morph="none" pos="word" start_char="818">concluded</TOKEN>
<TOKEN end_char="831" id="token-8-2" morph="none" pos="word" start_char="828">that</TOKEN>
<TOKEN end_char="834" id="token-8-3" morph="none" pos="word" start_char="833">if</TOKEN>
<TOKEN end_char="838" id="token-8-4" morph="none" pos="word" start_char="836">the</TOKEN>
<TOKEN end_char="844" id="token-8-5" morph="none" pos="word" start_char="840">virus</TOKEN>
<TOKEN end_char="849" id="token-8-6" morph="none" pos="word" start_char="846">were</TOKEN>
<TOKEN end_char="860" id="token-8-7" morph="none" pos="word" start_char="851">engineered</TOKEN>
<TOKEN end_char="861" id="token-8-8" morph="none" pos="punct" start_char="861">,</TOKEN>
<TOKEN end_char="865" id="token-8-9" morph="none" pos="word" start_char="863">its</TOKEN>
<TOKEN end_char="872" id="token-8-10" morph="none" pos="word" start_char="867">genome</TOKEN>
<TOKEN end_char="881" id="token-8-11" morph="none" pos="word" start_char="874">sequence</TOKEN>
<TOKEN end_char="887" id="token-8-12" morph="none" pos="word" start_char="883">would</TOKEN>
<TOKEN end_char="892" id="token-8-13" morph="none" pos="word" start_char="889">more</TOKEN>
<TOKEN end_char="900" id="token-8-14" morph="none" pos="word" start_char="894">closely</TOKEN>
<TOKEN end_char="909" id="token-8-15" morph="none" pos="word" start_char="902">resemble</TOKEN>
<TOKEN end_char="917" id="token-8-16" morph="none" pos="word" start_char="911">earlier</TOKEN>
<TOKEN end_char="921" id="token-8-17" morph="none" pos="word" start_char="919">and</TOKEN>
<TOKEN end_char="926" id="token-8-18" morph="none" pos="word" start_char="923">more</TOKEN>
<TOKEN end_char="934" id="token-8-19" morph="none" pos="word" start_char="928">serious</TOKEN>
<TOKEN end_char="943" id="token-8-20" morph="none" pos="word" start_char="936">versions</TOKEN>
<TOKEN end_char="946" id="token-8-21" morph="none" pos="word" start_char="945">of</TOKEN>
<TOKEN end_char="950" id="token-8-22" morph="none" pos="word" start_char="948">the</TOKEN>
<TOKEN end_char="962" id="token-8-23" morph="none" pos="word" start_char="952">coronavirus</TOKEN>
<TOKEN end_char="963" id="token-8-24" morph="none" pos="punct" start_char="963">.</TOKEN>
</SEG>
<SEG end_char="993" id="segment-9" start_char="966">
<ORIGINAL_TEXT>FactCheck.org stated on Feb.</ORIGINAL_TEXT>
<TOKEN end_char="978" id="token-9-0" morph="none" pos="unknown" start_char="966">FactCheck.org</TOKEN>
<TOKEN end_char="985" id="token-9-1" morph="none" pos="word" start_char="980">stated</TOKEN>
<TOKEN end_char="988" id="token-9-2" morph="none" pos="word" start_char="987">on</TOKEN>
<TOKEN end_char="992" id="token-9-3" morph="none" pos="word" start_char="990">Feb</TOKEN>
<TOKEN end_char="993" id="token-9-4" morph="none" pos="punct" start_char="993">.</TOKEN>
</SEG>
<SEG end_char="1111" id="segment-10" start_char="995">
<ORIGINAL_TEXT>7, 2020, "There is no evidence that the new virus was bioengineered, and every indication it came from an animal. ...</ORIGINAL_TEXT>
<TOKEN end_char="995" id="token-10-0" morph="none" pos="word" start_char="995">7</TOKEN>
<TOKEN end_char="996" id="token-10-1" morph="none" pos="punct" start_char="996">,</TOKEN>
<TOKEN end_char="1001" id="token-10-2" morph="none" pos="word" start_char="998">2020</TOKEN>
<TOKEN end_char="1002" id="token-10-3" morph="none" pos="punct" start_char="1002">,</TOKEN>
<TOKEN end_char="1004" id="token-10-4" morph="none" pos="punct" start_char="1004">"</TOKEN>
<TOKEN end_char="1009" id="token-10-5" morph="none" pos="word" start_char="1005">There</TOKEN>
<TOKEN end_char="1012" id="token-10-6" morph="none" pos="word" start_char="1011">is</TOKEN>
<TOKEN end_char="1015" id="token-10-7" morph="none" pos="word" start_char="1014">no</TOKEN>
<TOKEN end_char="1024" id="token-10-8" morph="none" pos="word" start_char="1017">evidence</TOKEN>
<TOKEN end_char="1029" id="token-10-9" morph="none" pos="word" start_char="1026">that</TOKEN>
<TOKEN end_char="1033" id="token-10-10" morph="none" pos="word" start_char="1031">the</TOKEN>
<TOKEN end_char="1037" id="token-10-11" morph="none" pos="word" start_char="1035">new</TOKEN>
<TOKEN end_char="1043" id="token-10-12" morph="none" pos="word" start_char="1039">virus</TOKEN>
<TOKEN end_char="1047" id="token-10-13" morph="none" pos="word" start_char="1045">was</TOKEN>
<TOKEN end_char="1061" id="token-10-14" morph="none" pos="word" start_char="1049">bioengineered</TOKEN>
<TOKEN end_char="1062" id="token-10-15" morph="none" pos="punct" start_char="1062">,</TOKEN>
<TOKEN end_char="1066" id="token-10-16" morph="none" pos="word" start_char="1064">and</TOKEN>
<TOKEN end_char="1072" id="token-10-17" morph="none" pos="word" start_char="1068">every</TOKEN>
<TOKEN end_char="1083" id="token-10-18" morph="none" pos="word" start_char="1074">indication</TOKEN>
<TOKEN end_char="1086" id="token-10-19" morph="none" pos="word" start_char="1085">it</TOKEN>
<TOKEN end_char="1091" id="token-10-20" morph="none" pos="word" start_char="1088">came</TOKEN>
<TOKEN end_char="1096" id="token-10-21" morph="none" pos="word" start_char="1093">from</TOKEN>
<TOKEN end_char="1099" id="token-10-22" morph="none" pos="word" start_char="1098">an</TOKEN>
<TOKEN end_char="1106" id="token-10-23" morph="none" pos="word" start_char="1101">animal</TOKEN>
<TOKEN end_char="1107" id="token-10-24" morph="none" pos="punct" start_char="1107">.</TOKEN>
<TOKEN end_char="1111" id="token-10-25" morph="none" pos="punct" start_char="1109">...</TOKEN>
</SEG>
<SEG end_char="1175" id="segment-11" start_char="1113">
<ORIGINAL_TEXT>All lines of evidence point to the virus coming from an animal.</ORIGINAL_TEXT>
<TOKEN end_char="1115" id="token-11-0" morph="none" pos="word" start_char="1113">All</TOKEN>
<TOKEN end_char="1121" id="token-11-1" morph="none" pos="word" start_char="1117">lines</TOKEN>
<TOKEN end_char="1124" id="token-11-2" morph="none" pos="word" start_char="1123">of</TOKEN>
<TOKEN end_char="1133" id="token-11-3" morph="none" pos="word" start_char="1126">evidence</TOKEN>
<TOKEN end_char="1139" id="token-11-4" morph="none" pos="word" start_char="1135">point</TOKEN>
<TOKEN end_char="1142" id="token-11-5" morph="none" pos="word" start_char="1141">to</TOKEN>
<TOKEN end_char="1146" id="token-11-6" morph="none" pos="word" start_char="1144">the</TOKEN>
<TOKEN end_char="1152" id="token-11-7" morph="none" pos="word" start_char="1148">virus</TOKEN>
<TOKEN end_char="1159" id="token-11-8" morph="none" pos="word" start_char="1154">coming</TOKEN>
<TOKEN end_char="1164" id="token-11-9" morph="none" pos="word" start_char="1161">from</TOKEN>
<TOKEN end_char="1167" id="token-11-10" morph="none" pos="word" start_char="1166">an</TOKEN>
<TOKEN end_char="1174" id="token-11-11" morph="none" pos="word" start_char="1169">animal</TOKEN>
<TOKEN end_char="1175" id="token-11-12" morph="none" pos="punct" start_char="1175">.</TOKEN>
</SEG>
<SEG end_char="1380" id="segment-12" start_char="1177">
<ORIGINAL_TEXT>That's consistent with what scientists have learned about the ecology of coronaviruses in the last 20 years," according to Timothy Sheahan, a virologist at the University of North Carolina at Chapel Hill.</ORIGINAL_TEXT>
<TOKEN end_char="1182" id="token-12-0" morph="none" pos="word" start_char="1177">That's</TOKEN>
<TOKEN end_char="1193" id="token-12-1" morph="none" pos="word" start_char="1184">consistent</TOKEN>
<TOKEN end_char="1198" id="token-12-2" morph="none" pos="word" start_char="1195">with</TOKEN>
<TOKEN end_char="1203" id="token-12-3" morph="none" pos="word" start_char="1200">what</TOKEN>
<TOKEN end_char="1214" id="token-12-4" morph="none" pos="word" start_char="1205">scientists</TOKEN>
<TOKEN end_char="1219" id="token-12-5" morph="none" pos="word" start_char="1216">have</TOKEN>
<TOKEN end_char="1227" id="token-12-6" morph="none" pos="word" start_char="1221">learned</TOKEN>
<TOKEN end_char="1233" id="token-12-7" morph="none" pos="word" start_char="1229">about</TOKEN>
<TOKEN end_char="1237" id="token-12-8" morph="none" pos="word" start_char="1235">the</TOKEN>
<TOKEN end_char="1245" id="token-12-9" morph="none" pos="word" start_char="1239">ecology</TOKEN>
<TOKEN end_char="1248" id="token-12-10" morph="none" pos="word" start_char="1247">of</TOKEN>
<TOKEN end_char="1262" id="token-12-11" morph="none" pos="word" start_char="1250">coronaviruses</TOKEN>
<TOKEN end_char="1265" id="token-12-12" morph="none" pos="word" start_char="1264">in</TOKEN>
<TOKEN end_char="1269" id="token-12-13" morph="none" pos="word" start_char="1267">the</TOKEN>
<TOKEN end_char="1274" id="token-12-14" morph="none" pos="word" start_char="1271">last</TOKEN>
<TOKEN end_char="1277" id="token-12-15" morph="none" pos="word" start_char="1276">20</TOKEN>
<TOKEN end_char="1283" id="token-12-16" morph="none" pos="word" start_char="1279">years</TOKEN>
<TOKEN end_char="1285" id="token-12-17" morph="none" pos="punct" start_char="1284">,"</TOKEN>
<TOKEN end_char="1295" id="token-12-18" morph="none" pos="word" start_char="1287">according</TOKEN>
<TOKEN end_char="1298" id="token-12-19" morph="none" pos="word" start_char="1297">to</TOKEN>
<TOKEN end_char="1306" id="token-12-20" morph="none" pos="word" start_char="1300">Timothy</TOKEN>
<TOKEN end_char="1314" id="token-12-21" morph="none" pos="word" start_char="1308">Sheahan</TOKEN>
<TOKEN end_char="1315" id="token-12-22" morph="none" pos="punct" start_char="1315">,</TOKEN>
<TOKEN end_char="1317" id="token-12-23" morph="none" pos="word" start_char="1317">a</TOKEN>
<TOKEN end_char="1328" id="token-12-24" morph="none" pos="word" start_char="1319">virologist</TOKEN>
<TOKEN end_char="1331" id="token-12-25" morph="none" pos="word" start_char="1330">at</TOKEN>
<TOKEN end_char="1335" id="token-12-26" morph="none" pos="word" start_char="1333">the</TOKEN>
<TOKEN end_char="1346" id="token-12-27" morph="none" pos="word" start_char="1337">University</TOKEN>
<TOKEN end_char="1349" id="token-12-28" morph="none" pos="word" start_char="1348">of</TOKEN>
<TOKEN end_char="1355" id="token-12-29" morph="none" pos="word" start_char="1351">North</TOKEN>
<TOKEN end_char="1364" id="token-12-30" morph="none" pos="word" start_char="1357">Carolina</TOKEN>
<TOKEN end_char="1367" id="token-12-31" morph="none" pos="word" start_char="1366">at</TOKEN>
<TOKEN end_char="1374" id="token-12-32" morph="none" pos="word" start_char="1369">Chapel</TOKEN>
<TOKEN end_char="1379" id="token-12-33" morph="none" pos="word" start_char="1376">Hill</TOKEN>
<TOKEN end_char="1380" id="token-12-34" morph="none" pos="punct" start_char="1380">.</TOKEN>
</SEG>
<SEG end_char="1460" id="segment-13" start_char="1382">
<ORIGINAL_TEXT>It fits with the fact that the virus shares 96% of its genome with a bat virus.</ORIGINAL_TEXT>
<TOKEN end_char="1383" id="token-13-0" morph="none" pos="word" start_char="1382">It</TOKEN>
<TOKEN end_char="1388" id="token-13-1" morph="none" pos="word" start_char="1385">fits</TOKEN>
<TOKEN end_char="1393" id="token-13-2" morph="none" pos="word" start_char="1390">with</TOKEN>
<TOKEN end_char="1397" id="token-13-3" morph="none" pos="word" start_char="1395">the</TOKEN>
<TOKEN end_char="1402" id="token-13-4" morph="none" pos="word" start_char="1399">fact</TOKEN>
<TOKEN end_char="1407" id="token-13-5" morph="none" pos="word" start_char="1404">that</TOKEN>
<TOKEN end_char="1411" id="token-13-6" morph="none" pos="word" start_char="1409">the</TOKEN>
<TOKEN end_char="1417" id="token-13-7" morph="none" pos="word" start_char="1413">virus</TOKEN>
<TOKEN end_char="1424" id="token-13-8" morph="none" pos="word" start_char="1419">shares</TOKEN>
<TOKEN end_char="1427" id="token-13-9" morph="none" pos="word" start_char="1426">96</TOKEN>
<TOKEN end_char="1428" id="token-13-10" morph="none" pos="punct" start_char="1428">%</TOKEN>
<TOKEN end_char="1431" id="token-13-11" morph="none" pos="word" start_char="1430">of</TOKEN>
<TOKEN end_char="1435" id="token-13-12" morph="none" pos="word" start_char="1433">its</TOKEN>
<TOKEN end_char="1442" id="token-13-13" morph="none" pos="word" start_char="1437">genome</TOKEN>
<TOKEN end_char="1447" id="token-13-14" morph="none" pos="word" start_char="1444">with</TOKEN>
<TOKEN end_char="1449" id="token-13-15" morph="none" pos="word" start_char="1449">a</TOKEN>
<TOKEN end_char="1453" id="token-13-16" morph="none" pos="word" start_char="1451">bat</TOKEN>
<TOKEN end_char="1459" id="token-13-17" morph="none" pos="word" start_char="1455">virus</TOKEN>
<TOKEN end_char="1460" id="token-13-18" morph="none" pos="punct" start_char="1460">.</TOKEN>
</SEG>
<SEG end_char="1557" id="segment-14" start_char="1463">
<ORIGINAL_TEXT>"The genetic data is pointing to this virus coming from a bat reservoir," he said, "not a lab."</ORIGINAL_TEXT>
<TOKEN end_char="1463" id="token-14-0" morph="none" pos="punct" start_char="1463">"</TOKEN>
<TOKEN end_char="1466" id="token-14-1" morph="none" pos="word" start_char="1464">The</TOKEN>
<TOKEN end_char="1474" id="token-14-2" morph="none" pos="word" start_char="1468">genetic</TOKEN>
<TOKEN end_char="1479" id="token-14-3" morph="none" pos="word" start_char="1476">data</TOKEN>
<TOKEN end_char="1482" id="token-14-4" morph="none" pos="word" start_char="1481">is</TOKEN>
<TOKEN end_char="1491" id="token-14-5" morph="none" pos="word" start_char="1484">pointing</TOKEN>
<TOKEN end_char="1494" id="token-14-6" morph="none" pos="word" start_char="1493">to</TOKEN>
<TOKEN end_char="1499" id="token-14-7" morph="none" pos="word" start_char="1496">this</TOKEN>
<TOKEN end_char="1505" id="token-14-8" morph="none" pos="word" start_char="1501">virus</TOKEN>
<TOKEN end_char="1512" id="token-14-9" morph="none" pos="word" start_char="1507">coming</TOKEN>
<TOKEN end_char="1517" id="token-14-10" morph="none" pos="word" start_char="1514">from</TOKEN>
<TOKEN end_char="1519" id="token-14-11" morph="none" pos="word" start_char="1519">a</TOKEN>
<TOKEN end_char="1523" id="token-14-12" morph="none" pos="word" start_char="1521">bat</TOKEN>
<TOKEN end_char="1533" id="token-14-13" morph="none" pos="word" start_char="1525">reservoir</TOKEN>
<TOKEN end_char="1535" id="token-14-14" morph="none" pos="punct" start_char="1534">,"</TOKEN>
<TOKEN end_char="1538" id="token-14-15" morph="none" pos="word" start_char="1537">he</TOKEN>
<TOKEN end_char="1543" id="token-14-16" morph="none" pos="word" start_char="1540">said</TOKEN>
<TOKEN end_char="1544" id="token-14-17" morph="none" pos="punct" start_char="1544">,</TOKEN>
<TOKEN end_char="1546" id="token-14-18" morph="none" pos="punct" start_char="1546">"</TOKEN>
<TOKEN end_char="1549" id="token-14-19" morph="none" pos="word" start_char="1547">not</TOKEN>
<TOKEN end_char="1551" id="token-14-20" morph="none" pos="word" start_char="1551">a</TOKEN>
<TOKEN end_char="1555" id="token-14-21" morph="none" pos="word" start_char="1553">lab</TOKEN>
<TOKEN end_char="1557" id="token-14-22" morph="none" pos="punct" start_char="1556">."</TOKEN>
</SEG>
<SEG end_char="1575" id="segment-15" start_char="1561">
<ORIGINAL_TEXT>ORIGINAL STORY:</ORIGINAL_TEXT>
<TOKEN end_char="1568" id="token-15-0" morph="none" pos="word" start_char="1561">ORIGINAL</TOKEN>
<TOKEN end_char="1574" id="token-15-1" morph="none" pos="word" start_char="1570">STORY</TOKEN>
<TOKEN end_char="1575" id="token-15-2" morph="none" pos="punct" start_char="1575">:</TOKEN>
</SEG>
<SEG end_char="1866" id="segment-16" start_char="1578">
<ORIGINAL_TEXT>China, the World Health Organization and the U.S. National Institutes of Health have dimissed the theory that the virus causing the global pandemic that has killed more than 2 million people and devastated economies worldwide escaped from the Wuhan, China, lab funded by the United States.</ORIGINAL_TEXT>
<TOKEN end_char="1582" id="token-16-0" morph="none" pos="word" start_char="1578">China</TOKEN>
<TOKEN end_char="1583" id="token-16-1" morph="none" pos="punct" start_char="1583">,</TOKEN>
<TOKEN end_char="1587" id="token-16-2" morph="none" pos="word" start_char="1585">the</TOKEN>
<TOKEN end_char="1593" id="token-16-3" morph="none" pos="word" start_char="1589">World</TOKEN>
<TOKEN end_char="1600" id="token-16-4" morph="none" pos="word" start_char="1595">Health</TOKEN>
<TOKEN end_char="1613" id="token-16-5" morph="none" pos="word" start_char="1602">Organization</TOKEN>
<TOKEN end_char="1617" id="token-16-6" morph="none" pos="word" start_char="1615">and</TOKEN>
<TOKEN end_char="1621" id="token-16-7" morph="none" pos="word" start_char="1619">the</TOKEN>
<TOKEN end_char="1625" id="token-16-8" morph="none" pos="unknown" start_char="1623">U.S</TOKEN>
<TOKEN end_char="1626" id="token-16-9" morph="none" pos="punct" start_char="1626">.</TOKEN>
<TOKEN end_char="1635" id="token-16-10" morph="none" pos="word" start_char="1628">National</TOKEN>
<TOKEN end_char="1646" id="token-16-11" morph="none" pos="word" start_char="1637">Institutes</TOKEN>
<TOKEN end_char="1649" id="token-16-12" morph="none" pos="word" start_char="1648">of</TOKEN>
<TOKEN end_char="1656" id="token-16-13" morph="none" pos="word" start_char="1651">Health</TOKEN>
<TOKEN end_char="1661" id="token-16-14" morph="none" pos="word" start_char="1658">have</TOKEN>
<TOKEN end_char="1670" id="token-16-15" morph="none" pos="word" start_char="1663">dimissed</TOKEN>
<TOKEN end_char="1674" id="token-16-16" morph="none" pos="word" start_char="1672">the</TOKEN>
<TOKEN end_char="1681" id="token-16-17" morph="none" pos="word" start_char="1676">theory</TOKEN>
<TOKEN end_char="1686" id="token-16-18" morph="none" pos="word" start_char="1683">that</TOKEN>
<TOKEN end_char="1690" id="token-16-19" morph="none" pos="word" start_char="1688">the</TOKEN>
<TOKEN end_char="1696" id="token-16-20" morph="none" pos="word" start_char="1692">virus</TOKEN>
<TOKEN end_char="1704" id="token-16-21" morph="none" pos="word" start_char="1698">causing</TOKEN>
<TOKEN end_char="1708" id="token-16-22" morph="none" pos="word" start_char="1706">the</TOKEN>
<TOKEN end_char="1715" id="token-16-23" morph="none" pos="word" start_char="1710">global</TOKEN>
<TOKEN end_char="1724" id="token-16-24" morph="none" pos="word" start_char="1717">pandemic</TOKEN>
<TOKEN end_char="1729" id="token-16-25" morph="none" pos="word" start_char="1726">that</TOKEN>
<TOKEN end_char="1733" id="token-16-26" morph="none" pos="word" start_char="1731">has</TOKEN>
<TOKEN end_char="1740" id="token-16-27" morph="none" pos="word" start_char="1735">killed</TOKEN>
<TOKEN end_char="1745" id="token-16-28" morph="none" pos="word" start_char="1742">more</TOKEN>
<TOKEN end_char="1750" id="token-16-29" morph="none" pos="word" start_char="1747">than</TOKEN>
<TOKEN end_char="1752" id="token-16-30" morph="none" pos="word" start_char="1752">2</TOKEN>
<TOKEN end_char="1760" id="token-16-31" morph="none" pos="word" start_char="1754">million</TOKEN>
<TOKEN end_char="1767" id="token-16-32" morph="none" pos="word" start_char="1762">people</TOKEN>
<TOKEN end_char="1771" id="token-16-33" morph="none" pos="word" start_char="1769">and</TOKEN>
<TOKEN end_char="1782" id="token-16-34" morph="none" pos="word" start_char="1773">devastated</TOKEN>
<TOKEN end_char="1792" id="token-16-35" morph="none" pos="word" start_char="1784">economies</TOKEN>
<TOKEN end_char="1802" id="token-16-36" morph="none" pos="word" start_char="1794">worldwide</TOKEN>
<TOKEN end_char="1810" id="token-16-37" morph="none" pos="word" start_char="1804">escaped</TOKEN>
<TOKEN end_char="1815" id="token-16-38" morph="none" pos="word" start_char="1812">from</TOKEN>
<TOKEN end_char="1819" id="token-16-39" morph="none" pos="word" start_char="1817">the</TOKEN>
<TOKEN end_char="1825" id="token-16-40" morph="none" pos="word" start_char="1821">Wuhan</TOKEN>
<TOKEN end_char="1826" id="token-16-41" morph="none" pos="punct" start_char="1826">,</TOKEN>
<TOKEN end_char="1832" id="token-16-42" morph="none" pos="word" start_char="1828">China</TOKEN>
<TOKEN end_char="1833" id="token-16-43" morph="none" pos="punct" start_char="1833">,</TOKEN>
<TOKEN end_char="1837" id="token-16-44" morph="none" pos="word" start_char="1835">lab</TOKEN>
<TOKEN end_char="1844" id="token-16-45" morph="none" pos="word" start_char="1839">funded</TOKEN>
<TOKEN end_char="1847" id="token-16-46" morph="none" pos="word" start_char="1846">by</TOKEN>
<TOKEN end_char="1851" id="token-16-47" morph="none" pos="word" start_char="1849">the</TOKEN>
<TOKEN end_char="1858" id="token-16-48" morph="none" pos="word" start_char="1853">United</TOKEN>
<TOKEN end_char="1865" id="token-16-49" morph="none" pos="word" start_char="1860">States</TOKEN>
<TOKEN end_char="1866" id="token-16-50" morph="none" pos="punct" start_char="1866">.</TOKEN>
</SEG>
<SEG end_char="1961" id="segment-17" start_char="1869">
<ORIGINAL_TEXT>But there's no disputing the fact, as Newsweek reported in April 2020, that NIH executive Dr.</ORIGINAL_TEXT>
<TOKEN end_char="1871" id="token-17-0" morph="none" pos="word" start_char="1869">But</TOKEN>
<TOKEN end_char="1879" id="token-17-1" morph="none" pos="word" start_char="1873">there's</TOKEN>
<TOKEN end_char="1882" id="token-17-2" morph="none" pos="word" start_char="1881">no</TOKEN>
<TOKEN end_char="1892" id="token-17-3" morph="none" pos="word" start_char="1884">disputing</TOKEN>
<TOKEN end_char="1896" id="token-17-4" morph="none" pos="word" start_char="1894">the</TOKEN>
<TOKEN end_char="1901" id="token-17-5" morph="none" pos="word" start_char="1898">fact</TOKEN>
<TOKEN end_char="1902" id="token-17-6" morph="none" pos="punct" start_char="1902">,</TOKEN>
<TOKEN end_char="1905" id="token-17-7" morph="none" pos="word" start_char="1904">as</TOKEN>
<TOKEN end_char="1914" id="token-17-8" morph="none" pos="word" start_char="1907">Newsweek</TOKEN>
<TOKEN end_char="1923" id="token-17-9" morph="none" pos="word" start_char="1916">reported</TOKEN>
<TOKEN end_char="1926" id="token-17-10" morph="none" pos="word" start_char="1925">in</TOKEN>
<TOKEN end_char="1932" id="token-17-11" morph="none" pos="word" start_char="1928">April</TOKEN>
<TOKEN end_char="1937" id="token-17-12" morph="none" pos="word" start_char="1934">2020</TOKEN>
<TOKEN end_char="1938" id="token-17-13" morph="none" pos="punct" start_char="1938">,</TOKEN>
<TOKEN end_char="1943" id="token-17-14" morph="none" pos="word" start_char="1940">that</TOKEN>
<TOKEN end_char="1947" id="token-17-15" morph="none" pos="word" start_char="1945">NIH</TOKEN>
<TOKEN end_char="1957" id="token-17-16" morph="none" pos="word" start_char="1949">executive</TOKEN>
<TOKEN end_char="1960" id="token-17-17" morph="none" pos="word" start_char="1959">Dr</TOKEN>
<TOKEN end_char="1961" id="token-17-18" morph="none" pos="punct" start_char="1961">.</TOKEN>
</SEG>
<SEG end_char="2111" id="segment-18" start_char="1963">
<ORIGINAL_TEXT>Anthony Fauci promoted a highly controversial type of research involving the manipulation of viruses to explore their potential for infecting humans.</ORIGINAL_TEXT>
<TOKEN end_char="1969" id="token-18-0" morph="none" pos="word" start_char="1963">Anthony</TOKEN>
<TOKEN end_char="1975" id="token-18-1" morph="none" pos="word" start_char="1971">Fauci</TOKEN>
<TOKEN end_char="1984" id="token-18-2" morph="none" pos="word" start_char="1977">promoted</TOKEN>
<TOKEN end_char="1986" id="token-18-3" morph="none" pos="word" start_char="1986">a</TOKEN>
<TOKEN end_char="1993" id="token-18-4" morph="none" pos="word" start_char="1988">highly</TOKEN>
<TOKEN end_char="2007" id="token-18-5" morph="none" pos="word" start_char="1995">controversial</TOKEN>
<TOKEN end_char="2012" id="token-18-6" morph="none" pos="word" start_char="2009">type</TOKEN>
<TOKEN end_char="2015" id="token-18-7" morph="none" pos="word" start_char="2014">of</TOKEN>
<TOKEN end_char="2024" id="token-18-8" morph="none" pos="word" start_char="2017">research</TOKEN>
<TOKEN end_char="2034" id="token-18-9" morph="none" pos="word" start_char="2026">involving</TOKEN>
<TOKEN end_char="2038" id="token-18-10" morph="none" pos="word" start_char="2036">the</TOKEN>
<TOKEN end_char="2051" id="token-18-11" morph="none" pos="word" start_char="2040">manipulation</TOKEN>
<TOKEN end_char="2054" id="token-18-12" morph="none" pos="word" start_char="2053">of</TOKEN>
<TOKEN end_char="2062" id="token-18-13" morph="none" pos="word" start_char="2056">viruses</TOKEN>
<TOKEN end_char="2065" id="token-18-14" morph="none" pos="word" start_char="2064">to</TOKEN>
<TOKEN end_char="2073" id="token-18-15" morph="none" pos="word" start_char="2067">explore</TOKEN>
<TOKEN end_char="2079" id="token-18-16" morph="none" pos="word" start_char="2075">their</TOKEN>
<TOKEN end_char="2089" id="token-18-17" morph="none" pos="word" start_char="2081">potential</TOKEN>
<TOKEN end_char="2093" id="token-18-18" morph="none" pos="word" start_char="2091">for</TOKEN>
<TOKEN end_char="2103" id="token-18-19" morph="none" pos="word" start_char="2095">infecting</TOKEN>
<TOKEN end_char="2110" id="token-18-20" morph="none" pos="word" start_char="2105">humans</TOKEN>
<TOKEN end_char="2111" id="token-18-21" morph="none" pos="punct" start_char="2111">.</TOKEN>
</SEG>
<SEG end_char="2346" id="segment-19" start_char="2113">
<ORIGINAL_TEXT>And it's known that more than 200 scientists pressured the Obama administration in 2014 to temporarily halt U.S. funding for that research because of the risk of a manipulated virus accidentally escaping a lab and igniting a pandemic.</ORIGINAL_TEXT>
<TOKEN end_char="2115" id="token-19-0" morph="none" pos="word" start_char="2113">And</TOKEN>
<TOKEN end_char="2120" id="token-19-1" morph="none" pos="word" start_char="2117">it's</TOKEN>
<TOKEN end_char="2126" id="token-19-2" morph="none" pos="word" start_char="2122">known</TOKEN>
<TOKEN end_char="2131" id="token-19-3" morph="none" pos="word" start_char="2128">that</TOKEN>
<TOKEN end_char="2136" id="token-19-4" morph="none" pos="word" start_char="2133">more</TOKEN>
<TOKEN end_char="2141" id="token-19-5" morph="none" pos="word" start_char="2138">than</TOKEN>
<TOKEN end_char="2145" id="token-19-6" morph="none" pos="word" start_char="2143">200</TOKEN>
<TOKEN end_char="2156" id="token-19-7" morph="none" pos="word" start_char="2147">scientists</TOKEN>
<TOKEN end_char="2166" id="token-19-8" morph="none" pos="word" start_char="2158">pressured</TOKEN>
<TOKEN end_char="2170" id="token-19-9" morph="none" pos="word" start_char="2168">the</TOKEN>
<TOKEN end_char="2176" id="token-19-10" morph="none" pos="word" start_char="2172">Obama</TOKEN>
<TOKEN end_char="2191" id="token-19-11" morph="none" pos="word" start_char="2178">administration</TOKEN>
<TOKEN end_char="2194" id="token-19-12" morph="none" pos="word" start_char="2193">in</TOKEN>
<TOKEN end_char="2199" id="token-19-13" morph="none" pos="word" start_char="2196">2014</TOKEN>
<TOKEN end_char="2202" id="token-19-14" morph="none" pos="word" start_char="2201">to</TOKEN>
<TOKEN end_char="2214" id="token-19-15" morph="none" pos="word" start_char="2204">temporarily</TOKEN>
<TOKEN end_char="2219" id="token-19-16" morph="none" pos="word" start_char="2216">halt</TOKEN>
<TOKEN end_char="2223" id="token-19-17" morph="none" pos="unknown" start_char="2221">U.S</TOKEN>
<TOKEN end_char="2224" id="token-19-18" morph="none" pos="punct" start_char="2224">.</TOKEN>
<TOKEN end_char="2232" id="token-19-19" morph="none" pos="word" start_char="2226">funding</TOKEN>
<TOKEN end_char="2236" id="token-19-20" morph="none" pos="word" start_char="2234">for</TOKEN>
<TOKEN end_char="2241" id="token-19-21" morph="none" pos="word" start_char="2238">that</TOKEN>
<TOKEN end_char="2250" id="token-19-22" morph="none" pos="word" start_char="2243">research</TOKEN>
<TOKEN end_char="2258" id="token-19-23" morph="none" pos="word" start_char="2252">because</TOKEN>
<TOKEN end_char="2261" id="token-19-24" morph="none" pos="word" start_char="2260">of</TOKEN>
<TOKEN end_char="2265" id="token-19-25" morph="none" pos="word" start_char="2263">the</TOKEN>
<TOKEN end_char="2270" id="token-19-26" morph="none" pos="word" start_char="2267">risk</TOKEN>
<TOKEN end_char="2273" id="token-19-27" morph="none" pos="word" start_char="2272">of</TOKEN>
<TOKEN end_char="2275" id="token-19-28" morph="none" pos="word" start_char="2275">a</TOKEN>
<TOKEN end_char="2287" id="token-19-29" morph="none" pos="word" start_char="2277">manipulated</TOKEN>
<TOKEN end_char="2293" id="token-19-30" morph="none" pos="word" start_char="2289">virus</TOKEN>
<TOKEN end_char="2306" id="token-19-31" morph="none" pos="word" start_char="2295">accidentally</TOKEN>
<TOKEN end_char="2315" id="token-19-32" morph="none" pos="word" start_char="2308">escaping</TOKEN>
<TOKEN end_char="2317" id="token-19-33" morph="none" pos="word" start_char="2317">a</TOKEN>
<TOKEN end_char="2321" id="token-19-34" morph="none" pos="word" start_char="2319">lab</TOKEN>
<TOKEN end_char="2325" id="token-19-35" morph="none" pos="word" start_char="2323">and</TOKEN>
<TOKEN end_char="2334" id="token-19-36" morph="none" pos="word" start_char="2327">igniting</TOKEN>
<TOKEN end_char="2336" id="token-19-37" morph="none" pos="word" start_char="2336">a</TOKEN>
<TOKEN end_char="2345" id="token-19-38" morph="none" pos="word" start_char="2338">pandemic</TOKEN>
<TOKEN end_char="2346" id="token-19-39" morph="none" pos="punct" start_char="2346">.</TOKEN>
</SEG>
<SEG end_char="2465" id="segment-20" start_char="2348">
<ORIGINAL_TEXT>Nevertheless, under Fauci's direction, the dangerous virus engineering resumed in 2017 and continued until April 2020.</ORIGINAL_TEXT>
<TOKEN end_char="2359" id="token-20-0" morph="none" pos="word" start_char="2348">Nevertheless</TOKEN>
<TOKEN end_char="2360" id="token-20-1" morph="none" pos="punct" start_char="2360">,</TOKEN>
<TOKEN end_char="2366" id="token-20-2" morph="none" pos="word" start_char="2362">under</TOKEN>
<TOKEN end_char="2374" id="token-20-3" morph="none" pos="word" start_char="2368">Fauci's</TOKEN>
<TOKEN end_char="2384" id="token-20-4" morph="none" pos="word" start_char="2376">direction</TOKEN>
<TOKEN end_char="2385" id="token-20-5" morph="none" pos="punct" start_char="2385">,</TOKEN>
<TOKEN end_char="2389" id="token-20-6" morph="none" pos="word" start_char="2387">the</TOKEN>
<TOKEN end_char="2399" id="token-20-7" morph="none" pos="word" start_char="2391">dangerous</TOKEN>
<TOKEN end_char="2405" id="token-20-8" morph="none" pos="word" start_char="2401">virus</TOKEN>
<TOKEN end_char="2417" id="token-20-9" morph="none" pos="word" start_char="2407">engineering</TOKEN>
<TOKEN end_char="2425" id="token-20-10" morph="none" pos="word" start_char="2419">resumed</TOKEN>
<TOKEN end_char="2428" id="token-20-11" morph="none" pos="word" start_char="2427">in</TOKEN>
<TOKEN end_char="2433" id="token-20-12" morph="none" pos="word" start_char="2430">2017</TOKEN>
<TOKEN end_char="2437" id="token-20-13" morph="none" pos="word" start_char="2435">and</TOKEN>
<TOKEN end_char="2447" id="token-20-14" morph="none" pos="word" start_char="2439">continued</TOKEN>
<TOKEN end_char="2453" id="token-20-15" morph="none" pos="word" start_char="2449">until</TOKEN>
<TOKEN end_char="2459" id="token-20-16" morph="none" pos="word" start_char="2455">April</TOKEN>
<TOKEN end_char="2464" id="token-20-17" morph="none" pos="word" start_char="2461">2020</TOKEN>
<TOKEN end_char="2465" id="token-20-18" morph="none" pos="punct" start_char="2465">.</TOKEN>
</SEG>
<SEG end_char="2838" id="segment-21" start_char="2468">
<ORIGINAL_TEXT>Now, documentary evidence makes it a "near certainty" that the coronavirus pandemic originated in the Wuhan Institute of Virology in China, where so-called "gain-of-function" research was funded by Fauci's National Institute of Allergy and Infectious Diseases, according to Steve Hilton, who is leading a special investigation for his Fox News show "The Next Revolution."</ORIGINAL_TEXT>
<TOKEN end_char="2470" id="token-21-0" morph="none" pos="word" start_char="2468">Now</TOKEN>
<TOKEN end_char="2471" id="token-21-1" morph="none" pos="punct" start_char="2471">,</TOKEN>
<TOKEN end_char="2483" id="token-21-2" morph="none" pos="word" start_char="2473">documentary</TOKEN>
<TOKEN end_char="2492" id="token-21-3" morph="none" pos="word" start_char="2485">evidence</TOKEN>
<TOKEN end_char="2498" id="token-21-4" morph="none" pos="word" start_char="2494">makes</TOKEN>
<TOKEN end_char="2501" id="token-21-5" morph="none" pos="word" start_char="2500">it</TOKEN>
<TOKEN end_char="2503" id="token-21-6" morph="none" pos="word" start_char="2503">a</TOKEN>
<TOKEN end_char="2505" id="token-21-7" morph="none" pos="punct" start_char="2505">"</TOKEN>
<TOKEN end_char="2509" id="token-21-8" morph="none" pos="word" start_char="2506">near</TOKEN>
<TOKEN end_char="2519" id="token-21-9" morph="none" pos="word" start_char="2511">certainty</TOKEN>
<TOKEN end_char="2520" id="token-21-10" morph="none" pos="punct" start_char="2520">"</TOKEN>
<TOKEN end_char="2525" id="token-21-11" morph="none" pos="word" start_char="2522">that</TOKEN>
<TOKEN end_char="2529" id="token-21-12" morph="none" pos="word" start_char="2527">the</TOKEN>
<TOKEN end_char="2541" id="token-21-13" morph="none" pos="word" start_char="2531">coronavirus</TOKEN>
<TOKEN end_char="2550" id="token-21-14" morph="none" pos="word" start_char="2543">pandemic</TOKEN>
<TOKEN end_char="2561" id="token-21-15" morph="none" pos="word" start_char="2552">originated</TOKEN>
<TOKEN end_char="2564" id="token-21-16" morph="none" pos="word" start_char="2563">in</TOKEN>
<TOKEN end_char="2568" id="token-21-17" morph="none" pos="word" start_char="2566">the</TOKEN>
<TOKEN end_char="2574" id="token-21-18" morph="none" pos="word" start_char="2570">Wuhan</TOKEN>
<TOKEN end_char="2584" id="token-21-19" morph="none" pos="word" start_char="2576">Institute</TOKEN>
<TOKEN end_char="2587" id="token-21-20" morph="none" pos="word" start_char="2586">of</TOKEN>
<TOKEN end_char="2596" id="token-21-21" morph="none" pos="word" start_char="2589">Virology</TOKEN>
<TOKEN end_char="2599" id="token-21-22" morph="none" pos="word" start_char="2598">in</TOKEN>
<TOKEN end_char="2605" id="token-21-23" morph="none" pos="word" start_char="2601">China</TOKEN>
<TOKEN end_char="2606" id="token-21-24" morph="none" pos="punct" start_char="2606">,</TOKEN>
<TOKEN end_char="2612" id="token-21-25" morph="none" pos="word" start_char="2608">where</TOKEN>
<TOKEN end_char="2622" id="token-21-26" morph="none" pos="unknown" start_char="2614">so-called</TOKEN>
<TOKEN end_char="2624" id="token-21-27" morph="none" pos="punct" start_char="2624">"</TOKEN>
<TOKEN end_char="2640" id="token-21-28" morph="none" pos="unknown" start_char="2625">gain-of-function</TOKEN>
<TOKEN end_char="2641" id="token-21-29" morph="none" pos="punct" start_char="2641">"</TOKEN>
<TOKEN end_char="2650" id="token-21-30" morph="none" pos="word" start_char="2643">research</TOKEN>
<TOKEN end_char="2654" id="token-21-31" morph="none" pos="word" start_char="2652">was</TOKEN>
<TOKEN end_char="2661" id="token-21-32" morph="none" pos="word" start_char="2656">funded</TOKEN>
<TOKEN end_char="2664" id="token-21-33" morph="none" pos="word" start_char="2663">by</TOKEN>
<TOKEN end_char="2672" id="token-21-34" morph="none" pos="word" start_char="2666">Fauci's</TOKEN>
<TOKEN end_char="2681" id="token-21-35" morph="none" pos="word" start_char="2674">National</TOKEN>
<TOKEN end_char="2691" id="token-21-36" morph="none" pos="word" start_char="2683">Institute</TOKEN>
<TOKEN end_char="2694" id="token-21-37" morph="none" pos="word" start_char="2693">of</TOKEN>
<TOKEN end_char="2702" id="token-21-38" morph="none" pos="word" start_char="2696">Allergy</TOKEN>
<TOKEN end_char="2706" id="token-21-39" morph="none" pos="word" start_char="2704">and</TOKEN>
<TOKEN end_char="2717" id="token-21-40" morph="none" pos="word" start_char="2708">Infectious</TOKEN>
<TOKEN end_char="2726" id="token-21-41" morph="none" pos="word" start_char="2719">Diseases</TOKEN>
<TOKEN end_char="2727" id="token-21-42" morph="none" pos="punct" start_char="2727">,</TOKEN>
<TOKEN end_char="2737" id="token-21-43" morph="none" pos="word" start_char="2729">according</TOKEN>
<TOKEN end_char="2740" id="token-21-44" morph="none" pos="word" start_char="2739">to</TOKEN>
<TOKEN end_char="2746" id="token-21-45" morph="none" pos="word" start_char="2742">Steve</TOKEN>
<TOKEN end_char="2753" id="token-21-46" morph="none" pos="word" start_char="2748">Hilton</TOKEN>
<TOKEN end_char="2754" id="token-21-47" morph="none" pos="punct" start_char="2754">,</TOKEN>
<TOKEN end_char="2758" id="token-21-48" morph="none" pos="word" start_char="2756">who</TOKEN>
<TOKEN end_char="2761" id="token-21-49" morph="none" pos="word" start_char="2760">is</TOKEN>
<TOKEN end_char="2769" id="token-21-50" morph="none" pos="word" start_char="2763">leading</TOKEN>
<TOKEN end_char="2771" id="token-21-51" morph="none" pos="word" start_char="2771">a</TOKEN>
<TOKEN end_char="2779" id="token-21-52" morph="none" pos="word" start_char="2773">special</TOKEN>
<TOKEN end_char="2793" id="token-21-53" morph="none" pos="word" start_char="2781">investigation</TOKEN>
<TOKEN end_char="2797" id="token-21-54" morph="none" pos="word" start_char="2795">for</TOKEN>
<TOKEN end_char="2801" id="token-21-55" morph="none" pos="word" start_char="2799">his</TOKEN>
<TOKEN end_char="2805" id="token-21-56" morph="none" pos="word" start_char="2803">Fox</TOKEN>
<TOKEN end_char="2810" id="token-21-57" morph="none" pos="word" start_char="2807">News</TOKEN>
<TOKEN end_char="2815" id="token-21-58" morph="none" pos="word" start_char="2812">show</TOKEN>
<TOKEN end_char="2817" id="token-21-59" morph="none" pos="punct" start_char="2817">"</TOKEN>
<TOKEN end_char="2820" id="token-21-60" morph="none" pos="word" start_char="2818">The</TOKEN>
<TOKEN end_char="2825" id="token-21-61" morph="none" pos="word" start_char="2822">Next</TOKEN>
<TOKEN end_char="2836" id="token-21-62" morph="none" pos="word" start_char="2827">Revolution</TOKEN>
<TOKEN end_char="2838" id="token-21-63" morph="none" pos="punct" start_char="2837">."</TOKEN>
</SEG>
<SEG end_char="3040" id="segment-22" start_char="2841">
<ORIGINAL_TEXT>Significantly, his investigation found a direct link between a bat coronavirus discovered a decade ago in a mine in Yunnan province and one that had been engineered in the Wuhan lab, 1,000 miles away.</ORIGINAL_TEXT>
<TOKEN end_char="2853" id="token-22-0" morph="none" pos="word" start_char="2841">Significantly</TOKEN>
<TOKEN end_char="2854" id="token-22-1" morph="none" pos="punct" start_char="2854">,</TOKEN>
<TOKEN end_char="2858" id="token-22-2" morph="none" pos="word" start_char="2856">his</TOKEN>
<TOKEN end_char="2872" id="token-22-3" morph="none" pos="word" start_char="2860">investigation</TOKEN>
<TOKEN end_char="2878" id="token-22-4" morph="none" pos="word" start_char="2874">found</TOKEN>
<TOKEN end_char="2880" id="token-22-5" morph="none" pos="word" start_char="2880">a</TOKEN>
<TOKEN end_char="2887" id="token-22-6" morph="none" pos="word" start_char="2882">direct</TOKEN>
<TOKEN end_char="2892" id="token-22-7" morph="none" pos="word" start_char="2889">link</TOKEN>
<TOKEN end_char="2900" id="token-22-8" morph="none" pos="word" start_char="2894">between</TOKEN>
<TOKEN end_char="2902" id="token-22-9" morph="none" pos="word" start_char="2902">a</TOKEN>
<TOKEN end_char="2906" id="token-22-10" morph="none" pos="word" start_char="2904">bat</TOKEN>
<TOKEN end_char="2918" id="token-22-11" morph="none" pos="word" start_char="2908">coronavirus</TOKEN>
<TOKEN end_char="2929" id="token-22-12" morph="none" pos="word" start_char="2920">discovered</TOKEN>
<TOKEN end_char="2931" id="token-22-13" morph="none" pos="word" start_char="2931">a</TOKEN>
<TOKEN end_char="2938" id="token-22-14" morph="none" pos="word" start_char="2933">decade</TOKEN>
<TOKEN end_char="2942" id="token-22-15" morph="none" pos="word" start_char="2940">ago</TOKEN>
<TOKEN end_char="2945" id="token-22-16" morph="none" pos="word" start_char="2944">in</TOKEN>
<TOKEN end_char="2947" id="token-22-17" morph="none" pos="word" start_char="2947">a</TOKEN>
<TOKEN end_char="2952" id="token-22-18" morph="none" pos="word" start_char="2949">mine</TOKEN>
<TOKEN end_char="2955" id="token-22-19" morph="none" pos="word" start_char="2954">in</TOKEN>
<TOKEN end_char="2962" id="token-22-20" morph="none" pos="word" start_char="2957">Yunnan</TOKEN>
<TOKEN end_char="2971" id="token-22-21" morph="none" pos="word" start_char="2964">province</TOKEN>
<TOKEN end_char="2975" id="token-22-22" morph="none" pos="word" start_char="2973">and</TOKEN>
<TOKEN end_char="2979" id="token-22-23" morph="none" pos="word" start_char="2977">one</TOKEN>
<TOKEN end_char="2984" id="token-22-24" morph="none" pos="word" start_char="2981">that</TOKEN>
<TOKEN end_char="2988" id="token-22-25" morph="none" pos="word" start_char="2986">had</TOKEN>
<TOKEN end_char="2993" id="token-22-26" morph="none" pos="word" start_char="2990">been</TOKEN>
<TOKEN end_char="3004" id="token-22-27" morph="none" pos="word" start_char="2995">engineered</TOKEN>
<TOKEN end_char="3007" id="token-22-28" morph="none" pos="word" start_char="3006">in</TOKEN>
<TOKEN end_char="3011" id="token-22-29" morph="none" pos="word" start_char="3009">the</TOKEN>
<TOKEN end_char="3017" id="token-22-30" morph="none" pos="word" start_char="3013">Wuhan</TOKEN>
<TOKEN end_char="3021" id="token-22-31" morph="none" pos="word" start_char="3019">lab</TOKEN>
<TOKEN end_char="3022" id="token-22-32" morph="none" pos="punct" start_char="3022">,</TOKEN>
<TOKEN end_char="3028" id="token-22-33" morph="none" pos="unknown" start_char="3024">1,000</TOKEN>
<TOKEN end_char="3034" id="token-22-34" morph="none" pos="word" start_char="3030">miles</TOKEN>
<TOKEN end_char="3039" id="token-22-35" morph="none" pos="word" start_char="3036">away</TOKEN>
<TOKEN end_char="3040" id="token-22-36" morph="none" pos="punct" start_char="3040">.</TOKEN>
</SEG>
<SEG end_char="3261" id="segment-23" start_char="3043">
<ORIGINAL_TEXT>Hilton noted on his show Sunday night that scientists at the Wuhan lab published a paper in February 2020 stating they had recently discovered a virus in Yunnan province that "showed high sequence identity" to COVID-19.</ORIGINAL_TEXT>
<TOKEN end_char="3048" id="token-23-0" morph="none" pos="word" start_char="3043">Hilton</TOKEN>
<TOKEN end_char="3054" id="token-23-1" morph="none" pos="word" start_char="3050">noted</TOKEN>
<TOKEN end_char="3057" id="token-23-2" morph="none" pos="word" start_char="3056">on</TOKEN>
<TOKEN end_char="3061" id="token-23-3" morph="none" pos="word" start_char="3059">his</TOKEN>
<TOKEN end_char="3066" id="token-23-4" morph="none" pos="word" start_char="3063">show</TOKEN>
<TOKEN end_char="3073" id="token-23-5" morph="none" pos="word" start_char="3068">Sunday</TOKEN>
<TOKEN end_char="3079" id="token-23-6" morph="none" pos="word" start_char="3075">night</TOKEN>
<TOKEN end_char="3084" id="token-23-7" morph="none" pos="word" start_char="3081">that</TOKEN>
<TOKEN end_char="3095" id="token-23-8" morph="none" pos="word" start_char="3086">scientists</TOKEN>
<TOKEN end_char="3098" id="token-23-9" morph="none" pos="word" start_char="3097">at</TOKEN>
<TOKEN end_char="3102" id="token-23-10" morph="none" pos="word" start_char="3100">the</TOKEN>
<TOKEN end_char="3108" id="token-23-11" morph="none" pos="word" start_char="3104">Wuhan</TOKEN>
<TOKEN end_char="3112" id="token-23-12" morph="none" pos="word" start_char="3110">lab</TOKEN>
<TOKEN end_char="3122" id="token-23-13" morph="none" pos="word" start_char="3114">published</TOKEN>
<TOKEN end_char="3124" id="token-23-14" morph="none" pos="word" start_char="3124">a</TOKEN>
<TOKEN end_char="3130" id="token-23-15" morph="none" pos="word" start_char="3126">paper</TOKEN>
<TOKEN end_char="3133" id="token-23-16" morph="none" pos="word" start_char="3132">in</TOKEN>
<TOKEN end_char="3142" id="token-23-17" morph="none" pos="word" start_char="3135">February</TOKEN>
<TOKEN end_char="3147" id="token-23-18" morph="none" pos="word" start_char="3144">2020</TOKEN>
<TOKEN end_char="3155" id="token-23-19" morph="none" pos="word" start_char="3149">stating</TOKEN>
<TOKEN end_char="3160" id="token-23-20" morph="none" pos="word" start_char="3157">they</TOKEN>
<TOKEN end_char="3164" id="token-23-21" morph="none" pos="word" start_char="3162">had</TOKEN>
<TOKEN end_char="3173" id="token-23-22" morph="none" pos="word" start_char="3166">recently</TOKEN>
<TOKEN end_char="3184" id="token-23-23" morph="none" pos="word" start_char="3175">discovered</TOKEN>
<TOKEN end_char="3186" id="token-23-24" morph="none" pos="word" start_char="3186">a</TOKEN>
<TOKEN end_char="3192" id="token-23-25" morph="none" pos="word" start_char="3188">virus</TOKEN>
<TOKEN end_char="3195" id="token-23-26" morph="none" pos="word" start_char="3194">in</TOKEN>
<TOKEN end_char="3202" id="token-23-27" morph="none" pos="word" start_char="3197">Yunnan</TOKEN>
<TOKEN end_char="3211" id="token-23-28" morph="none" pos="word" start_char="3204">province</TOKEN>
<TOKEN end_char="3216" id="token-23-29" morph="none" pos="word" start_char="3213">that</TOKEN>
<TOKEN end_char="3218" id="token-23-30" morph="none" pos="punct" start_char="3218">"</TOKEN>
<TOKEN end_char="3224" id="token-23-31" morph="none" pos="word" start_char="3219">showed</TOKEN>
<TOKEN end_char="3229" id="token-23-32" morph="none" pos="word" start_char="3226">high</TOKEN>
<TOKEN end_char="3238" id="token-23-33" morph="none" pos="word" start_char="3231">sequence</TOKEN>
<TOKEN end_char="3247" id="token-23-34" morph="none" pos="word" start_char="3240">identity</TOKEN>
<TOKEN end_char="3248" id="token-23-35" morph="none" pos="punct" start_char="3248">"</TOKEN>
<TOKEN end_char="3251" id="token-23-36" morph="none" pos="word" start_char="3250">to</TOKEN>
<TOKEN end_char="3260" id="token-23-37" morph="none" pos="unknown" start_char="3253">COVID-19</TOKEN>
<TOKEN end_char="3261" id="token-23-38" morph="none" pos="punct" start_char="3261">.</TOKEN>
</SEG>
<SEG end_char="3418" id="segment-24" start_char="3264">
<ORIGINAL_TEXT>However, Hilton discovered after running the virus's genome sequence through the NIH's GenBank database that only one virus was an exact match to COVID-19.</ORIGINAL_TEXT>
<TOKEN end_char="3270" id="token-24-0" morph="none" pos="word" start_char="3264">However</TOKEN>
<TOKEN end_char="3271" id="token-24-1" morph="none" pos="punct" start_char="3271">,</TOKEN>
<TOKEN end_char="3278" id="token-24-2" morph="none" pos="word" start_char="3273">Hilton</TOKEN>
<TOKEN end_char="3289" id="token-24-3" morph="none" pos="word" start_char="3280">discovered</TOKEN>
<TOKEN end_char="3295" id="token-24-4" morph="none" pos="word" start_char="3291">after</TOKEN>
<TOKEN end_char="3303" id="token-24-5" morph="none" pos="word" start_char="3297">running</TOKEN>
<TOKEN end_char="3307" id="token-24-6" morph="none" pos="word" start_char="3305">the</TOKEN>
<TOKEN end_char="3315" id="token-24-7" morph="none" pos="word" start_char="3309">virus's</TOKEN>
<TOKEN end_char="3322" id="token-24-8" morph="none" pos="word" start_char="3317">genome</TOKEN>
<TOKEN end_char="3331" id="token-24-9" morph="none" pos="word" start_char="3324">sequence</TOKEN>
<TOKEN end_char="3339" id="token-24-10" morph="none" pos="word" start_char="3333">through</TOKEN>
<TOKEN end_char="3343" id="token-24-11" morph="none" pos="word" start_char="3341">the</TOKEN>
<TOKEN end_char="3349" id="token-24-12" morph="none" pos="word" start_char="3345">NIH's</TOKEN>
<TOKEN end_char="3357" id="token-24-13" morph="none" pos="word" start_char="3351">GenBank</TOKEN>
<TOKEN end_char="3366" id="token-24-14" morph="none" pos="word" start_char="3359">database</TOKEN>
<TOKEN end_char="3371" id="token-24-15" morph="none" pos="word" start_char="3368">that</TOKEN>
<TOKEN end_char="3376" id="token-24-16" morph="none" pos="word" start_char="3373">only</TOKEN>
<TOKEN end_char="3380" id="token-24-17" morph="none" pos="word" start_char="3378">one</TOKEN>
<TOKEN end_char="3386" id="token-24-18" morph="none" pos="word" start_char="3382">virus</TOKEN>
<TOKEN end_char="3390" id="token-24-19" morph="none" pos="word" start_char="3388">was</TOKEN>
<TOKEN end_char="3393" id="token-24-20" morph="none" pos="word" start_char="3392">an</TOKEN>
<TOKEN end_char="3399" id="token-24-21" morph="none" pos="word" start_char="3395">exact</TOKEN>
<TOKEN end_char="3405" id="token-24-22" morph="none" pos="word" start_char="3401">match</TOKEN>
<TOKEN end_char="3408" id="token-24-23" morph="none" pos="word" start_char="3407">to</TOKEN>
<TOKEN end_char="3417" id="token-24-24" morph="none" pos="unknown" start_char="3410">COVID-19</TOKEN>
<TOKEN end_char="3418" id="token-24-25" morph="none" pos="punct" start_char="3418">.</TOKEN>
</SEG>
<SEG end_char="3459" id="segment-25" start_char="3420">
<ORIGINAL_TEXT>It wasn't the virus discovered recently.</ORIGINAL_TEXT>
<TOKEN end_char="3421" id="token-25-0" morph="none" pos="word" start_char="3420">It</TOKEN>
<TOKEN end_char="3428" id="token-25-1" morph="none" pos="word" start_char="3423">wasn't</TOKEN>
<TOKEN end_char="3432" id="token-25-2" morph="none" pos="word" start_char="3430">the</TOKEN>
<TOKEN end_char="3438" id="token-25-3" morph="none" pos="word" start_char="3434">virus</TOKEN>
<TOKEN end_char="3449" id="token-25-4" morph="none" pos="word" start_char="3440">discovered</TOKEN>
<TOKEN end_char="3458" id="token-25-5" morph="none" pos="word" start_char="3451">recently</TOKEN>
<TOKEN end_char="3459" id="token-25-6" morph="none" pos="punct" start_char="3459">.</TOKEN>
</SEG>
<SEG end_char="3567" id="segment-26" start_char="3461">
<ORIGINAL_TEXT>It was the once discovered a decade ago in Yunnan province that killed miners who had stirred up bat feces.</ORIGINAL_TEXT>
<TOKEN end_char="3462" id="token-26-0" morph="none" pos="word" start_char="3461">It</TOKEN>
<TOKEN end_char="3466" id="token-26-1" morph="none" pos="word" start_char="3464">was</TOKEN>
<TOKEN end_char="3470" id="token-26-2" morph="none" pos="word" start_char="3468">the</TOKEN>
<TOKEN end_char="3475" id="token-26-3" morph="none" pos="word" start_char="3472">once</TOKEN>
<TOKEN end_char="3486" id="token-26-4" morph="none" pos="word" start_char="3477">discovered</TOKEN>
<TOKEN end_char="3488" id="token-26-5" morph="none" pos="word" start_char="3488">a</TOKEN>
<TOKEN end_char="3495" id="token-26-6" morph="none" pos="word" start_char="3490">decade</TOKEN>
<TOKEN end_char="3499" id="token-26-7" morph="none" pos="word" start_char="3497">ago</TOKEN>
<TOKEN end_char="3502" id="token-26-8" morph="none" pos="word" start_char="3501">in</TOKEN>
<TOKEN end_char="3509" id="token-26-9" morph="none" pos="word" start_char="3504">Yunnan</TOKEN>
<TOKEN end_char="3518" id="token-26-10" morph="none" pos="word" start_char="3511">province</TOKEN>
<TOKEN end_char="3523" id="token-26-11" morph="none" pos="word" start_char="3520">that</TOKEN>
<TOKEN end_char="3530" id="token-26-12" morph="none" pos="word" start_char="3525">killed</TOKEN>
<TOKEN end_char="3537" id="token-26-13" morph="none" pos="word" start_char="3532">miners</TOKEN>
<TOKEN end_char="3541" id="token-26-14" morph="none" pos="word" start_char="3539">who</TOKEN>
<TOKEN end_char="3545" id="token-26-15" morph="none" pos="word" start_char="3543">had</TOKEN>
<TOKEN end_char="3553" id="token-26-16" morph="none" pos="word" start_char="3547">stirred</TOKEN>
<TOKEN end_char="3556" id="token-26-17" morph="none" pos="word" start_char="3555">up</TOKEN>
<TOKEN end_char="3560" id="token-26-18" morph="none" pos="word" start_char="3558">bat</TOKEN>
<TOKEN end_char="3566" id="token-26-19" morph="none" pos="word" start_char="3562">feces</TOKEN>
<TOKEN end_char="3567" id="token-26-20" morph="none" pos="punct" start_char="3567">.</TOKEN>
</SEG>
<SEG end_char="3721" id="segment-27" start_char="3570">
<ORIGINAL_TEXT>Hilton found it curious that the Wuhan researchers not only didn't reveal that fact, they changed the name of the Yunnan virus, as indicated by GenBank.</ORIGINAL_TEXT>
<TOKEN end_char="3575" id="token-27-0" morph="none" pos="word" start_char="3570">Hilton</TOKEN>
<TOKEN end_char="3581" id="token-27-1" morph="none" pos="word" start_char="3577">found</TOKEN>
<TOKEN end_char="3584" id="token-27-2" morph="none" pos="word" start_char="3583">it</TOKEN>
<TOKEN end_char="3592" id="token-27-3" morph="none" pos="word" start_char="3586">curious</TOKEN>
<TOKEN end_char="3597" id="token-27-4" morph="none" pos="word" start_char="3594">that</TOKEN>
<TOKEN end_char="3601" id="token-27-5" morph="none" pos="word" start_char="3599">the</TOKEN>
<TOKEN end_char="3607" id="token-27-6" morph="none" pos="word" start_char="3603">Wuhan</TOKEN>
<TOKEN end_char="3619" id="token-27-7" morph="none" pos="word" start_char="3609">researchers</TOKEN>
<TOKEN end_char="3623" id="token-27-8" morph="none" pos="word" start_char="3621">not</TOKEN>
<TOKEN end_char="3628" id="token-27-9" morph="none" pos="word" start_char="3625">only</TOKEN>
<TOKEN end_char="3635" id="token-27-10" morph="none" pos="word" start_char="3630">didn't</TOKEN>
<TOKEN end_char="3642" id="token-27-11" morph="none" pos="word" start_char="3637">reveal</TOKEN>
<TOKEN end_char="3647" id="token-27-12" morph="none" pos="word" start_char="3644">that</TOKEN>
<TOKEN end_char="3652" id="token-27-13" morph="none" pos="word" start_char="3649">fact</TOKEN>
<TOKEN end_char="3653" id="token-27-14" morph="none" pos="punct" start_char="3653">,</TOKEN>
<TOKEN end_char="3658" id="token-27-15" morph="none" pos="word" start_char="3655">they</TOKEN>
<TOKEN end_char="3666" id="token-27-16" morph="none" pos="word" start_char="3660">changed</TOKEN>
<TOKEN end_char="3670" id="token-27-17" morph="none" pos="word" start_char="3668">the</TOKEN>
<TOKEN end_char="3675" id="token-27-18" morph="none" pos="word" start_char="3672">name</TOKEN>
<TOKEN end_char="3678" id="token-27-19" morph="none" pos="word" start_char="3677">of</TOKEN>
<TOKEN end_char="3682" id="token-27-20" morph="none" pos="word" start_char="3680">the</TOKEN>
<TOKEN end_char="3689" id="token-27-21" morph="none" pos="word" start_char="3684">Yunnan</TOKEN>
<TOKEN end_char="3695" id="token-27-22" morph="none" pos="word" start_char="3691">virus</TOKEN>
<TOKEN end_char="3696" id="token-27-23" morph="none" pos="punct" start_char="3696">,</TOKEN>
<TOKEN end_char="3699" id="token-27-24" morph="none" pos="word" start_char="3698">as</TOKEN>
<TOKEN end_char="3709" id="token-27-25" morph="none" pos="word" start_char="3701">indicated</TOKEN>
<TOKEN end_char="3712" id="token-27-26" morph="none" pos="word" start_char="3711">by</TOKEN>
<TOKEN end_char="3720" id="token-27-27" morph="none" pos="word" start_char="3714">GenBank</TOKEN>
<TOKEN end_char="3721" id="token-27-28" morph="none" pos="punct" start_char="3721">.</TOKEN>
</SEG>
<SEG end_char="3964" id="segment-28" start_char="3724">
<ORIGINAL_TEXT>As evidence that the Yunnan virus was manipulated in the Wuhan lab, Hilton pointed out that the two viruses are the same, except for two key elements: The COVID-19 virus is more infectious and can enter human cells in the respiratory system.</ORIGINAL_TEXT>
<TOKEN end_char="3725" id="token-28-0" morph="none" pos="word" start_char="3724">As</TOKEN>
<TOKEN end_char="3734" id="token-28-1" morph="none" pos="word" start_char="3727">evidence</TOKEN>
<TOKEN end_char="3739" id="token-28-2" morph="none" pos="word" start_char="3736">that</TOKEN>
<TOKEN end_char="3743" id="token-28-3" morph="none" pos="word" start_char="3741">the</TOKEN>
<TOKEN end_char="3750" id="token-28-4" morph="none" pos="word" start_char="3745">Yunnan</TOKEN>
<TOKEN end_char="3756" id="token-28-5" morph="none" pos="word" start_char="3752">virus</TOKEN>
<TOKEN end_char="3760" id="token-28-6" morph="none" pos="word" start_char="3758">was</TOKEN>
<TOKEN end_char="3772" id="token-28-7" morph="none" pos="word" start_char="3762">manipulated</TOKEN>
<TOKEN end_char="3775" id="token-28-8" morph="none" pos="word" start_char="3774">in</TOKEN>
<TOKEN end_char="3779" id="token-28-9" morph="none" pos="word" start_char="3777">the</TOKEN>
<TOKEN end_char="3785" id="token-28-10" morph="none" pos="word" start_char="3781">Wuhan</TOKEN>
<TOKEN end_char="3789" id="token-28-11" morph="none" pos="word" start_char="3787">lab</TOKEN>
<TOKEN end_char="3790" id="token-28-12" morph="none" pos="punct" start_char="3790">,</TOKEN>
<TOKEN end_char="3797" id="token-28-13" morph="none" pos="word" start_char="3792">Hilton</TOKEN>
<TOKEN end_char="3805" id="token-28-14" morph="none" pos="word" start_char="3799">pointed</TOKEN>
<TOKEN end_char="3809" id="token-28-15" morph="none" pos="word" start_char="3807">out</TOKEN>
<TOKEN end_char="3814" id="token-28-16" morph="none" pos="word" start_char="3811">that</TOKEN>
<TOKEN end_char="3818" id="token-28-17" morph="none" pos="word" start_char="3816">the</TOKEN>
<TOKEN end_char="3822" id="token-28-18" morph="none" pos="word" start_char="3820">two</TOKEN>
<TOKEN end_char="3830" id="token-28-19" morph="none" pos="word" start_char="3824">viruses</TOKEN>
<TOKEN end_char="3834" id="token-28-20" morph="none" pos="word" start_char="3832">are</TOKEN>
<TOKEN end_char="3838" id="token-28-21" morph="none" pos="word" start_char="3836">the</TOKEN>
<TOKEN end_char="3843" id="token-28-22" morph="none" pos="word" start_char="3840">same</TOKEN>
<TOKEN end_char="3844" id="token-28-23" morph="none" pos="punct" start_char="3844">,</TOKEN>
<TOKEN end_char="3851" id="token-28-24" morph="none" pos="word" start_char="3846">except</TOKEN>
<TOKEN end_char="3855" id="token-28-25" morph="none" pos="word" start_char="3853">for</TOKEN>
<TOKEN end_char="3859" id="token-28-26" morph="none" pos="word" start_char="3857">two</TOKEN>
<TOKEN end_char="3863" id="token-28-27" morph="none" pos="word" start_char="3861">key</TOKEN>
<TOKEN end_char="3872" id="token-28-28" morph="none" pos="word" start_char="3865">elements</TOKEN>
<TOKEN end_char="3873" id="token-28-29" morph="none" pos="punct" start_char="3873">:</TOKEN>
<TOKEN end_char="3877" id="token-28-30" morph="none" pos="word" start_char="3875">The</TOKEN>
<TOKEN end_char="3886" id="token-28-31" morph="none" pos="unknown" start_char="3879">COVID-19</TOKEN>
<TOKEN end_char="3892" id="token-28-32" morph="none" pos="word" start_char="3888">virus</TOKEN>
<TOKEN end_char="3895" id="token-28-33" morph="none" pos="word" start_char="3894">is</TOKEN>
<TOKEN end_char="3900" id="token-28-34" morph="none" pos="word" start_char="3897">more</TOKEN>
<TOKEN end_char="3911" id="token-28-35" morph="none" pos="word" start_char="3902">infectious</TOKEN>
<TOKEN end_char="3915" id="token-28-36" morph="none" pos="word" start_char="3913">and</TOKEN>
<TOKEN end_char="3919" id="token-28-37" morph="none" pos="word" start_char="3917">can</TOKEN>
<TOKEN end_char="3925" id="token-28-38" morph="none" pos="word" start_char="3921">enter</TOKEN>
<TOKEN end_char="3931" id="token-28-39" morph="none" pos="word" start_char="3927">human</TOKEN>
<TOKEN end_char="3937" id="token-28-40" morph="none" pos="word" start_char="3933">cells</TOKEN>
<TOKEN end_char="3940" id="token-28-41" morph="none" pos="word" start_char="3939">in</TOKEN>
<TOKEN end_char="3944" id="token-28-42" morph="none" pos="word" start_char="3942">the</TOKEN>
<TOKEN end_char="3956" id="token-28-43" morph="none" pos="word" start_char="3946">respiratory</TOKEN>
<TOKEN end_char="3963" id="token-28-44" morph="none" pos="word" start_char="3958">system</TOKEN>
<TOKEN end_char="3964" id="token-28-45" morph="none" pos="punct" start_char="3964">.</TOKEN>
</SEG>
<SEG end_char="4188" id="segment-29" start_char="3967">
<ORIGINAL_TEXT>"Those are the exact places in the viral sequence where gain-of-function techniques would be applied, if ... you were funded by the NAID to research bat coronaviruses to explore emergences or spillover potential," he said.</ORIGINAL_TEXT>
<TOKEN end_char="3967" id="token-29-0" morph="none" pos="punct" start_char="3967">"</TOKEN>
<TOKEN end_char="3972" id="token-29-1" morph="none" pos="word" start_char="3968">Those</TOKEN>
<TOKEN end_char="3976" id="token-29-2" morph="none" pos="word" start_char="3974">are</TOKEN>
<TOKEN end_char="3980" id="token-29-3" morph="none" pos="word" start_char="3978">the</TOKEN>
<TOKEN end_char="3986" id="token-29-4" morph="none" pos="word" start_char="3982">exact</TOKEN>
<TOKEN end_char="3993" id="token-29-5" morph="none" pos="word" start_char="3988">places</TOKEN>
<TOKEN end_char="3996" id="token-29-6" morph="none" pos="word" start_char="3995">in</TOKEN>
<TOKEN end_char="4000" id="token-29-7" morph="none" pos="word" start_char="3998">the</TOKEN>
<TOKEN end_char="4006" id="token-29-8" morph="none" pos="word" start_char="4002">viral</TOKEN>
<TOKEN end_char="4015" id="token-29-9" morph="none" pos="word" start_char="4008">sequence</TOKEN>
<TOKEN end_char="4021" id="token-29-10" morph="none" pos="word" start_char="4017">where</TOKEN>
<TOKEN end_char="4038" id="token-29-11" morph="none" pos="unknown" start_char="4023">gain-of-function</TOKEN>
<TOKEN end_char="4049" id="token-29-12" morph="none" pos="word" start_char="4040">techniques</TOKEN>
<TOKEN end_char="4055" id="token-29-13" morph="none" pos="word" start_char="4051">would</TOKEN>
<TOKEN end_char="4058" id="token-29-14" morph="none" pos="word" start_char="4057">be</TOKEN>
<TOKEN end_char="4066" id="token-29-15" morph="none" pos="word" start_char="4060">applied</TOKEN>
<TOKEN end_char="4067" id="token-29-16" morph="none" pos="punct" start_char="4067">,</TOKEN>
<TOKEN end_char="4070" id="token-29-17" morph="none" pos="word" start_char="4069">if</TOKEN>
<TOKEN end_char="4074" id="token-29-18" morph="none" pos="punct" start_char="4072">...</TOKEN>
<TOKEN end_char="4078" id="token-29-19" morph="none" pos="word" start_char="4076">you</TOKEN>
<TOKEN end_char="4083" id="token-29-20" morph="none" pos="word" start_char="4080">were</TOKEN>
<TOKEN end_char="4090" id="token-29-21" morph="none" pos="word" start_char="4085">funded</TOKEN>
<TOKEN end_char="4093" id="token-29-22" morph="none" pos="word" start_char="4092">by</TOKEN>
<TOKEN end_char="4097" id="token-29-23" morph="none" pos="word" start_char="4095">the</TOKEN>
<TOKEN end_char="4102" id="token-29-24" morph="none" pos="word" start_char="4099">NAID</TOKEN>
<TOKEN end_char="4105" id="token-29-25" morph="none" pos="word" start_char="4104">to</TOKEN>
<TOKEN end_char="4114" id="token-29-26" morph="none" pos="word" start_char="4107">research</TOKEN>
<TOKEN end_char="4118" id="token-29-27" morph="none" pos="word" start_char="4116">bat</TOKEN>
<TOKEN end_char="4132" id="token-29-28" morph="none" pos="word" start_char="4120">coronaviruses</TOKEN>
<TOKEN end_char="4135" id="token-29-29" morph="none" pos="word" start_char="4134">to</TOKEN>
<TOKEN end_char="4143" id="token-29-30" morph="none" pos="word" start_char="4137">explore</TOKEN>
<TOKEN end_char="4154" id="token-29-31" morph="none" pos="word" start_char="4145">emergences</TOKEN>
<TOKEN end_char="4157" id="token-29-32" morph="none" pos="word" start_char="4156">or</TOKEN>
<TOKEN end_char="4167" id="token-29-33" morph="none" pos="word" start_char="4159">spillover</TOKEN>
<TOKEN end_char="4177" id="token-29-34" morph="none" pos="word" start_char="4169">potential</TOKEN>
<TOKEN end_char="4179" id="token-29-35" morph="none" pos="punct" start_char="4178">,"</TOKEN>
<TOKEN end_char="4182" id="token-29-36" morph="none" pos="word" start_char="4181">he</TOKEN>
<TOKEN end_char="4187" id="token-29-37" morph="none" pos="word" start_char="4184">said</TOKEN>
<TOKEN end_char="4188" id="token-29-38" morph="none" pos="punct" start_char="4188">.</TOKEN>
</SEG>
<SEG end_char="4276" id="segment-30" start_char="4191">
<ORIGINAL_TEXT>"Spillover potential" refers to the ability of a virus to jump from animals to humans.</ORIGINAL_TEXT>
<TOKEN end_char="4191" id="token-30-0" morph="none" pos="punct" start_char="4191">"</TOKEN>
<TOKEN end_char="4200" id="token-30-1" morph="none" pos="word" start_char="4192">Spillover</TOKEN>
<TOKEN end_char="4210" id="token-30-2" morph="none" pos="word" start_char="4202">potential</TOKEN>
<TOKEN end_char="4211" id="token-30-3" morph="none" pos="punct" start_char="4211">"</TOKEN>
<TOKEN end_char="4218" id="token-30-4" morph="none" pos="word" start_char="4213">refers</TOKEN>
<TOKEN end_char="4221" id="token-30-5" morph="none" pos="word" start_char="4220">to</TOKEN>
<TOKEN end_char="4225" id="token-30-6" morph="none" pos="word" start_char="4223">the</TOKEN>
<TOKEN end_char="4233" id="token-30-7" morph="none" pos="word" start_char="4227">ability</TOKEN>
<TOKEN end_char="4236" id="token-30-8" morph="none" pos="word" start_char="4235">of</TOKEN>
<TOKEN end_char="4238" id="token-30-9" morph="none" pos="word" start_char="4238">a</TOKEN>
<TOKEN end_char="4244" id="token-30-10" morph="none" pos="word" start_char="4240">virus</TOKEN>
<TOKEN end_char="4247" id="token-30-11" morph="none" pos="word" start_char="4246">to</TOKEN>
<TOKEN end_char="4252" id="token-30-12" morph="none" pos="word" start_char="4249">jump</TOKEN>
<TOKEN end_char="4257" id="token-30-13" morph="none" pos="word" start_char="4254">from</TOKEN>
<TOKEN end_char="4265" id="token-30-14" morph="none" pos="word" start_char="4259">animals</TOKEN>
<TOKEN end_char="4268" id="token-30-15" morph="none" pos="word" start_char="4267">to</TOKEN>
<TOKEN end_char="4275" id="token-30-16" morph="none" pos="word" start_char="4270">humans</TOKEN>
<TOKEN end_char="4276" id="token-30-17" morph="none" pos="punct" start_char="4276">.</TOKEN>
</SEG>
<SEG end_char="4352" id="segment-31" start_char="4279">
<ORIGINAL_TEXT>That exact gain-of-function research, he pointed out, was touted in a Nov.</ORIGINAL_TEXT>
<TOKEN end_char="4282" id="token-31-0" morph="none" pos="word" start_char="4279">That</TOKEN>
<TOKEN end_char="4288" id="token-31-1" morph="none" pos="word" start_char="4284">exact</TOKEN>
<TOKEN end_char="4305" id="token-31-2" morph="none" pos="unknown" start_char="4290">gain-of-function</TOKEN>
<TOKEN end_char="4314" id="token-31-3" morph="none" pos="word" start_char="4307">research</TOKEN>
<TOKEN end_char="4315" id="token-31-4" morph="none" pos="punct" start_char="4315">,</TOKEN>
<TOKEN end_char="4318" id="token-31-5" morph="none" pos="word" start_char="4317">he</TOKEN>
<TOKEN end_char="4326" id="token-31-6" morph="none" pos="word" start_char="4320">pointed</TOKEN>
<TOKEN end_char="4330" id="token-31-7" morph="none" pos="word" start_char="4328">out</TOKEN>
<TOKEN end_char="4331" id="token-31-8" morph="none" pos="punct" start_char="4331">,</TOKEN>
<TOKEN end_char="4335" id="token-31-9" morph="none" pos="word" start_char="4333">was</TOKEN>
<TOKEN end_char="4342" id="token-31-10" morph="none" pos="word" start_char="4337">touted</TOKEN>
<TOKEN end_char="4345" id="token-31-11" morph="none" pos="word" start_char="4344">in</TOKEN>
<TOKEN end_char="4347" id="token-31-12" morph="none" pos="word" start_char="4347">a</TOKEN>
<TOKEN end_char="4351" id="token-31-13" morph="none" pos="word" start_char="4349">Nov</TOKEN>
<TOKEN end_char="4352" id="token-31-14" morph="none" pos="punct" start_char="4352">.</TOKEN>
</SEG>
<SEG end_char="4401" id="segment-32" start_char="4354">
<ORIGINAL_TEXT>30, 2017, progress report tied to an NAID grant.</ORIGINAL_TEXT>
<TOKEN end_char="4355" id="token-32-0" morph="none" pos="word" start_char="4354">30</TOKEN>
<TOKEN end_char="4356" id="token-32-1" morph="none" pos="punct" start_char="4356">,</TOKEN>
<TOKEN end_char="4361" id="token-32-2" morph="none" pos="word" start_char="4358">2017</TOKEN>
<TOKEN end_char="4362" id="token-32-3" morph="none" pos="punct" start_char="4362">,</TOKEN>
<TOKEN end_char="4371" id="token-32-4" morph="none" pos="word" start_char="4364">progress</TOKEN>
<TOKEN end_char="4378" id="token-32-5" morph="none" pos="word" start_char="4373">report</TOKEN>
<TOKEN end_char="4383" id="token-32-6" morph="none" pos="word" start_char="4380">tied</TOKEN>
<TOKEN end_char="4386" id="token-32-7" morph="none" pos="word" start_char="4385">to</TOKEN>
<TOKEN end_char="4389" id="token-32-8" morph="none" pos="word" start_char="4388">an</TOKEN>
<TOKEN end_char="4394" id="token-32-9" morph="none" pos="word" start_char="4391">NAID</TOKEN>
<TOKEN end_char="4400" id="token-32-10" morph="none" pos="word" start_char="4396">grant</TOKEN>
<TOKEN end_char="4401" id="token-32-11" morph="none" pos="punct" start_char="4401">.</TOKEN>
</SEG>
<SEG end_char="4556" id="segment-33" start_char="4404">
<ORIGINAL_TEXT>The crucial question, Hilton said, was whether the virus at the center of that U.S.-funded work was the one that was discovered in the mine a decade ago.</ORIGINAL_TEXT>
<TOKEN end_char="4406" id="token-33-0" morph="none" pos="word" start_char="4404">The</TOKEN>
<TOKEN end_char="4414" id="token-33-1" morph="none" pos="word" start_char="4408">crucial</TOKEN>
<TOKEN end_char="4423" id="token-33-2" morph="none" pos="word" start_char="4416">question</TOKEN>
<TOKEN end_char="4424" id="token-33-3" morph="none" pos="punct" start_char="4424">,</TOKEN>
<TOKEN end_char="4431" id="token-33-4" morph="none" pos="word" start_char="4426">Hilton</TOKEN>
<TOKEN end_char="4436" id="token-33-5" morph="none" pos="word" start_char="4433">said</TOKEN>
<TOKEN end_char="4437" id="token-33-6" morph="none" pos="punct" start_char="4437">,</TOKEN>
<TOKEN end_char="4441" id="token-33-7" morph="none" pos="word" start_char="4439">was</TOKEN>
<TOKEN end_char="4449" id="token-33-8" morph="none" pos="word" start_char="4443">whether</TOKEN>
<TOKEN end_char="4453" id="token-33-9" morph="none" pos="word" start_char="4451">the</TOKEN>
<TOKEN end_char="4459" id="token-33-10" morph="none" pos="word" start_char="4455">virus</TOKEN>
<TOKEN end_char="4462" id="token-33-11" morph="none" pos="word" start_char="4461">at</TOKEN>
<TOKEN end_char="4466" id="token-33-12" morph="none" pos="word" start_char="4464">the</TOKEN>
<TOKEN end_char="4473" id="token-33-13" morph="none" pos="word" start_char="4468">center</TOKEN>
<TOKEN end_char="4476" id="token-33-14" morph="none" pos="word" start_char="4475">of</TOKEN>
<TOKEN end_char="4481" id="token-33-15" morph="none" pos="word" start_char="4478">that</TOKEN>
<TOKEN end_char="4493" id="token-33-16" morph="none" pos="unknown" start_char="4483">U.S.-funded</TOKEN>
<TOKEN end_char="4498" id="token-33-17" morph="none" pos="word" start_char="4495">work</TOKEN>
<TOKEN end_char="4502" id="token-33-18" morph="none" pos="word" start_char="4500">was</TOKEN>
<TOKEN end_char="4506" id="token-33-19" morph="none" pos="word" start_char="4504">the</TOKEN>
<TOKEN end_char="4510" id="token-33-20" morph="none" pos="word" start_char="4508">one</TOKEN>
<TOKEN end_char="4515" id="token-33-21" morph="none" pos="word" start_char="4512">that</TOKEN>
<TOKEN end_char="4519" id="token-33-22" morph="none" pos="word" start_char="4517">was</TOKEN>
<TOKEN end_char="4530" id="token-33-23" morph="none" pos="word" start_char="4521">discovered</TOKEN>
<TOKEN end_char="4533" id="token-33-24" morph="none" pos="word" start_char="4532">in</TOKEN>
<TOKEN end_char="4537" id="token-33-25" morph="none" pos="word" start_char="4535">the</TOKEN>
<TOKEN end_char="4542" id="token-33-26" morph="none" pos="word" start_char="4539">mine</TOKEN>
<TOKEN end_char="4544" id="token-33-27" morph="none" pos="word" start_char="4544">a</TOKEN>
<TOKEN end_char="4551" id="token-33-28" morph="none" pos="word" start_char="4546">decade</TOKEN>
<TOKEN end_char="4555" id="token-33-29" morph="none" pos="word" start_char="4553">ago</TOKEN>
<TOKEN end_char="4556" id="token-33-30" morph="none" pos="punct" start_char="4556">.</TOKEN>
</SEG>
<SEG end_char="4687" id="segment-34" start_char="4559">
<ORIGINAL_TEXT>"The match between that virus and the work commissioned by NAID is so perfect, it's impossible to believe they weren't," he said.</ORIGINAL_TEXT>
<TOKEN end_char="4559" id="token-34-0" morph="none" pos="punct" start_char="4559">"</TOKEN>
<TOKEN end_char="4562" id="token-34-1" morph="none" pos="word" start_char="4560">The</TOKEN>
<TOKEN end_char="4568" id="token-34-2" morph="none" pos="word" start_char="4564">match</TOKEN>
<TOKEN end_char="4576" id="token-34-3" morph="none" pos="word" start_char="4570">between</TOKEN>
<TOKEN end_char="4581" id="token-34-4" morph="none" pos="word" start_char="4578">that</TOKEN>
<TOKEN end_char="4587" id="token-34-5" morph="none" pos="word" start_char="4583">virus</TOKEN>
<TOKEN end_char="4591" id="token-34-6" morph="none" pos="word" start_char="4589">and</TOKEN>
<TOKEN end_char="4595" id="token-34-7" morph="none" pos="word" start_char="4593">the</TOKEN>
<TOKEN end_char="4600" id="token-34-8" morph="none" pos="word" start_char="4597">work</TOKEN>
<TOKEN end_char="4613" id="token-34-9" morph="none" pos="word" start_char="4602">commissioned</TOKEN>
<TOKEN end_char="4616" id="token-34-10" morph="none" pos="word" start_char="4615">by</TOKEN>
<TOKEN end_char="4621" id="token-34-11" morph="none" pos="word" start_char="4618">NAID</TOKEN>
<TOKEN end_char="4624" id="token-34-12" morph="none" pos="word" start_char="4623">is</TOKEN>
<TOKEN end_char="4627" id="token-34-13" morph="none" pos="word" start_char="4626">so</TOKEN>
<TOKEN end_char="4635" id="token-34-14" morph="none" pos="word" start_char="4629">perfect</TOKEN>
<TOKEN end_char="4636" id="token-34-15" morph="none" pos="punct" start_char="4636">,</TOKEN>
<TOKEN end_char="4641" id="token-34-16" morph="none" pos="word" start_char="4638">it's</TOKEN>
<TOKEN end_char="4652" id="token-34-17" morph="none" pos="word" start_char="4643">impossible</TOKEN>
<TOKEN end_char="4655" id="token-34-18" morph="none" pos="word" start_char="4654">to</TOKEN>
<TOKEN end_char="4663" id="token-34-19" morph="none" pos="word" start_char="4657">believe</TOKEN>
<TOKEN end_char="4668" id="token-34-20" morph="none" pos="word" start_char="4665">they</TOKEN>
<TOKEN end_char="4676" id="token-34-21" morph="none" pos="word" start_char="4670">weren't</TOKEN>
<TOKEN end_char="4678" id="token-34-22" morph="none" pos="punct" start_char="4677">,"</TOKEN>
<TOKEN end_char="4681" id="token-34-23" morph="none" pos="word" start_char="4680">he</TOKEN>
<TOKEN end_char="4686" id="token-34-24" morph="none" pos="word" start_char="4683">said</TOKEN>
<TOKEN end_char="4687" id="token-34-25" morph="none" pos="punct" start_char="4687">.</TOKEN>
</SEG>
<SEG end_char="4792" id="segment-35" start_char="4690">
<ORIGINAL_TEXT>He noted that workers in the Wuhan lab were the first identified cases of COVID-19 in the fall of 2019.</ORIGINAL_TEXT>
<TOKEN end_char="4691" id="token-35-0" morph="none" pos="word" start_char="4690">He</TOKEN>
<TOKEN end_char="4697" id="token-35-1" morph="none" pos="word" start_char="4693">noted</TOKEN>
<TOKEN end_char="4702" id="token-35-2" morph="none" pos="word" start_char="4699">that</TOKEN>
<TOKEN end_char="4710" id="token-35-3" morph="none" pos="word" start_char="4704">workers</TOKEN>
<TOKEN end_char="4713" id="token-35-4" morph="none" pos="word" start_char="4712">in</TOKEN>
<TOKEN end_char="4717" id="token-35-5" morph="none" pos="word" start_char="4715">the</TOKEN>
<TOKEN end_char="4723" id="token-35-6" morph="none" pos="word" start_char="4719">Wuhan</TOKEN>
<TOKEN end_char="4727" id="token-35-7" morph="none" pos="word" start_char="4725">lab</TOKEN>
<TOKEN end_char="4732" id="token-35-8" morph="none" pos="word" start_char="4729">were</TOKEN>
<TOKEN end_char="4736" id="token-35-9" morph="none" pos="word" start_char="4734">the</TOKEN>
<TOKEN end_char="4742" id="token-35-10" morph="none" pos="word" start_char="4738">first</TOKEN>
<TOKEN end_char="4753" id="token-35-11" morph="none" pos="word" start_char="4744">identified</TOKEN>
<TOKEN end_char="4759" id="token-35-12" morph="none" pos="word" start_char="4755">cases</TOKEN>
<TOKEN end_char="4762" id="token-35-13" morph="none" pos="word" start_char="4761">of</TOKEN>
<TOKEN end_char="4771" id="token-35-14" morph="none" pos="unknown" start_char="4764">COVID-19</TOKEN>
<TOKEN end_char="4774" id="token-35-15" morph="none" pos="word" start_char="4773">in</TOKEN>
<TOKEN end_char="4778" id="token-35-16" morph="none" pos="word" start_char="4776">the</TOKEN>
<TOKEN end_char="4783" id="token-35-17" morph="none" pos="word" start_char="4780">fall</TOKEN>
<TOKEN end_char="4786" id="token-35-18" morph="none" pos="word" start_char="4785">of</TOKEN>
<TOKEN end_char="4791" id="token-35-19" morph="none" pos="word" start_char="4788">2019</TOKEN>
<TOKEN end_char="4792" id="token-35-20" morph="none" pos="punct" start_char="4792">.</TOKEN>
</SEG>
<SEG end_char="4818" id="segment-36" start_char="4795">
<ORIGINAL_TEXT>Implausible coincidences</ORIGINAL_TEXT>
<TOKEN end_char="4805" id="token-36-0" morph="none" pos="word" start_char="4795">Implausible</TOKEN>
<TOKEN end_char="4818" id="token-36-1" morph="none" pos="word" start_char="4807">coincidences</TOKEN>
<TRANSLATED_TEXT>Implosibile coincidenze</TRANSLATED_TEXT><DETECTED_LANGUAGE>fr</DETECTED_LANGUAGE></SEG>
<SEG end_char="4913" id="segment-37" start_char="4821">
<ORIGINAL_TEXT>The WHO and others are leaning toward a "natural" explanation for the pandemic, Hilton noted.</ORIGINAL_TEXT>
<TOKEN end_char="4823" id="token-37-0" morph="none" pos="word" start_char="4821">The</TOKEN>
<TOKEN end_char="4827" id="token-37-1" morph="none" pos="word" start_char="4825">WHO</TOKEN>
<TOKEN end_char="4831" id="token-37-2" morph="none" pos="word" start_char="4829">and</TOKEN>
<TOKEN end_char="4838" id="token-37-3" morph="none" pos="word" start_char="4833">others</TOKEN>
<TOKEN end_char="4842" id="token-37-4" morph="none" pos="word" start_char="4840">are</TOKEN>
<TOKEN end_char="4850" id="token-37-5" morph="none" pos="word" start_char="4844">leaning</TOKEN>
<TOKEN end_char="4857" id="token-37-6" morph="none" pos="word" start_char="4852">toward</TOKEN>
<TOKEN end_char="4859" id="token-37-7" morph="none" pos="word" start_char="4859">a</TOKEN>
<TOKEN end_char="4861" id="token-37-8" morph="none" pos="punct" start_char="4861">"</TOKEN>
<TOKEN end_char="4868" id="token-37-9" morph="none" pos="word" start_char="4862">natural</TOKEN>
<TOKEN end_char="4869" id="token-37-10" morph="none" pos="punct" start_char="4869">"</TOKEN>
<TOKEN end_char="4881" id="token-37-11" morph="none" pos="word" start_char="4871">explanation</TOKEN>
<TOKEN end_char="4885" id="token-37-12" morph="none" pos="word" start_char="4883">for</TOKEN>
<TOKEN end_char="4889" id="token-37-13" morph="none" pos="word" start_char="4887">the</TOKEN>
<TOKEN end_char="4898" id="token-37-14" morph="none" pos="word" start_char="4891">pandemic</TOKEN>
<TOKEN end_char="4899" id="token-37-15" morph="none" pos="punct" start_char="4899">,</TOKEN>
<TOKEN end_char="4906" id="token-37-16" morph="none" pos="word" start_char="4901">Hilton</TOKEN>
<TOKEN end_char="4912" id="token-37-17" morph="none" pos="word" start_char="4908">noted</TOKEN>
<TOKEN end_char="4913" id="token-37-18" morph="none" pos="punct" start_char="4913">.</TOKEN>
</SEG>
<SEG end_char="5149" id="segment-38" start_char="4915">
<ORIGINAL_TEXT>But if the COVID-19 pandemic originated naturally in the Yunnan mine  as the genome sequence indicates  but had nothing to do with research at the Wuhan lab, you would "have to believe in a laughably implausible set of coincidences."</ORIGINAL_TEXT>
<TOKEN end_char="4917" id="token-38-0" morph="none" pos="word" start_char="4915">But</TOKEN>
<TOKEN end_char="4920" id="token-38-1" morph="none" pos="word" start_char="4919">if</TOKEN>
<TOKEN end_char="4924" id="token-38-2" morph="none" pos="word" start_char="4922">the</TOKEN>
<TOKEN end_char="4933" id="token-38-3" morph="none" pos="unknown" start_char="4926">COVID-19</TOKEN>
<TOKEN end_char="4942" id="token-38-4" morph="none" pos="word" start_char="4935">pandemic</TOKEN>
<TOKEN end_char="4953" id="token-38-5" morph="none" pos="word" start_char="4944">originated</TOKEN>
<TOKEN end_char="4963" id="token-38-6" morph="none" pos="word" start_char="4955">naturally</TOKEN>
<TOKEN end_char="4966" id="token-38-7" morph="none" pos="word" start_char="4965">in</TOKEN>
<TOKEN end_char="4970" id="token-38-8" morph="none" pos="word" start_char="4968">the</TOKEN>
<TOKEN end_char="4977" id="token-38-9" morph="none" pos="word" start_char="4972">Yunnan</TOKEN>
<TOKEN end_char="4982" id="token-38-10" morph="none" pos="word" start_char="4979">mine</TOKEN>
<TOKEN end_char="4984" id="token-38-11" morph="none" pos="punct" start_char="4984"></TOKEN>
<TOKEN end_char="4987" id="token-38-12" morph="none" pos="word" start_char="4986">as</TOKEN>
<TOKEN end_char="4991" id="token-38-13" morph="none" pos="word" start_char="4989">the</TOKEN>
<TOKEN end_char="4998" id="token-38-14" morph="none" pos="word" start_char="4993">genome</TOKEN>
<TOKEN end_char="5007" id="token-38-15" morph="none" pos="word" start_char="5000">sequence</TOKEN>
<TOKEN end_char="5017" id="token-38-16" morph="none" pos="word" start_char="5009">indicates</TOKEN>
<TOKEN end_char="5019" id="token-38-17" morph="none" pos="punct" start_char="5019"></TOKEN>
<TOKEN end_char="5023" id="token-38-18" morph="none" pos="word" start_char="5021">but</TOKEN>
<TOKEN end_char="5027" id="token-38-19" morph="none" pos="word" start_char="5025">had</TOKEN>
<TOKEN end_char="5035" id="token-38-20" morph="none" pos="word" start_char="5029">nothing</TOKEN>
<TOKEN end_char="5038" id="token-38-21" morph="none" pos="word" start_char="5037">to</TOKEN>
<TOKEN end_char="5041" id="token-38-22" morph="none" pos="word" start_char="5040">do</TOKEN>
<TOKEN end_char="5046" id="token-38-23" morph="none" pos="word" start_char="5043">with</TOKEN>
<TOKEN end_char="5055" id="token-38-24" morph="none" pos="word" start_char="5048">research</TOKEN>
<TOKEN end_char="5058" id="token-38-25" morph="none" pos="word" start_char="5057">at</TOKEN>
<TOKEN end_char="5062" id="token-38-26" morph="none" pos="word" start_char="5060">the</TOKEN>
<TOKEN end_char="5068" id="token-38-27" morph="none" pos="word" start_char="5064">Wuhan</TOKEN>
<TOKEN end_char="5072" id="token-38-28" morph="none" pos="word" start_char="5070">lab</TOKEN>
<TOKEN end_char="5073" id="token-38-29" morph="none" pos="punct" start_char="5073">,</TOKEN>
<TOKEN end_char="5077" id="token-38-30" morph="none" pos="word" start_char="5075">you</TOKEN>
<TOKEN end_char="5083" id="token-38-31" morph="none" pos="word" start_char="5079">would</TOKEN>
<TOKEN end_char="5085" id="token-38-32" morph="none" pos="punct" start_char="5085">"</TOKEN>
<TOKEN end_char="5089" id="token-38-33" morph="none" pos="word" start_char="5086">have</TOKEN>
<TOKEN end_char="5092" id="token-38-34" morph="none" pos="word" start_char="5091">to</TOKEN>
<TOKEN end_char="5100" id="token-38-35" morph="none" pos="word" start_char="5094">believe</TOKEN>
<TOKEN end_char="5103" id="token-38-36" morph="none" pos="word" start_char="5102">in</TOKEN>
<TOKEN end_char="5105" id="token-38-37" morph="none" pos="word" start_char="5105">a</TOKEN>
<TOKEN end_char="5115" id="token-38-38" morph="none" pos="word" start_char="5107">laughably</TOKEN>
<TOKEN end_char="5127" id="token-38-39" morph="none" pos="word" start_char="5117">implausible</TOKEN>
<TOKEN end_char="5131" id="token-38-40" morph="none" pos="word" start_char="5129">set</TOKEN>
<TOKEN end_char="5134" id="token-38-41" morph="none" pos="word" start_char="5133">of</TOKEN>
<TOKEN end_char="5147" id="token-38-42" morph="none" pos="word" start_char="5136">coincidences</TOKEN>
<TOKEN end_char="5149" id="token-38-43" morph="none" pos="punct" start_char="5148">."</TOKEN>
</SEG>
<SEG end_char="5338" id="segment-39" start_char="5151">
<ORIGINAL_TEXT>The bats in Yunnan province would have had to infect each other and another unknown animal or a human and then travel 1,000 miles  without infecting anyone else  until they got to Wuhan.</ORIGINAL_TEXT>
<TOKEN end_char="5153" id="token-39-0" morph="none" pos="word" start_char="5151">The</TOKEN>
<TOKEN end_char="5158" id="token-39-1" morph="none" pos="word" start_char="5155">bats</TOKEN>
<TOKEN end_char="5161" id="token-39-2" morph="none" pos="word" start_char="5160">in</TOKEN>
<TOKEN end_char="5168" id="token-39-3" morph="none" pos="word" start_char="5163">Yunnan</TOKEN>
<TOKEN end_char="5177" id="token-39-4" morph="none" pos="word" start_char="5170">province</TOKEN>
<TOKEN end_char="5183" id="token-39-5" morph="none" pos="word" start_char="5179">would</TOKEN>
<TOKEN end_char="5188" id="token-39-6" morph="none" pos="word" start_char="5185">have</TOKEN>
<TOKEN end_char="5192" id="token-39-7" morph="none" pos="word" start_char="5190">had</TOKEN>
<TOKEN end_char="5195" id="token-39-8" morph="none" pos="word" start_char="5194">to</TOKEN>
<TOKEN end_char="5202" id="token-39-9" morph="none" pos="word" start_char="5197">infect</TOKEN>
<TOKEN end_char="5207" id="token-39-10" morph="none" pos="word" start_char="5204">each</TOKEN>
<TOKEN end_char="5213" id="token-39-11" morph="none" pos="word" start_char="5209">other</TOKEN>
<TOKEN end_char="5217" id="token-39-12" morph="none" pos="word" start_char="5215">and</TOKEN>
<TOKEN end_char="5225" id="token-39-13" morph="none" pos="word" start_char="5219">another</TOKEN>
<TOKEN end_char="5233" id="token-39-14" morph="none" pos="word" start_char="5227">unknown</TOKEN>
<TOKEN end_char="5240" id="token-39-15" morph="none" pos="word" start_char="5235">animal</TOKEN>
<TOKEN end_char="5243" id="token-39-16" morph="none" pos="word" start_char="5242">or</TOKEN>
<TOKEN end_char="5245" id="token-39-17" morph="none" pos="word" start_char="5245">a</TOKEN>
<TOKEN end_char="5251" id="token-39-18" morph="none" pos="word" start_char="5247">human</TOKEN>
<TOKEN end_char="5255" id="token-39-19" morph="none" pos="word" start_char="5253">and</TOKEN>
<TOKEN end_char="5260" id="token-39-20" morph="none" pos="word" start_char="5257">then</TOKEN>
<TOKEN end_char="5267" id="token-39-21" morph="none" pos="word" start_char="5262">travel</TOKEN>
<TOKEN end_char="5273" id="token-39-22" morph="none" pos="unknown" start_char="5269">1,000</TOKEN>
<TOKEN end_char="5279" id="token-39-23" morph="none" pos="word" start_char="5275">miles</TOKEN>
<TOKEN end_char="5281" id="token-39-24" morph="none" pos="punct" start_char="5281"></TOKEN>
<TOKEN end_char="5289" id="token-39-25" morph="none" pos="word" start_char="5283">without</TOKEN>
<TOKEN end_char="5299" id="token-39-26" morph="none" pos="word" start_char="5291">infecting</TOKEN>
<TOKEN end_char="5306" id="token-39-27" morph="none" pos="word" start_char="5301">anyone</TOKEN>
<TOKEN end_char="5311" id="token-39-28" morph="none" pos="word" start_char="5308">else</TOKEN>
<TOKEN end_char="5313" id="token-39-29" morph="none" pos="punct" start_char="5313"></TOKEN>
<TOKEN end_char="5319" id="token-39-30" morph="none" pos="word" start_char="5315">until</TOKEN>
<TOKEN end_char="5324" id="token-39-31" morph="none" pos="word" start_char="5321">they</TOKEN>
<TOKEN end_char="5328" id="token-39-32" morph="none" pos="word" start_char="5326">got</TOKEN>
<TOKEN end_char="5331" id="token-39-33" morph="none" pos="word" start_char="5330">to</TOKEN>
<TOKEN end_char="5337" id="token-39-34" morph="none" pos="word" start_char="5333">Wuhan</TOKEN>
<TOKEN end_char="5338" id="token-39-35" morph="none" pos="punct" start_char="5338">.</TOKEN>
</SEG>
<SEG end_char="5472" id="segment-40" start_char="5341">
<ORIGINAL_TEXT>Before any mutations, he argued, the virus was 10 to 20 times more infectious than any previously observed virus occuring in nature.</ORIGINAL_TEXT>
<TOKEN end_char="5346" id="token-40-0" morph="none" pos="word" start_char="5341">Before</TOKEN>
<TOKEN end_char="5350" id="token-40-1" morph="none" pos="word" start_char="5348">any</TOKEN>
<TOKEN end_char="5360" id="token-40-2" morph="none" pos="word" start_char="5352">mutations</TOKEN>
<TOKEN end_char="5361" id="token-40-3" morph="none" pos="punct" start_char="5361">,</TOKEN>
<TOKEN end_char="5364" id="token-40-4" morph="none" pos="word" start_char="5363">he</TOKEN>
<TOKEN end_char="5371" id="token-40-5" morph="none" pos="word" start_char="5366">argued</TOKEN>
<TOKEN end_char="5372" id="token-40-6" morph="none" pos="punct" start_char="5372">,</TOKEN>
<TOKEN end_char="5376" id="token-40-7" morph="none" pos="word" start_char="5374">the</TOKEN>
<TOKEN end_char="5382" id="token-40-8" morph="none" pos="word" start_char="5378">virus</TOKEN>
<TOKEN end_char="5386" id="token-40-9" morph="none" pos="word" start_char="5384">was</TOKEN>
<TOKEN end_char="5389" id="token-40-10" morph="none" pos="word" start_char="5388">10</TOKEN>
<TOKEN end_char="5392" id="token-40-11" morph="none" pos="word" start_char="5391">to</TOKEN>
<TOKEN end_char="5395" id="token-40-12" morph="none" pos="word" start_char="5394">20</TOKEN>
<TOKEN end_char="5401" id="token-40-13" morph="none" pos="word" start_char="5397">times</TOKEN>
<TOKEN end_char="5406" id="token-40-14" morph="none" pos="word" start_char="5403">more</TOKEN>
<TOKEN end_char="5417" id="token-40-15" morph="none" pos="word" start_char="5408">infectious</TOKEN>
<TOKEN end_char="5422" id="token-40-16" morph="none" pos="word" start_char="5419">than</TOKEN>
<TOKEN end_char="5426" id="token-40-17" morph="none" pos="word" start_char="5424">any</TOKEN>
<TOKEN end_char="5437" id="token-40-18" morph="none" pos="word" start_char="5428">previously</TOKEN>
<TOKEN end_char="5446" id="token-40-19" morph="none" pos="word" start_char="5439">observed</TOKEN>
<TOKEN end_char="5452" id="token-40-20" morph="none" pos="word" start_char="5448">virus</TOKEN>
<TOKEN end_char="5461" id="token-40-21" morph="none" pos="word" start_char="5454">occuring</TOKEN>
<TOKEN end_char="5464" id="token-40-22" morph="none" pos="word" start_char="5463">in</TOKEN>
<TOKEN end_char="5471" id="token-40-23" morph="none" pos="word" start_char="5466">nature</TOKEN>
<TOKEN end_char="5472" id="token-40-24" morph="none" pos="punct" start_char="5472">.</TOKEN>
</SEG>
<SEG end_char="5723" id="segment-41" start_char="5475">
<ORIGINAL_TEXT>"And most incredibly of all," he added, "the infected animal or human would have somehow chosen to make that 1,000-mile trek to the only place in all of China that had been working for years on the virus it was already infected with," the Wuhan lab.</ORIGINAL_TEXT>
<TOKEN end_char="5475" id="token-41-0" morph="none" pos="punct" start_char="5475">"</TOKEN>
<TOKEN end_char="5478" id="token-41-1" morph="none" pos="word" start_char="5476">And</TOKEN>
<TOKEN end_char="5483" id="token-41-2" morph="none" pos="word" start_char="5480">most</TOKEN>
<TOKEN end_char="5494" id="token-41-3" morph="none" pos="word" start_char="5485">incredibly</TOKEN>
<TOKEN end_char="5497" id="token-41-4" morph="none" pos="word" start_char="5496">of</TOKEN>
<TOKEN end_char="5501" id="token-41-5" morph="none" pos="word" start_char="5499">all</TOKEN>
<TOKEN end_char="5503" id="token-41-6" morph="none" pos="punct" start_char="5502">,"</TOKEN>
<TOKEN end_char="5506" id="token-41-7" morph="none" pos="word" start_char="5505">he</TOKEN>
<TOKEN end_char="5512" id="token-41-8" morph="none" pos="word" start_char="5508">added</TOKEN>
<TOKEN end_char="5513" id="token-41-9" morph="none" pos="punct" start_char="5513">,</TOKEN>
<TOKEN end_char="5515" id="token-41-10" morph="none" pos="punct" start_char="5515">"</TOKEN>
<TOKEN end_char="5518" id="token-41-11" morph="none" pos="word" start_char="5516">the</TOKEN>
<TOKEN end_char="5527" id="token-41-12" morph="none" pos="word" start_char="5520">infected</TOKEN>
<TOKEN end_char="5534" id="token-41-13" morph="none" pos="word" start_char="5529">animal</TOKEN>
<TOKEN end_char="5537" id="token-41-14" morph="none" pos="word" start_char="5536">or</TOKEN>
<TOKEN end_char="5543" id="token-41-15" morph="none" pos="word" start_char="5539">human</TOKEN>
<TOKEN end_char="5549" id="token-41-16" morph="none" pos="word" start_char="5545">would</TOKEN>
<TOKEN end_char="5554" id="token-41-17" morph="none" pos="word" start_char="5551">have</TOKEN>
<TOKEN end_char="5562" id="token-41-18" morph="none" pos="word" start_char="5556">somehow</TOKEN>
<TOKEN end_char="5569" id="token-41-19" morph="none" pos="word" start_char="5564">chosen</TOKEN>
<TOKEN end_char="5572" id="token-41-20" morph="none" pos="word" start_char="5571">to</TOKEN>
<TOKEN end_char="5577" id="token-41-21" morph="none" pos="word" start_char="5574">make</TOKEN>
<TOKEN end_char="5582" id="token-41-22" morph="none" pos="word" start_char="5579">that</TOKEN>
<TOKEN end_char="5593" id="token-41-23" morph="none" pos="unknown" start_char="5584">1,000-mile</TOKEN>
<TOKEN end_char="5598" id="token-41-24" morph="none" pos="word" start_char="5595">trek</TOKEN>
<TOKEN end_char="5601" id="token-41-25" morph="none" pos="word" start_char="5600">to</TOKEN>
<TOKEN end_char="5605" id="token-41-26" morph="none" pos="word" start_char="5603">the</TOKEN>
<TOKEN end_char="5610" id="token-41-27" morph="none" pos="word" start_char="5607">only</TOKEN>
<TOKEN end_char="5616" id="token-41-28" morph="none" pos="word" start_char="5612">place</TOKEN>
<TOKEN end_char="5619" id="token-41-29" morph="none" pos="word" start_char="5618">in</TOKEN>
<TOKEN end_char="5623" id="token-41-30" morph="none" pos="word" start_char="5621">all</TOKEN>
<TOKEN end_char="5626" id="token-41-31" morph="none" pos="word" start_char="5625">of</TOKEN>
<TOKEN end_char="5632" id="token-41-32" morph="none" pos="word" start_char="5628">China</TOKEN>
<TOKEN end_char="5637" id="token-41-33" morph="none" pos="word" start_char="5634">that</TOKEN>
<TOKEN end_char="5641" id="token-41-34" morph="none" pos="word" start_char="5639">had</TOKEN>
<TOKEN end_char="5646" id="token-41-35" morph="none" pos="word" start_char="5643">been</TOKEN>
<TOKEN end_char="5654" id="token-41-36" morph="none" pos="word" start_char="5648">working</TOKEN>
<TOKEN end_char="5658" id="token-41-37" morph="none" pos="word" start_char="5656">for</TOKEN>
<TOKEN end_char="5664" id="token-41-38" morph="none" pos="word" start_char="5660">years</TOKEN>
<TOKEN end_char="5667" id="token-41-39" morph="none" pos="word" start_char="5666">on</TOKEN>
<TOKEN end_char="5671" id="token-41-40" morph="none" pos="word" start_char="5669">the</TOKEN>
<TOKEN end_char="5677" id="token-41-41" morph="none" pos="word" start_char="5673">virus</TOKEN>
<TOKEN end_char="5680" id="token-41-42" morph="none" pos="word" start_char="5679">it</TOKEN>
<TOKEN end_char="5684" id="token-41-43" morph="none" pos="word" start_char="5682">was</TOKEN>
<TOKEN end_char="5692" id="token-41-44" morph="none" pos="word" start_char="5686">already</TOKEN>
<TOKEN end_char="5701" id="token-41-45" morph="none" pos="word" start_char="5694">infected</TOKEN>
<TOKEN end_char="5706" id="token-41-46" morph="none" pos="word" start_char="5703">with</TOKEN>
<TOKEN end_char="5708" id="token-41-47" morph="none" pos="punct" start_char="5707">,"</TOKEN>
<TOKEN end_char="5712" id="token-41-48" morph="none" pos="word" start_char="5710">the</TOKEN>
<TOKEN end_char="5718" id="token-41-49" morph="none" pos="word" start_char="5714">Wuhan</TOKEN>
<TOKEN end_char="5722" id="token-41-50" morph="none" pos="word" start_char="5720">lab</TOKEN>
<TOKEN end_char="5723" id="token-41-51" morph="none" pos="punct" start_char="5723">.</TOKEN>
</SEG>
<SEG end_char="5795" id="segment-42" start_char="5726">
<ORIGINAL_TEXT>Significantly, the Chinese regime has blocked access to the Wuhan lab.</ORIGINAL_TEXT>
<TOKEN end_char="5738" id="token-42-0" morph="none" pos="word" start_char="5726">Significantly</TOKEN>
<TOKEN end_char="5739" id="token-42-1" morph="none" pos="punct" start_char="5739">,</TOKEN>
<TOKEN end_char="5743" id="token-42-2" morph="none" pos="word" start_char="5741">the</TOKEN>
<TOKEN end_char="5751" id="token-42-3" morph="none" pos="word" start_char="5745">Chinese</TOKEN>
<TOKEN end_char="5758" id="token-42-4" morph="none" pos="word" start_char="5753">regime</TOKEN>
<TOKEN end_char="5762" id="token-42-5" morph="none" pos="word" start_char="5760">has</TOKEN>
<TOKEN end_char="5770" id="token-42-6" morph="none" pos="word" start_char="5764">blocked</TOKEN>
<TOKEN end_char="5777" id="token-42-7" morph="none" pos="word" start_char="5772">access</TOKEN>
<TOKEN end_char="5780" id="token-42-8" morph="none" pos="word" start_char="5779">to</TOKEN>
<TOKEN end_char="5784" id="token-42-9" morph="none" pos="word" start_char="5782">the</TOKEN>
<TOKEN end_char="5790" id="token-42-10" morph="none" pos="word" start_char="5786">Wuhan</TOKEN>
<TOKEN end_char="5794" id="token-42-11" morph="none" pos="word" start_char="5792">lab</TOKEN>
<TOKEN end_char="5795" id="token-42-12" morph="none" pos="punct" start_char="5795">.</TOKEN>
</SEG>
<SEG end_char="5936" id="segment-43" start_char="5797">
<ORIGINAL_TEXT>Last week, NBC News reported that a Wuhan Institute of Virology database with 20,000 entries was removed last spring for "security reasons."</ORIGINAL_TEXT>
<TOKEN end_char="5800" id="token-43-0" morph="none" pos="word" start_char="5797">Last</TOKEN>
<TOKEN end_char="5805" id="token-43-1" morph="none" pos="word" start_char="5802">week</TOKEN>
<TOKEN end_char="5806" id="token-43-2" morph="none" pos="punct" start_char="5806">,</TOKEN>
<TOKEN end_char="5810" id="token-43-3" morph="none" pos="word" start_char="5808">NBC</TOKEN>
<TOKEN end_char="5815" id="token-43-4" morph="none" pos="word" start_char="5812">News</TOKEN>
<TOKEN end_char="5824" id="token-43-5" morph="none" pos="word" start_char="5817">reported</TOKEN>
<TOKEN end_char="5829" id="token-43-6" morph="none" pos="word" start_char="5826">that</TOKEN>
<TOKEN end_char="5831" id="token-43-7" morph="none" pos="word" start_char="5831">a</TOKEN>
<TOKEN end_char="5837" id="token-43-8" morph="none" pos="word" start_char="5833">Wuhan</TOKEN>
<TOKEN end_char="5847" id="token-43-9" morph="none" pos="word" start_char="5839">Institute</TOKEN>
<TOKEN end_char="5850" id="token-43-10" morph="none" pos="word" start_char="5849">of</TOKEN>
<TOKEN end_char="5859" id="token-43-11" morph="none" pos="word" start_char="5852">Virology</TOKEN>
<TOKEN end_char="5868" id="token-43-12" morph="none" pos="word" start_char="5861">database</TOKEN>
<TOKEN end_char="5873" id="token-43-13" morph="none" pos="word" start_char="5870">with</TOKEN>
<TOKEN end_char="5880" id="token-43-14" morph="none" pos="unknown" start_char="5875">20,000</TOKEN>
<TOKEN end_char="5888" id="token-43-15" morph="none" pos="word" start_char="5882">entries</TOKEN>
<TOKEN end_char="5892" id="token-43-16" morph="none" pos="word" start_char="5890">was</TOKEN>
<TOKEN end_char="5900" id="token-43-17" morph="none" pos="word" start_char="5894">removed</TOKEN>
<TOKEN end_char="5905" id="token-43-18" morph="none" pos="word" start_char="5902">last</TOKEN>
<TOKEN end_char="5912" id="token-43-19" morph="none" pos="word" start_char="5907">spring</TOKEN>
<TOKEN end_char="5916" id="token-43-20" morph="none" pos="word" start_char="5914">for</TOKEN>
<TOKEN end_char="5918" id="token-43-21" morph="none" pos="punct" start_char="5918">"</TOKEN>
<TOKEN end_char="5926" id="token-43-22" morph="none" pos="word" start_char="5919">security</TOKEN>
<TOKEN end_char="5934" id="token-43-23" morph="none" pos="word" start_char="5928">reasons</TOKEN>
<TOKEN end_char="5936" id="token-43-24" morph="none" pos="punct" start_char="5935">."</TOKEN>
</SEG>
<SEG end_char="6004" id="segment-44" start_char="5939">
<ORIGINAL_TEXT>But Hilton said the U.S. government also has not been forthcoming.</ORIGINAL_TEXT>
<TOKEN end_char="5941" id="token-44-0" morph="none" pos="word" start_char="5939">But</TOKEN>
<TOKEN end_char="5948" id="token-44-1" morph="none" pos="word" start_char="5943">Hilton</TOKEN>
<TOKEN end_char="5953" id="token-44-2" morph="none" pos="word" start_char="5950">said</TOKEN>
<TOKEN end_char="5957" id="token-44-3" morph="none" pos="word" start_char="5955">the</TOKEN>
<TOKEN end_char="5961" id="token-44-4" morph="none" pos="unknown" start_char="5959">U.S</TOKEN>
<TOKEN end_char="5962" id="token-44-5" morph="none" pos="punct" start_char="5962">.</TOKEN>
<TOKEN end_char="5973" id="token-44-6" morph="none" pos="word" start_char="5964">government</TOKEN>
<TOKEN end_char="5978" id="token-44-7" morph="none" pos="word" start_char="5975">also</TOKEN>
<TOKEN end_char="5982" id="token-44-8" morph="none" pos="word" start_char="5980">has</TOKEN>
<TOKEN end_char="5986" id="token-44-9" morph="none" pos="word" start_char="5984">not</TOKEN>
<TOKEN end_char="5991" id="token-44-10" morph="none" pos="word" start_char="5988">been</TOKEN>
<TOKEN end_char="6003" id="token-44-11" morph="none" pos="word" start_char="5993">forthcoming</TOKEN>
<TOKEN end_char="6004" id="token-44-12" morph="none" pos="punct" start_char="6004">.</TOKEN>
</SEG>
<SEG end_char="6200" id="segment-45" start_char="6006">
<ORIGINAL_TEXT>After two weeks, the NIH finally responded last Friday to his request for comment on the coronavirus gain-of-function research project that began after the Obama administration's halt in funding.</ORIGINAL_TEXT>
<TOKEN end_char="6010" id="token-45-0" morph="none" pos="word" start_char="6006">After</TOKEN>
<TOKEN end_char="6014" id="token-45-1" morph="none" pos="word" start_char="6012">two</TOKEN>
<TOKEN end_char="6020" id="token-45-2" morph="none" pos="word" start_char="6016">weeks</TOKEN>
<TOKEN end_char="6021" id="token-45-3" morph="none" pos="punct" start_char="6021">,</TOKEN>
<TOKEN end_char="6025" id="token-45-4" morph="none" pos="word" start_char="6023">the</TOKEN>
<TOKEN end_char="6029" id="token-45-5" morph="none" pos="word" start_char="6027">NIH</TOKEN>
<TOKEN end_char="6037" id="token-45-6" morph="none" pos="word" start_char="6031">finally</TOKEN>
<TOKEN end_char="6047" id="token-45-7" morph="none" pos="word" start_char="6039">responded</TOKEN>
<TOKEN end_char="6052" id="token-45-8" morph="none" pos="word" start_char="6049">last</TOKEN>
<TOKEN end_char="6059" id="token-45-9" morph="none" pos="word" start_char="6054">Friday</TOKEN>
<TOKEN end_char="6062" id="token-45-10" morph="none" pos="word" start_char="6061">to</TOKEN>
<TOKEN end_char="6066" id="token-45-11" morph="none" pos="word" start_char="6064">his</TOKEN>
<TOKEN end_char="6074" id="token-45-12" morph="none" pos="word" start_char="6068">request</TOKEN>
<TOKEN end_char="6078" id="token-45-13" morph="none" pos="word" start_char="6076">for</TOKEN>
<TOKEN end_char="6086" id="token-45-14" morph="none" pos="word" start_char="6080">comment</TOKEN>
<TOKEN end_char="6089" id="token-45-15" morph="none" pos="word" start_char="6088">on</TOKEN>
<TOKEN end_char="6093" id="token-45-16" morph="none" pos="word" start_char="6091">the</TOKEN>
<TOKEN end_char="6105" id="token-45-17" morph="none" pos="word" start_char="6095">coronavirus</TOKEN>
<TOKEN end_char="6122" id="token-45-18" morph="none" pos="unknown" start_char="6107">gain-of-function</TOKEN>
<TOKEN end_char="6131" id="token-45-19" morph="none" pos="word" start_char="6124">research</TOKEN>
<TOKEN end_char="6139" id="token-45-20" morph="none" pos="word" start_char="6133">project</TOKEN>
<TOKEN end_char="6144" id="token-45-21" morph="none" pos="word" start_char="6141">that</TOKEN>
<TOKEN end_char="6150" id="token-45-22" morph="none" pos="word" start_char="6146">began</TOKEN>
<TOKEN end_char="6156" id="token-45-23" morph="none" pos="word" start_char="6152">after</TOKEN>
<TOKEN end_char="6160" id="token-45-24" morph="none" pos="word" start_char="6158">the</TOKEN>
<TOKEN end_char="6166" id="token-45-25" morph="none" pos="word" start_char="6162">Obama</TOKEN>
<TOKEN end_char="6183" id="token-45-26" morph="none" pos="word" start_char="6168">administration's</TOKEN>
<TOKEN end_char="6188" id="token-45-27" morph="none" pos="word" start_char="6185">halt</TOKEN>
<TOKEN end_char="6191" id="token-45-28" morph="none" pos="word" start_char="6190">in</TOKEN>
<TOKEN end_char="6199" id="token-45-29" morph="none" pos="word" start_char="6193">funding</TOKEN>
<TOKEN end_char="6200" id="token-45-30" morph="none" pos="punct" start_char="6200">.</TOKEN>
</SEG>
<SEG end_char="6277" id="segment-46" start_char="6203">
<ORIGINAL_TEXT>The NIH replied that the project did not involve gain-of-function research.</ORIGINAL_TEXT>
<TOKEN end_char="6205" id="token-46-0" morph="none" pos="word" start_char="6203">The</TOKEN>
<TOKEN end_char="6209" id="token-46-1" morph="none" pos="word" start_char="6207">NIH</TOKEN>
<TOKEN end_char="6217" id="token-46-2" morph="none" pos="word" start_char="6211">replied</TOKEN>
<TOKEN end_char="6222" id="token-46-3" morph="none" pos="word" start_char="6219">that</TOKEN>
<TOKEN end_char="6226" id="token-46-4" morph="none" pos="word" start_char="6224">the</TOKEN>
<TOKEN end_char="6234" id="token-46-5" morph="none" pos="word" start_char="6228">project</TOKEN>
<TOKEN end_char="6238" id="token-46-6" morph="none" pos="word" start_char="6236">did</TOKEN>
<TOKEN end_char="6242" id="token-46-7" morph="none" pos="word" start_char="6240">not</TOKEN>
<TOKEN end_char="6250" id="token-46-8" morph="none" pos="word" start_char="6244">involve</TOKEN>
<TOKEN end_char="6267" id="token-46-9" morph="none" pos="unknown" start_char="6252">gain-of-function</TOKEN>
<TOKEN end_char="6276" id="token-46-10" morph="none" pos="word" start_char="6269">research</TOKEN>
<TOKEN end_char="6277" id="token-46-11" morph="none" pos="punct" start_char="6277">.</TOKEN>
</SEG>
<SEG end_char="6419" id="segment-47" start_char="6279">
<ORIGINAL_TEXT>But Hilton noted that the project to which NIH referred was not the project he was asking about, which clearly was gain-of-function research.</ORIGINAL_TEXT>
<TOKEN end_char="6281" id="token-47-0" morph="none" pos="word" start_char="6279">But</TOKEN>
<TOKEN end_char="6288" id="token-47-1" morph="none" pos="word" start_char="6283">Hilton</TOKEN>
<TOKEN end_char="6294" id="token-47-2" morph="none" pos="word" start_char="6290">noted</TOKEN>
<TOKEN end_char="6299" id="token-47-3" morph="none" pos="word" start_char="6296">that</TOKEN>
<TOKEN end_char="6303" id="token-47-4" morph="none" pos="word" start_char="6301">the</TOKEN>
<TOKEN end_char="6311" id="token-47-5" morph="none" pos="word" start_char="6305">project</TOKEN>
<TOKEN end_char="6314" id="token-47-6" morph="none" pos="word" start_char="6313">to</TOKEN>
<TOKEN end_char="6320" id="token-47-7" morph="none" pos="word" start_char="6316">which</TOKEN>
<TOKEN end_char="6324" id="token-47-8" morph="none" pos="word" start_char="6322">NIH</TOKEN>
<TOKEN end_char="6333" id="token-47-9" morph="none" pos="word" start_char="6326">referred</TOKEN>
<TOKEN end_char="6337" id="token-47-10" morph="none" pos="word" start_char="6335">was</TOKEN>
<TOKEN end_char="6341" id="token-47-11" morph="none" pos="word" start_char="6339">not</TOKEN>
<TOKEN end_char="6345" id="token-47-12" morph="none" pos="word" start_char="6343">the</TOKEN>
<TOKEN end_char="6353" id="token-47-13" morph="none" pos="word" start_char="6347">project</TOKEN>
<TOKEN end_char="6356" id="token-47-14" morph="none" pos="word" start_char="6355">he</TOKEN>
<TOKEN end_char="6360" id="token-47-15" morph="none" pos="word" start_char="6358">was</TOKEN>
<TOKEN end_char="6367" id="token-47-16" morph="none" pos="word" start_char="6362">asking</TOKEN>
<TOKEN end_char="6373" id="token-47-17" morph="none" pos="word" start_char="6369">about</TOKEN>
<TOKEN end_char="6374" id="token-47-18" morph="none" pos="punct" start_char="6374">,</TOKEN>
<TOKEN end_char="6380" id="token-47-19" morph="none" pos="word" start_char="6376">which</TOKEN>
<TOKEN end_char="6388" id="token-47-20" morph="none" pos="word" start_char="6382">clearly</TOKEN>
<TOKEN end_char="6392" id="token-47-21" morph="none" pos="word" start_char="6390">was</TOKEN>
<TOKEN end_char="6409" id="token-47-22" morph="none" pos="unknown" start_char="6394">gain-of-function</TOKEN>
<TOKEN end_char="6418" id="token-47-23" morph="none" pos="word" start_char="6411">research</TOKEN>
<TOKEN end_char="6419" id="token-47-24" morph="none" pos="punct" start_char="6419">.</TOKEN>
</SEG>
<SEG end_char="6573" id="segment-48" start_char="6422">
<ORIGINAL_TEXT>Calling the response "deceptive," he wanted to know whether or not the director of NIH, the famed scientist Francis Collins, was aware of the statement.</ORIGINAL_TEXT>
<TOKEN end_char="6428" id="token-48-0" morph="none" pos="word" start_char="6422">Calling</TOKEN>
<TOKEN end_char="6432" id="token-48-1" morph="none" pos="word" start_char="6430">the</TOKEN>
<TOKEN end_char="6441" id="token-48-2" morph="none" pos="word" start_char="6434">response</TOKEN>
<TOKEN end_char="6443" id="token-48-3" morph="none" pos="punct" start_char="6443">"</TOKEN>
<TOKEN end_char="6452" id="token-48-4" morph="none" pos="word" start_char="6444">deceptive</TOKEN>
<TOKEN end_char="6454" id="token-48-5" morph="none" pos="punct" start_char="6453">,"</TOKEN>
<TOKEN end_char="6457" id="token-48-6" morph="none" pos="word" start_char="6456">he</TOKEN>
<TOKEN end_char="6464" id="token-48-7" morph="none" pos="word" start_char="6459">wanted</TOKEN>
<TOKEN end_char="6467" id="token-48-8" morph="none" pos="word" start_char="6466">to</TOKEN>
<TOKEN end_char="6472" id="token-48-9" morph="none" pos="word" start_char="6469">know</TOKEN>
<TOKEN end_char="6480" id="token-48-10" morph="none" pos="word" start_char="6474">whether</TOKEN>
<TOKEN end_char="6483" id="token-48-11" morph="none" pos="word" start_char="6482">or</TOKEN>
<TOKEN end_char="6487" id="token-48-12" morph="none" pos="word" start_char="6485">not</TOKEN>
<TOKEN end_char="6491" id="token-48-13" morph="none" pos="word" start_char="6489">the</TOKEN>
<TOKEN end_char="6500" id="token-48-14" morph="none" pos="word" start_char="6493">director</TOKEN>
<TOKEN end_char="6503" id="token-48-15" morph="none" pos="word" start_char="6502">of</TOKEN>
<TOKEN end_char="6507" id="token-48-16" morph="none" pos="word" start_char="6505">NIH</TOKEN>
<TOKEN end_char="6508" id="token-48-17" morph="none" pos="punct" start_char="6508">,</TOKEN>
<TOKEN end_char="6512" id="token-48-18" morph="none" pos="word" start_char="6510">the</TOKEN>
<TOKEN end_char="6518" id="token-48-19" morph="none" pos="word" start_char="6514">famed</TOKEN>
<TOKEN end_char="6528" id="token-48-20" morph="none" pos="word" start_char="6520">scientist</TOKEN>
<TOKEN end_char="6536" id="token-48-21" morph="none" pos="word" start_char="6530">Francis</TOKEN>
<TOKEN end_char="6544" id="token-48-22" morph="none" pos="word" start_char="6538">Collins</TOKEN>
<TOKEN end_char="6545" id="token-48-23" morph="none" pos="punct" start_char="6545">,</TOKEN>
<TOKEN end_char="6549" id="token-48-24" morph="none" pos="word" start_char="6547">was</TOKEN>
<TOKEN end_char="6555" id="token-48-25" morph="none" pos="word" start_char="6551">aware</TOKEN>
<TOKEN end_char="6558" id="token-48-26" morph="none" pos="word" start_char="6557">of</TOKEN>
<TOKEN end_char="6562" id="token-48-27" morph="none" pos="word" start_char="6560">the</TOKEN>
<TOKEN end_char="6572" id="token-48-28" morph="none" pos="word" start_char="6564">statement</TOKEN>
<TOKEN end_char="6573" id="token-48-29" morph="none" pos="punct" start_char="6573">.</TOKEN>
</SEG>
<SEG end_char="6696" id="segment-49" start_char="6576">
<ORIGINAL_TEXT>The Chinese regime can certainly be blamed for a cover-up allowing the outbreak to become a global pandemic, Hilton said.</ORIGINAL_TEXT>
<TOKEN end_char="6578" id="token-49-0" morph="none" pos="word" start_char="6576">The</TOKEN>
<TOKEN end_char="6586" id="token-49-1" morph="none" pos="word" start_char="6580">Chinese</TOKEN>
<TOKEN end_char="6593" id="token-49-2" morph="none" pos="word" start_char="6588">regime</TOKEN>
<TOKEN end_char="6597" id="token-49-3" morph="none" pos="word" start_char="6595">can</TOKEN>
<TOKEN end_char="6607" id="token-49-4" morph="none" pos="word" start_char="6599">certainly</TOKEN>
<TOKEN end_char="6610" id="token-49-5" morph="none" pos="word" start_char="6609">be</TOKEN>
<TOKEN end_char="6617" id="token-49-6" morph="none" pos="word" start_char="6612">blamed</TOKEN>
<TOKEN end_char="6621" id="token-49-7" morph="none" pos="word" start_char="6619">for</TOKEN>
<TOKEN end_char="6623" id="token-49-8" morph="none" pos="word" start_char="6623">a</TOKEN>
<TOKEN end_char="6632" id="token-49-9" morph="none" pos="unknown" start_char="6625">cover-up</TOKEN>
<TOKEN end_char="6641" id="token-49-10" morph="none" pos="word" start_char="6634">allowing</TOKEN>
<TOKEN end_char="6645" id="token-49-11" morph="none" pos="word" start_char="6643">the</TOKEN>
<TOKEN end_char="6654" id="token-49-12" morph="none" pos="word" start_char="6647">outbreak</TOKEN>
<TOKEN end_char="6657" id="token-49-13" morph="none" pos="word" start_char="6656">to</TOKEN>
<TOKEN end_char="6664" id="token-49-14" morph="none" pos="word" start_char="6659">become</TOKEN>
<TOKEN end_char="6666" id="token-49-15" morph="none" pos="word" start_char="6666">a</TOKEN>
<TOKEN end_char="6673" id="token-49-16" morph="none" pos="word" start_char="6668">global</TOKEN>
<TOKEN end_char="6682" id="token-49-17" morph="none" pos="word" start_char="6675">pandemic</TOKEN>
<TOKEN end_char="6683" id="token-49-18" morph="none" pos="punct" start_char="6683">,</TOKEN>
<TOKEN end_char="6690" id="token-49-19" morph="none" pos="word" start_char="6685">Hilton</TOKEN>
<TOKEN end_char="6695" id="token-49-20" morph="none" pos="word" start_char="6692">said</TOKEN>
<TOKEN end_char="6696" id="token-49-21" morph="none" pos="punct" start_char="6696">.</TOKEN>
</SEG>
<SEG end_char="6943" id="segment-50" start_char="6698">
<ORIGINAL_TEXT>But the reason the virus exists and is so contagious, he asserted, can be traced back to the decision of Collins and Fauci to go ahead with the gain-of-function research as a "risk worth taking" after the Obama administration stopped the funding.</ORIGINAL_TEXT>
<TOKEN end_char="6700" id="token-50-0" morph="none" pos="word" start_char="6698">But</TOKEN>
<TOKEN end_char="6704" id="token-50-1" morph="none" pos="word" start_char="6702">the</TOKEN>
<TOKEN end_char="6711" id="token-50-2" morph="none" pos="word" start_char="6706">reason</TOKEN>
<TOKEN end_char="6715" id="token-50-3" morph="none" pos="word" start_char="6713">the</TOKEN>
<TOKEN end_char="6721" id="token-50-4" morph="none" pos="word" start_char="6717">virus</TOKEN>
<TOKEN end_char="6728" id="token-50-5" morph="none" pos="word" start_char="6723">exists</TOKEN>
<TOKEN end_char="6732" id="token-50-6" morph="none" pos="word" start_char="6730">and</TOKEN>
<TOKEN end_char="6735" id="token-50-7" morph="none" pos="word" start_char="6734">is</TOKEN>
<TOKEN end_char="6738" id="token-50-8" morph="none" pos="word" start_char="6737">so</TOKEN>
<TOKEN end_char="6749" id="token-50-9" morph="none" pos="word" start_char="6740">contagious</TOKEN>
<TOKEN end_char="6750" id="token-50-10" morph="none" pos="punct" start_char="6750">,</TOKEN>
<TOKEN end_char="6753" id="token-50-11" morph="none" pos="word" start_char="6752">he</TOKEN>
<TOKEN end_char="6762" id="token-50-12" morph="none" pos="word" start_char="6755">asserted</TOKEN>
<TOKEN end_char="6763" id="token-50-13" morph="none" pos="punct" start_char="6763">,</TOKEN>
<TOKEN end_char="6767" id="token-50-14" morph="none" pos="word" start_char="6765">can</TOKEN>
<TOKEN end_char="6770" id="token-50-15" morph="none" pos="word" start_char="6769">be</TOKEN>
<TOKEN end_char="6777" id="token-50-16" morph="none" pos="word" start_char="6772">traced</TOKEN>
<TOKEN end_char="6782" id="token-50-17" morph="none" pos="word" start_char="6779">back</TOKEN>
<TOKEN end_char="6785" id="token-50-18" morph="none" pos="word" start_char="6784">to</TOKEN>
<TOKEN end_char="6789" id="token-50-19" morph="none" pos="word" start_char="6787">the</TOKEN>
<TOKEN end_char="6798" id="token-50-20" morph="none" pos="word" start_char="6791">decision</TOKEN>
<TOKEN end_char="6801" id="token-50-21" morph="none" pos="word" start_char="6800">of</TOKEN>
<TOKEN end_char="6809" id="token-50-22" morph="none" pos="word" start_char="6803">Collins</TOKEN>
<TOKEN end_char="6813" id="token-50-23" morph="none" pos="word" start_char="6811">and</TOKEN>
<TOKEN end_char="6819" id="token-50-24" morph="none" pos="word" start_char="6815">Fauci</TOKEN>
<TOKEN end_char="6822" id="token-50-25" morph="none" pos="word" start_char="6821">to</TOKEN>
<TOKEN end_char="6825" id="token-50-26" morph="none" pos="word" start_char="6824">go</TOKEN>
<TOKEN end_char="6831" id="token-50-27" morph="none" pos="word" start_char="6827">ahead</TOKEN>
<TOKEN end_char="6836" id="token-50-28" morph="none" pos="word" start_char="6833">with</TOKEN>
<TOKEN end_char="6840" id="token-50-29" morph="none" pos="word" start_char="6838">the</TOKEN>
<TOKEN end_char="6857" id="token-50-30" morph="none" pos="unknown" start_char="6842">gain-of-function</TOKEN>
<TOKEN end_char="6866" id="token-50-31" morph="none" pos="word" start_char="6859">research</TOKEN>
<TOKEN end_char="6869" id="token-50-32" morph="none" pos="word" start_char="6868">as</TOKEN>
<TOKEN end_char="6871" id="token-50-33" morph="none" pos="word" start_char="6871">a</TOKEN>
<TOKEN end_char="6873" id="token-50-34" morph="none" pos="punct" start_char="6873">"</TOKEN>
<TOKEN end_char="6877" id="token-50-35" morph="none" pos="word" start_char="6874">risk</TOKEN>
<TOKEN end_char="6883" id="token-50-36" morph="none" pos="word" start_char="6879">worth</TOKEN>
<TOKEN end_char="6890" id="token-50-37" morph="none" pos="word" start_char="6885">taking</TOKEN>
<TOKEN end_char="6891" id="token-50-38" morph="none" pos="punct" start_char="6891">"</TOKEN>
<TOKEN end_char="6897" id="token-50-39" morph="none" pos="word" start_char="6893">after</TOKEN>
<TOKEN end_char="6901" id="token-50-40" morph="none" pos="word" start_char="6899">the</TOKEN>
<TOKEN end_char="6907" id="token-50-41" morph="none" pos="word" start_char="6903">Obama</TOKEN>
<TOKEN end_char="6922" id="token-50-42" morph="none" pos="word" start_char="6909">administration</TOKEN>
<TOKEN end_char="6930" id="token-50-43" morph="none" pos="word" start_char="6924">stopped</TOKEN>
<TOKEN end_char="6934" id="token-50-44" morph="none" pos="word" start_char="6932">the</TOKEN>
<TOKEN end_char="6942" id="token-50-45" morph="none" pos="word" start_char="6936">funding</TOKEN>
<TOKEN end_char="6943" id="token-50-46" morph="none" pos="punct" start_char="6943">.</TOKEN>
</SEG>
<SEG end_char="7019" id="segment-51" start_char="6946">
<ORIGINAL_TEXT>"Of course Dr. Collins or Dr. Fauci didn't create the pandemic on purpose.</ORIGINAL_TEXT>
<TOKEN end_char="6946" id="token-51-0" morph="none" pos="punct" start_char="6946">"</TOKEN>
<TOKEN end_char="6948" id="token-51-1" morph="none" pos="word" start_char="6947">Of</TOKEN>
<TOKEN end_char="6955" id="token-51-2" morph="none" pos="word" start_char="6950">course</TOKEN>
<TOKEN end_char="6958" id="token-51-3" morph="none" pos="word" start_char="6957">Dr</TOKEN>
<TOKEN end_char="6959" id="token-51-4" morph="none" pos="punct" start_char="6959">.</TOKEN>
<TOKEN end_char="6967" id="token-51-5" morph="none" pos="word" start_char="6961">Collins</TOKEN>
<TOKEN end_char="6970" id="token-51-6" morph="none" pos="word" start_char="6969">or</TOKEN>
<TOKEN end_char="6973" id="token-51-7" morph="none" pos="word" start_char="6972">Dr</TOKEN>
<TOKEN end_char="6974" id="token-51-8" morph="none" pos="punct" start_char="6974">.</TOKEN>
<TOKEN end_char="6980" id="token-51-9" morph="none" pos="word" start_char="6976">Fauci</TOKEN>
<TOKEN end_char="6987" id="token-51-10" morph="none" pos="word" start_char="6982">didn't</TOKEN>
<TOKEN end_char="6994" id="token-51-11" morph="none" pos="word" start_char="6989">create</TOKEN>
<TOKEN end_char="6998" id="token-51-12" morph="none" pos="word" start_char="6996">the</TOKEN>
<TOKEN end_char="7007" id="token-51-13" morph="none" pos="word" start_char="7000">pandemic</TOKEN>
<TOKEN end_char="7010" id="token-51-14" morph="none" pos="word" start_char="7009">on</TOKEN>
<TOKEN end_char="7018" id="token-51-15" morph="none" pos="word" start_char="7012">purpose</TOKEN>
<TOKEN end_char="7019" id="token-51-16" morph="none" pos="punct" start_char="7019">.</TOKEN>
</SEG>
<SEG end_char="7048" id="segment-52" start_char="7021">
<ORIGINAL_TEXT>That is obviously ludicrous.</ORIGINAL_TEXT>
<TOKEN end_char="7024" id="token-52-0" morph="none" pos="word" start_char="7021">That</TOKEN>
<TOKEN end_char="7027" id="token-52-1" morph="none" pos="word" start_char="7026">is</TOKEN>
<TOKEN end_char="7037" id="token-52-2" morph="none" pos="word" start_char="7029">obviously</TOKEN>
<TOKEN end_char="7047" id="token-52-3" morph="none" pos="word" start_char="7039">ludicrous</TOKEN>
<TOKEN end_char="7048" id="token-52-4" morph="none" pos="punct" start_char="7048">.</TOKEN>
</SEG>
<SEG end_char="7115" id="segment-53" start_char="7050">
<ORIGINAL_TEXT>They've dedicated their careers to fighting disease," Hilton said.</ORIGINAL_TEXT>
<TOKEN end_char="7056" id="token-53-0" morph="none" pos="word" start_char="7050">They've</TOKEN>
<TOKEN end_char="7066" id="token-53-1" morph="none" pos="word" start_char="7058">dedicated</TOKEN>
<TOKEN end_char="7072" id="token-53-2" morph="none" pos="word" start_char="7068">their</TOKEN>
<TOKEN end_char="7080" id="token-53-3" morph="none" pos="word" start_char="7074">careers</TOKEN>
<TOKEN end_char="7083" id="token-53-4" morph="none" pos="word" start_char="7082">to</TOKEN>
<TOKEN end_char="7092" id="token-53-5" morph="none" pos="word" start_char="7085">fighting</TOKEN>
<TOKEN end_char="7100" id="token-53-6" morph="none" pos="word" start_char="7094">disease</TOKEN>
<TOKEN end_char="7102" id="token-53-7" morph="none" pos="punct" start_char="7101">,"</TOKEN>
<TOKEN end_char="7109" id="token-53-8" morph="none" pos="word" start_char="7104">Hilton</TOKEN>
<TOKEN end_char="7114" id="token-53-9" morph="none" pos="word" start_char="7111">said</TOKEN>
<TOKEN end_char="7115" id="token-53-10" morph="none" pos="punct" start_char="7115">.</TOKEN>
</SEG>
<SEG end_char="7220" id="segment-54" start_char="7118">
<ORIGINAL_TEXT>"But there's little doubt that one of their weapons of choice in that fight did lead to this pandemic."</ORIGINAL_TEXT>
<TOKEN end_char="7118" id="token-54-0" morph="none" pos="punct" start_char="7118">"</TOKEN>
<TOKEN end_char="7121" id="token-54-1" morph="none" pos="word" start_char="7119">But</TOKEN>
<TOKEN end_char="7129" id="token-54-2" morph="none" pos="word" start_char="7123">there's</TOKEN>
<TOKEN end_char="7136" id="token-54-3" morph="none" pos="word" start_char="7131">little</TOKEN>
<TOKEN end_char="7142" id="token-54-4" morph="none" pos="word" start_char="7138">doubt</TOKEN>
<TOKEN end_char="7147" id="token-54-5" morph="none" pos="word" start_char="7144">that</TOKEN>
<TOKEN end_char="7151" id="token-54-6" morph="none" pos="word" start_char="7149">one</TOKEN>
<TOKEN end_char="7154" id="token-54-7" morph="none" pos="word" start_char="7153">of</TOKEN>
<TOKEN end_char="7160" id="token-54-8" morph="none" pos="word" start_char="7156">their</TOKEN>
<TOKEN end_char="7168" id="token-54-9" morph="none" pos="word" start_char="7162">weapons</TOKEN>
<TOKEN end_char="7171" id="token-54-10" morph="none" pos="word" start_char="7170">of</TOKEN>
<TOKEN end_char="7178" id="token-54-11" morph="none" pos="word" start_char="7173">choice</TOKEN>
<TOKEN end_char="7181" id="token-54-12" morph="none" pos="word" start_char="7180">in</TOKEN>
<TOKEN end_char="7186" id="token-54-13" morph="none" pos="word" start_char="7183">that</TOKEN>
<TOKEN end_char="7192" id="token-54-14" morph="none" pos="word" start_char="7188">fight</TOKEN>
<TOKEN end_char="7196" id="token-54-15" morph="none" pos="word" start_char="7194">did</TOKEN>
<TOKEN end_char="7201" id="token-54-16" morph="none" pos="word" start_char="7198">lead</TOKEN>
<TOKEN end_char="7204" id="token-54-17" morph="none" pos="word" start_char="7203">to</TOKEN>
<TOKEN end_char="7209" id="token-54-18" morph="none" pos="word" start_char="7206">this</TOKEN>
<TOKEN end_char="7218" id="token-54-19" morph="none" pos="word" start_char="7211">pandemic</TOKEN>
<TOKEN end_char="7220" id="token-54-20" morph="none" pos="punct" start_char="7219">."</TOKEN>
</SEG>
<SEG end_char="7264" id="segment-55" start_char="7223">
<ORIGINAL_TEXT>And they were warned that it could happen.</ORIGINAL_TEXT>
<TOKEN end_char="7225" id="token-55-0" morph="none" pos="word" start_char="7223">And</TOKEN>
<TOKEN end_char="7230" id="token-55-1" morph="none" pos="word" start_char="7227">they</TOKEN>
<TOKEN end_char="7235" id="token-55-2" morph="none" pos="word" start_char="7232">were</TOKEN>
<TOKEN end_char="7242" id="token-55-3" morph="none" pos="word" start_char="7237">warned</TOKEN>
<TOKEN end_char="7247" id="token-55-4" morph="none" pos="word" start_char="7244">that</TOKEN>
<TOKEN end_char="7250" id="token-55-5" morph="none" pos="word" start_char="7249">it</TOKEN>
<TOKEN end_char="7256" id="token-55-6" morph="none" pos="word" start_char="7252">could</TOKEN>
<TOKEN end_char="7263" id="token-55-7" morph="none" pos="word" start_char="7258">happen</TOKEN>
<TOKEN end_char="7264" id="token-55-8" morph="none" pos="punct" start_char="7264">.</TOKEN>
</SEG>
<SEG end_char="7292" id="segment-56" start_char="7267">
<ORIGINAL_TEXT>Finding the Achilles' heel</ORIGINAL_TEXT>
<TOKEN end_char="7273" id="token-56-0" morph="none" pos="word" start_char="7267">Finding</TOKEN>
<TOKEN end_char="7277" id="token-56-1" morph="none" pos="word" start_char="7275">the</TOKEN>
<TOKEN end_char="7286" id="token-56-2" morph="none" pos="word" start_char="7279">Achilles</TOKEN>
<TOKEN end_char="7287" id="token-56-3" morph="none" pos="punct" start_char="7287">'</TOKEN>
<TOKEN end_char="7292" id="token-56-4" morph="none" pos="word" start_char="7289">heel</TOKEN>
</SEG>
<SEG end_char="7481" id="segment-57" start_char="7295">
<ORIGINAL_TEXT>A Newsweek report in April 2020 confirmed that NAID funded scientists at the Wuhan Institute of Virology and other institutions for work on gain-of-function research on bat coronaviruses.</ORIGINAL_TEXT>
<TOKEN end_char="7295" id="token-57-0" morph="none" pos="word" start_char="7295">A</TOKEN>
<TOKEN end_char="7304" id="token-57-1" morph="none" pos="word" start_char="7297">Newsweek</TOKEN>
<TOKEN end_char="7311" id="token-57-2" morph="none" pos="word" start_char="7306">report</TOKEN>
<TOKEN end_char="7314" id="token-57-3" morph="none" pos="word" start_char="7313">in</TOKEN>
<TOKEN end_char="7320" id="token-57-4" morph="none" pos="word" start_char="7316">April</TOKEN>
<TOKEN end_char="7325" id="token-57-5" morph="none" pos="word" start_char="7322">2020</TOKEN>
<TOKEN end_char="7335" id="token-57-6" morph="none" pos="word" start_char="7327">confirmed</TOKEN>
<TOKEN end_char="7340" id="token-57-7" morph="none" pos="word" start_char="7337">that</TOKEN>
<TOKEN end_char="7345" id="token-57-8" morph="none" pos="word" start_char="7342">NAID</TOKEN>
<TOKEN end_char="7352" id="token-57-9" morph="none" pos="word" start_char="7347">funded</TOKEN>
<TOKEN end_char="7363" id="token-57-10" morph="none" pos="word" start_char="7354">scientists</TOKEN>
<TOKEN end_char="7366" id="token-57-11" morph="none" pos="word" start_char="7365">at</TOKEN>
<TOKEN end_char="7370" id="token-57-12" morph="none" pos="word" start_char="7368">the</TOKEN>
<TOKEN end_char="7376" id="token-57-13" morph="none" pos="word" start_char="7372">Wuhan</TOKEN>
<TOKEN end_char="7386" id="token-57-14" morph="none" pos="word" start_char="7378">Institute</TOKEN>
<TOKEN end_char="7389" id="token-57-15" morph="none" pos="word" start_char="7388">of</TOKEN>
<TOKEN end_char="7398" id="token-57-16" morph="none" pos="word" start_char="7391">Virology</TOKEN>
<TOKEN end_char="7402" id="token-57-17" morph="none" pos="word" start_char="7400">and</TOKEN>
<TOKEN end_char="7408" id="token-57-18" morph="none" pos="word" start_char="7404">other</TOKEN>
<TOKEN end_char="7421" id="token-57-19" morph="none" pos="word" start_char="7410">institutions</TOKEN>
<TOKEN end_char="7425" id="token-57-20" morph="none" pos="word" start_char="7423">for</TOKEN>
<TOKEN end_char="7430" id="token-57-21" morph="none" pos="word" start_char="7427">work</TOKEN>
<TOKEN end_char="7433" id="token-57-22" morph="none" pos="word" start_char="7432">on</TOKEN>
<TOKEN end_char="7450" id="token-57-23" morph="none" pos="unknown" start_char="7435">gain-of-function</TOKEN>
<TOKEN end_char="7459" id="token-57-24" morph="none" pos="word" start_char="7452">research</TOKEN>
<TOKEN end_char="7462" id="token-57-25" morph="none" pos="word" start_char="7461">on</TOKEN>
<TOKEN end_char="7466" id="token-57-26" morph="none" pos="word" start_char="7464">bat</TOKEN>
<TOKEN end_char="7480" id="token-57-27" morph="none" pos="word" start_char="7468">coronaviruses</TOKEN>
<TOKEN end_char="7481" id="token-57-28" morph="none" pos="punct" start_char="7481">.</TOKEN>
</SEG>
<SEG end_char="7705" id="segment-58" start_char="7483">
<ORIGINAL_TEXT>In 2011, Fauci played an important role in promoting the work, arguing the research was worth the risk, because it could enable scientists to prepare treatments and vaccines in advance if a pandemic occurred, Newsweek said.</ORIGINAL_TEXT>
<TOKEN end_char="7484" id="token-58-0" morph="none" pos="word" start_char="7483">In</TOKEN>
<TOKEN end_char="7489" id="token-58-1" morph="none" pos="word" start_char="7486">2011</TOKEN>
<TOKEN end_char="7490" id="token-58-2" morph="none" pos="punct" start_char="7490">,</TOKEN>
<TOKEN end_char="7496" id="token-58-3" morph="none" pos="word" start_char="7492">Fauci</TOKEN>
<TOKEN end_char="7503" id="token-58-4" morph="none" pos="word" start_char="7498">played</TOKEN>
<TOKEN end_char="7506" id="token-58-5" morph="none" pos="word" start_char="7505">an</TOKEN>
<TOKEN end_char="7516" id="token-58-6" morph="none" pos="word" start_char="7508">important</TOKEN>
<TOKEN end_char="7521" id="token-58-7" morph="none" pos="word" start_char="7518">role</TOKEN>
<TOKEN end_char="7524" id="token-58-8" morph="none" pos="word" start_char="7523">in</TOKEN>
<TOKEN end_char="7534" id="token-58-9" morph="none" pos="word" start_char="7526">promoting</TOKEN>
<TOKEN end_char="7538" id="token-58-10" morph="none" pos="word" start_char="7536">the</TOKEN>
<TOKEN end_char="7543" id="token-58-11" morph="none" pos="word" start_char="7540">work</TOKEN>
<TOKEN end_char="7544" id="token-58-12" morph="none" pos="punct" start_char="7544">,</TOKEN>
<TOKEN end_char="7552" id="token-58-13" morph="none" pos="word" start_char="7546">arguing</TOKEN>
<TOKEN end_char="7556" id="token-58-14" morph="none" pos="word" start_char="7554">the</TOKEN>
<TOKEN end_char="7565" id="token-58-15" morph="none" pos="word" start_char="7558">research</TOKEN>
<TOKEN end_char="7569" id="token-58-16" morph="none" pos="word" start_char="7567">was</TOKEN>
<TOKEN end_char="7575" id="token-58-17" morph="none" pos="word" start_char="7571">worth</TOKEN>
<TOKEN end_char="7579" id="token-58-18" morph="none" pos="word" start_char="7577">the</TOKEN>
<TOKEN end_char="7584" id="token-58-19" morph="none" pos="word" start_char="7581">risk</TOKEN>
<TOKEN end_char="7585" id="token-58-20" morph="none" pos="punct" start_char="7585">,</TOKEN>
<TOKEN end_char="7593" id="token-58-21" morph="none" pos="word" start_char="7587">because</TOKEN>
<TOKEN end_char="7596" id="token-58-22" morph="none" pos="word" start_char="7595">it</TOKEN>
<TOKEN end_char="7602" id="token-58-23" morph="none" pos="word" start_char="7598">could</TOKEN>
<TOKEN end_char="7609" id="token-58-24" morph="none" pos="word" start_char="7604">enable</TOKEN>
<TOKEN end_char="7620" id="token-58-25" morph="none" pos="word" start_char="7611">scientists</TOKEN>
<TOKEN end_char="7623" id="token-58-26" morph="none" pos="word" start_char="7622">to</TOKEN>
<TOKEN end_char="7631" id="token-58-27" morph="none" pos="word" start_char="7625">prepare</TOKEN>
<TOKEN end_char="7642" id="token-58-28" morph="none" pos="word" start_char="7633">treatments</TOKEN>
<TOKEN end_char="7646" id="token-58-29" morph="none" pos="word" start_char="7644">and</TOKEN>
<TOKEN end_char="7655" id="token-58-30" morph="none" pos="word" start_char="7648">vaccines</TOKEN>
<TOKEN end_char="7658" id="token-58-31" morph="none" pos="word" start_char="7657">in</TOKEN>
<TOKEN end_char="7666" id="token-58-32" morph="none" pos="word" start_char="7660">advance</TOKEN>
<TOKEN end_char="7669" id="token-58-33" morph="none" pos="word" start_char="7668">if</TOKEN>
<TOKEN end_char="7671" id="token-58-34" morph="none" pos="word" start_char="7671">a</TOKEN>
<TOKEN end_char="7680" id="token-58-35" morph="none" pos="word" start_char="7673">pandemic</TOKEN>
<TOKEN end_char="7689" id="token-58-36" morph="none" pos="word" start_char="7682">occurred</TOKEN>
<TOKEN end_char="7690" id="token-58-37" morph="none" pos="punct" start_char="7690">,</TOKEN>
<TOKEN end_char="7699" id="token-58-38" morph="none" pos="word" start_char="7692">Newsweek</TOKEN>
<TOKEN end_char="7704" id="token-58-39" morph="none" pos="word" start_char="7701">said</TOKEN>
<TOKEN end_char="7705" id="token-58-40" morph="none" pos="punct" start_char="7705">.</TOKEN>
</SEG>
<SEG end_char="8028" id="segment-59" start_char="7708">
<ORIGINAL_TEXT>Fauci and two co-authors defended the work in the Washington Post in December 2011, arguing that "determining the molecular Achilles' heel of these viruses can allow scientists to identify novel antiviral drug targets that could be used to prevent infection in those at risk or to better treat those who become infected."</ORIGINAL_TEXT>
<TOKEN end_char="7712" id="token-59-0" morph="none" pos="word" start_char="7708">Fauci</TOKEN>
<TOKEN end_char="7716" id="token-59-1" morph="none" pos="word" start_char="7714">and</TOKEN>
<TOKEN end_char="7720" id="token-59-2" morph="none" pos="word" start_char="7718">two</TOKEN>
<TOKEN end_char="7731" id="token-59-3" morph="none" pos="unknown" start_char="7722">co-authors</TOKEN>
<TOKEN end_char="7740" id="token-59-4" morph="none" pos="word" start_char="7733">defended</TOKEN>
<TOKEN end_char="7744" id="token-59-5" morph="none" pos="word" start_char="7742">the</TOKEN>
<TOKEN end_char="7749" id="token-59-6" morph="none" pos="word" start_char="7746">work</TOKEN>
<TOKEN end_char="7752" id="token-59-7" morph="none" pos="word" start_char="7751">in</TOKEN>
<TOKEN end_char="7756" id="token-59-8" morph="none" pos="word" start_char="7754">the</TOKEN>
<TOKEN end_char="7767" id="token-59-9" morph="none" pos="word" start_char="7758">Washington</TOKEN>
<TOKEN end_char="7772" id="token-59-10" morph="none" pos="word" start_char="7769">Post</TOKEN>
<TOKEN end_char="7775" id="token-59-11" morph="none" pos="word" start_char="7774">in</TOKEN>
<TOKEN end_char="7784" id="token-59-12" morph="none" pos="word" start_char="7777">December</TOKEN>
<TOKEN end_char="7789" id="token-59-13" morph="none" pos="word" start_char="7786">2011</TOKEN>
<TOKEN end_char="7790" id="token-59-14" morph="none" pos="punct" start_char="7790">,</TOKEN>
<TOKEN end_char="7798" id="token-59-15" morph="none" pos="word" start_char="7792">arguing</TOKEN>
<TOKEN end_char="7803" id="token-59-16" morph="none" pos="word" start_char="7800">that</TOKEN>
<TOKEN end_char="7805" id="token-59-17" morph="none" pos="punct" start_char="7805">"</TOKEN>
<TOKEN end_char="7816" id="token-59-18" morph="none" pos="word" start_char="7806">determining</TOKEN>
<TOKEN end_char="7820" id="token-59-19" morph="none" pos="word" start_char="7818">the</TOKEN>
<TOKEN end_char="7830" id="token-59-20" morph="none" pos="word" start_char="7822">molecular</TOKEN>
<TOKEN end_char="7839" id="token-59-21" morph="none" pos="word" start_char="7832">Achilles</TOKEN>
<TOKEN end_char="7840" id="token-59-22" morph="none" pos="punct" start_char="7840">'</TOKEN>
<TOKEN end_char="7845" id="token-59-23" morph="none" pos="word" start_char="7842">heel</TOKEN>
<TOKEN end_char="7848" id="token-59-24" morph="none" pos="word" start_char="7847">of</TOKEN>
<TOKEN end_char="7854" id="token-59-25" morph="none" pos="word" start_char="7850">these</TOKEN>
<TOKEN end_char="7862" id="token-59-26" morph="none" pos="word" start_char="7856">viruses</TOKEN>
<TOKEN end_char="7866" id="token-59-27" morph="none" pos="word" start_char="7864">can</TOKEN>
<TOKEN end_char="7872" id="token-59-28" morph="none" pos="word" start_char="7868">allow</TOKEN>
<TOKEN end_char="7883" id="token-59-29" morph="none" pos="word" start_char="7874">scientists</TOKEN>
<TOKEN end_char="7886" id="token-59-30" morph="none" pos="word" start_char="7885">to</TOKEN>
<TOKEN end_char="7895" id="token-59-31" morph="none" pos="word" start_char="7888">identify</TOKEN>
<TOKEN end_char="7901" id="token-59-32" morph="none" pos="word" start_char="7897">novel</TOKEN>
<TOKEN end_char="7911" id="token-59-33" morph="none" pos="word" start_char="7903">antiviral</TOKEN>
<TOKEN end_char="7916" id="token-59-34" morph="none" pos="word" start_char="7913">drug</TOKEN>
<TOKEN end_char="7924" id="token-59-35" morph="none" pos="word" start_char="7918">targets</TOKEN>
<TOKEN end_char="7929" id="token-59-36" morph="none" pos="word" start_char="7926">that</TOKEN>
<TOKEN end_char="7935" id="token-59-37" morph="none" pos="word" start_char="7931">could</TOKEN>
<TOKEN end_char="7938" id="token-59-38" morph="none" pos="word" start_char="7937">be</TOKEN>
<TOKEN end_char="7943" id="token-59-39" morph="none" pos="word" start_char="7940">used</TOKEN>
<TOKEN end_char="7946" id="token-59-40" morph="none" pos="word" start_char="7945">to</TOKEN>
<TOKEN end_char="7954" id="token-59-41" morph="none" pos="word" start_char="7948">prevent</TOKEN>
<TOKEN end_char="7964" id="token-59-42" morph="none" pos="word" start_char="7956">infection</TOKEN>
<TOKEN end_char="7967" id="token-59-43" morph="none" pos="word" start_char="7966">in</TOKEN>
<TOKEN end_char="7973" id="token-59-44" morph="none" pos="word" start_char="7969">those</TOKEN>
<TOKEN end_char="7976" id="token-59-45" morph="none" pos="word" start_char="7975">at</TOKEN>
<TOKEN end_char="7981" id="token-59-46" morph="none" pos="word" start_char="7978">risk</TOKEN>
<TOKEN end_char="7984" id="token-59-47" morph="none" pos="word" start_char="7983">or</TOKEN>
<TOKEN end_char="7987" id="token-59-48" morph="none" pos="word" start_char="7986">to</TOKEN>
<TOKEN end_char="7994" id="token-59-49" morph="none" pos="word" start_char="7989">better</TOKEN>
<TOKEN end_char="8000" id="token-59-50" morph="none" pos="word" start_char="7996">treat</TOKEN>
<TOKEN end_char="8006" id="token-59-51" morph="none" pos="word" start_char="8002">those</TOKEN>
<TOKEN end_char="8010" id="token-59-52" morph="none" pos="word" start_char="8008">who</TOKEN>
<TOKEN end_char="8017" id="token-59-53" morph="none" pos="word" start_char="8012">become</TOKEN>
<TOKEN end_char="8026" id="token-59-54" morph="none" pos="word" start_char="8019">infected</TOKEN>
<TOKEN end_char="8028" id="token-59-55" morph="none" pos="punct" start_char="8027">."</TOKEN>
</SEG>
<SEG end_char="8181" id="segment-60" start_char="8031">
<ORIGINAL_TEXT>The work was halted by the Obama administration in 2014 under pressure from scientists but resumed in December 2017 when the NIH lifted the moratorium.</ORIGINAL_TEXT>
<TOKEN end_char="8033" id="token-60-0" morph="none" pos="word" start_char="8031">The</TOKEN>
<TOKEN end_char="8038" id="token-60-1" morph="none" pos="word" start_char="8035">work</TOKEN>
<TOKEN end_char="8042" id="token-60-2" morph="none" pos="word" start_char="8040">was</TOKEN>
<TOKEN end_char="8049" id="token-60-3" morph="none" pos="word" start_char="8044">halted</TOKEN>
<TOKEN end_char="8052" id="token-60-4" morph="none" pos="word" start_char="8051">by</TOKEN>
<TOKEN end_char="8056" id="token-60-5" morph="none" pos="word" start_char="8054">the</TOKEN>
<TOKEN end_char="8062" id="token-60-6" morph="none" pos="word" start_char="8058">Obama</TOKEN>
<TOKEN end_char="8077" id="token-60-7" morph="none" pos="word" start_char="8064">administration</TOKEN>
<TOKEN end_char="8080" id="token-60-8" morph="none" pos="word" start_char="8079">in</TOKEN>
<TOKEN end_char="8085" id="token-60-9" morph="none" pos="word" start_char="8082">2014</TOKEN>
<TOKEN end_char="8091" id="token-60-10" morph="none" pos="word" start_char="8087">under</TOKEN>
<TOKEN end_char="8100" id="token-60-11" morph="none" pos="word" start_char="8093">pressure</TOKEN>
<TOKEN end_char="8105" id="token-60-12" morph="none" pos="word" start_char="8102">from</TOKEN>
<TOKEN end_char="8116" id="token-60-13" morph="none" pos="word" start_char="8107">scientists</TOKEN>
<TOKEN end_char="8120" id="token-60-14" morph="none" pos="word" start_char="8118">but</TOKEN>
<TOKEN end_char="8128" id="token-60-15" morph="none" pos="word" start_char="8122">resumed</TOKEN>
<TOKEN end_char="8131" id="token-60-16" morph="none" pos="word" start_char="8130">in</TOKEN>
<TOKEN end_char="8140" id="token-60-17" morph="none" pos="word" start_char="8133">December</TOKEN>
<TOKEN end_char="8145" id="token-60-18" morph="none" pos="word" start_char="8142">2017</TOKEN>
<TOKEN end_char="8150" id="token-60-19" morph="none" pos="word" start_char="8147">when</TOKEN>
<TOKEN end_char="8154" id="token-60-20" morph="none" pos="word" start_char="8152">the</TOKEN>
<TOKEN end_char="8158" id="token-60-21" morph="none" pos="word" start_char="8156">NIH</TOKEN>
<TOKEN end_char="8165" id="token-60-22" morph="none" pos="word" start_char="8160">lifted</TOKEN>
<TOKEN end_char="8169" id="token-60-23" morph="none" pos="word" start_char="8167">the</TOKEN>
<TOKEN end_char="8180" id="token-60-24" morph="none" pos="word" start_char="8171">moratorium</TOKEN>
<TOKEN end_char="8181" id="token-60-25" morph="none" pos="punct" start_char="8181">.</TOKEN>
</SEG>
<SEG end_char="8312" id="segment-61" start_char="8183">
<ORIGINAL_TEXT>Going forward, scientists had to get approval from a panel of experts who would determine whether or not the risks were justified.</ORIGINAL_TEXT>
<TOKEN end_char="8187" id="token-61-0" morph="none" pos="word" start_char="8183">Going</TOKEN>
<TOKEN end_char="8195" id="token-61-1" morph="none" pos="word" start_char="8189">forward</TOKEN>
<TOKEN end_char="8196" id="token-61-2" morph="none" pos="punct" start_char="8196">,</TOKEN>
<TOKEN end_char="8207" id="token-61-3" morph="none" pos="word" start_char="8198">scientists</TOKEN>
<TOKEN end_char="8211" id="token-61-4" morph="none" pos="word" start_char="8209">had</TOKEN>
<TOKEN end_char="8214" id="token-61-5" morph="none" pos="word" start_char="8213">to</TOKEN>
<TOKEN end_char="8218" id="token-61-6" morph="none" pos="word" start_char="8216">get</TOKEN>
<TOKEN end_char="8227" id="token-61-7" morph="none" pos="word" start_char="8220">approval</TOKEN>
<TOKEN end_char="8232" id="token-61-8" morph="none" pos="word" start_char="8229">from</TOKEN>
<TOKEN end_char="8234" id="token-61-9" morph="none" pos="word" start_char="8234">a</TOKEN>
<TOKEN end_char="8240" id="token-61-10" morph="none" pos="word" start_char="8236">panel</TOKEN>
<TOKEN end_char="8243" id="token-61-11" morph="none" pos="word" start_char="8242">of</TOKEN>
<TOKEN end_char="8251" id="token-61-12" morph="none" pos="word" start_char="8245">experts</TOKEN>
<TOKEN end_char="8255" id="token-61-13" morph="none" pos="word" start_char="8253">who</TOKEN>
<TOKEN end_char="8261" id="token-61-14" morph="none" pos="word" start_char="8257">would</TOKEN>
<TOKEN end_char="8271" id="token-61-15" morph="none" pos="word" start_char="8263">determine</TOKEN>
<TOKEN end_char="8279" id="token-61-16" morph="none" pos="word" start_char="8273">whether</TOKEN>
<TOKEN end_char="8282" id="token-61-17" morph="none" pos="word" start_char="8281">or</TOKEN>
<TOKEN end_char="8286" id="token-61-18" morph="none" pos="word" start_char="8284">not</TOKEN>
<TOKEN end_char="8290" id="token-61-19" morph="none" pos="word" start_char="8288">the</TOKEN>
<TOKEN end_char="8296" id="token-61-20" morph="none" pos="word" start_char="8292">risks</TOKEN>
<TOKEN end_char="8301" id="token-61-21" morph="none" pos="word" start_char="8298">were</TOKEN>
<TOKEN end_char="8311" id="token-61-22" morph="none" pos="word" start_char="8303">justified</TOKEN>
<TOKEN end_char="8312" id="token-61-23" morph="none" pos="punct" start_char="8312">.</TOKEN>
</SEG>
<SEG end_char="8543" id="segment-62" start_char="8315">
<ORIGINAL_TEXT>The research was conducted in secret until, in early 2019, a reporter for Science magazine discovered that the NIH had approved two gain-of-function projects, drawing rebuke from scientists in an editorial in the Washington Post.</ORIGINAL_TEXT>
<TOKEN end_char="8317" id="token-62-0" morph="none" pos="word" start_char="8315">The</TOKEN>
<TOKEN end_char="8326" id="token-62-1" morph="none" pos="word" start_char="8319">research</TOKEN>
<TOKEN end_char="8330" id="token-62-2" morph="none" pos="word" start_char="8328">was</TOKEN>
<TOKEN end_char="8340" id="token-62-3" morph="none" pos="word" start_char="8332">conducted</TOKEN>
<TOKEN end_char="8343" id="token-62-4" morph="none" pos="word" start_char="8342">in</TOKEN>
<TOKEN end_char="8350" id="token-62-5" morph="none" pos="word" start_char="8345">secret</TOKEN>
<TOKEN end_char="8356" id="token-62-6" morph="none" pos="word" start_char="8352">until</TOKEN>
<TOKEN end_char="8357" id="token-62-7" morph="none" pos="punct" start_char="8357">,</TOKEN>
<TOKEN end_char="8360" id="token-62-8" morph="none" pos="word" start_char="8359">in</TOKEN>
<TOKEN end_char="8366" id="token-62-9" morph="none" pos="word" start_char="8362">early</TOKEN>
<TOKEN end_char="8371" id="token-62-10" morph="none" pos="word" start_char="8368">2019</TOKEN>
<TOKEN end_char="8372" id="token-62-11" morph="none" pos="punct" start_char="8372">,</TOKEN>
<TOKEN end_char="8374" id="token-62-12" morph="none" pos="word" start_char="8374">a</TOKEN>
<TOKEN end_char="8383" id="token-62-13" morph="none" pos="word" start_char="8376">reporter</TOKEN>
<TOKEN end_char="8387" id="token-62-14" morph="none" pos="word" start_char="8385">for</TOKEN>
<TOKEN end_char="8395" id="token-62-15" morph="none" pos="word" start_char="8389">Science</TOKEN>
<TOKEN end_char="8404" id="token-62-16" morph="none" pos="word" start_char="8397">magazine</TOKEN>
<TOKEN end_char="8415" id="token-62-17" morph="none" pos="word" start_char="8406">discovered</TOKEN>
<TOKEN end_char="8420" id="token-62-18" morph="none" pos="word" start_char="8417">that</TOKEN>
<TOKEN end_char="8424" id="token-62-19" morph="none" pos="word" start_char="8422">the</TOKEN>
<TOKEN end_char="8428" id="token-62-20" morph="none" pos="word" start_char="8426">NIH</TOKEN>
<TOKEN end_char="8432" id="token-62-21" morph="none" pos="word" start_char="8430">had</TOKEN>
<TOKEN end_char="8441" id="token-62-22" morph="none" pos="word" start_char="8434">approved</TOKEN>
<TOKEN end_char="8445" id="token-62-23" morph="none" pos="word" start_char="8443">two</TOKEN>
<TOKEN end_char="8462" id="token-62-24" morph="none" pos="unknown" start_char="8447">gain-of-function</TOKEN>
<TOKEN end_char="8471" id="token-62-25" morph="none" pos="word" start_char="8464">projects</TOKEN>
<TOKEN end_char="8472" id="token-62-26" morph="none" pos="punct" start_char="8472">,</TOKEN>
<TOKEN end_char="8480" id="token-62-27" morph="none" pos="word" start_char="8474">drawing</TOKEN>
<TOKEN end_char="8487" id="token-62-28" morph="none" pos="word" start_char="8482">rebuke</TOKEN>
<TOKEN end_char="8492" id="token-62-29" morph="none" pos="word" start_char="8489">from</TOKEN>
<TOKEN end_char="8503" id="token-62-30" morph="none" pos="word" start_char="8494">scientists</TOKEN>
<TOKEN end_char="8506" id="token-62-31" morph="none" pos="word" start_char="8505">in</TOKEN>
<TOKEN end_char="8509" id="token-62-32" morph="none" pos="word" start_char="8508">an</TOKEN>
<TOKEN end_char="8519" id="token-62-33" morph="none" pos="word" start_char="8511">editorial</TOKEN>
<TOKEN end_char="8522" id="token-62-34" morph="none" pos="word" start_char="8521">in</TOKEN>
<TOKEN end_char="8526" id="token-62-35" morph="none" pos="word" start_char="8524">the</TOKEN>
<TOKEN end_char="8537" id="token-62-36" morph="none" pos="word" start_char="8528">Washington</TOKEN>
<TOKEN end_char="8542" id="token-62-37" morph="none" pos="word" start_char="8539">Post</TOKEN>
<TOKEN end_char="8543" id="token-62-38" morph="none" pos="punct" start_char="8543">.</TOKEN>
</SEG>
<SEG end_char="8706" id="segment-63" start_char="8546">
<ORIGINAL_TEXT>"We have serious doubts about whether these experiments should be conducted at all," wrote Tom Inglesby of Johns Hopkins University and Marc Lipsitch of Harvard.</ORIGINAL_TEXT>
<TOKEN end_char="8546" id="token-63-0" morph="none" pos="punct" start_char="8546">"</TOKEN>
<TOKEN end_char="8548" id="token-63-1" morph="none" pos="word" start_char="8547">We</TOKEN>
<TOKEN end_char="8553" id="token-63-2" morph="none" pos="word" start_char="8550">have</TOKEN>
<TOKEN end_char="8561" id="token-63-3" morph="none" pos="word" start_char="8555">serious</TOKEN>
<TOKEN end_char="8568" id="token-63-4" morph="none" pos="word" start_char="8563">doubts</TOKEN>
<TOKEN end_char="8574" id="token-63-5" morph="none" pos="word" start_char="8570">about</TOKEN>
<TOKEN end_char="8582" id="token-63-6" morph="none" pos="word" start_char="8576">whether</TOKEN>
<TOKEN end_char="8588" id="token-63-7" morph="none" pos="word" start_char="8584">these</TOKEN>
<TOKEN end_char="8600" id="token-63-8" morph="none" pos="word" start_char="8590">experiments</TOKEN>
<TOKEN end_char="8607" id="token-63-9" morph="none" pos="word" start_char="8602">should</TOKEN>
<TOKEN end_char="8610" id="token-63-10" morph="none" pos="word" start_char="8609">be</TOKEN>
<TOKEN end_char="8620" id="token-63-11" morph="none" pos="word" start_char="8612">conducted</TOKEN>
<TOKEN end_char="8623" id="token-63-12" morph="none" pos="word" start_char="8622">at</TOKEN>
<TOKEN end_char="8627" id="token-63-13" morph="none" pos="word" start_char="8625">all</TOKEN>
<TOKEN end_char="8629" id="token-63-14" morph="none" pos="punct" start_char="8628">,"</TOKEN>
<TOKEN end_char="8635" id="token-63-15" morph="none" pos="word" start_char="8631">wrote</TOKEN>
<TOKEN end_char="8639" id="token-63-16" morph="none" pos="word" start_char="8637">Tom</TOKEN>
<TOKEN end_char="8648" id="token-63-17" morph="none" pos="word" start_char="8641">Inglesby</TOKEN>
<TOKEN end_char="8651" id="token-63-18" morph="none" pos="word" start_char="8650">of</TOKEN>
<TOKEN end_char="8657" id="token-63-19" morph="none" pos="word" start_char="8653">Johns</TOKEN>
<TOKEN end_char="8665" id="token-63-20" morph="none" pos="word" start_char="8659">Hopkins</TOKEN>
<TOKEN end_char="8676" id="token-63-21" morph="none" pos="word" start_char="8667">University</TOKEN>
<TOKEN end_char="8680" id="token-63-22" morph="none" pos="word" start_char="8678">and</TOKEN>
<TOKEN end_char="8685" id="token-63-23" morph="none" pos="word" start_char="8682">Marc</TOKEN>
<TOKEN end_char="8694" id="token-63-24" morph="none" pos="word" start_char="8687">Lipsitch</TOKEN>
<TOKEN end_char="8697" id="token-63-25" morph="none" pos="word" start_char="8696">of</TOKEN>
<TOKEN end_char="8705" id="token-63-26" morph="none" pos="word" start_char="8699">Harvard</TOKEN>
<TOKEN end_char="8706" id="token-63-27" morph="none" pos="punct" start_char="8706">.</TOKEN>
</SEG>
<SEG end_char="8905" id="segment-64" start_char="8708">
<ORIGINAL_TEXT>"[W]ith deliberations kept behind closed doors, none of us will have the opportunity to understand how the government arrived at these decisions or to judge the rigor and integrity of that process."</ORIGINAL_TEXT>
<TOKEN end_char="8709" id="token-64-0" morph="none" pos="punct" start_char="8708">"[</TOKEN>
<TOKEN end_char="8714" id="token-64-1" morph="none" pos="unknown" start_char="8710">W]ith</TOKEN>
<TOKEN end_char="8728" id="token-64-2" morph="none" pos="word" start_char="8716">deliberations</TOKEN>
<TOKEN end_char="8733" id="token-64-3" morph="none" pos="word" start_char="8730">kept</TOKEN>
<TOKEN end_char="8740" id="token-64-4" morph="none" pos="word" start_char="8735">behind</TOKEN>
<TOKEN end_char="8747" id="token-64-5" morph="none" pos="word" start_char="8742">closed</TOKEN>
<TOKEN end_char="8753" id="token-64-6" morph="none" pos="word" start_char="8749">doors</TOKEN>
<TOKEN end_char="8754" id="token-64-7" morph="none" pos="punct" start_char="8754">,</TOKEN>
<TOKEN end_char="8759" id="token-64-8" morph="none" pos="word" start_char="8756">none</TOKEN>
<TOKEN end_char="8762" id="token-64-9" morph="none" pos="word" start_char="8761">of</TOKEN>
<TOKEN end_char="8765" id="token-64-10" morph="none" pos="word" start_char="8764">us</TOKEN>
<TOKEN end_char="8770" id="token-64-11" morph="none" pos="word" start_char="8767">will</TOKEN>
<TOKEN end_char="8775" id="token-64-12" morph="none" pos="word" start_char="8772">have</TOKEN>
<TOKEN end_char="8779" id="token-64-13" morph="none" pos="word" start_char="8777">the</TOKEN>
<TOKEN end_char="8791" id="token-64-14" morph="none" pos="word" start_char="8781">opportunity</TOKEN>
<TOKEN end_char="8794" id="token-64-15" morph="none" pos="word" start_char="8793">to</TOKEN>
<TOKEN end_char="8805" id="token-64-16" morph="none" pos="word" start_char="8796">understand</TOKEN>
<TOKEN end_char="8809" id="token-64-17" morph="none" pos="word" start_char="8807">how</TOKEN>
<TOKEN end_char="8813" id="token-64-18" morph="none" pos="word" start_char="8811">the</TOKEN>
<TOKEN end_char="8824" id="token-64-19" morph="none" pos="word" start_char="8815">government</TOKEN>
<TOKEN end_char="8832" id="token-64-20" morph="none" pos="word" start_char="8826">arrived</TOKEN>
<TOKEN end_char="8835" id="token-64-21" morph="none" pos="word" start_char="8834">at</TOKEN>
<TOKEN end_char="8841" id="token-64-22" morph="none" pos="word" start_char="8837">these</TOKEN>
<TOKEN end_char="8851" id="token-64-23" morph="none" pos="word" start_char="8843">decisions</TOKEN>
<TOKEN end_char="8854" id="token-64-24" morph="none" pos="word" start_char="8853">or</TOKEN>
<TOKEN end_char="8857" id="token-64-25" morph="none" pos="word" start_char="8856">to</TOKEN>
<TOKEN end_char="8863" id="token-64-26" morph="none" pos="word" start_char="8859">judge</TOKEN>
<TOKEN end_char="8867" id="token-64-27" morph="none" pos="word" start_char="8865">the</TOKEN>
<TOKEN end_char="8873" id="token-64-28" morph="none" pos="word" start_char="8869">rigor</TOKEN>
<TOKEN end_char="8877" id="token-64-29" morph="none" pos="word" start_char="8875">and</TOKEN>
<TOKEN end_char="8887" id="token-64-30" morph="none" pos="word" start_char="8879">integrity</TOKEN>
<TOKEN end_char="8890" id="token-64-31" morph="none" pos="word" start_char="8889">of</TOKEN>
<TOKEN end_char="8895" id="token-64-32" morph="none" pos="word" start_char="8892">that</TOKEN>
<TOKEN end_char="8903" id="token-64-33" morph="none" pos="word" start_char="8897">process</TOKEN>
<TOKEN end_char="8905" id="token-64-34" morph="none" pos="punct" start_char="8904">."</TOKEN>
</SEG>
<SEG end_char="8928" id="segment-65" start_char="8908">
<ORIGINAL_TEXT>See Hilton's segment:</ORIGINAL_TEXT>
<TOKEN end_char="8910" id="token-65-0" morph="none" pos="word" start_char="8908">See</TOKEN>
<TOKEN end_char="8919" id="token-65-1" morph="none" pos="word" start_char="8912">Hilton's</TOKEN>
<TOKEN end_char="8927" id="token-65-2" morph="none" pos="word" start_char="8921">segment</TOKEN>
<TOKEN end_char="8928" id="token-65-3" morph="none" pos="punct" start_char="8928">:</TOKEN>
<TRANSLATED_TEXT>Zie Hilton's segment:</TRANSLATED_TEXT><DETECTED_LANGUAGE>nl</DETECTED_LANGUAGE></SEG>
<SEG end_char="8965" id="segment-66" start_char="8932">
<ORIGINAL_TEXT>Wuhan lab the 'most likely' source</ORIGINAL_TEXT>
<TOKEN end_char="8936" id="token-66-0" morph="none" pos="word" start_char="8932">Wuhan</TOKEN>
<TOKEN end_char="8940" id="token-66-1" morph="none" pos="word" start_char="8938">lab</TOKEN>
<TOKEN end_char="8944" id="token-66-2" morph="none" pos="word" start_char="8942">the</TOKEN>
<TOKEN end_char="8946" id="token-66-3" morph="none" pos="punct" start_char="8946">'</TOKEN>
<TOKEN end_char="8950" id="token-66-4" morph="none" pos="word" start_char="8947">most</TOKEN>
<TOKEN end_char="8957" id="token-66-5" morph="none" pos="word" start_char="8952">likely</TOKEN>
<TOKEN end_char="8958" id="token-66-6" morph="none" pos="punct" start_char="8958">'</TOKEN>
<TOKEN end_char="8965" id="token-66-7" morph="none" pos="word" start_char="8960">source</TOKEN>
</SEG>
<SEG end_char="9118" id="segment-67" start_char="8968">
<ORIGINAL_TEXT>In April 2020, a U.S. government report concluded the Wuhan lab was the "most likely" source of COVID-19, finding other explanations "highly unlikely."</ORIGINAL_TEXT>
<TOKEN end_char="8969" id="token-67-0" morph="none" pos="word" start_char="8968">In</TOKEN>
<TOKEN end_char="8975" id="token-67-1" morph="none" pos="word" start_char="8971">April</TOKEN>
<TOKEN end_char="8980" id="token-67-2" morph="none" pos="word" start_char="8977">2020</TOKEN>
<TOKEN end_char="8981" id="token-67-3" morph="none" pos="punct" start_char="8981">,</TOKEN>
<TOKEN end_char="8983" id="token-67-4" morph="none" pos="word" start_char="8983">a</TOKEN>
<TOKEN end_char="8987" id="token-67-5" morph="none" pos="unknown" start_char="8985">U.S</TOKEN>
<TOKEN end_char="8988" id="token-67-6" morph="none" pos="punct" start_char="8988">.</TOKEN>
<TOKEN end_char="8999" id="token-67-7" morph="none" pos="word" start_char="8990">government</TOKEN>
<TOKEN end_char="9006" id="token-67-8" morph="none" pos="word" start_char="9001">report</TOKEN>
<TOKEN end_char="9016" id="token-67-9" morph="none" pos="word" start_char="9008">concluded</TOKEN>
<TOKEN end_char="9020" id="token-67-10" morph="none" pos="word" start_char="9018">the</TOKEN>
<TOKEN end_char="9026" id="token-67-11" morph="none" pos="word" start_char="9022">Wuhan</TOKEN>
<TOKEN end_char="9030" id="token-67-12" morph="none" pos="word" start_char="9028">lab</TOKEN>
<TOKEN end_char="9034" id="token-67-13" morph="none" pos="word" start_char="9032">was</TOKEN>
<TOKEN end_char="9038" id="token-67-14" morph="none" pos="word" start_char="9036">the</TOKEN>
<TOKEN end_char="9040" id="token-67-15" morph="none" pos="punct" start_char="9040">"</TOKEN>
<TOKEN end_char="9044" id="token-67-16" morph="none" pos="word" start_char="9041">most</TOKEN>
<TOKEN end_char="9051" id="token-67-17" morph="none" pos="word" start_char="9046">likely</TOKEN>
<TOKEN end_char="9052" id="token-67-18" morph="none" pos="punct" start_char="9052">"</TOKEN>
<TOKEN end_char="9059" id="token-67-19" morph="none" pos="word" start_char="9054">source</TOKEN>
<TOKEN end_char="9062" id="token-67-20" morph="none" pos="word" start_char="9061">of</TOKEN>
<TOKEN end_char="9071" id="token-67-21" morph="none" pos="unknown" start_char="9064">COVID-19</TOKEN>
<TOKEN end_char="9072" id="token-67-22" morph="none" pos="punct" start_char="9072">,</TOKEN>
<TOKEN end_char="9080" id="token-67-23" morph="none" pos="word" start_char="9074">finding</TOKEN>
<TOKEN end_char="9086" id="token-67-24" morph="none" pos="word" start_char="9082">other</TOKEN>
<TOKEN end_char="9099" id="token-67-25" morph="none" pos="word" start_char="9088">explanations</TOKEN>
<TOKEN end_char="9101" id="token-67-26" morph="none" pos="punct" start_char="9101">"</TOKEN>
<TOKEN end_char="9107" id="token-67-27" morph="none" pos="word" start_char="9102">highly</TOKEN>
<TOKEN end_char="9116" id="token-67-28" morph="none" pos="word" start_char="9109">unlikely</TOKEN>
<TOKEN end_char="9118" id="token-67-29" morph="none" pos="punct" start_char="9117">."</TOKEN>
</SEG>
<SEG end_char="9222" id="segment-68" start_char="9121">
<ORIGINAL_TEXT>The report noted the activities of Shi Zhengli, a leader in bat coronavirus research at the Wuhan lab.</ORIGINAL_TEXT>
<TOKEN end_char="9123" id="token-68-0" morph="none" pos="word" start_char="9121">The</TOKEN>
<TOKEN end_char="9130" id="token-68-1" morph="none" pos="word" start_char="9125">report</TOKEN>
<TOKEN end_char="9136" id="token-68-2" morph="none" pos="word" start_char="9132">noted</TOKEN>
<TOKEN end_char="9140" id="token-68-3" morph="none" pos="word" start_char="9138">the</TOKEN>
<TOKEN end_char="9151" id="token-68-4" morph="none" pos="word" start_char="9142">activities</TOKEN>
<TOKEN end_char="9154" id="token-68-5" morph="none" pos="word" start_char="9153">of</TOKEN>
<TOKEN end_char="9158" id="token-68-6" morph="none" pos="word" start_char="9156">Shi</TOKEN>
<TOKEN end_char="9166" id="token-68-7" morph="none" pos="word" start_char="9160">Zhengli</TOKEN>
<TOKEN end_char="9167" id="token-68-8" morph="none" pos="punct" start_char="9167">,</TOKEN>
<TOKEN end_char="9169" id="token-68-9" morph="none" pos="word" start_char="9169">a</TOKEN>
<TOKEN end_char="9176" id="token-68-10" morph="none" pos="word" start_char="9171">leader</TOKEN>
<TOKEN end_char="9179" id="token-68-11" morph="none" pos="word" start_char="9178">in</TOKEN>
<TOKEN end_char="9183" id="token-68-12" morph="none" pos="word" start_char="9181">bat</TOKEN>
<TOKEN end_char="9195" id="token-68-13" morph="none" pos="word" start_char="9185">coronavirus</TOKEN>
<TOKEN end_char="9204" id="token-68-14" morph="none" pos="word" start_char="9197">research</TOKEN>
<TOKEN end_char="9207" id="token-68-15" morph="none" pos="word" start_char="9206">at</TOKEN>
<TOKEN end_char="9211" id="token-68-16" morph="none" pos="word" start_char="9209">the</TOKEN>
<TOKEN end_char="9217" id="token-68-17" morph="none" pos="word" start_char="9213">Wuhan</TOKEN>
<TOKEN end_char="9221" id="token-68-18" morph="none" pos="word" start_char="9219">lab</TOKEN>
<TOKEN end_char="9222" id="token-68-19" morph="none" pos="punct" start_char="9222">.</TOKEN>
</SEG>
<SEG end_char="9513" id="segment-69" start_char="9224">
<ORIGINAL_TEXT>A 2015 academic report in Nature Medicine by Shi and 14 other scientists said that while researching the potential for bat coronaviruses to infect humans, "we built a chimeric virus encoding a novel, zoonotic (animal-origin) spike protein ... that was isolated from Chinese horseshoe bats."</ORIGINAL_TEXT>
<TOKEN end_char="9224" id="token-69-0" morph="none" pos="word" start_char="9224">A</TOKEN>
<TOKEN end_char="9229" id="token-69-1" morph="none" pos="word" start_char="9226">2015</TOKEN>
<TOKEN end_char="9238" id="token-69-2" morph="none" pos="word" start_char="9231">academic</TOKEN>
<TOKEN end_char="9245" id="token-69-3" morph="none" pos="word" start_char="9240">report</TOKEN>
<TOKEN end_char="9248" id="token-69-4" morph="none" pos="word" start_char="9247">in</TOKEN>
<TOKEN end_char="9255" id="token-69-5" morph="none" pos="word" start_char="9250">Nature</TOKEN>
<TOKEN end_char="9264" id="token-69-6" morph="none" pos="word" start_char="9257">Medicine</TOKEN>
<TOKEN end_char="9267" id="token-69-7" morph="none" pos="word" start_char="9266">by</TOKEN>
<TOKEN end_char="9271" id="token-69-8" morph="none" pos="word" start_char="9269">Shi</TOKEN>
<TOKEN end_char="9275" id="token-69-9" morph="none" pos="word" start_char="9273">and</TOKEN>
<TOKEN end_char="9278" id="token-69-10" morph="none" pos="word" start_char="9277">14</TOKEN>
<TOKEN end_char="9284" id="token-69-11" morph="none" pos="word" start_char="9280">other</TOKEN>
<TOKEN end_char="9295" id="token-69-12" morph="none" pos="word" start_char="9286">scientists</TOKEN>
<TOKEN end_char="9300" id="token-69-13" morph="none" pos="word" start_char="9297">said</TOKEN>
<TOKEN end_char="9305" id="token-69-14" morph="none" pos="word" start_char="9302">that</TOKEN>
<TOKEN end_char="9311" id="token-69-15" morph="none" pos="word" start_char="9307">while</TOKEN>
<TOKEN end_char="9323" id="token-69-16" morph="none" pos="word" start_char="9313">researching</TOKEN>
<TOKEN end_char="9327" id="token-69-17" morph="none" pos="word" start_char="9325">the</TOKEN>
<TOKEN end_char="9337" id="token-69-18" morph="none" pos="word" start_char="9329">potential</TOKEN>
<TOKEN end_char="9341" id="token-69-19" morph="none" pos="word" start_char="9339">for</TOKEN>
<TOKEN end_char="9345" id="token-69-20" morph="none" pos="word" start_char="9343">bat</TOKEN>
<TOKEN end_char="9359" id="token-69-21" morph="none" pos="word" start_char="9347">coronaviruses</TOKEN>
<TOKEN end_char="9362" id="token-69-22" morph="none" pos="word" start_char="9361">to</TOKEN>
<TOKEN end_char="9369" id="token-69-23" morph="none" pos="word" start_char="9364">infect</TOKEN>
<TOKEN end_char="9376" id="token-69-24" morph="none" pos="word" start_char="9371">humans</TOKEN>
<TOKEN end_char="9377" id="token-69-25" morph="none" pos="punct" start_char="9377">,</TOKEN>
<TOKEN end_char="9379" id="token-69-26" morph="none" pos="punct" start_char="9379">"</TOKEN>
<TOKEN end_char="9381" id="token-69-27" morph="none" pos="word" start_char="9380">we</TOKEN>
<TOKEN end_char="9387" id="token-69-28" morph="none" pos="word" start_char="9383">built</TOKEN>
<TOKEN end_char="9389" id="token-69-29" morph="none" pos="word" start_char="9389">a</TOKEN>
<TOKEN end_char="9398" id="token-69-30" morph="none" pos="word" start_char="9391">chimeric</TOKEN>
<TOKEN end_char="9404" id="token-69-31" morph="none" pos="word" start_char="9400">virus</TOKEN>
<TOKEN end_char="9413" id="token-69-32" morph="none" pos="word" start_char="9406">encoding</TOKEN>
<TOKEN end_char="9415" id="token-69-33" morph="none" pos="word" start_char="9415">a</TOKEN>
<TOKEN end_char="9421" id="token-69-34" morph="none" pos="word" start_char="9417">novel</TOKEN>
<TOKEN end_char="9422" id="token-69-35" morph="none" pos="punct" start_char="9422">,</TOKEN>
<TOKEN end_char="9431" id="token-69-36" morph="none" pos="word" start_char="9424">zoonotic</TOKEN>
<TOKEN end_char="9433" id="token-69-37" morph="none" pos="punct" start_char="9433">(</TOKEN>
<TOKEN end_char="9446" id="token-69-38" morph="none" pos="unknown" start_char="9434">animal-origin</TOKEN>
<TOKEN end_char="9447" id="token-69-39" morph="none" pos="punct" start_char="9447">)</TOKEN>
<TOKEN end_char="9453" id="token-69-40" morph="none" pos="word" start_char="9449">spike</TOKEN>
<TOKEN end_char="9461" id="token-69-41" morph="none" pos="word" start_char="9455">protein</TOKEN>
<TOKEN end_char="9465" id="token-69-42" morph="none" pos="punct" start_char="9463">...</TOKEN>
<TOKEN end_char="9470" id="token-69-43" morph="none" pos="word" start_char="9467">that</TOKEN>
<TOKEN end_char="9474" id="token-69-44" morph="none" pos="word" start_char="9472">was</TOKEN>
<TOKEN end_char="9483" id="token-69-45" morph="none" pos="word" start_char="9476">isolated</TOKEN>
<TOKEN end_char="9488" id="token-69-46" morph="none" pos="word" start_char="9485">from</TOKEN>
<TOKEN end_char="9496" id="token-69-47" morph="none" pos="word" start_char="9490">Chinese</TOKEN>
<TOKEN end_char="9506" id="token-69-48" morph="none" pos="word" start_char="9498">horseshoe</TOKEN>
<TOKEN end_char="9511" id="token-69-49" morph="none" pos="word" start_char="9508">bats</TOKEN>
<TOKEN end_char="9513" id="token-69-50" morph="none" pos="punct" start_char="9512">."</TOKEN>
</SEG>
<SEG end_char="9752" id="segment-70" start_char="9516">
<ORIGINAL_TEXT>The U.S. government analysis, reported by the Washington Times, found virus-carrying animals had been "sold as pets, dead laboratory animals were not properly disposed of, and lab workers were known to boil and eat laboratory-used eggs."</ORIGINAL_TEXT>
<TOKEN end_char="9518" id="token-70-0" morph="none" pos="word" start_char="9516">The</TOKEN>
<TOKEN end_char="9522" id="token-70-1" morph="none" pos="unknown" start_char="9520">U.S</TOKEN>
<TOKEN end_char="9523" id="token-70-2" morph="none" pos="punct" start_char="9523">.</TOKEN>
<TOKEN end_char="9534" id="token-70-3" morph="none" pos="word" start_char="9525">government</TOKEN>
<TOKEN end_char="9543" id="token-70-4" morph="none" pos="word" start_char="9536">analysis</TOKEN>
<TOKEN end_char="9544" id="token-70-5" morph="none" pos="punct" start_char="9544">,</TOKEN>
<TOKEN end_char="9553" id="token-70-6" morph="none" pos="word" start_char="9546">reported</TOKEN>
<TOKEN end_char="9556" id="token-70-7" morph="none" pos="word" start_char="9555">by</TOKEN>
<TOKEN end_char="9560" id="token-70-8" morph="none" pos="word" start_char="9558">the</TOKEN>
<TOKEN end_char="9571" id="token-70-9" morph="none" pos="word" start_char="9562">Washington</TOKEN>
<TOKEN end_char="9577" id="token-70-10" morph="none" pos="word" start_char="9573">Times</TOKEN>
<TOKEN end_char="9578" id="token-70-11" morph="none" pos="punct" start_char="9578">,</TOKEN>
<TOKEN end_char="9584" id="token-70-12" morph="none" pos="word" start_char="9580">found</TOKEN>
<TOKEN end_char="9599" id="token-70-13" morph="none" pos="unknown" start_char="9586">virus-carrying</TOKEN>
<TOKEN end_char="9607" id="token-70-14" morph="none" pos="word" start_char="9601">animals</TOKEN>
<TOKEN end_char="9611" id="token-70-15" morph="none" pos="word" start_char="9609">had</TOKEN>
<TOKEN end_char="9616" id="token-70-16" morph="none" pos="word" start_char="9613">been</TOKEN>
<TOKEN end_char="9618" id="token-70-17" morph="none" pos="punct" start_char="9618">"</TOKEN>
<TOKEN end_char="9622" id="token-70-18" morph="none" pos="word" start_char="9619">sold</TOKEN>
<TOKEN end_char="9625" id="token-70-19" morph="none" pos="word" start_char="9624">as</TOKEN>
<TOKEN end_char="9630" id="token-70-20" morph="none" pos="word" start_char="9627">pets</TOKEN>
<TOKEN end_char="9631" id="token-70-21" morph="none" pos="punct" start_char="9631">,</TOKEN>
<TOKEN end_char="9636" id="token-70-22" morph="none" pos="word" start_char="9633">dead</TOKEN>
<TOKEN end_char="9647" id="token-70-23" morph="none" pos="word" start_char="9638">laboratory</TOKEN>
<TOKEN end_char="9655" id="token-70-24" morph="none" pos="word" start_char="9649">animals</TOKEN>
<TOKEN end_char="9660" id="token-70-25" morph="none" pos="word" start_char="9657">were</TOKEN>
<TOKEN end_char="9664" id="token-70-26" morph="none" pos="word" start_char="9662">not</TOKEN>
<TOKEN end_char="9673" id="token-70-27" morph="none" pos="word" start_char="9666">properly</TOKEN>
<TOKEN end_char="9682" id="token-70-28" morph="none" pos="word" start_char="9675">disposed</TOKEN>
<TOKEN end_char="9685" id="token-70-29" morph="none" pos="word" start_char="9684">of</TOKEN>
<TOKEN end_char="9686" id="token-70-30" morph="none" pos="punct" start_char="9686">,</TOKEN>
<TOKEN end_char="9690" id="token-70-31" morph="none" pos="word" start_char="9688">and</TOKEN>
<TOKEN end_char="9694" id="token-70-32" morph="none" pos="word" start_char="9692">lab</TOKEN>
<TOKEN end_char="9702" id="token-70-33" morph="none" pos="word" start_char="9696">workers</TOKEN>
<TOKEN end_char="9707" id="token-70-34" morph="none" pos="word" start_char="9704">were</TOKEN>
<TOKEN end_char="9713" id="token-70-35" morph="none" pos="word" start_char="9709">known</TOKEN>
<TOKEN end_char="9716" id="token-70-36" morph="none" pos="word" start_char="9715">to</TOKEN>
<TOKEN end_char="9721" id="token-70-37" morph="none" pos="word" start_char="9718">boil</TOKEN>
<TOKEN end_char="9725" id="token-70-38" morph="none" pos="word" start_char="9723">and</TOKEN>
<TOKEN end_char="9729" id="token-70-39" morph="none" pos="word" start_char="9727">eat</TOKEN>
<TOKEN end_char="9745" id="token-70-40" morph="none" pos="unknown" start_char="9731">laboratory-used</TOKEN>
<TOKEN end_char="9750" id="token-70-41" morph="none" pos="word" start_char="9747">eggs</TOKEN>
<TOKEN end_char="9752" id="token-70-42" morph="none" pos="punct" start_char="9751">."</TOKEN>
</SEG>
<SEG end_char="9948" id="segment-71" start_char="9755">
<ORIGINAL_TEXT>The report noted that China was clamping down on efforts to investigate whether the virus came from a lab, issuing a "gag order" and putting a military microbiologist in charge of the Wuhan lab.</ORIGINAL_TEXT>
<TOKEN end_char="9757" id="token-71-0" morph="none" pos="word" start_char="9755">The</TOKEN>
<TOKEN end_char="9764" id="token-71-1" morph="none" pos="word" start_char="9759">report</TOKEN>
<TOKEN end_char="9770" id="token-71-2" morph="none" pos="word" start_char="9766">noted</TOKEN>
<TOKEN end_char="9775" id="token-71-3" morph="none" pos="word" start_char="9772">that</TOKEN>
<TOKEN end_char="9781" id="token-71-4" morph="none" pos="word" start_char="9777">China</TOKEN>
<TOKEN end_char="9785" id="token-71-5" morph="none" pos="word" start_char="9783">was</TOKEN>
<TOKEN end_char="9794" id="token-71-6" morph="none" pos="word" start_char="9787">clamping</TOKEN>
<TOKEN end_char="9799" id="token-71-7" morph="none" pos="word" start_char="9796">down</TOKEN>
<TOKEN end_char="9802" id="token-71-8" morph="none" pos="word" start_char="9801">on</TOKEN>
<TOKEN end_char="9810" id="token-71-9" morph="none" pos="word" start_char="9804">efforts</TOKEN>
<TOKEN end_char="9813" id="token-71-10" morph="none" pos="word" start_char="9812">to</TOKEN>
<TOKEN end_char="9825" id="token-71-11" morph="none" pos="word" start_char="9815">investigate</TOKEN>
<TOKEN end_char="9833" id="token-71-12" morph="none" pos="word" start_char="9827">whether</TOKEN>
<TOKEN end_char="9837" id="token-71-13" morph="none" pos="word" start_char="9835">the</TOKEN>
<TOKEN end_char="9843" id="token-71-14" morph="none" pos="word" start_char="9839">virus</TOKEN>
<TOKEN end_char="9848" id="token-71-15" morph="none" pos="word" start_char="9845">came</TOKEN>
<TOKEN end_char="9853" id="token-71-16" morph="none" pos="word" start_char="9850">from</TOKEN>
<TOKEN end_char="9855" id="token-71-17" morph="none" pos="word" start_char="9855">a</TOKEN>
<TOKEN end_char="9859" id="token-71-18" morph="none" pos="word" start_char="9857">lab</TOKEN>
<TOKEN end_char="9860" id="token-71-19" morph="none" pos="punct" start_char="9860">,</TOKEN>
<TOKEN end_char="9868" id="token-71-20" morph="none" pos="word" start_char="9862">issuing</TOKEN>
<TOKEN end_char="9870" id="token-71-21" morph="none" pos="word" start_char="9870">a</TOKEN>
<TOKEN end_char="9872" id="token-71-22" morph="none" pos="punct" start_char="9872">"</TOKEN>
<TOKEN end_char="9875" id="token-71-23" morph="none" pos="word" start_char="9873">gag</TOKEN>
<TOKEN end_char="9881" id="token-71-24" morph="none" pos="word" start_char="9877">order</TOKEN>
<TOKEN end_char="9882" id="token-71-25" morph="none" pos="punct" start_char="9882">"</TOKEN>
<TOKEN end_char="9886" id="token-71-26" morph="none" pos="word" start_char="9884">and</TOKEN>
<TOKEN end_char="9894" id="token-71-27" morph="none" pos="word" start_char="9888">putting</TOKEN>
<TOKEN end_char="9896" id="token-71-28" morph="none" pos="word" start_char="9896">a</TOKEN>
<TOKEN end_char="9905" id="token-71-29" morph="none" pos="word" start_char="9898">military</TOKEN>
<TOKEN end_char="9920" id="token-71-30" morph="none" pos="word" start_char="9907">microbiologist</TOKEN>
<TOKEN end_char="9923" id="token-71-31" morph="none" pos="word" start_char="9922">in</TOKEN>
<TOKEN end_char="9930" id="token-71-32" morph="none" pos="word" start_char="9925">charge</TOKEN>
<TOKEN end_char="9933" id="token-71-33" morph="none" pos="word" start_char="9932">of</TOKEN>
<TOKEN end_char="9937" id="token-71-34" morph="none" pos="word" start_char="9935">the</TOKEN>
<TOKEN end_char="9943" id="token-71-35" morph="none" pos="word" start_char="9939">Wuhan</TOKEN>
<TOKEN end_char="9947" id="token-71-36" morph="none" pos="word" start_char="9945">lab</TOKEN>
<TOKEN end_char="9948" id="token-71-37" morph="none" pos="punct" start_char="9948">.</TOKEN>
</SEG>
<SEG end_char="10101" id="segment-72" start_char="9951">
<ORIGINAL_TEXT>Content created by the WND News Center is available for re-publication without charge to any eligible news publisher that can provide a large audience.</ORIGINAL_TEXT>
<TOKEN end_char="9957" id="token-72-0" morph="none" pos="word" start_char="9951">Content</TOKEN>
<TOKEN end_char="9965" id="token-72-1" morph="none" pos="word" start_char="9959">created</TOKEN>
<TOKEN end_char="9968" id="token-72-2" morph="none" pos="word" start_char="9967">by</TOKEN>
<TOKEN end_char="9972" id="token-72-3" morph="none" pos="word" start_char="9970">the</TOKEN>
<TOKEN end_char="9976" id="token-72-4" morph="none" pos="word" start_char="9974">WND</TOKEN>
<TOKEN end_char="9981" id="token-72-5" morph="none" pos="word" start_char="9978">News</TOKEN>
<TOKEN end_char="9988" id="token-72-6" morph="none" pos="word" start_char="9983">Center</TOKEN>
<TOKEN end_char="9991" id="token-72-7" morph="none" pos="word" start_char="9990">is</TOKEN>
<TOKEN end_char="10001" id="token-72-8" morph="none" pos="word" start_char="9993">available</TOKEN>
<TOKEN end_char="10005" id="token-72-9" morph="none" pos="word" start_char="10003">for</TOKEN>
<TOKEN end_char="10020" id="token-72-10" morph="none" pos="unknown" start_char="10007">re-publication</TOKEN>
<TOKEN end_char="10028" id="token-72-11" morph="none" pos="word" start_char="10022">without</TOKEN>
<TOKEN end_char="10035" id="token-72-12" morph="none" pos="word" start_char="10030">charge</TOKEN>
<TOKEN end_char="10038" id="token-72-13" morph="none" pos="word" start_char="10037">to</TOKEN>
<TOKEN end_char="10042" id="token-72-14" morph="none" pos="word" start_char="10040">any</TOKEN>
<TOKEN end_char="10051" id="token-72-15" morph="none" pos="word" start_char="10044">eligible</TOKEN>
<TOKEN end_char="10056" id="token-72-16" morph="none" pos="word" start_char="10053">news</TOKEN>
<TOKEN end_char="10066" id="token-72-17" morph="none" pos="word" start_char="10058">publisher</TOKEN>
<TOKEN end_char="10071" id="token-72-18" morph="none" pos="word" start_char="10068">that</TOKEN>
<TOKEN end_char="10075" id="token-72-19" morph="none" pos="word" start_char="10073">can</TOKEN>
<TOKEN end_char="10083" id="token-72-20" morph="none" pos="word" start_char="10077">provide</TOKEN>
<TOKEN end_char="10085" id="token-72-21" morph="none" pos="word" start_char="10085">a</TOKEN>
<TOKEN end_char="10091" id="token-72-22" morph="none" pos="word" start_char="10087">large</TOKEN>
<TOKEN end_char="10100" id="token-72-23" morph="none" pos="word" start_char="10093">audience</TOKEN>
<TOKEN end_char="10101" id="token-72-24" morph="none" pos="punct" start_char="10101">.</TOKEN>
</SEG>
<SEG end_char="10198" id="segment-73" start_char="10103">
<ORIGINAL_TEXT>For licensing opportunities of our original content, please contact licensing@wndnewscenter.org.</ORIGINAL_TEXT>
<TOKEN end_char="10105" id="token-73-0" morph="none" pos="word" start_char="10103">For</TOKEN>
<TOKEN end_char="10115" id="token-73-1" morph="none" pos="word" start_char="10107">licensing</TOKEN>
<TOKEN end_char="10129" id="token-73-2" morph="none" pos="word" start_char="10117">opportunities</TOKEN>
<TOKEN end_char="10132" id="token-73-3" morph="none" pos="word" start_char="10131">of</TOKEN>
<TOKEN end_char="10136" id="token-73-4" morph="none" pos="word" start_char="10134">our</TOKEN>
<TOKEN end_char="10145" id="token-73-5" morph="none" pos="word" start_char="10138">original</TOKEN>
<TOKEN end_char="10153" id="token-73-6" morph="none" pos="word" start_char="10147">content</TOKEN>
<TOKEN end_char="10154" id="token-73-7" morph="none" pos="punct" start_char="10154">,</TOKEN>
<TOKEN end_char="10161" id="token-73-8" morph="none" pos="word" start_char="10156">please</TOKEN>
<TOKEN end_char="10169" id="token-73-9" morph="none" pos="word" start_char="10163">contact</TOKEN>
<TOKEN end_char="10197" id="token-73-10" morph="none" pos="unknown" start_char="10171">licensing@wndnewscenter.org</TOKEN>
<TOKEN end_char="10198" id="token-73-11" morph="none" pos="punct" start_char="10198">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
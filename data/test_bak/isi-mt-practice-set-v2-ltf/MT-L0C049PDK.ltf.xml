<LCTL_TEXT lang="ukr">
<DOC grammar="none" id="L0C049PDK" lang="ukr" raw_text_char_length="17987" raw_text_md5="ef1e64b8a3b71d355b3f05d33a8e8277" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="59" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Did coronavirus originate in Chinese government laboratory?</ORIGINAL_TEXT>
<TOKEN end_char="3" id="token-0-0" morph="none" pos="word" start_char="1">Did</TOKEN>
<TOKEN end_char="15" id="token-0-1" morph="none" pos="word" start_char="5">coronavirus</TOKEN>
<TOKEN end_char="25" id="token-0-2" morph="none" pos="word" start_char="17">originate</TOKEN>
<TOKEN end_char="28" id="token-0-3" morph="none" pos="word" start_char="27">in</TOKEN>
<TOKEN end_char="36" id="token-0-4" morph="none" pos="word" start_char="30">Chinese</TOKEN>
<TOKEN end_char="47" id="token-0-5" morph="none" pos="word" start_char="38">government</TOKEN>
<TOKEN end_char="58" id="token-0-6" morph="none" pos="word" start_char="49">laboratory</TOKEN>
<TOKEN end_char="59" id="token-0-7" morph="none" pos="punct" start_char="59">?</TOKEN>
</SEG>
<SEG end_char="96" id="segment-1" start_char="61">
<ORIGINAL_TEXT>Chinese Scientists believe "it did."</ORIGINAL_TEXT>
<TOKEN end_char="67" id="token-1-0" morph="none" pos="word" start_char="61">Chinese</TOKEN>
<TOKEN end_char="78" id="token-1-1" morph="none" pos="word" start_char="69">Scientists</TOKEN>
<TOKEN end_char="86" id="token-1-2" morph="none" pos="word" start_char="80">believe</TOKEN>
<TOKEN end_char="88" id="token-1-3" morph="none" pos="punct" start_char="88">"</TOKEN>
<TOKEN end_char="90" id="token-1-4" morph="none" pos="word" start_char="89">it</TOKEN>
<TOKEN end_char="94" id="token-1-5" morph="none" pos="word" start_char="92">did</TOKEN>
<TOKEN end_char="96" id="token-1-6" morph="none" pos="punct" start_char="95">."</TOKEN>
<TRANSLATED_TEXT>Chinese scientists believe "it did."</TRANSLATED_TEXT><DETECTED_LANGUAGE>nl</DETECTED_LANGUAGE></SEG>
<SEG end_char="151" id="segment-2" start_char="100">
<ORIGINAL_TEXT>(Had to truncate the title because it was too long.)</ORIGINAL_TEXT>
<TOKEN end_char="100" id="token-2-0" morph="none" pos="punct" start_char="100">(</TOKEN>
<TOKEN end_char="103" id="token-2-1" morph="none" pos="word" start_char="101">Had</TOKEN>
<TOKEN end_char="106" id="token-2-2" morph="none" pos="word" start_char="105">to</TOKEN>
<TOKEN end_char="115" id="token-2-3" morph="none" pos="word" start_char="108">truncate</TOKEN>
<TOKEN end_char="119" id="token-2-4" morph="none" pos="word" start_char="117">the</TOKEN>
<TOKEN end_char="125" id="token-2-5" morph="none" pos="word" start_char="121">title</TOKEN>
<TOKEN end_char="133" id="token-2-6" morph="none" pos="word" start_char="127">because</TOKEN>
<TOKEN end_char="136" id="token-2-7" morph="none" pos="word" start_char="135">it</TOKEN>
<TOKEN end_char="140" id="token-2-8" morph="none" pos="word" start_char="138">was</TOKEN>
<TOKEN end_char="144" id="token-2-9" morph="none" pos="word" start_char="142">too</TOKEN>
<TOKEN end_char="149" id="token-2-10" morph="none" pos="word" start_char="146">long</TOKEN>
<TOKEN end_char="151" id="token-2-11" morph="none" pos="punct" start_char="150">.)</TOKEN>
</SEG>
<SEG end_char="290" id="segment-3" start_char="154">
<ORIGINAL_TEXT>Chinese scientists believe the deadly coronavirus may have started life in a research facility just 300 yards from the Wuhan fish market.</ORIGINAL_TEXT>
<TOKEN end_char="160" id="token-3-0" morph="none" pos="word" start_char="154">Chinese</TOKEN>
<TOKEN end_char="171" id="token-3-1" morph="none" pos="word" start_char="162">scientists</TOKEN>
<TOKEN end_char="179" id="token-3-2" morph="none" pos="word" start_char="173">believe</TOKEN>
<TOKEN end_char="183" id="token-3-3" morph="none" pos="word" start_char="181">the</TOKEN>
<TOKEN end_char="190" id="token-3-4" morph="none" pos="word" start_char="185">deadly</TOKEN>
<TOKEN end_char="202" id="token-3-5" morph="none" pos="word" start_char="192">coronavirus</TOKEN>
<TOKEN end_char="206" id="token-3-6" morph="none" pos="word" start_char="204">may</TOKEN>
<TOKEN end_char="211" id="token-3-7" morph="none" pos="word" start_char="208">have</TOKEN>
<TOKEN end_char="219" id="token-3-8" morph="none" pos="word" start_char="213">started</TOKEN>
<TOKEN end_char="224" id="token-3-9" morph="none" pos="word" start_char="221">life</TOKEN>
<TOKEN end_char="227" id="token-3-10" morph="none" pos="word" start_char="226">in</TOKEN>
<TOKEN end_char="229" id="token-3-11" morph="none" pos="word" start_char="229">a</TOKEN>
<TOKEN end_char="238" id="token-3-12" morph="none" pos="word" start_char="231">research</TOKEN>
<TOKEN end_char="247" id="token-3-13" morph="none" pos="word" start_char="240">facility</TOKEN>
<TOKEN end_char="252" id="token-3-14" morph="none" pos="word" start_char="249">just</TOKEN>
<TOKEN end_char="256" id="token-3-15" morph="none" pos="word" start_char="254">300</TOKEN>
<TOKEN end_char="262" id="token-3-16" morph="none" pos="word" start_char="258">yards</TOKEN>
<TOKEN end_char="267" id="token-3-17" morph="none" pos="word" start_char="264">from</TOKEN>
<TOKEN end_char="271" id="token-3-18" morph="none" pos="word" start_char="269">the</TOKEN>
<TOKEN end_char="277" id="token-3-19" morph="none" pos="word" start_char="273">Wuhan</TOKEN>
<TOKEN end_char="282" id="token-3-20" morph="none" pos="word" start_char="279">fish</TOKEN>
<TOKEN end_char="289" id="token-3-21" morph="none" pos="word" start_char="284">market</TOKEN>
<TOKEN end_char="290" id="token-3-22" morph="none" pos="punct" start_char="290">.</TOKEN>
</SEG>
<SEG end_char="483" id="segment-4" start_char="292">
<ORIGINAL_TEXT>A new bombshell paper from the Beijing-sponsored South China University of Technology says that the Wuhan Center for Disease Control (WHCDC) could have spawned the contagion in Hubei province.</ORIGINAL_TEXT>
<TOKEN end_char="292" id="token-4-0" morph="none" pos="word" start_char="292">A</TOKEN>
<TOKEN end_char="296" id="token-4-1" morph="none" pos="word" start_char="294">new</TOKEN>
<TOKEN end_char="306" id="token-4-2" morph="none" pos="word" start_char="298">bombshell</TOKEN>
<TOKEN end_char="312" id="token-4-3" morph="none" pos="word" start_char="308">paper</TOKEN>
<TOKEN end_char="317" id="token-4-4" morph="none" pos="word" start_char="314">from</TOKEN>
<TOKEN end_char="321" id="token-4-5" morph="none" pos="word" start_char="319">the</TOKEN>
<TOKEN end_char="339" id="token-4-6" morph="none" pos="unknown" start_char="323">Beijing-sponsored</TOKEN>
<TOKEN end_char="345" id="token-4-7" morph="none" pos="word" start_char="341">South</TOKEN>
<TOKEN end_char="351" id="token-4-8" morph="none" pos="word" start_char="347">China</TOKEN>
<TOKEN end_char="362" id="token-4-9" morph="none" pos="word" start_char="353">University</TOKEN>
<TOKEN end_char="365" id="token-4-10" morph="none" pos="word" start_char="364">of</TOKEN>
<TOKEN end_char="376" id="token-4-11" morph="none" pos="word" start_char="367">Technology</TOKEN>
<TOKEN end_char="381" id="token-4-12" morph="none" pos="word" start_char="378">says</TOKEN>
<TOKEN end_char="386" id="token-4-13" morph="none" pos="word" start_char="383">that</TOKEN>
<TOKEN end_char="390" id="token-4-14" morph="none" pos="word" start_char="388">the</TOKEN>
<TOKEN end_char="396" id="token-4-15" morph="none" pos="word" start_char="392">Wuhan</TOKEN>
<TOKEN end_char="403" id="token-4-16" morph="none" pos="word" start_char="398">Center</TOKEN>
<TOKEN end_char="407" id="token-4-17" morph="none" pos="word" start_char="405">for</TOKEN>
<TOKEN end_char="415" id="token-4-18" morph="none" pos="word" start_char="409">Disease</TOKEN>
<TOKEN end_char="423" id="token-4-19" morph="none" pos="word" start_char="417">Control</TOKEN>
<TOKEN end_char="425" id="token-4-20" morph="none" pos="punct" start_char="425">(</TOKEN>
<TOKEN end_char="430" id="token-4-21" morph="none" pos="word" start_char="426">WHCDC</TOKEN>
<TOKEN end_char="431" id="token-4-22" morph="none" pos="punct" start_char="431">)</TOKEN>
<TOKEN end_char="437" id="token-4-23" morph="none" pos="word" start_char="433">could</TOKEN>
<TOKEN end_char="442" id="token-4-24" morph="none" pos="word" start_char="439">have</TOKEN>
<TOKEN end_char="450" id="token-4-25" morph="none" pos="word" start_char="444">spawned</TOKEN>
<TOKEN end_char="454" id="token-4-26" morph="none" pos="word" start_char="452">the</TOKEN>
<TOKEN end_char="464" id="token-4-27" morph="none" pos="word" start_char="456">contagion</TOKEN>
<TOKEN end_char="467" id="token-4-28" morph="none" pos="word" start_char="466">in</TOKEN>
<TOKEN end_char="473" id="token-4-29" morph="none" pos="word" start_char="469">Hubei</TOKEN>
<TOKEN end_char="482" id="token-4-30" morph="none" pos="word" start_char="475">province</TOKEN>
<TOKEN end_char="483" id="token-4-31" morph="none" pos="punct" start_char="483">.</TOKEN>
</SEG>
<SEG end_char="657" id="segment-5" start_char="485">
<ORIGINAL_TEXT>'The possible origins of 2019-nCoV coronavirus,' penned by scholars Botao Xiao and Lei Xiao claims the WHCDC kept disease-ridden animals in laboratories, including 605 bats.</ORIGINAL_TEXT>
<TOKEN end_char="485" id="token-5-0" morph="none" pos="punct" start_char="485">'</TOKEN>
<TOKEN end_char="488" id="token-5-1" morph="none" pos="word" start_char="486">The</TOKEN>
<TOKEN end_char="497" id="token-5-2" morph="none" pos="word" start_char="490">possible</TOKEN>
<TOKEN end_char="505" id="token-5-3" morph="none" pos="word" start_char="499">origins</TOKEN>
<TOKEN end_char="508" id="token-5-4" morph="none" pos="word" start_char="507">of</TOKEN>
<TOKEN end_char="518" id="token-5-5" morph="none" pos="unknown" start_char="510">2019-nCoV</TOKEN>
<TOKEN end_char="530" id="token-5-6" morph="none" pos="word" start_char="520">coronavirus</TOKEN>
<TOKEN end_char="532" id="token-5-7" morph="none" pos="punct" start_char="531">,'</TOKEN>
<TOKEN end_char="539" id="token-5-8" morph="none" pos="word" start_char="534">penned</TOKEN>
<TOKEN end_char="542" id="token-5-9" morph="none" pos="word" start_char="541">by</TOKEN>
<TOKEN end_char="551" id="token-5-10" morph="none" pos="word" start_char="544">scholars</TOKEN>
<TOKEN end_char="557" id="token-5-11" morph="none" pos="word" start_char="553">Botao</TOKEN>
<TOKEN end_char="562" id="token-5-12" morph="none" pos="word" start_char="559">Xiao</TOKEN>
<TOKEN end_char="566" id="token-5-13" morph="none" pos="word" start_char="564">and</TOKEN>
<TOKEN end_char="570" id="token-5-14" morph="none" pos="word" start_char="568">Lei</TOKEN>
<TOKEN end_char="575" id="token-5-15" morph="none" pos="word" start_char="572">Xiao</TOKEN>
<TOKEN end_char="582" id="token-5-16" morph="none" pos="word" start_char="577">claims</TOKEN>
<TOKEN end_char="586" id="token-5-17" morph="none" pos="word" start_char="584">the</TOKEN>
<TOKEN end_char="592" id="token-5-18" morph="none" pos="word" start_char="588">WHCDC</TOKEN>
<TOKEN end_char="597" id="token-5-19" morph="none" pos="word" start_char="594">kept</TOKEN>
<TOKEN end_char="612" id="token-5-20" morph="none" pos="unknown" start_char="599">disease-ridden</TOKEN>
<TOKEN end_char="620" id="token-5-21" morph="none" pos="word" start_char="614">animals</TOKEN>
<TOKEN end_char="623" id="token-5-22" morph="none" pos="word" start_char="622">in</TOKEN>
<TOKEN end_char="636" id="token-5-23" morph="none" pos="word" start_char="625">laboratories</TOKEN>
<TOKEN end_char="637" id="token-5-24" morph="none" pos="punct" start_char="637">,</TOKEN>
<TOKEN end_char="647" id="token-5-25" morph="none" pos="word" start_char="639">including</TOKEN>
<TOKEN end_char="651" id="token-5-26" morph="none" pos="word" start_char="649">605</TOKEN>
<TOKEN end_char="656" id="token-5-27" morph="none" pos="word" start_char="653">bats</TOKEN>
<TOKEN end_char="657" id="token-5-28" morph="none" pos="punct" start_char="657">.</TOKEN>
</SEG>
<SEG end_char="783" id="segment-6" start_char="659">
<ORIGINAL_TEXT>It also mentions that bats - which are linked to coronavirus - once attacked a researcher and 'blood of bat was on his skin.'</ORIGINAL_TEXT>
<TOKEN end_char="660" id="token-6-0" morph="none" pos="word" start_char="659">It</TOKEN>
<TOKEN end_char="665" id="token-6-1" morph="none" pos="word" start_char="662">also</TOKEN>
<TOKEN end_char="674" id="token-6-2" morph="none" pos="word" start_char="667">mentions</TOKEN>
<TOKEN end_char="679" id="token-6-3" morph="none" pos="word" start_char="676">that</TOKEN>
<TOKEN end_char="684" id="token-6-4" morph="none" pos="word" start_char="681">bats</TOKEN>
<TOKEN end_char="686" id="token-6-5" morph="none" pos="punct" start_char="686">-</TOKEN>
<TOKEN end_char="692" id="token-6-6" morph="none" pos="word" start_char="688">which</TOKEN>
<TOKEN end_char="696" id="token-6-7" morph="none" pos="word" start_char="694">are</TOKEN>
<TOKEN end_char="703" id="token-6-8" morph="none" pos="word" start_char="698">linked</TOKEN>
<TOKEN end_char="706" id="token-6-9" morph="none" pos="word" start_char="705">to</TOKEN>
<TOKEN end_char="718" id="token-6-10" morph="none" pos="word" start_char="708">coronavirus</TOKEN>
<TOKEN end_char="720" id="token-6-11" morph="none" pos="punct" start_char="720">-</TOKEN>
<TOKEN end_char="725" id="token-6-12" morph="none" pos="word" start_char="722">once</TOKEN>
<TOKEN end_char="734" id="token-6-13" morph="none" pos="word" start_char="727">attacked</TOKEN>
<TOKEN end_char="736" id="token-6-14" morph="none" pos="word" start_char="736">a</TOKEN>
<TOKEN end_char="747" id="token-6-15" morph="none" pos="word" start_char="738">researcher</TOKEN>
<TOKEN end_char="751" id="token-6-16" morph="none" pos="word" start_char="749">and</TOKEN>
<TOKEN end_char="753" id="token-6-17" morph="none" pos="punct" start_char="753">'</TOKEN>
<TOKEN end_char="758" id="token-6-18" morph="none" pos="word" start_char="754">blood</TOKEN>
<TOKEN end_char="761" id="token-6-19" morph="none" pos="word" start_char="760">of</TOKEN>
<TOKEN end_char="765" id="token-6-20" morph="none" pos="word" start_char="763">bat</TOKEN>
<TOKEN end_char="769" id="token-6-21" morph="none" pos="word" start_char="767">was</TOKEN>
<TOKEN end_char="772" id="token-6-22" morph="none" pos="word" start_char="771">on</TOKEN>
<TOKEN end_char="776" id="token-6-23" morph="none" pos="word" start_char="774">his</TOKEN>
<TOKEN end_char="781" id="token-6-24" morph="none" pos="word" start_char="778">skin</TOKEN>
<TOKEN end_char="783" id="token-6-25" morph="none" pos="punct" start_char="782">.'</TOKEN>
</SEG>
<SEG end_char="787" id="segment-7" start_char="785">
<ORIGINAL_TEXT>...</ORIGINAL_TEXT>
<TOKEN end_char="787" id="token-7-0" morph="none" pos="punct" start_char="785">...</TOKEN>
<TRANSLATED_TEXT>I...</TRANSLATED_TEXT><DETECTED_LANGUAGE /></SEG>
<SEG end_char="848" id="segment-8" start_char="790">
<ORIGINAL_TEXT>Did coronavirus originate in Chinese government laboratory?</ORIGINAL_TEXT>
<TOKEN end_char="792" id="token-8-0" morph="none" pos="word" start_char="790">Did</TOKEN>
<TOKEN end_char="804" id="token-8-1" morph="none" pos="word" start_char="794">coronavirus</TOKEN>
<TOKEN end_char="814" id="token-8-2" morph="none" pos="word" start_char="806">originate</TOKEN>
<TOKEN end_char="817" id="token-8-3" morph="none" pos="word" start_char="816">in</TOKEN>
<TOKEN end_char="825" id="token-8-4" morph="none" pos="word" start_char="819">Chinese</TOKEN>
<TOKEN end_char="836" id="token-8-5" morph="none" pos="word" start_char="827">government</TOKEN>
<TOKEN end_char="847" id="token-8-6" morph="none" pos="word" start_char="838">laboratory</TOKEN>
<TOKEN end_char="848" id="token-8-7" morph="none" pos="punct" start_char="848">?</TOKEN>
</SEG>
<SEG end_char="955" id="segment-9" start_char="850">
<ORIGINAL_TEXT>Scientists believe killer disease may have begun in research facility 300 yards from Wuhan wet fish market</ORIGINAL_TEXT>
<TOKEN end_char="859" id="token-9-0" morph="none" pos="word" start_char="850">Scientists</TOKEN>
<TOKEN end_char="867" id="token-9-1" morph="none" pos="word" start_char="861">believe</TOKEN>
<TOKEN end_char="874" id="token-9-2" morph="none" pos="word" start_char="869">killer</TOKEN>
<TOKEN end_char="882" id="token-9-3" morph="none" pos="word" start_char="876">disease</TOKEN>
<TOKEN end_char="886" id="token-9-4" morph="none" pos="word" start_char="884">may</TOKEN>
<TOKEN end_char="891" id="token-9-5" morph="none" pos="word" start_char="888">have</TOKEN>
<TOKEN end_char="897" id="token-9-6" morph="none" pos="word" start_char="893">begun</TOKEN>
<TOKEN end_char="900" id="token-9-7" morph="none" pos="word" start_char="899">in</TOKEN>
<TOKEN end_char="909" id="token-9-8" morph="none" pos="word" start_char="902">research</TOKEN>
<TOKEN end_char="918" id="token-9-9" morph="none" pos="word" start_char="911">facility</TOKEN>
<TOKEN end_char="922" id="token-9-10" morph="none" pos="word" start_char="920">300</TOKEN>
<TOKEN end_char="928" id="token-9-11" morph="none" pos="word" start_char="924">yards</TOKEN>
<TOKEN end_char="933" id="token-9-12" morph="none" pos="word" start_char="930">from</TOKEN>
<TOKEN end_char="939" id="token-9-13" morph="none" pos="word" start_char="935">Wuhan</TOKEN>
<TOKEN end_char="943" id="token-9-14" morph="none" pos="word" start_char="941">wet</TOKEN>
<TOKEN end_char="948" id="token-9-15" morph="none" pos="word" start_char="945">fish</TOKEN>
<TOKEN end_char="955" id="token-9-16" morph="none" pos="word" start_char="950">market</TOKEN>
</SEG>
<SEG end_char="1312" id="segment-10" start_char="958">
<ORIGINAL_TEXT>Despite the lies being told by the Chinese government, which now is trying to blame the U.S. for COVID-19, in fact a "Beijing-sponsored South China University of Technology study" concluded that the COVID-19 virus was in fact caused by an accident, in which bats infected with the virus attacked a researcher and "blood of a bat was on skin of researcher.</ORIGINAL_TEXT>
<TOKEN end_char="964" id="token-10-0" morph="none" pos="word" start_char="958">Despite</TOKEN>
<TOKEN end_char="968" id="token-10-1" morph="none" pos="word" start_char="966">the</TOKEN>
<TOKEN end_char="973" id="token-10-2" morph="none" pos="word" start_char="970">lies</TOKEN>
<TOKEN end_char="979" id="token-10-3" morph="none" pos="word" start_char="975">being</TOKEN>
<TOKEN end_char="984" id="token-10-4" morph="none" pos="word" start_char="981">told</TOKEN>
<TOKEN end_char="987" id="token-10-5" morph="none" pos="word" start_char="986">by</TOKEN>
<TOKEN end_char="991" id="token-10-6" morph="none" pos="word" start_char="989">the</TOKEN>
<TOKEN end_char="999" id="token-10-7" morph="none" pos="word" start_char="993">Chinese</TOKEN>
<TOKEN end_char="1010" id="token-10-8" morph="none" pos="word" start_char="1001">government</TOKEN>
<TOKEN end_char="1011" id="token-10-9" morph="none" pos="punct" start_char="1011">,</TOKEN>
<TOKEN end_char="1017" id="token-10-10" morph="none" pos="word" start_char="1013">which</TOKEN>
<TOKEN end_char="1021" id="token-10-11" morph="none" pos="word" start_char="1019">now</TOKEN>
<TOKEN end_char="1024" id="token-10-12" morph="none" pos="word" start_char="1023">is</TOKEN>
<TOKEN end_char="1031" id="token-10-13" morph="none" pos="word" start_char="1026">trying</TOKEN>
<TOKEN end_char="1034" id="token-10-14" morph="none" pos="word" start_char="1033">to</TOKEN>
<TOKEN end_char="1040" id="token-10-15" morph="none" pos="word" start_char="1036">blame</TOKEN>
<TOKEN end_char="1044" id="token-10-16" morph="none" pos="word" start_char="1042">the</TOKEN>
<TOKEN end_char="1048" id="token-10-17" morph="none" pos="unknown" start_char="1046">U.S</TOKEN>
<TOKEN end_char="1049" id="token-10-18" morph="none" pos="punct" start_char="1049">.</TOKEN>
<TOKEN end_char="1053" id="token-10-19" morph="none" pos="word" start_char="1051">for</TOKEN>
<TOKEN end_char="1062" id="token-10-20" morph="none" pos="unknown" start_char="1055">COVID-19</TOKEN>
<TOKEN end_char="1063" id="token-10-21" morph="none" pos="punct" start_char="1063">,</TOKEN>
<TOKEN end_char="1066" id="token-10-22" morph="none" pos="word" start_char="1065">in</TOKEN>
<TOKEN end_char="1071" id="token-10-23" morph="none" pos="word" start_char="1068">fact</TOKEN>
<TOKEN end_char="1073" id="token-10-24" morph="none" pos="word" start_char="1073">a</TOKEN>
<TOKEN end_char="1075" id="token-10-25" morph="none" pos="punct" start_char="1075">"</TOKEN>
<TOKEN end_char="1092" id="token-10-26" morph="none" pos="unknown" start_char="1076">Beijing-sponsored</TOKEN>
<TOKEN end_char="1098" id="token-10-27" morph="none" pos="word" start_char="1094">South</TOKEN>
<TOKEN end_char="1104" id="token-10-28" morph="none" pos="word" start_char="1100">China</TOKEN>
<TOKEN end_char="1115" id="token-10-29" morph="none" pos="word" start_char="1106">University</TOKEN>
<TOKEN end_char="1118" id="token-10-30" morph="none" pos="word" start_char="1117">of</TOKEN>
<TOKEN end_char="1129" id="token-10-31" morph="none" pos="word" start_char="1120">Technology</TOKEN>
<TOKEN end_char="1135" id="token-10-32" morph="none" pos="word" start_char="1131">study</TOKEN>
<TOKEN end_char="1136" id="token-10-33" morph="none" pos="punct" start_char="1136">"</TOKEN>
<TOKEN end_char="1146" id="token-10-34" morph="none" pos="word" start_char="1138">concluded</TOKEN>
<TOKEN end_char="1151" id="token-10-35" morph="none" pos="word" start_char="1148">that</TOKEN>
<TOKEN end_char="1155" id="token-10-36" morph="none" pos="word" start_char="1153">the</TOKEN>
<TOKEN end_char="1164" id="token-10-37" morph="none" pos="unknown" start_char="1157">COVID-19</TOKEN>
<TOKEN end_char="1170" id="token-10-38" morph="none" pos="word" start_char="1166">virus</TOKEN>
<TOKEN end_char="1174" id="token-10-39" morph="none" pos="word" start_char="1172">was</TOKEN>
<TOKEN end_char="1177" id="token-10-40" morph="none" pos="word" start_char="1176">in</TOKEN>
<TOKEN end_char="1182" id="token-10-41" morph="none" pos="word" start_char="1179">fact</TOKEN>
<TOKEN end_char="1189" id="token-10-42" morph="none" pos="word" start_char="1184">caused</TOKEN>
<TOKEN end_char="1192" id="token-10-43" morph="none" pos="word" start_char="1191">by</TOKEN>
<TOKEN end_char="1195" id="token-10-44" morph="none" pos="word" start_char="1194">an</TOKEN>
<TOKEN end_char="1204" id="token-10-45" morph="none" pos="word" start_char="1197">accident</TOKEN>
<TOKEN end_char="1205" id="token-10-46" morph="none" pos="punct" start_char="1205">,</TOKEN>
<TOKEN end_char="1208" id="token-10-47" morph="none" pos="word" start_char="1207">in</TOKEN>
<TOKEN end_char="1214" id="token-10-48" morph="none" pos="word" start_char="1210">which</TOKEN>
<TOKEN end_char="1219" id="token-10-49" morph="none" pos="word" start_char="1216">bats</TOKEN>
<TOKEN end_char="1228" id="token-10-50" morph="none" pos="word" start_char="1221">infected</TOKEN>
<TOKEN end_char="1233" id="token-10-51" morph="none" pos="word" start_char="1230">with</TOKEN>
<TOKEN end_char="1237" id="token-10-52" morph="none" pos="word" start_char="1235">the</TOKEN>
<TOKEN end_char="1243" id="token-10-53" morph="none" pos="word" start_char="1239">virus</TOKEN>
<TOKEN end_char="1252" id="token-10-54" morph="none" pos="word" start_char="1245">attacked</TOKEN>
<TOKEN end_char="1254" id="token-10-55" morph="none" pos="word" start_char="1254">a</TOKEN>
<TOKEN end_char="1265" id="token-10-56" morph="none" pos="word" start_char="1256">researcher</TOKEN>
<TOKEN end_char="1269" id="token-10-57" morph="none" pos="word" start_char="1267">and</TOKEN>
<TOKEN end_char="1271" id="token-10-58" morph="none" pos="punct" start_char="1271">"</TOKEN>
<TOKEN end_char="1276" id="token-10-59" morph="none" pos="word" start_char="1272">blood</TOKEN>
<TOKEN end_char="1279" id="token-10-60" morph="none" pos="word" start_char="1278">of</TOKEN>
<TOKEN end_char="1281" id="token-10-61" morph="none" pos="word" start_char="1281">a</TOKEN>
<TOKEN end_char="1285" id="token-10-62" morph="none" pos="word" start_char="1283">bat</TOKEN>
<TOKEN end_char="1289" id="token-10-63" morph="none" pos="word" start_char="1287">was</TOKEN>
<TOKEN end_char="1292" id="token-10-64" morph="none" pos="word" start_char="1291">on</TOKEN>
<TOKEN end_char="1297" id="token-10-65" morph="none" pos="word" start_char="1294">skin</TOKEN>
<TOKEN end_char="1300" id="token-10-66" morph="none" pos="word" start_char="1299">of</TOKEN>
<TOKEN end_char="1311" id="token-10-67" morph="none" pos="word" start_char="1302">researcher</TOKEN>
<TOKEN end_char="1312" id="token-10-68" morph="none" pos="punct" start_char="1312">.</TOKEN>
</SEG>
<SEG end_char="1482" id="segment-11" start_char="1315">
<ORIGINAL_TEXT>According to the study, the accident occurred in a research facility at the "Wuhan Center for Disease Control and prevention" just 300 yards from the Wuhan fish market.</ORIGINAL_TEXT>
<TOKEN end_char="1323" id="token-11-0" morph="none" pos="word" start_char="1315">According</TOKEN>
<TOKEN end_char="1326" id="token-11-1" morph="none" pos="word" start_char="1325">to</TOKEN>
<TOKEN end_char="1330" id="token-11-2" morph="none" pos="word" start_char="1328">the</TOKEN>
<TOKEN end_char="1336" id="token-11-3" morph="none" pos="word" start_char="1332">study</TOKEN>
<TOKEN end_char="1337" id="token-11-4" morph="none" pos="punct" start_char="1337">,</TOKEN>
<TOKEN end_char="1341" id="token-11-5" morph="none" pos="word" start_char="1339">the</TOKEN>
<TOKEN end_char="1350" id="token-11-6" morph="none" pos="word" start_char="1343">accident</TOKEN>
<TOKEN end_char="1359" id="token-11-7" morph="none" pos="word" start_char="1352">occurred</TOKEN>
<TOKEN end_char="1362" id="token-11-8" morph="none" pos="word" start_char="1361">in</TOKEN>
<TOKEN end_char="1364" id="token-11-9" morph="none" pos="word" start_char="1364">a</TOKEN>
<TOKEN end_char="1373" id="token-11-10" morph="none" pos="word" start_char="1366">research</TOKEN>
<TOKEN end_char="1382" id="token-11-11" morph="none" pos="word" start_char="1375">facility</TOKEN>
<TOKEN end_char="1385" id="token-11-12" morph="none" pos="word" start_char="1384">at</TOKEN>
<TOKEN end_char="1389" id="token-11-13" morph="none" pos="word" start_char="1387">the</TOKEN>
<TOKEN end_char="1391" id="token-11-14" morph="none" pos="punct" start_char="1391">"</TOKEN>
<TOKEN end_char="1396" id="token-11-15" morph="none" pos="word" start_char="1392">Wuhan</TOKEN>
<TOKEN end_char="1403" id="token-11-16" morph="none" pos="word" start_char="1398">Center</TOKEN>
<TOKEN end_char="1407" id="token-11-17" morph="none" pos="word" start_char="1405">for</TOKEN>
<TOKEN end_char="1415" id="token-11-18" morph="none" pos="word" start_char="1409">Disease</TOKEN>
<TOKEN end_char="1423" id="token-11-19" morph="none" pos="word" start_char="1417">Control</TOKEN>
<TOKEN end_char="1427" id="token-11-20" morph="none" pos="word" start_char="1425">and</TOKEN>
<TOKEN end_char="1438" id="token-11-21" morph="none" pos="word" start_char="1429">prevention</TOKEN>
<TOKEN end_char="1439" id="token-11-22" morph="none" pos="punct" start_char="1439">"</TOKEN>
<TOKEN end_char="1444" id="token-11-23" morph="none" pos="word" start_char="1441">just</TOKEN>
<TOKEN end_char="1448" id="token-11-24" morph="none" pos="word" start_char="1446">300</TOKEN>
<TOKEN end_char="1454" id="token-11-25" morph="none" pos="word" start_char="1450">yards</TOKEN>
<TOKEN end_char="1459" id="token-11-26" morph="none" pos="word" start_char="1456">from</TOKEN>
<TOKEN end_char="1463" id="token-11-27" morph="none" pos="word" start_char="1461">the</TOKEN>
<TOKEN end_char="1469" id="token-11-28" morph="none" pos="word" start_char="1465">Wuhan</TOKEN>
<TOKEN end_char="1474" id="token-11-29" morph="none" pos="word" start_char="1471">fish</TOKEN>
<TOKEN end_char="1481" id="token-11-30" morph="none" pos="word" start_char="1476">market</TOKEN>
<TOKEN end_char="1482" id="token-11-31" morph="none" pos="punct" start_char="1482">.</TOKEN>
</SEG>
<SEG end_char="1655" id="segment-12" start_char="1485">
<ORIGINAL_TEXT>So folks, despite all the lies that even the western left-wing media themselves, and the Chinese government, have been claiming this virus is a Wuhan/Chinese caused virus.</ORIGINAL_TEXT>
<TOKEN end_char="1486" id="token-12-0" morph="none" pos="word" start_char="1485">So</TOKEN>
<TOKEN end_char="1492" id="token-12-1" morph="none" pos="word" start_char="1488">folks</TOKEN>
<TOKEN end_char="1493" id="token-12-2" morph="none" pos="punct" start_char="1493">,</TOKEN>
<TOKEN end_char="1501" id="token-12-3" morph="none" pos="word" start_char="1495">despite</TOKEN>
<TOKEN end_char="1505" id="token-12-4" morph="none" pos="word" start_char="1503">all</TOKEN>
<TOKEN end_char="1509" id="token-12-5" morph="none" pos="word" start_char="1507">the</TOKEN>
<TOKEN end_char="1514" id="token-12-6" morph="none" pos="word" start_char="1511">lies</TOKEN>
<TOKEN end_char="1519" id="token-12-7" morph="none" pos="word" start_char="1516">that</TOKEN>
<TOKEN end_char="1524" id="token-12-8" morph="none" pos="word" start_char="1521">even</TOKEN>
<TOKEN end_char="1528" id="token-12-9" morph="none" pos="word" start_char="1526">the</TOKEN>
<TOKEN end_char="1536" id="token-12-10" morph="none" pos="word" start_char="1530">western</TOKEN>
<TOKEN end_char="1546" id="token-12-11" morph="none" pos="unknown" start_char="1538">left-wing</TOKEN>
<TOKEN end_char="1552" id="token-12-12" morph="none" pos="word" start_char="1548">media</TOKEN>
<TOKEN end_char="1563" id="token-12-13" morph="none" pos="word" start_char="1554">themselves</TOKEN>
<TOKEN end_char="1564" id="token-12-14" morph="none" pos="punct" start_char="1564">,</TOKEN>
<TOKEN end_char="1568" id="token-12-15" morph="none" pos="word" start_char="1566">and</TOKEN>
<TOKEN end_char="1572" id="token-12-16" morph="none" pos="word" start_char="1570">the</TOKEN>
<TOKEN end_char="1580" id="token-12-17" morph="none" pos="word" start_char="1574">Chinese</TOKEN>
<TOKEN end_char="1591" id="token-12-18" morph="none" pos="word" start_char="1582">government</TOKEN>
<TOKEN end_char="1592" id="token-12-19" morph="none" pos="punct" start_char="1592">,</TOKEN>
<TOKEN end_char="1597" id="token-12-20" morph="none" pos="word" start_char="1594">have</TOKEN>
<TOKEN end_char="1602" id="token-12-21" morph="none" pos="word" start_char="1599">been</TOKEN>
<TOKEN end_char="1611" id="token-12-22" morph="none" pos="word" start_char="1604">claiming</TOKEN>
<TOKEN end_char="1616" id="token-12-23" morph="none" pos="word" start_char="1613">this</TOKEN>
<TOKEN end_char="1622" id="token-12-24" morph="none" pos="word" start_char="1618">virus</TOKEN>
<TOKEN end_char="1625" id="token-12-25" morph="none" pos="word" start_char="1624">is</TOKEN>
<TOKEN end_char="1627" id="token-12-26" morph="none" pos="word" start_char="1627">a</TOKEN>
<TOKEN end_char="1641" id="token-12-27" morph="none" pos="unknown" start_char="1629">Wuhan/Chinese</TOKEN>
<TOKEN end_char="1648" id="token-12-28" morph="none" pos="word" start_char="1643">caused</TOKEN>
<TOKEN end_char="1654" id="token-12-29" morph="none" pos="word" start_char="1650">virus</TOKEN>
<TOKEN end_char="1655" id="token-12-30" morph="none" pos="punct" start_char="1655">.</TOKEN>
</SEG>
<SEG end_char="1730" id="segment-13" start_char="1658">
<ORIGINAL_TEXT>edit on 12-3-2020 by ElectricUniverse because: correct comment and title.</ORIGINAL_TEXT>
<TOKEN end_char="1661" id="token-13-0" morph="none" pos="word" start_char="1658">edit</TOKEN>
<TOKEN end_char="1664" id="token-13-1" morph="none" pos="word" start_char="1663">on</TOKEN>
<TOKEN end_char="1674" id="token-13-2" morph="none" pos="unknown" start_char="1666">12-3-2020</TOKEN>
<TOKEN end_char="1677" id="token-13-3" morph="none" pos="word" start_char="1676">by</TOKEN>
<TOKEN end_char="1694" id="token-13-4" morph="none" pos="word" start_char="1679">ElectricUniverse</TOKEN>
<TOKEN end_char="1702" id="token-13-5" morph="none" pos="word" start_char="1696">because</TOKEN>
<TOKEN end_char="1703" id="token-13-6" morph="none" pos="punct" start_char="1703">:</TOKEN>
<TOKEN end_char="1711" id="token-13-7" morph="none" pos="word" start_char="1705">correct</TOKEN>
<TOKEN end_char="1719" id="token-13-8" morph="none" pos="word" start_char="1713">comment</TOKEN>
<TOKEN end_char="1723" id="token-13-9" morph="none" pos="word" start_char="1721">and</TOKEN>
<TOKEN end_char="1729" id="token-13-10" morph="none" pos="word" start_char="1725">title</TOKEN>
<TOKEN end_char="1730" id="token-13-11" morph="none" pos="punct" start_char="1730">.</TOKEN>
</SEG>
<SEG end_char="1768" id="segment-14" start_char="1734">
<ORIGINAL_TEXT>Man, that article is purely hearsy.</ORIGINAL_TEXT>
<TOKEN end_char="1736" id="token-14-0" morph="none" pos="word" start_char="1734">Man</TOKEN>
<TOKEN end_char="1737" id="token-14-1" morph="none" pos="punct" start_char="1737">,</TOKEN>
<TOKEN end_char="1742" id="token-14-2" morph="none" pos="word" start_char="1739">that</TOKEN>
<TOKEN end_char="1750" id="token-14-3" morph="none" pos="word" start_char="1744">article</TOKEN>
<TOKEN end_char="1753" id="token-14-4" morph="none" pos="word" start_char="1752">is</TOKEN>
<TOKEN end_char="1760" id="token-14-5" morph="none" pos="word" start_char="1755">purely</TOKEN>
<TOKEN end_char="1767" id="token-14-6" morph="none" pos="word" start_char="1762">hearsy</TOKEN>
<TOKEN end_char="1768" id="token-14-7" morph="none" pos="punct" start_char="1768">.</TOKEN>
</SEG>
<SEG end_char="1848" id="segment-15" start_char="1770">
<ORIGINAL_TEXT>The DailyMail and other sites that mention this "bombshell" say the same thing.</ORIGINAL_TEXT>
<TOKEN end_char="1772" id="token-15-0" morph="none" pos="word" start_char="1770">The</TOKEN>
<TOKEN end_char="1782" id="token-15-1" morph="none" pos="word" start_char="1774">DailyMail</TOKEN>
<TOKEN end_char="1786" id="token-15-2" morph="none" pos="word" start_char="1784">and</TOKEN>
<TOKEN end_char="1792" id="token-15-3" morph="none" pos="word" start_char="1788">other</TOKEN>
<TOKEN end_char="1798" id="token-15-4" morph="none" pos="word" start_char="1794">sites</TOKEN>
<TOKEN end_char="1803" id="token-15-5" morph="none" pos="word" start_char="1800">that</TOKEN>
<TOKEN end_char="1811" id="token-15-6" morph="none" pos="word" start_char="1805">mention</TOKEN>
<TOKEN end_char="1816" id="token-15-7" morph="none" pos="word" start_char="1813">this</TOKEN>
<TOKEN end_char="1818" id="token-15-8" morph="none" pos="punct" start_char="1818">"</TOKEN>
<TOKEN end_char="1827" id="token-15-9" morph="none" pos="word" start_char="1819">bombshell</TOKEN>
<TOKEN end_char="1828" id="token-15-10" morph="none" pos="punct" start_char="1828">"</TOKEN>
<TOKEN end_char="1832" id="token-15-11" morph="none" pos="word" start_char="1830">say</TOKEN>
<TOKEN end_char="1836" id="token-15-12" morph="none" pos="word" start_char="1834">the</TOKEN>
<TOKEN end_char="1841" id="token-15-13" morph="none" pos="word" start_char="1838">same</TOKEN>
<TOKEN end_char="1847" id="token-15-14" morph="none" pos="word" start_char="1843">thing</TOKEN>
<TOKEN end_char="1848" id="token-15-15" morph="none" pos="punct" start_char="1848">.</TOKEN>
</SEG>
<SEG end_char="1879" id="segment-16" start_char="1851">
<ORIGINAL_TEXT>Without linking to the paper.</ORIGINAL_TEXT>
<TOKEN end_char="1857" id="token-16-0" morph="none" pos="word" start_char="1851">Without</TOKEN>
<TOKEN end_char="1865" id="token-16-1" morph="none" pos="word" start_char="1859">linking</TOKEN>
<TOKEN end_char="1868" id="token-16-2" morph="none" pos="word" start_char="1867">to</TOKEN>
<TOKEN end_char="1872" id="token-16-3" morph="none" pos="word" start_char="1870">the</TOKEN>
<TOKEN end_char="1878" id="token-16-4" morph="none" pos="word" start_char="1874">paper</TOKEN>
<TOKEN end_char="1879" id="token-16-5" morph="none" pos="punct" start_char="1879">.</TOKEN>
</SEG>
<SEG end_char="1948" id="segment-17" start_char="1881">
<ORIGINAL_TEXT>This is fake news till we can get a legitimate source for the paper.</ORIGINAL_TEXT>
<TOKEN end_char="1884" id="token-17-0" morph="none" pos="word" start_char="1881">This</TOKEN>
<TOKEN end_char="1887" id="token-17-1" morph="none" pos="word" start_char="1886">is</TOKEN>
<TOKEN end_char="1892" id="token-17-2" morph="none" pos="word" start_char="1889">fake</TOKEN>
<TOKEN end_char="1897" id="token-17-3" morph="none" pos="word" start_char="1894">news</TOKEN>
<TOKEN end_char="1902" id="token-17-4" morph="none" pos="word" start_char="1899">till</TOKEN>
<TOKEN end_char="1905" id="token-17-5" morph="none" pos="word" start_char="1904">we</TOKEN>
<TOKEN end_char="1909" id="token-17-6" morph="none" pos="word" start_char="1907">can</TOKEN>
<TOKEN end_char="1913" id="token-17-7" morph="none" pos="word" start_char="1911">get</TOKEN>
<TOKEN end_char="1915" id="token-17-8" morph="none" pos="word" start_char="1915">a</TOKEN>
<TOKEN end_char="1926" id="token-17-9" morph="none" pos="word" start_char="1917">legitimate</TOKEN>
<TOKEN end_char="1933" id="token-17-10" morph="none" pos="word" start_char="1928">source</TOKEN>
<TOKEN end_char="1937" id="token-17-11" morph="none" pos="word" start_char="1935">for</TOKEN>
<TOKEN end_char="1941" id="token-17-12" morph="none" pos="word" start_char="1939">the</TOKEN>
<TOKEN end_char="1947" id="token-17-13" morph="none" pos="word" start_char="1943">paper</TOKEN>
<TOKEN end_char="1948" id="token-17-14" morph="none" pos="punct" start_char="1948">.</TOKEN>
</SEG>
<SEG end_char="1977" id="segment-18" start_char="1951">
<ORIGINAL_TEXT>Or the actual paper itself.</ORIGINAL_TEXT>
<TOKEN end_char="1952" id="token-18-0" morph="none" pos="word" start_char="1951">Or</TOKEN>
<TOKEN end_char="1956" id="token-18-1" morph="none" pos="word" start_char="1954">the</TOKEN>
<TOKEN end_char="1963" id="token-18-2" morph="none" pos="word" start_char="1958">actual</TOKEN>
<TOKEN end_char="1969" id="token-18-3" morph="none" pos="word" start_char="1965">paper</TOKEN>
<TOKEN end_char="1976" id="token-18-4" morph="none" pos="word" start_char="1971">itself</TOKEN>
<TOKEN end_char="1977" id="token-18-5" morph="none" pos="punct" start_char="1977">.</TOKEN>
</SEG>
<SEG end_char="1999" id="segment-19" start_char="1980">
<ORIGINAL_TEXT>Nevermind, found it!</ORIGINAL_TEXT>
<TOKEN end_char="1988" id="token-19-0" morph="none" pos="word" start_char="1980">Nevermind</TOKEN>
<TOKEN end_char="1989" id="token-19-1" morph="none" pos="punct" start_char="1989">,</TOKEN>
<TOKEN end_char="1995" id="token-19-2" morph="none" pos="word" start_char="1991">found</TOKEN>
<TOKEN end_char="1998" id="token-19-3" morph="none" pos="word" start_char="1997">it</TOKEN>
<TOKEN end_char="1999" id="token-19-4" morph="none" pos="punct" start_char="1999">!</TOKEN>
</SEG>
<SEG end_char="2045" id="segment-20" start_char="2001">
<ORIGINAL_TEXT>The possible origins of 2019-nCoV coronavirus</ORIGINAL_TEXT>
<TOKEN end_char="2003" id="token-20-0" morph="none" pos="word" start_char="2001">The</TOKEN>
<TOKEN end_char="2012" id="token-20-1" morph="none" pos="word" start_char="2005">possible</TOKEN>
<TOKEN end_char="2020" id="token-20-2" morph="none" pos="word" start_char="2014">origins</TOKEN>
<TOKEN end_char="2023" id="token-20-3" morph="none" pos="word" start_char="2022">of</TOKEN>
<TOKEN end_char="2033" id="token-20-4" morph="none" pos="unknown" start_char="2025">2019-nCoV</TOKEN>
<TOKEN end_char="2045" id="token-20-5" morph="none" pos="word" start_char="2035">coronavirus</TOKEN>
</SEG>
<SEG end_char="2069" id="segment-21" start_char="2049">
<ORIGINAL_TEXT>a reply to: cenpuppie</ORIGINAL_TEXT>
<TOKEN end_char="2049" id="token-21-0" morph="none" pos="word" start_char="2049">a</TOKEN>
<TOKEN end_char="2055" id="token-21-1" morph="none" pos="word" start_char="2051">reply</TOKEN>
<TOKEN end_char="2058" id="token-21-2" morph="none" pos="word" start_char="2057">to</TOKEN>
<TOKEN end_char="2059" id="token-21-3" morph="none" pos="punct" start_char="2059">:</TOKEN>
<TOKEN end_char="2069" id="token-21-4" morph="none" pos="word" start_char="2061">cenpuppie</TOKEN>
</SEG>
<SEG end_char="2120" id="segment-22" start_char="2072">
<ORIGINAL_TEXT>I also wonder about the provenance of this paper.</ORIGINAL_TEXT>
<TOKEN end_char="2072" id="token-22-0" morph="none" pos="word" start_char="2072">I</TOKEN>
<TOKEN end_char="2077" id="token-22-1" morph="none" pos="word" start_char="2074">also</TOKEN>
<TOKEN end_char="2084" id="token-22-2" morph="none" pos="word" start_char="2079">wonder</TOKEN>
<TOKEN end_char="2090" id="token-22-3" morph="none" pos="word" start_char="2086">about</TOKEN>
<TOKEN end_char="2094" id="token-22-4" morph="none" pos="word" start_char="2092">the</TOKEN>
<TOKEN end_char="2105" id="token-22-5" morph="none" pos="word" start_char="2096">provenance</TOKEN>
<TOKEN end_char="2108" id="token-22-6" morph="none" pos="word" start_char="2107">of</TOKEN>
<TOKEN end_char="2113" id="token-22-7" morph="none" pos="word" start_char="2110">this</TOKEN>
<TOKEN end_char="2119" id="token-22-8" morph="none" pos="word" start_char="2115">paper</TOKEN>
<TOKEN end_char="2120" id="token-22-9" morph="none" pos="punct" start_char="2120">.</TOKEN>
</SEG>
<SEG end_char="2190" id="segment-23" start_char="2122">
<ORIGINAL_TEXT>Is clien.net an official forum for distribution of research in China?</ORIGINAL_TEXT>
<TOKEN end_char="2123" id="token-23-0" morph="none" pos="word" start_char="2122">Is</TOKEN>
<TOKEN end_char="2133" id="token-23-1" morph="none" pos="unknown" start_char="2125">clien.net</TOKEN>
<TOKEN end_char="2136" id="token-23-2" morph="none" pos="word" start_char="2135">an</TOKEN>
<TOKEN end_char="2145" id="token-23-3" morph="none" pos="word" start_char="2138">official</TOKEN>
<TOKEN end_char="2151" id="token-23-4" morph="none" pos="word" start_char="2147">forum</TOKEN>
<TOKEN end_char="2155" id="token-23-5" morph="none" pos="word" start_char="2153">for</TOKEN>
<TOKEN end_char="2168" id="token-23-6" morph="none" pos="word" start_char="2157">distribution</TOKEN>
<TOKEN end_char="2171" id="token-23-7" morph="none" pos="word" start_char="2170">of</TOKEN>
<TOKEN end_char="2180" id="token-23-8" morph="none" pos="word" start_char="2173">research</TOKEN>
<TOKEN end_char="2183" id="token-23-9" morph="none" pos="word" start_char="2182">in</TOKEN>
<TOKEN end_char="2189" id="token-23-10" morph="none" pos="word" start_char="2185">China</TOKEN>
<TOKEN end_char="2190" id="token-23-11" morph="none" pos="punct" start_char="2190">?</TOKEN>
</SEG>
<SEG end_char="2246" id="segment-24" start_char="2192">
<ORIGINAL_TEXT>(I can't see anything implying that in a brief search.)</ORIGINAL_TEXT>
<TOKEN end_char="2192" id="token-24-0" morph="none" pos="punct" start_char="2192">(</TOKEN>
<TOKEN end_char="2193" id="token-24-1" morph="none" pos="word" start_char="2193">I</TOKEN>
<TOKEN end_char="2199" id="token-24-2" morph="none" pos="word" start_char="2195">can't</TOKEN>
<TOKEN end_char="2203" id="token-24-3" morph="none" pos="word" start_char="2201">see</TOKEN>
<TOKEN end_char="2212" id="token-24-4" morph="none" pos="word" start_char="2205">anything</TOKEN>
<TOKEN end_char="2221" id="token-24-5" morph="none" pos="word" start_char="2214">implying</TOKEN>
<TOKEN end_char="2226" id="token-24-6" morph="none" pos="word" start_char="2223">that</TOKEN>
<TOKEN end_char="2229" id="token-24-7" morph="none" pos="word" start_char="2228">in</TOKEN>
<TOKEN end_char="2231" id="token-24-8" morph="none" pos="word" start_char="2231">a</TOKEN>
<TOKEN end_char="2237" id="token-24-9" morph="none" pos="word" start_char="2233">brief</TOKEN>
<TOKEN end_char="2244" id="token-24-10" morph="none" pos="word" start_char="2239">search</TOKEN>
<TOKEN end_char="2246" id="token-24-11" morph="none" pos="punct" start_char="2245">.)</TOKEN>
</SEG>
<SEG end_char="2307" id="segment-25" start_char="2249">
<ORIGINAL_TEXT>Just wondering if this document isn't something fraudulent.</ORIGINAL_TEXT>
<TOKEN end_char="2252" id="token-25-0" morph="none" pos="word" start_char="2249">Just</TOKEN>
<TOKEN end_char="2262" id="token-25-1" morph="none" pos="word" start_char="2254">wondering</TOKEN>
<TOKEN end_char="2265" id="token-25-2" morph="none" pos="word" start_char="2264">if</TOKEN>
<TOKEN end_char="2270" id="token-25-3" morph="none" pos="word" start_char="2267">this</TOKEN>
<TOKEN end_char="2279" id="token-25-4" morph="none" pos="word" start_char="2272">document</TOKEN>
<TOKEN end_char="2285" id="token-25-5" morph="none" pos="word" start_char="2281">isn't</TOKEN>
<TOKEN end_char="2295" id="token-25-6" morph="none" pos="word" start_char="2287">something</TOKEN>
<TOKEN end_char="2306" id="token-25-7" morph="none" pos="word" start_char="2297">fraudulent</TOKEN>
<TOKEN end_char="2307" id="token-25-8" morph="none" pos="punct" start_char="2307">.</TOKEN>
</SEG>
<SEG end_char="2376" id="segment-26" start_char="2309">
<ORIGINAL_TEXT>Hard to believe the CCP would be okay with that kind of speculation.</ORIGINAL_TEXT>
<TOKEN end_char="2312" id="token-26-0" morph="none" pos="word" start_char="2309">Hard</TOKEN>
<TOKEN end_char="2315" id="token-26-1" morph="none" pos="word" start_char="2314">to</TOKEN>
<TOKEN end_char="2323" id="token-26-2" morph="none" pos="word" start_char="2317">believe</TOKEN>
<TOKEN end_char="2327" id="token-26-3" morph="none" pos="word" start_char="2325">the</TOKEN>
<TOKEN end_char="2331" id="token-26-4" morph="none" pos="word" start_char="2329">CCP</TOKEN>
<TOKEN end_char="2337" id="token-26-5" morph="none" pos="word" start_char="2333">would</TOKEN>
<TOKEN end_char="2340" id="token-26-6" morph="none" pos="word" start_char="2339">be</TOKEN>
<TOKEN end_char="2345" id="token-26-7" morph="none" pos="word" start_char="2342">okay</TOKEN>
<TOKEN end_char="2350" id="token-26-8" morph="none" pos="word" start_char="2347">with</TOKEN>
<TOKEN end_char="2355" id="token-26-9" morph="none" pos="word" start_char="2352">that</TOKEN>
<TOKEN end_char="2360" id="token-26-10" morph="none" pos="word" start_char="2357">kind</TOKEN>
<TOKEN end_char="2363" id="token-26-11" morph="none" pos="word" start_char="2362">of</TOKEN>
<TOKEN end_char="2375" id="token-26-12" morph="none" pos="word" start_char="2365">speculation</TOKEN>
<TOKEN end_char="2376" id="token-26-13" morph="none" pos="punct" start_char="2376">.</TOKEN>
</SEG>
<SEG end_char="2384" id="segment-27" start_char="2379">
<ORIGINAL_TEXT>Cheers</ORIGINAL_TEXT>
<TOKEN end_char="2384" id="token-27-0" morph="none" pos="word" start_char="2379">Cheers</TOKEN>
<TRANSLATED_TEXT>Cheers!</TRANSLATED_TEXT><DETECTED_LANGUAGE>nl</DETECTED_LANGUAGE></SEG>
<SEG end_char="2527" id="segment-28" start_char="2388">
<ORIGINAL_TEXT>Or the Chinese in Wuhan province are dirty hamsters and this is the natural result of poor food preparation and lack of sanitary conditions.</ORIGINAL_TEXT>
<TOKEN end_char="2389" id="token-28-0" morph="none" pos="word" start_char="2388">Or</TOKEN>
<TOKEN end_char="2393" id="token-28-1" morph="none" pos="word" start_char="2391">the</TOKEN>
<TOKEN end_char="2401" id="token-28-2" morph="none" pos="word" start_char="2395">Chinese</TOKEN>
<TOKEN end_char="2404" id="token-28-3" morph="none" pos="word" start_char="2403">in</TOKEN>
<TOKEN end_char="2410" id="token-28-4" morph="none" pos="word" start_char="2406">Wuhan</TOKEN>
<TOKEN end_char="2419" id="token-28-5" morph="none" pos="word" start_char="2412">province</TOKEN>
<TOKEN end_char="2423" id="token-28-6" morph="none" pos="word" start_char="2421">are</TOKEN>
<TOKEN end_char="2429" id="token-28-7" morph="none" pos="word" start_char="2425">dirty</TOKEN>
<TOKEN end_char="2438" id="token-28-8" morph="none" pos="word" start_char="2431">hamsters</TOKEN>
<TOKEN end_char="2442" id="token-28-9" morph="none" pos="word" start_char="2440">and</TOKEN>
<TOKEN end_char="2447" id="token-28-10" morph="none" pos="word" start_char="2444">this</TOKEN>
<TOKEN end_char="2450" id="token-28-11" morph="none" pos="word" start_char="2449">is</TOKEN>
<TOKEN end_char="2454" id="token-28-12" morph="none" pos="word" start_char="2452">the</TOKEN>
<TOKEN end_char="2462" id="token-28-13" morph="none" pos="word" start_char="2456">natural</TOKEN>
<TOKEN end_char="2469" id="token-28-14" morph="none" pos="word" start_char="2464">result</TOKEN>
<TOKEN end_char="2472" id="token-28-15" morph="none" pos="word" start_char="2471">of</TOKEN>
<TOKEN end_char="2477" id="token-28-16" morph="none" pos="word" start_char="2474">poor</TOKEN>
<TOKEN end_char="2482" id="token-28-17" morph="none" pos="word" start_char="2479">food</TOKEN>
<TOKEN end_char="2494" id="token-28-18" morph="none" pos="word" start_char="2484">preparation</TOKEN>
<TOKEN end_char="2498" id="token-28-19" morph="none" pos="word" start_char="2496">and</TOKEN>
<TOKEN end_char="2503" id="token-28-20" morph="none" pos="word" start_char="2500">lack</TOKEN>
<TOKEN end_char="2506" id="token-28-21" morph="none" pos="word" start_char="2505">of</TOKEN>
<TOKEN end_char="2515" id="token-28-22" morph="none" pos="word" start_char="2508">sanitary</TOKEN>
<TOKEN end_char="2526" id="token-28-23" morph="none" pos="word" start_char="2517">conditions</TOKEN>
<TOKEN end_char="2527" id="token-28-24" morph="none" pos="punct" start_char="2527">.</TOKEN>
</SEG>
<SEG end_char="2795" id="segment-29" start_char="2531">
<ORIGINAL_TEXT>Corona virus was first discovered in the 1960s, fair to say the military in many countries have tried to weaponise it, maybe the Chinese succeeded, maybe the Americans did, one thing is for sure the daily fail and other infotainment agencies don't have the answers.</ORIGINAL_TEXT>
<TOKEN end_char="2536" id="token-29-0" morph="none" pos="word" start_char="2531">Corona</TOKEN>
<TOKEN end_char="2542" id="token-29-1" morph="none" pos="word" start_char="2538">virus</TOKEN>
<TOKEN end_char="2546" id="token-29-2" morph="none" pos="word" start_char="2544">was</TOKEN>
<TOKEN end_char="2552" id="token-29-3" morph="none" pos="word" start_char="2548">first</TOKEN>
<TOKEN end_char="2563" id="token-29-4" morph="none" pos="word" start_char="2554">discovered</TOKEN>
<TOKEN end_char="2566" id="token-29-5" morph="none" pos="word" start_char="2565">in</TOKEN>
<TOKEN end_char="2570" id="token-29-6" morph="none" pos="word" start_char="2568">the</TOKEN>
<TOKEN end_char="2576" id="token-29-7" morph="none" pos="word" start_char="2572">1960s</TOKEN>
<TOKEN end_char="2577" id="token-29-8" morph="none" pos="punct" start_char="2577">,</TOKEN>
<TOKEN end_char="2582" id="token-29-9" morph="none" pos="word" start_char="2579">fair</TOKEN>
<TOKEN end_char="2585" id="token-29-10" morph="none" pos="word" start_char="2584">to</TOKEN>
<TOKEN end_char="2589" id="token-29-11" morph="none" pos="word" start_char="2587">say</TOKEN>
<TOKEN end_char="2593" id="token-29-12" morph="none" pos="word" start_char="2591">the</TOKEN>
<TOKEN end_char="2602" id="token-29-13" morph="none" pos="word" start_char="2595">military</TOKEN>
<TOKEN end_char="2605" id="token-29-14" morph="none" pos="word" start_char="2604">in</TOKEN>
<TOKEN end_char="2610" id="token-29-15" morph="none" pos="word" start_char="2607">many</TOKEN>
<TOKEN end_char="2620" id="token-29-16" morph="none" pos="word" start_char="2612">countries</TOKEN>
<TOKEN end_char="2625" id="token-29-17" morph="none" pos="word" start_char="2622">have</TOKEN>
<TOKEN end_char="2631" id="token-29-18" morph="none" pos="word" start_char="2627">tried</TOKEN>
<TOKEN end_char="2634" id="token-29-19" morph="none" pos="word" start_char="2633">to</TOKEN>
<TOKEN end_char="2644" id="token-29-20" morph="none" pos="word" start_char="2636">weaponise</TOKEN>
<TOKEN end_char="2647" id="token-29-21" morph="none" pos="word" start_char="2646">it</TOKEN>
<TOKEN end_char="2648" id="token-29-22" morph="none" pos="punct" start_char="2648">,</TOKEN>
<TOKEN end_char="2654" id="token-29-23" morph="none" pos="word" start_char="2650">maybe</TOKEN>
<TOKEN end_char="2658" id="token-29-24" morph="none" pos="word" start_char="2656">the</TOKEN>
<TOKEN end_char="2666" id="token-29-25" morph="none" pos="word" start_char="2660">Chinese</TOKEN>
<TOKEN end_char="2676" id="token-29-26" morph="none" pos="word" start_char="2668">succeeded</TOKEN>
<TOKEN end_char="2677" id="token-29-27" morph="none" pos="punct" start_char="2677">,</TOKEN>
<TOKEN end_char="2683" id="token-29-28" morph="none" pos="word" start_char="2679">maybe</TOKEN>
<TOKEN end_char="2687" id="token-29-29" morph="none" pos="word" start_char="2685">the</TOKEN>
<TOKEN end_char="2697" id="token-29-30" morph="none" pos="word" start_char="2689">Americans</TOKEN>
<TOKEN end_char="2701" id="token-29-31" morph="none" pos="word" start_char="2699">did</TOKEN>
<TOKEN end_char="2702" id="token-29-32" morph="none" pos="punct" start_char="2702">,</TOKEN>
<TOKEN end_char="2706" id="token-29-33" morph="none" pos="word" start_char="2704">one</TOKEN>
<TOKEN end_char="2712" id="token-29-34" morph="none" pos="word" start_char="2708">thing</TOKEN>
<TOKEN end_char="2715" id="token-29-35" morph="none" pos="word" start_char="2714">is</TOKEN>
<TOKEN end_char="2719" id="token-29-36" morph="none" pos="word" start_char="2717">for</TOKEN>
<TOKEN end_char="2724" id="token-29-37" morph="none" pos="word" start_char="2721">sure</TOKEN>
<TOKEN end_char="2728" id="token-29-38" morph="none" pos="word" start_char="2726">the</TOKEN>
<TOKEN end_char="2734" id="token-29-39" morph="none" pos="word" start_char="2730">daily</TOKEN>
<TOKEN end_char="2739" id="token-29-40" morph="none" pos="word" start_char="2736">fail</TOKEN>
<TOKEN end_char="2743" id="token-29-41" morph="none" pos="word" start_char="2741">and</TOKEN>
<TOKEN end_char="2749" id="token-29-42" morph="none" pos="word" start_char="2745">other</TOKEN>
<TOKEN end_char="2762" id="token-29-43" morph="none" pos="word" start_char="2751">infotainment</TOKEN>
<TOKEN end_char="2771" id="token-29-44" morph="none" pos="word" start_char="2764">agencies</TOKEN>
<TOKEN end_char="2777" id="token-29-45" morph="none" pos="word" start_char="2773">don't</TOKEN>
<TOKEN end_char="2782" id="token-29-46" morph="none" pos="word" start_char="2779">have</TOKEN>
<TOKEN end_char="2786" id="token-29-47" morph="none" pos="word" start_char="2784">the</TOKEN>
<TOKEN end_char="2794" id="token-29-48" morph="none" pos="word" start_char="2788">answers</TOKEN>
<TOKEN end_char="2795" id="token-29-49" morph="none" pos="punct" start_char="2795">.</TOKEN>
</SEG>
<SEG end_char="2837" id="segment-30" start_char="2799">
<ORIGINAL_TEXT>This strain was planted by you know who</ORIGINAL_TEXT>
<TOKEN end_char="2802" id="token-30-0" morph="none" pos="word" start_char="2799">This</TOKEN>
<TOKEN end_char="2809" id="token-30-1" morph="none" pos="word" start_char="2804">strain</TOKEN>
<TOKEN end_char="2813" id="token-30-2" morph="none" pos="word" start_char="2811">was</TOKEN>
<TOKEN end_char="2821" id="token-30-3" morph="none" pos="word" start_char="2815">planted</TOKEN>
<TOKEN end_char="2824" id="token-30-4" morph="none" pos="word" start_char="2823">by</TOKEN>
<TOKEN end_char="2828" id="token-30-5" morph="none" pos="word" start_char="2826">you</TOKEN>
<TOKEN end_char="2833" id="token-30-6" morph="none" pos="word" start_char="2830">know</TOKEN>
<TOKEN end_char="2837" id="token-30-7" morph="none" pos="word" start_char="2835">who</TOKEN>
</SEG>
<SEG end_char="2927" id="segment-31" start_char="2841">
<ORIGINAL_TEXT>I am no authority on this, but aren't there genetic markers when a virus is engineered?</ORIGINAL_TEXT>
<TOKEN end_char="2841" id="token-31-0" morph="none" pos="word" start_char="2841">I</TOKEN>
<TOKEN end_char="2844" id="token-31-1" morph="none" pos="word" start_char="2843">am</TOKEN>
<TOKEN end_char="2847" id="token-31-2" morph="none" pos="word" start_char="2846">no</TOKEN>
<TOKEN end_char="2857" id="token-31-3" morph="none" pos="word" start_char="2849">authority</TOKEN>
<TOKEN end_char="2860" id="token-31-4" morph="none" pos="word" start_char="2859">on</TOKEN>
<TOKEN end_char="2865" id="token-31-5" morph="none" pos="word" start_char="2862">this</TOKEN>
<TOKEN end_char="2866" id="token-31-6" morph="none" pos="punct" start_char="2866">,</TOKEN>
<TOKEN end_char="2870" id="token-31-7" morph="none" pos="word" start_char="2868">but</TOKEN>
<TOKEN end_char="2877" id="token-31-8" morph="none" pos="word" start_char="2872">aren't</TOKEN>
<TOKEN end_char="2883" id="token-31-9" morph="none" pos="word" start_char="2879">there</TOKEN>
<TOKEN end_char="2891" id="token-31-10" morph="none" pos="word" start_char="2885">genetic</TOKEN>
<TOKEN end_char="2899" id="token-31-11" morph="none" pos="word" start_char="2893">markers</TOKEN>
<TOKEN end_char="2904" id="token-31-12" morph="none" pos="word" start_char="2901">when</TOKEN>
<TOKEN end_char="2906" id="token-31-13" morph="none" pos="word" start_char="2906">a</TOKEN>
<TOKEN end_char="2912" id="token-31-14" morph="none" pos="word" start_char="2908">virus</TOKEN>
<TOKEN end_char="2915" id="token-31-15" morph="none" pos="word" start_char="2914">is</TOKEN>
<TOKEN end_char="2926" id="token-31-16" morph="none" pos="word" start_char="2917">engineered</TOKEN>
<TOKEN end_char="2927" id="token-31-17" morph="none" pos="punct" start_char="2927">?</TOKEN>
</SEG>
<SEG end_char="3012" id="segment-32" start_char="2929">
<ORIGINAL_TEXT>With this many people looking at it I would think someone would have noticed by now.</ORIGINAL_TEXT>
<TOKEN end_char="2932" id="token-32-0" morph="none" pos="word" start_char="2929">With</TOKEN>
<TOKEN end_char="2937" id="token-32-1" morph="none" pos="word" start_char="2934">this</TOKEN>
<TOKEN end_char="2942" id="token-32-2" morph="none" pos="word" start_char="2939">many</TOKEN>
<TOKEN end_char="2949" id="token-32-3" morph="none" pos="word" start_char="2944">people</TOKEN>
<TOKEN end_char="2957" id="token-32-4" morph="none" pos="word" start_char="2951">looking</TOKEN>
<TOKEN end_char="2960" id="token-32-5" morph="none" pos="word" start_char="2959">at</TOKEN>
<TOKEN end_char="2963" id="token-32-6" morph="none" pos="word" start_char="2962">it</TOKEN>
<TOKEN end_char="2965" id="token-32-7" morph="none" pos="word" start_char="2965">I</TOKEN>
<TOKEN end_char="2971" id="token-32-8" morph="none" pos="word" start_char="2967">would</TOKEN>
<TOKEN end_char="2977" id="token-32-9" morph="none" pos="word" start_char="2973">think</TOKEN>
<TOKEN end_char="2985" id="token-32-10" morph="none" pos="word" start_char="2979">someone</TOKEN>
<TOKEN end_char="2991" id="token-32-11" morph="none" pos="word" start_char="2987">would</TOKEN>
<TOKEN end_char="2996" id="token-32-12" morph="none" pos="word" start_char="2993">have</TOKEN>
<TOKEN end_char="3004" id="token-32-13" morph="none" pos="word" start_char="2998">noticed</TOKEN>
<TOKEN end_char="3007" id="token-32-14" morph="none" pos="word" start_char="3006">by</TOKEN>
<TOKEN end_char="3011" id="token-32-15" morph="none" pos="word" start_char="3009">now</TOKEN>
<TOKEN end_char="3012" id="token-32-16" morph="none" pos="punct" start_char="3012">.</TOKEN>
</SEG>
<SEG end_char="3043" id="segment-33" start_char="3016">
<ORIGINAL_TEXT>a reply to: ElectricUniverse</ORIGINAL_TEXT>
<TOKEN end_char="3016" id="token-33-0" morph="none" pos="word" start_char="3016">a</TOKEN>
<TOKEN end_char="3022" id="token-33-1" morph="none" pos="word" start_char="3018">reply</TOKEN>
<TOKEN end_char="3025" id="token-33-2" morph="none" pos="word" start_char="3024">to</TOKEN>
<TOKEN end_char="3026" id="token-33-3" morph="none" pos="punct" start_char="3026">:</TOKEN>
<TOKEN end_char="3043" id="token-33-4" morph="none" pos="word" start_char="3028">ElectricUniverse</TOKEN>
</SEG>
<SEG end_char="3071" id="segment-34" start_char="3046">
<ORIGINAL_TEXT>I can't say I'm surprised.</ORIGINAL_TEXT>
<TOKEN end_char="3046" id="token-34-0" morph="none" pos="word" start_char="3046">I</TOKEN>
<TOKEN end_char="3052" id="token-34-1" morph="none" pos="word" start_char="3048">can't</TOKEN>
<TOKEN end_char="3056" id="token-34-2" morph="none" pos="word" start_char="3054">say</TOKEN>
<TOKEN end_char="3060" id="token-34-3" morph="none" pos="word" start_char="3058">I'm</TOKEN>
<TOKEN end_char="3070" id="token-34-4" morph="none" pos="word" start_char="3062">surprised</TOKEN>
<TOKEN end_char="3071" id="token-34-5" morph="none" pos="punct" start_char="3071">.</TOKEN>
</SEG>
<SEG end_char="3115" id="segment-35" start_char="3073">
<ORIGINAL_TEXT>As I noted in this really excellent thread.</ORIGINAL_TEXT>
<TOKEN end_char="3074" id="token-35-0" morph="none" pos="word" start_char="3073">As</TOKEN>
<TOKEN end_char="3076" id="token-35-1" morph="none" pos="word" start_char="3076">I</TOKEN>
<TOKEN end_char="3082" id="token-35-2" morph="none" pos="word" start_char="3078">noted</TOKEN>
<TOKEN end_char="3085" id="token-35-3" morph="none" pos="word" start_char="3084">in</TOKEN>
<TOKEN end_char="3090" id="token-35-4" morph="none" pos="word" start_char="3087">this</TOKEN>
<TOKEN end_char="3097" id="token-35-5" morph="none" pos="word" start_char="3092">really</TOKEN>
<TOKEN end_char="3107" id="token-35-6" morph="none" pos="word" start_char="3099">excellent</TOKEN>
<TOKEN end_char="3114" id="token-35-7" morph="none" pos="word" start_char="3109">thread</TOKEN>
<TOKEN end_char="3115" id="token-35-8" morph="none" pos="punct" start_char="3115">.</TOKEN>
</SEG>
<SEG end_char="3234" id="segment-36" start_char="3118">
<ORIGINAL_TEXT>unless our collective Minitruths can compile a story that it wasn't actually the Chinese.....don't rule that one out.</ORIGINAL_TEXT>
<TOKEN end_char="3123" id="token-36-0" morph="none" pos="word" start_char="3118">unless</TOKEN>
<TOKEN end_char="3127" id="token-36-1" morph="none" pos="word" start_char="3125">our</TOKEN>
<TOKEN end_char="3138" id="token-36-2" morph="none" pos="word" start_char="3129">collective</TOKEN>
<TOKEN end_char="3149" id="token-36-3" morph="none" pos="word" start_char="3140">Minitruths</TOKEN>
<TOKEN end_char="3153" id="token-36-4" morph="none" pos="word" start_char="3151">can</TOKEN>
<TOKEN end_char="3161" id="token-36-5" morph="none" pos="word" start_char="3155">compile</TOKEN>
<TOKEN end_char="3163" id="token-36-6" morph="none" pos="word" start_char="3163">a</TOKEN>
<TOKEN end_char="3169" id="token-36-7" morph="none" pos="word" start_char="3165">story</TOKEN>
<TOKEN end_char="3174" id="token-36-8" morph="none" pos="word" start_char="3171">that</TOKEN>
<TOKEN end_char="3177" id="token-36-9" morph="none" pos="word" start_char="3176">it</TOKEN>
<TOKEN end_char="3184" id="token-36-10" morph="none" pos="word" start_char="3179">wasn't</TOKEN>
<TOKEN end_char="3193" id="token-36-11" morph="none" pos="word" start_char="3186">actually</TOKEN>
<TOKEN end_char="3197" id="token-36-12" morph="none" pos="word" start_char="3195">the</TOKEN>
<TOKEN end_char="3215" id="token-36-13" morph="none" pos="unknown" start_char="3199">Chinese.....don't</TOKEN>
<TOKEN end_char="3220" id="token-36-14" morph="none" pos="word" start_char="3217">rule</TOKEN>
<TOKEN end_char="3225" id="token-36-15" morph="none" pos="word" start_char="3222">that</TOKEN>
<TOKEN end_char="3229" id="token-36-16" morph="none" pos="word" start_char="3227">one</TOKEN>
<TOKEN end_char="3233" id="token-36-17" morph="none" pos="word" start_char="3231">out</TOKEN>
<TOKEN end_char="3234" id="token-36-18" morph="none" pos="punct" start_char="3234">.</TOKEN>
</SEG>
<SEG end_char="3376" id="segment-37" start_char="3237">
<ORIGINAL_TEXT>While that may not be an absolutely prefect suggestion, it nevertheless points to some fairly hardcore back peddling as outlined in your OP.</ORIGINAL_TEXT>
<TOKEN end_char="3241" id="token-37-0" morph="none" pos="word" start_char="3237">While</TOKEN>
<TOKEN end_char="3246" id="token-37-1" morph="none" pos="word" start_char="3243">that</TOKEN>
<TOKEN end_char="3250" id="token-37-2" morph="none" pos="word" start_char="3248">may</TOKEN>
<TOKEN end_char="3254" id="token-37-3" morph="none" pos="word" start_char="3252">not</TOKEN>
<TOKEN end_char="3257" id="token-37-4" morph="none" pos="word" start_char="3256">be</TOKEN>
<TOKEN end_char="3260" id="token-37-5" morph="none" pos="word" start_char="3259">an</TOKEN>
<TOKEN end_char="3271" id="token-37-6" morph="none" pos="word" start_char="3262">absolutely</TOKEN>
<TOKEN end_char="3279" id="token-37-7" morph="none" pos="word" start_char="3273">prefect</TOKEN>
<TOKEN end_char="3290" id="token-37-8" morph="none" pos="word" start_char="3281">suggestion</TOKEN>
<TOKEN end_char="3291" id="token-37-9" morph="none" pos="punct" start_char="3291">,</TOKEN>
<TOKEN end_char="3294" id="token-37-10" morph="none" pos="word" start_char="3293">it</TOKEN>
<TOKEN end_char="3307" id="token-37-11" morph="none" pos="word" start_char="3296">nevertheless</TOKEN>
<TOKEN end_char="3314" id="token-37-12" morph="none" pos="word" start_char="3309">points</TOKEN>
<TOKEN end_char="3317" id="token-37-13" morph="none" pos="word" start_char="3316">to</TOKEN>
<TOKEN end_char="3322" id="token-37-14" morph="none" pos="word" start_char="3319">some</TOKEN>
<TOKEN end_char="3329" id="token-37-15" morph="none" pos="word" start_char="3324">fairly</TOKEN>
<TOKEN end_char="3338" id="token-37-16" morph="none" pos="word" start_char="3331">hardcore</TOKEN>
<TOKEN end_char="3343" id="token-37-17" morph="none" pos="word" start_char="3340">back</TOKEN>
<TOKEN end_char="3352" id="token-37-18" morph="none" pos="word" start_char="3345">peddling</TOKEN>
<TOKEN end_char="3355" id="token-37-19" morph="none" pos="word" start_char="3354">as</TOKEN>
<TOKEN end_char="3364" id="token-37-20" morph="none" pos="word" start_char="3357">outlined</TOKEN>
<TOKEN end_char="3367" id="token-37-21" morph="none" pos="word" start_char="3366">in</TOKEN>
<TOKEN end_char="3372" id="token-37-22" morph="none" pos="word" start_char="3369">your</TOKEN>
<TOKEN end_char="3375" id="token-37-23" morph="none" pos="word" start_char="3374">OP</TOKEN>
<TOKEN end_char="3376" id="token-37-24" morph="none" pos="punct" start_char="3376">.</TOKEN>
</SEG>
<SEG end_char="3552" id="segment-38" start_char="3380">
<ORIGINAL_TEXT>The same month as the out break Wuhan Biosafety Lab was granted level 4 status meaning it had approval for the highest most deadly of virus's including Ebola and bioweapons.</ORIGINAL_TEXT>
<TOKEN end_char="3382" id="token-38-0" morph="none" pos="word" start_char="3380">The</TOKEN>
<TOKEN end_char="3387" id="token-38-1" morph="none" pos="word" start_char="3384">same</TOKEN>
<TOKEN end_char="3393" id="token-38-2" morph="none" pos="word" start_char="3389">month</TOKEN>
<TOKEN end_char="3396" id="token-38-3" morph="none" pos="word" start_char="3395">as</TOKEN>
<TOKEN end_char="3400" id="token-38-4" morph="none" pos="word" start_char="3398">the</TOKEN>
<TOKEN end_char="3404" id="token-38-5" morph="none" pos="word" start_char="3402">out</TOKEN>
<TOKEN end_char="3410" id="token-38-6" morph="none" pos="word" start_char="3406">break</TOKEN>
<TOKEN end_char="3416" id="token-38-7" morph="none" pos="word" start_char="3412">Wuhan</TOKEN>
<TOKEN end_char="3426" id="token-38-8" morph="none" pos="word" start_char="3418">Biosafety</TOKEN>
<TOKEN end_char="3430" id="token-38-9" morph="none" pos="word" start_char="3428">Lab</TOKEN>
<TOKEN end_char="3434" id="token-38-10" morph="none" pos="word" start_char="3432">was</TOKEN>
<TOKEN end_char="3442" id="token-38-11" morph="none" pos="word" start_char="3436">granted</TOKEN>
<TOKEN end_char="3448" id="token-38-12" morph="none" pos="word" start_char="3444">level</TOKEN>
<TOKEN end_char="3450" id="token-38-13" morph="none" pos="word" start_char="3450">4</TOKEN>
<TOKEN end_char="3457" id="token-38-14" morph="none" pos="word" start_char="3452">status</TOKEN>
<TOKEN end_char="3465" id="token-38-15" morph="none" pos="word" start_char="3459">meaning</TOKEN>
<TOKEN end_char="3468" id="token-38-16" morph="none" pos="word" start_char="3467">it</TOKEN>
<TOKEN end_char="3472" id="token-38-17" morph="none" pos="word" start_char="3470">had</TOKEN>
<TOKEN end_char="3481" id="token-38-18" morph="none" pos="word" start_char="3474">approval</TOKEN>
<TOKEN end_char="3485" id="token-38-19" morph="none" pos="word" start_char="3483">for</TOKEN>
<TOKEN end_char="3489" id="token-38-20" morph="none" pos="word" start_char="3487">the</TOKEN>
<TOKEN end_char="3497" id="token-38-21" morph="none" pos="word" start_char="3491">highest</TOKEN>
<TOKEN end_char="3502" id="token-38-22" morph="none" pos="word" start_char="3499">most</TOKEN>
<TOKEN end_char="3509" id="token-38-23" morph="none" pos="word" start_char="3504">deadly</TOKEN>
<TOKEN end_char="3512" id="token-38-24" morph="none" pos="word" start_char="3511">of</TOKEN>
<TOKEN end_char="3520" id="token-38-25" morph="none" pos="word" start_char="3514">virus's</TOKEN>
<TOKEN end_char="3530" id="token-38-26" morph="none" pos="word" start_char="3522">including</TOKEN>
<TOKEN end_char="3536" id="token-38-27" morph="none" pos="word" start_char="3532">Ebola</TOKEN>
<TOKEN end_char="3540" id="token-38-28" morph="none" pos="word" start_char="3538">and</TOKEN>
<TOKEN end_char="3551" id="token-38-29" morph="none" pos="word" start_char="3542">bioweapons</TOKEN>
<TOKEN end_char="3552" id="token-38-30" morph="none" pos="punct" start_char="3552">.</TOKEN>
</SEG>
<SEG end_char="3636" id="segment-39" start_char="3554">
<ORIGINAL_TEXT>Make of that what you will but to me this was either an accident or perhaps a test.</ORIGINAL_TEXT>
<TOKEN end_char="3557" id="token-39-0" morph="none" pos="word" start_char="3554">Make</TOKEN>
<TOKEN end_char="3560" id="token-39-1" morph="none" pos="word" start_char="3559">of</TOKEN>
<TOKEN end_char="3565" id="token-39-2" morph="none" pos="word" start_char="3562">that</TOKEN>
<TOKEN end_char="3570" id="token-39-3" morph="none" pos="word" start_char="3567">what</TOKEN>
<TOKEN end_char="3574" id="token-39-4" morph="none" pos="word" start_char="3572">you</TOKEN>
<TOKEN end_char="3579" id="token-39-5" morph="none" pos="word" start_char="3576">will</TOKEN>
<TOKEN end_char="3583" id="token-39-6" morph="none" pos="word" start_char="3581">but</TOKEN>
<TOKEN end_char="3586" id="token-39-7" morph="none" pos="word" start_char="3585">to</TOKEN>
<TOKEN end_char="3589" id="token-39-8" morph="none" pos="word" start_char="3588">me</TOKEN>
<TOKEN end_char="3594" id="token-39-9" morph="none" pos="word" start_char="3591">this</TOKEN>
<TOKEN end_char="3598" id="token-39-10" morph="none" pos="word" start_char="3596">was</TOKEN>
<TOKEN end_char="3605" id="token-39-11" morph="none" pos="word" start_char="3600">either</TOKEN>
<TOKEN end_char="3608" id="token-39-12" morph="none" pos="word" start_char="3607">an</TOKEN>
<TOKEN end_char="3617" id="token-39-13" morph="none" pos="word" start_char="3610">accident</TOKEN>
<TOKEN end_char="3620" id="token-39-14" morph="none" pos="word" start_char="3619">or</TOKEN>
<TOKEN end_char="3628" id="token-39-15" morph="none" pos="word" start_char="3622">perhaps</TOKEN>
<TOKEN end_char="3630" id="token-39-16" morph="none" pos="word" start_char="3630">a</TOKEN>
<TOKEN end_char="3635" id="token-39-17" morph="none" pos="word" start_char="3632">test</TOKEN>
<TOKEN end_char="3636" id="token-39-18" morph="none" pos="punct" start_char="3636">.</TOKEN>
</SEG>
<SEG end_char="3792" id="segment-40" start_char="3638">
<ORIGINAL_TEXT>So far the Chinese have blamed bats, pangolins and dogs and as we all know, the information released from Chinese Government sources are far from reliable.</ORIGINAL_TEXT>
<TOKEN end_char="3639" id="token-40-0" morph="none" pos="word" start_char="3638">So</TOKEN>
<TOKEN end_char="3643" id="token-40-1" morph="none" pos="word" start_char="3641">far</TOKEN>
<TOKEN end_char="3647" id="token-40-2" morph="none" pos="word" start_char="3645">the</TOKEN>
<TOKEN end_char="3655" id="token-40-3" morph="none" pos="word" start_char="3649">Chinese</TOKEN>
<TOKEN end_char="3660" id="token-40-4" morph="none" pos="word" start_char="3657">have</TOKEN>
<TOKEN end_char="3667" id="token-40-5" morph="none" pos="word" start_char="3662">blamed</TOKEN>
<TOKEN end_char="3672" id="token-40-6" morph="none" pos="word" start_char="3669">bats</TOKEN>
<TOKEN end_char="3673" id="token-40-7" morph="none" pos="punct" start_char="3673">,</TOKEN>
<TOKEN end_char="3683" id="token-40-8" morph="none" pos="word" start_char="3675">pangolins</TOKEN>
<TOKEN end_char="3687" id="token-40-9" morph="none" pos="word" start_char="3685">and</TOKEN>
<TOKEN end_char="3692" id="token-40-10" morph="none" pos="word" start_char="3689">dogs</TOKEN>
<TOKEN end_char="3696" id="token-40-11" morph="none" pos="word" start_char="3694">and</TOKEN>
<TOKEN end_char="3699" id="token-40-12" morph="none" pos="word" start_char="3698">as</TOKEN>
<TOKEN end_char="3702" id="token-40-13" morph="none" pos="word" start_char="3701">we</TOKEN>
<TOKEN end_char="3706" id="token-40-14" morph="none" pos="word" start_char="3704">all</TOKEN>
<TOKEN end_char="3711" id="token-40-15" morph="none" pos="word" start_char="3708">know</TOKEN>
<TOKEN end_char="3712" id="token-40-16" morph="none" pos="punct" start_char="3712">,</TOKEN>
<TOKEN end_char="3716" id="token-40-17" morph="none" pos="word" start_char="3714">the</TOKEN>
<TOKEN end_char="3728" id="token-40-18" morph="none" pos="word" start_char="3718">information</TOKEN>
<TOKEN end_char="3737" id="token-40-19" morph="none" pos="word" start_char="3730">released</TOKEN>
<TOKEN end_char="3742" id="token-40-20" morph="none" pos="word" start_char="3739">from</TOKEN>
<TOKEN end_char="3750" id="token-40-21" morph="none" pos="word" start_char="3744">Chinese</TOKEN>
<TOKEN end_char="3761" id="token-40-22" morph="none" pos="word" start_char="3752">Government</TOKEN>
<TOKEN end_char="3769" id="token-40-23" morph="none" pos="word" start_char="3763">sources</TOKEN>
<TOKEN end_char="3773" id="token-40-24" morph="none" pos="word" start_char="3771">are</TOKEN>
<TOKEN end_char="3777" id="token-40-25" morph="none" pos="word" start_char="3775">far</TOKEN>
<TOKEN end_char="3782" id="token-40-26" morph="none" pos="word" start_char="3779">from</TOKEN>
<TOKEN end_char="3791" id="token-40-27" morph="none" pos="word" start_char="3784">reliable</TOKEN>
<TOKEN end_char="3792" id="token-40-28" morph="none" pos="punct" start_char="3792">.</TOKEN>
</SEG>
<SEG end_char="3918" id="segment-41" start_char="3795">
<ORIGINAL_TEXT>Let's also not forget that the SARS virus escaped multiple times from Bejing Laboratories so their track record isn't great!</ORIGINAL_TEXT>
<TOKEN end_char="3799" id="token-41-0" morph="none" pos="word" start_char="3795">Let's</TOKEN>
<TOKEN end_char="3804" id="token-41-1" morph="none" pos="word" start_char="3801">also</TOKEN>
<TOKEN end_char="3808" id="token-41-2" morph="none" pos="word" start_char="3806">not</TOKEN>
<TOKEN end_char="3815" id="token-41-3" morph="none" pos="word" start_char="3810">forget</TOKEN>
<TOKEN end_char="3820" id="token-41-4" morph="none" pos="word" start_char="3817">that</TOKEN>
<TOKEN end_char="3824" id="token-41-5" morph="none" pos="word" start_char="3822">the</TOKEN>
<TOKEN end_char="3829" id="token-41-6" morph="none" pos="word" start_char="3826">SARS</TOKEN>
<TOKEN end_char="3835" id="token-41-7" morph="none" pos="word" start_char="3831">virus</TOKEN>
<TOKEN end_char="3843" id="token-41-8" morph="none" pos="word" start_char="3837">escaped</TOKEN>
<TOKEN end_char="3852" id="token-41-9" morph="none" pos="word" start_char="3845">multiple</TOKEN>
<TOKEN end_char="3858" id="token-41-10" morph="none" pos="word" start_char="3854">times</TOKEN>
<TOKEN end_char="3863" id="token-41-11" morph="none" pos="word" start_char="3860">from</TOKEN>
<TOKEN end_char="3870" id="token-41-12" morph="none" pos="word" start_char="3865">Bejing</TOKEN>
<TOKEN end_char="3883" id="token-41-13" morph="none" pos="word" start_char="3872">Laboratories</TOKEN>
<TOKEN end_char="3886" id="token-41-14" morph="none" pos="word" start_char="3885">so</TOKEN>
<TOKEN end_char="3892" id="token-41-15" morph="none" pos="word" start_char="3888">their</TOKEN>
<TOKEN end_char="3898" id="token-41-16" morph="none" pos="word" start_char="3894">track</TOKEN>
<TOKEN end_char="3905" id="token-41-17" morph="none" pos="word" start_char="3900">record</TOKEN>
<TOKEN end_char="3911" id="token-41-18" morph="none" pos="word" start_char="3907">isn't</TOKEN>
<TOKEN end_char="3917" id="token-41-19" morph="none" pos="word" start_char="3913">great</TOKEN>
<TOKEN end_char="3918" id="token-41-20" morph="none" pos="punct" start_char="3918">!</TOKEN>
</SEG>
<SEG end_char="3949" id="segment-42" start_char="3922">
<ORIGINAL_TEXT>a reply to: ElectricUniverse</ORIGINAL_TEXT>
<TOKEN end_char="3922" id="token-42-0" morph="none" pos="word" start_char="3922">a</TOKEN>
<TOKEN end_char="3928" id="token-42-1" morph="none" pos="word" start_char="3924">reply</TOKEN>
<TOKEN end_char="3931" id="token-42-2" morph="none" pos="word" start_char="3930">to</TOKEN>
<TOKEN end_char="3932" id="token-42-3" morph="none" pos="punct" start_char="3932">:</TOKEN>
<TOKEN end_char="3949" id="token-42-4" morph="none" pos="word" start_char="3934">ElectricUniverse</TOKEN>
</SEG>
<SEG end_char="4192" id="segment-43" start_char="3952">
<ORIGINAL_TEXT>QUESTIONABLE SOURCE A questionable source exhibits one or more of the following: extreme bias, consistent promotion of propaganda/conspiracies, poor or no sourcing to credible information, a complete lack of transparency and/or is fake news.</ORIGINAL_TEXT>
<TOKEN end_char="3963" id="token-43-0" morph="none" pos="word" start_char="3952">QUESTIONABLE</TOKEN>
<TOKEN end_char="3970" id="token-43-1" morph="none" pos="word" start_char="3965">SOURCE</TOKEN>
<TOKEN end_char="3972" id="token-43-2" morph="none" pos="word" start_char="3972">A</TOKEN>
<TOKEN end_char="3985" id="token-43-3" morph="none" pos="word" start_char="3974">questionable</TOKEN>
<TOKEN end_char="3992" id="token-43-4" morph="none" pos="word" start_char="3987">source</TOKEN>
<TOKEN end_char="4001" id="token-43-5" morph="none" pos="word" start_char="3994">exhibits</TOKEN>
<TOKEN end_char="4005" id="token-43-6" morph="none" pos="word" start_char="4003">one</TOKEN>
<TOKEN end_char="4008" id="token-43-7" morph="none" pos="word" start_char="4007">or</TOKEN>
<TOKEN end_char="4013" id="token-43-8" morph="none" pos="word" start_char="4010">more</TOKEN>
<TOKEN end_char="4016" id="token-43-9" morph="none" pos="word" start_char="4015">of</TOKEN>
<TOKEN end_char="4020" id="token-43-10" morph="none" pos="word" start_char="4018">the</TOKEN>
<TOKEN end_char="4030" id="token-43-11" morph="none" pos="word" start_char="4022">following</TOKEN>
<TOKEN end_char="4031" id="token-43-12" morph="none" pos="punct" start_char="4031">:</TOKEN>
<TOKEN end_char="4039" id="token-43-13" morph="none" pos="word" start_char="4033">extreme</TOKEN>
<TOKEN end_char="4044" id="token-43-14" morph="none" pos="word" start_char="4041">bias</TOKEN>
<TOKEN end_char="4045" id="token-43-15" morph="none" pos="punct" start_char="4045">,</TOKEN>
<TOKEN end_char="4056" id="token-43-16" morph="none" pos="word" start_char="4047">consistent</TOKEN>
<TOKEN end_char="4066" id="token-43-17" morph="none" pos="word" start_char="4058">promotion</TOKEN>
<TOKEN end_char="4069" id="token-43-18" morph="none" pos="word" start_char="4068">of</TOKEN>
<TOKEN end_char="4093" id="token-43-19" morph="none" pos="unknown" start_char="4071">propaganda/conspiracies</TOKEN>
<TOKEN end_char="4094" id="token-43-20" morph="none" pos="punct" start_char="4094">,</TOKEN>
<TOKEN end_char="4099" id="token-43-21" morph="none" pos="word" start_char="4096">poor</TOKEN>
<TOKEN end_char="4102" id="token-43-22" morph="none" pos="word" start_char="4101">or</TOKEN>
<TOKEN end_char="4105" id="token-43-23" morph="none" pos="word" start_char="4104">no</TOKEN>
<TOKEN end_char="4114" id="token-43-24" morph="none" pos="word" start_char="4107">sourcing</TOKEN>
<TOKEN end_char="4117" id="token-43-25" morph="none" pos="word" start_char="4116">to</TOKEN>
<TOKEN end_char="4126" id="token-43-26" morph="none" pos="word" start_char="4119">credible</TOKEN>
<TOKEN end_char="4138" id="token-43-27" morph="none" pos="word" start_char="4128">information</TOKEN>
<TOKEN end_char="4139" id="token-43-28" morph="none" pos="punct" start_char="4139">,</TOKEN>
<TOKEN end_char="4141" id="token-43-29" morph="none" pos="word" start_char="4141">a</TOKEN>
<TOKEN end_char="4150" id="token-43-30" morph="none" pos="word" start_char="4143">complete</TOKEN>
<TOKEN end_char="4155" id="token-43-31" morph="none" pos="word" start_char="4152">lack</TOKEN>
<TOKEN end_char="4158" id="token-43-32" morph="none" pos="word" start_char="4157">of</TOKEN>
<TOKEN end_char="4171" id="token-43-33" morph="none" pos="word" start_char="4160">transparency</TOKEN>
<TOKEN end_char="4178" id="token-43-34" morph="none" pos="unknown" start_char="4173">and/or</TOKEN>
<TOKEN end_char="4181" id="token-43-35" morph="none" pos="word" start_char="4180">is</TOKEN>
<TOKEN end_char="4186" id="token-43-36" morph="none" pos="word" start_char="4183">fake</TOKEN>
<TOKEN end_char="4191" id="token-43-37" morph="none" pos="word" start_char="4188">news</TOKEN>
<TOKEN end_char="4192" id="token-43-38" morph="none" pos="punct" start_char="4192">.</TOKEN>
</SEG>
<SEG end_char="4321" id="segment-44" start_char="4194">
<ORIGINAL_TEXT>Fake News is the deliberate attempt to publish hoaxes and/or disinformation for the purpose of profit or influence (Learn More).</ORIGINAL_TEXT>
<TOKEN end_char="4197" id="token-44-0" morph="none" pos="word" start_char="4194">Fake</TOKEN>
<TOKEN end_char="4202" id="token-44-1" morph="none" pos="word" start_char="4199">News</TOKEN>
<TOKEN end_char="4205" id="token-44-2" morph="none" pos="word" start_char="4204">is</TOKEN>
<TOKEN end_char="4209" id="token-44-3" morph="none" pos="word" start_char="4207">the</TOKEN>
<TOKEN end_char="4220" id="token-44-4" morph="none" pos="word" start_char="4211">deliberate</TOKEN>
<TOKEN end_char="4228" id="token-44-5" morph="none" pos="word" start_char="4222">attempt</TOKEN>
<TOKEN end_char="4231" id="token-44-6" morph="none" pos="word" start_char="4230">to</TOKEN>
<TOKEN end_char="4239" id="token-44-7" morph="none" pos="word" start_char="4233">publish</TOKEN>
<TOKEN end_char="4246" id="token-44-8" morph="none" pos="word" start_char="4241">hoaxes</TOKEN>
<TOKEN end_char="4253" id="token-44-9" morph="none" pos="unknown" start_char="4248">and/or</TOKEN>
<TOKEN end_char="4268" id="token-44-10" morph="none" pos="word" start_char="4255">disinformation</TOKEN>
<TOKEN end_char="4272" id="token-44-11" morph="none" pos="word" start_char="4270">for</TOKEN>
<TOKEN end_char="4276" id="token-44-12" morph="none" pos="word" start_char="4274">the</TOKEN>
<TOKEN end_char="4284" id="token-44-13" morph="none" pos="word" start_char="4278">purpose</TOKEN>
<TOKEN end_char="4287" id="token-44-14" morph="none" pos="word" start_char="4286">of</TOKEN>
<TOKEN end_char="4294" id="token-44-15" morph="none" pos="word" start_char="4289">profit</TOKEN>
<TOKEN end_char="4297" id="token-44-16" morph="none" pos="word" start_char="4296">or</TOKEN>
<TOKEN end_char="4307" id="token-44-17" morph="none" pos="word" start_char="4299">influence</TOKEN>
<TOKEN end_char="4309" id="token-44-18" morph="none" pos="punct" start_char="4309">(</TOKEN>
<TOKEN end_char="4314" id="token-44-19" morph="none" pos="word" start_char="4310">Learn</TOKEN>
<TOKEN end_char="4319" id="token-44-20" morph="none" pos="word" start_char="4316">More</TOKEN>
<TOKEN end_char="4321" id="token-44-21" morph="none" pos="punct" start_char="4320">).</TOKEN>
</SEG>
<SEG end_char="4442" id="segment-45" start_char="4323">
<ORIGINAL_TEXT>Sources listed in the Questionable Category may be very untrustworthy and should be fact checked on a per article basis.</ORIGINAL_TEXT>
<TOKEN end_char="4329" id="token-45-0" morph="none" pos="word" start_char="4323">Sources</TOKEN>
<TOKEN end_char="4336" id="token-45-1" morph="none" pos="word" start_char="4331">listed</TOKEN>
<TOKEN end_char="4339" id="token-45-2" morph="none" pos="word" start_char="4338">in</TOKEN>
<TOKEN end_char="4343" id="token-45-3" morph="none" pos="word" start_char="4341">the</TOKEN>
<TOKEN end_char="4356" id="token-45-4" morph="none" pos="word" start_char="4345">Questionable</TOKEN>
<TOKEN end_char="4365" id="token-45-5" morph="none" pos="word" start_char="4358">Category</TOKEN>
<TOKEN end_char="4369" id="token-45-6" morph="none" pos="word" start_char="4367">may</TOKEN>
<TOKEN end_char="4372" id="token-45-7" morph="none" pos="word" start_char="4371">be</TOKEN>
<TOKEN end_char="4377" id="token-45-8" morph="none" pos="word" start_char="4374">very</TOKEN>
<TOKEN end_char="4391" id="token-45-9" morph="none" pos="word" start_char="4379">untrustworthy</TOKEN>
<TOKEN end_char="4395" id="token-45-10" morph="none" pos="word" start_char="4393">and</TOKEN>
<TOKEN end_char="4402" id="token-45-11" morph="none" pos="word" start_char="4397">should</TOKEN>
<TOKEN end_char="4405" id="token-45-12" morph="none" pos="word" start_char="4404">be</TOKEN>
<TOKEN end_char="4410" id="token-45-13" morph="none" pos="word" start_char="4407">fact</TOKEN>
<TOKEN end_char="4418" id="token-45-14" morph="none" pos="word" start_char="4412">checked</TOKEN>
<TOKEN end_char="4421" id="token-45-15" morph="none" pos="word" start_char="4420">on</TOKEN>
<TOKEN end_char="4423" id="token-45-16" morph="none" pos="word" start_char="4423">a</TOKEN>
<TOKEN end_char="4427" id="token-45-17" morph="none" pos="word" start_char="4425">per</TOKEN>
<TOKEN end_char="4435" id="token-45-18" morph="none" pos="word" start_char="4429">article</TOKEN>
<TOKEN end_char="4441" id="token-45-19" morph="none" pos="word" start_char="4437">basis</TOKEN>
<TOKEN end_char="4442" id="token-45-20" morph="none" pos="punct" start_char="4442">.</TOKEN>
</SEG>
<SEG end_char="4574" id="segment-46" start_char="4444">
<ORIGINAL_TEXT>Please note sources on this list are not considered fake news unless specifically written in the reasoning section for that source.</ORIGINAL_TEXT>
<TOKEN end_char="4449" id="token-46-0" morph="none" pos="word" start_char="4444">Please</TOKEN>
<TOKEN end_char="4454" id="token-46-1" morph="none" pos="word" start_char="4451">note</TOKEN>
<TOKEN end_char="4462" id="token-46-2" morph="none" pos="word" start_char="4456">sources</TOKEN>
<TOKEN end_char="4465" id="token-46-3" morph="none" pos="word" start_char="4464">on</TOKEN>
<TOKEN end_char="4470" id="token-46-4" morph="none" pos="word" start_char="4467">this</TOKEN>
<TOKEN end_char="4475" id="token-46-5" morph="none" pos="word" start_char="4472">list</TOKEN>
<TOKEN end_char="4479" id="token-46-6" morph="none" pos="word" start_char="4477">are</TOKEN>
<TOKEN end_char="4483" id="token-46-7" morph="none" pos="word" start_char="4481">not</TOKEN>
<TOKEN end_char="4494" id="token-46-8" morph="none" pos="word" start_char="4485">considered</TOKEN>
<TOKEN end_char="4499" id="token-46-9" morph="none" pos="word" start_char="4496">fake</TOKEN>
<TOKEN end_char="4504" id="token-46-10" morph="none" pos="word" start_char="4501">news</TOKEN>
<TOKEN end_char="4511" id="token-46-11" morph="none" pos="word" start_char="4506">unless</TOKEN>
<TOKEN end_char="4524" id="token-46-12" morph="none" pos="word" start_char="4513">specifically</TOKEN>
<TOKEN end_char="4532" id="token-46-13" morph="none" pos="word" start_char="4526">written</TOKEN>
<TOKEN end_char="4535" id="token-46-14" morph="none" pos="word" start_char="4534">in</TOKEN>
<TOKEN end_char="4539" id="token-46-15" morph="none" pos="word" start_char="4537">the</TOKEN>
<TOKEN end_char="4549" id="token-46-16" morph="none" pos="word" start_char="4541">reasoning</TOKEN>
<TOKEN end_char="4557" id="token-46-17" morph="none" pos="word" start_char="4551">section</TOKEN>
<TOKEN end_char="4561" id="token-46-18" morph="none" pos="word" start_char="4559">for</TOKEN>
<TOKEN end_char="4566" id="token-46-19" morph="none" pos="word" start_char="4563">that</TOKEN>
<TOKEN end_char="4573" id="token-46-20" morph="none" pos="word" start_char="4568">source</TOKEN>
<TOKEN end_char="4574" id="token-46-21" morph="none" pos="punct" start_char="4574">.</TOKEN>
</SEG>
<SEG end_char="4604" id="segment-47" start_char="4576">
<ORIGINAL_TEXT>See all Questionable sources.</ORIGINAL_TEXT>
<TOKEN end_char="4578" id="token-47-0" morph="none" pos="word" start_char="4576">See</TOKEN>
<TOKEN end_char="4582" id="token-47-1" morph="none" pos="word" start_char="4580">all</TOKEN>
<TOKEN end_char="4595" id="token-47-2" morph="none" pos="word" start_char="4584">Questionable</TOKEN>
<TOKEN end_char="4603" id="token-47-3" morph="none" pos="word" start_char="4597">sources</TOKEN>
<TOKEN end_char="4604" id="token-47-4" morph="none" pos="punct" start_char="4604">.</TOKEN>
<TRANSLATED_TEXT>Zie alle Questionable Sources.</TRANSLATED_TEXT><DETECTED_LANGUAGE>fr</DETECTED_LANGUAGE></SEG>
<SEG end_char="4714" id="segment-48" start_char="4606">
<ORIGINAL_TEXT>Overall, we rate Daily Mail Questionable due to numerous failed fact checks and poor sourcing of information.</ORIGINAL_TEXT>
<TOKEN end_char="4612" id="token-48-0" morph="none" pos="word" start_char="4606">Overall</TOKEN>
<TOKEN end_char="4613" id="token-48-1" morph="none" pos="punct" start_char="4613">,</TOKEN>
<TOKEN end_char="4616" id="token-48-2" morph="none" pos="word" start_char="4615">we</TOKEN>
<TOKEN end_char="4621" id="token-48-3" morph="none" pos="word" start_char="4618">rate</TOKEN>
<TOKEN end_char="4627" id="token-48-4" morph="none" pos="word" start_char="4623">Daily</TOKEN>
<TOKEN end_char="4632" id="token-48-5" morph="none" pos="word" start_char="4629">Mail</TOKEN>
<TOKEN end_char="4645" id="token-48-6" morph="none" pos="word" start_char="4634">Questionable</TOKEN>
<TOKEN end_char="4649" id="token-48-7" morph="none" pos="word" start_char="4647">due</TOKEN>
<TOKEN end_char="4652" id="token-48-8" morph="none" pos="word" start_char="4651">to</TOKEN>
<TOKEN end_char="4661" id="token-48-9" morph="none" pos="word" start_char="4654">numerous</TOKEN>
<TOKEN end_char="4668" id="token-48-10" morph="none" pos="word" start_char="4663">failed</TOKEN>
<TOKEN end_char="4673" id="token-48-11" morph="none" pos="word" start_char="4670">fact</TOKEN>
<TOKEN end_char="4680" id="token-48-12" morph="none" pos="word" start_char="4675">checks</TOKEN>
<TOKEN end_char="4684" id="token-48-13" morph="none" pos="word" start_char="4682">and</TOKEN>
<TOKEN end_char="4689" id="token-48-14" morph="none" pos="word" start_char="4686">poor</TOKEN>
<TOKEN end_char="4698" id="token-48-15" morph="none" pos="word" start_char="4691">sourcing</TOKEN>
<TOKEN end_char="4701" id="token-48-16" morph="none" pos="word" start_char="4700">of</TOKEN>
<TOKEN end_char="4713" id="token-48-17" morph="none" pos="word" start_char="4703">information</TOKEN>
<TOKEN end_char="4714" id="token-48-18" morph="none" pos="punct" start_char="4714">.</TOKEN>
</SEG>
<SEG end_char="4725" id="segment-49" start_char="4716">
<ORIGINAL_TEXT>Daily Mail</ORIGINAL_TEXT>
<TOKEN end_char="4720" id="token-49-0" morph="none" pos="word" start_char="4716">Daily</TOKEN>
<TOKEN end_char="4725" id="token-49-1" morph="none" pos="word" start_char="4722">Mail</TOKEN>
</SEG>
<SEG end_char="4760" id="segment-50" start_char="4728">
<ORIGINAL_TEXT>please, a super market tabloid???</ORIGINAL_TEXT>
<TOKEN end_char="4733" id="token-50-0" morph="none" pos="word" start_char="4728">please</TOKEN>
<TOKEN end_char="4734" id="token-50-1" morph="none" pos="punct" start_char="4734">,</TOKEN>
<TOKEN end_char="4736" id="token-50-2" morph="none" pos="word" start_char="4736">a</TOKEN>
<TOKEN end_char="4742" id="token-50-3" morph="none" pos="word" start_char="4738">super</TOKEN>
<TOKEN end_char="4749" id="token-50-4" morph="none" pos="word" start_char="4744">market</TOKEN>
<TOKEN end_char="4757" id="token-50-5" morph="none" pos="word" start_char="4751">tabloid</TOKEN>
<TOKEN end_char="4760" id="token-50-6" morph="none" pos="punct" start_char="4758">???</TOKEN>
</SEG>
<SEG end_char="4824" id="segment-51" start_char="4763">
<ORIGINAL_TEXT>edit on 13-3-2020 by hounddoghowlie because: (no reason given)</ORIGINAL_TEXT>
<TOKEN end_char="4766" id="token-51-0" morph="none" pos="word" start_char="4763">edit</TOKEN>
<TOKEN end_char="4769" id="token-51-1" morph="none" pos="word" start_char="4768">on</TOKEN>
<TOKEN end_char="4779" id="token-51-2" morph="none" pos="unknown" start_char="4771">13-3-2020</TOKEN>
<TOKEN end_char="4782" id="token-51-3" morph="none" pos="word" start_char="4781">by</TOKEN>
<TOKEN end_char="4797" id="token-51-4" morph="none" pos="word" start_char="4784">hounddoghowlie</TOKEN>
<TOKEN end_char="4805" id="token-51-5" morph="none" pos="word" start_char="4799">because</TOKEN>
<TOKEN end_char="4806" id="token-51-6" morph="none" pos="punct" start_char="4806">:</TOKEN>
<TOKEN end_char="4808" id="token-51-7" morph="none" pos="punct" start_char="4808">(</TOKEN>
<TOKEN end_char="4810" id="token-51-8" morph="none" pos="word" start_char="4809">no</TOKEN>
<TOKEN end_char="4817" id="token-51-9" morph="none" pos="word" start_char="4812">reason</TOKEN>
<TOKEN end_char="4823" id="token-51-10" morph="none" pos="word" start_char="4819">given</TOKEN>
<TOKEN end_char="4824" id="token-51-11" morph="none" pos="punct" start_char="4824">)</TOKEN>
</SEG>
<SEG end_char="5041" id="segment-52" start_char="4829">
<ORIGINAL_TEXT>originally posted by: PhyllidaDavenport The same month as the out break Wuhan Biosafety Lab was granted level 4 status meaning it had approval for the highest most deadly of virus's including Ebola and bioweapons.</ORIGINAL_TEXT>
<TOKEN end_char="4838" id="token-52-0" morph="none" pos="word" start_char="4829">originally</TOKEN>
<TOKEN end_char="4845" id="token-52-1" morph="none" pos="word" start_char="4840">posted</TOKEN>
<TOKEN end_char="4848" id="token-52-2" morph="none" pos="word" start_char="4847">by</TOKEN>
<TOKEN end_char="4849" id="token-52-3" morph="none" pos="punct" start_char="4849">:</TOKEN>
<TOKEN end_char="4867" id="token-52-4" morph="none" pos="word" start_char="4851">PhyllidaDavenport</TOKEN>
<TOKEN end_char="4871" id="token-52-5" morph="none" pos="word" start_char="4869">The</TOKEN>
<TOKEN end_char="4876" id="token-52-6" morph="none" pos="word" start_char="4873">same</TOKEN>
<TOKEN end_char="4882" id="token-52-7" morph="none" pos="word" start_char="4878">month</TOKEN>
<TOKEN end_char="4885" id="token-52-8" morph="none" pos="word" start_char="4884">as</TOKEN>
<TOKEN end_char="4889" id="token-52-9" morph="none" pos="word" start_char="4887">the</TOKEN>
<TOKEN end_char="4893" id="token-52-10" morph="none" pos="word" start_char="4891">out</TOKEN>
<TOKEN end_char="4899" id="token-52-11" morph="none" pos="word" start_char="4895">break</TOKEN>
<TOKEN end_char="4905" id="token-52-12" morph="none" pos="word" start_char="4901">Wuhan</TOKEN>
<TOKEN end_char="4915" id="token-52-13" morph="none" pos="word" start_char="4907">Biosafety</TOKEN>
<TOKEN end_char="4919" id="token-52-14" morph="none" pos="word" start_char="4917">Lab</TOKEN>
<TOKEN end_char="4923" id="token-52-15" morph="none" pos="word" start_char="4921">was</TOKEN>
<TOKEN end_char="4931" id="token-52-16" morph="none" pos="word" start_char="4925">granted</TOKEN>
<TOKEN end_char="4937" id="token-52-17" morph="none" pos="word" start_char="4933">level</TOKEN>
<TOKEN end_char="4939" id="token-52-18" morph="none" pos="word" start_char="4939">4</TOKEN>
<TOKEN end_char="4946" id="token-52-19" morph="none" pos="word" start_char="4941">status</TOKEN>
<TOKEN end_char="4954" id="token-52-20" morph="none" pos="word" start_char="4948">meaning</TOKEN>
<TOKEN end_char="4957" id="token-52-21" morph="none" pos="word" start_char="4956">it</TOKEN>
<TOKEN end_char="4961" id="token-52-22" morph="none" pos="word" start_char="4959">had</TOKEN>
<TOKEN end_char="4970" id="token-52-23" morph="none" pos="word" start_char="4963">approval</TOKEN>
<TOKEN end_char="4974" id="token-52-24" morph="none" pos="word" start_char="4972">for</TOKEN>
<TOKEN end_char="4978" id="token-52-25" morph="none" pos="word" start_char="4976">the</TOKEN>
<TOKEN end_char="4986" id="token-52-26" morph="none" pos="word" start_char="4980">highest</TOKEN>
<TOKEN end_char="4991" id="token-52-27" morph="none" pos="word" start_char="4988">most</TOKEN>
<TOKEN end_char="4998" id="token-52-28" morph="none" pos="word" start_char="4993">deadly</TOKEN>
<TOKEN end_char="5001" id="token-52-29" morph="none" pos="word" start_char="5000">of</TOKEN>
<TOKEN end_char="5009" id="token-52-30" morph="none" pos="word" start_char="5003">virus's</TOKEN>
<TOKEN end_char="5019" id="token-52-31" morph="none" pos="word" start_char="5011">including</TOKEN>
<TOKEN end_char="5025" id="token-52-32" morph="none" pos="word" start_char="5021">Ebola</TOKEN>
<TOKEN end_char="5029" id="token-52-33" morph="none" pos="word" start_char="5027">and</TOKEN>
<TOKEN end_char="5040" id="token-52-34" morph="none" pos="word" start_char="5031">bioweapons</TOKEN>
<TOKEN end_char="5041" id="token-52-35" morph="none" pos="punct" start_char="5041">.</TOKEN>
</SEG>
<SEG end_char="5125" id="segment-53" start_char="5043">
<ORIGINAL_TEXT>Make of that what you will but to me this was either an accident or perhaps a test.</ORIGINAL_TEXT>
<TOKEN end_char="5046" id="token-53-0" morph="none" pos="word" start_char="5043">Make</TOKEN>
<TOKEN end_char="5049" id="token-53-1" morph="none" pos="word" start_char="5048">of</TOKEN>
<TOKEN end_char="5054" id="token-53-2" morph="none" pos="word" start_char="5051">that</TOKEN>
<TOKEN end_char="5059" id="token-53-3" morph="none" pos="word" start_char="5056">what</TOKEN>
<TOKEN end_char="5063" id="token-53-4" morph="none" pos="word" start_char="5061">you</TOKEN>
<TOKEN end_char="5068" id="token-53-5" morph="none" pos="word" start_char="5065">will</TOKEN>
<TOKEN end_char="5072" id="token-53-6" morph="none" pos="word" start_char="5070">but</TOKEN>
<TOKEN end_char="5075" id="token-53-7" morph="none" pos="word" start_char="5074">to</TOKEN>
<TOKEN end_char="5078" id="token-53-8" morph="none" pos="word" start_char="5077">me</TOKEN>
<TOKEN end_char="5083" id="token-53-9" morph="none" pos="word" start_char="5080">this</TOKEN>
<TOKEN end_char="5087" id="token-53-10" morph="none" pos="word" start_char="5085">was</TOKEN>
<TOKEN end_char="5094" id="token-53-11" morph="none" pos="word" start_char="5089">either</TOKEN>
<TOKEN end_char="5097" id="token-53-12" morph="none" pos="word" start_char="5096">an</TOKEN>
<TOKEN end_char="5106" id="token-53-13" morph="none" pos="word" start_char="5099">accident</TOKEN>
<TOKEN end_char="5109" id="token-53-14" morph="none" pos="word" start_char="5108">or</TOKEN>
<TOKEN end_char="5117" id="token-53-15" morph="none" pos="word" start_char="5111">perhaps</TOKEN>
<TOKEN end_char="5119" id="token-53-16" morph="none" pos="word" start_char="5119">a</TOKEN>
<TOKEN end_char="5124" id="token-53-17" morph="none" pos="word" start_char="5121">test</TOKEN>
<TOKEN end_char="5125" id="token-53-18" morph="none" pos="punct" start_char="5125">.</TOKEN>
</SEG>
<SEG end_char="5281" id="segment-54" start_char="5127">
<ORIGINAL_TEXT>So far the Chinese have blamed bats, pangolins and dogs and as we all know, the information released from Chinese Government sources are far from reliable.</ORIGINAL_TEXT>
<TOKEN end_char="5128" id="token-54-0" morph="none" pos="word" start_char="5127">So</TOKEN>
<TOKEN end_char="5132" id="token-54-1" morph="none" pos="word" start_char="5130">far</TOKEN>
<TOKEN end_char="5136" id="token-54-2" morph="none" pos="word" start_char="5134">the</TOKEN>
<TOKEN end_char="5144" id="token-54-3" morph="none" pos="word" start_char="5138">Chinese</TOKEN>
<TOKEN end_char="5149" id="token-54-4" morph="none" pos="word" start_char="5146">have</TOKEN>
<TOKEN end_char="5156" id="token-54-5" morph="none" pos="word" start_char="5151">blamed</TOKEN>
<TOKEN end_char="5161" id="token-54-6" morph="none" pos="word" start_char="5158">bats</TOKEN>
<TOKEN end_char="5162" id="token-54-7" morph="none" pos="punct" start_char="5162">,</TOKEN>
<TOKEN end_char="5172" id="token-54-8" morph="none" pos="word" start_char="5164">pangolins</TOKEN>
<TOKEN end_char="5176" id="token-54-9" morph="none" pos="word" start_char="5174">and</TOKEN>
<TOKEN end_char="5181" id="token-54-10" morph="none" pos="word" start_char="5178">dogs</TOKEN>
<TOKEN end_char="5185" id="token-54-11" morph="none" pos="word" start_char="5183">and</TOKEN>
<TOKEN end_char="5188" id="token-54-12" morph="none" pos="word" start_char="5187">as</TOKEN>
<TOKEN end_char="5191" id="token-54-13" morph="none" pos="word" start_char="5190">we</TOKEN>
<TOKEN end_char="5195" id="token-54-14" morph="none" pos="word" start_char="5193">all</TOKEN>
<TOKEN end_char="5200" id="token-54-15" morph="none" pos="word" start_char="5197">know</TOKEN>
<TOKEN end_char="5201" id="token-54-16" morph="none" pos="punct" start_char="5201">,</TOKEN>
<TOKEN end_char="5205" id="token-54-17" morph="none" pos="word" start_char="5203">the</TOKEN>
<TOKEN end_char="5217" id="token-54-18" morph="none" pos="word" start_char="5207">information</TOKEN>
<TOKEN end_char="5226" id="token-54-19" morph="none" pos="word" start_char="5219">released</TOKEN>
<TOKEN end_char="5231" id="token-54-20" morph="none" pos="word" start_char="5228">from</TOKEN>
<TOKEN end_char="5239" id="token-54-21" morph="none" pos="word" start_char="5233">Chinese</TOKEN>
<TOKEN end_char="5250" id="token-54-22" morph="none" pos="word" start_char="5241">Government</TOKEN>
<TOKEN end_char="5258" id="token-54-23" morph="none" pos="word" start_char="5252">sources</TOKEN>
<TOKEN end_char="5262" id="token-54-24" morph="none" pos="word" start_char="5260">are</TOKEN>
<TOKEN end_char="5266" id="token-54-25" morph="none" pos="word" start_char="5264">far</TOKEN>
<TOKEN end_char="5271" id="token-54-26" morph="none" pos="word" start_char="5268">from</TOKEN>
<TOKEN end_char="5280" id="token-54-27" morph="none" pos="word" start_char="5273">reliable</TOKEN>
<TOKEN end_char="5281" id="token-54-28" morph="none" pos="punct" start_char="5281">.</TOKEN>
</SEG>
<SEG end_char="5406" id="segment-55" start_char="5283">
<ORIGINAL_TEXT>Let's also not forget that the SARS virus escaped multiple times from Bejing Laboratories so their track record isn't great!</ORIGINAL_TEXT>
<TOKEN end_char="5287" id="token-55-0" morph="none" pos="word" start_char="5283">Let's</TOKEN>
<TOKEN end_char="5292" id="token-55-1" morph="none" pos="word" start_char="5289">also</TOKEN>
<TOKEN end_char="5296" id="token-55-2" morph="none" pos="word" start_char="5294">not</TOKEN>
<TOKEN end_char="5303" id="token-55-3" morph="none" pos="word" start_char="5298">forget</TOKEN>
<TOKEN end_char="5308" id="token-55-4" morph="none" pos="word" start_char="5305">that</TOKEN>
<TOKEN end_char="5312" id="token-55-5" morph="none" pos="word" start_char="5310">the</TOKEN>
<TOKEN end_char="5317" id="token-55-6" morph="none" pos="word" start_char="5314">SARS</TOKEN>
<TOKEN end_char="5323" id="token-55-7" morph="none" pos="word" start_char="5319">virus</TOKEN>
<TOKEN end_char="5331" id="token-55-8" morph="none" pos="word" start_char="5325">escaped</TOKEN>
<TOKEN end_char="5340" id="token-55-9" morph="none" pos="word" start_char="5333">multiple</TOKEN>
<TOKEN end_char="5346" id="token-55-10" morph="none" pos="word" start_char="5342">times</TOKEN>
<TOKEN end_char="5351" id="token-55-11" morph="none" pos="word" start_char="5348">from</TOKEN>
<TOKEN end_char="5358" id="token-55-12" morph="none" pos="word" start_char="5353">Bejing</TOKEN>
<TOKEN end_char="5371" id="token-55-13" morph="none" pos="word" start_char="5360">Laboratories</TOKEN>
<TOKEN end_char="5374" id="token-55-14" morph="none" pos="word" start_char="5373">so</TOKEN>
<TOKEN end_char="5380" id="token-55-15" morph="none" pos="word" start_char="5376">their</TOKEN>
<TOKEN end_char="5386" id="token-55-16" morph="none" pos="word" start_char="5382">track</TOKEN>
<TOKEN end_char="5393" id="token-55-17" morph="none" pos="word" start_char="5388">record</TOKEN>
<TOKEN end_char="5399" id="token-55-18" morph="none" pos="word" start_char="5395">isn't</TOKEN>
<TOKEN end_char="5405" id="token-55-19" morph="none" pos="word" start_char="5401">great</TOKEN>
<TOKEN end_char="5406" id="token-55-20" morph="none" pos="punct" start_char="5406">!</TOKEN>
</SEG>
<SEG end_char="5524" id="segment-56" start_char="5409">
<ORIGINAL_TEXT>This virus has an almost perfect tool-set in terms of debilitating and eliminating humans who are weak, ill and old.</ORIGINAL_TEXT>
<TOKEN end_char="5412" id="token-56-0" morph="none" pos="word" start_char="5409">This</TOKEN>
<TOKEN end_char="5418" id="token-56-1" morph="none" pos="word" start_char="5414">virus</TOKEN>
<TOKEN end_char="5422" id="token-56-2" morph="none" pos="word" start_char="5420">has</TOKEN>
<TOKEN end_char="5425" id="token-56-3" morph="none" pos="word" start_char="5424">an</TOKEN>
<TOKEN end_char="5432" id="token-56-4" morph="none" pos="word" start_char="5427">almost</TOKEN>
<TOKEN end_char="5440" id="token-56-5" morph="none" pos="word" start_char="5434">perfect</TOKEN>
<TOKEN end_char="5449" id="token-56-6" morph="none" pos="unknown" start_char="5442">tool-set</TOKEN>
<TOKEN end_char="5452" id="token-56-7" morph="none" pos="word" start_char="5451">in</TOKEN>
<TOKEN end_char="5458" id="token-56-8" morph="none" pos="word" start_char="5454">terms</TOKEN>
<TOKEN end_char="5461" id="token-56-9" morph="none" pos="word" start_char="5460">of</TOKEN>
<TOKEN end_char="5474" id="token-56-10" morph="none" pos="word" start_char="5463">debilitating</TOKEN>
<TOKEN end_char="5478" id="token-56-11" morph="none" pos="word" start_char="5476">and</TOKEN>
<TOKEN end_char="5490" id="token-56-12" morph="none" pos="word" start_char="5480">eliminating</TOKEN>
<TOKEN end_char="5497" id="token-56-13" morph="none" pos="word" start_char="5492">humans</TOKEN>
<TOKEN end_char="5501" id="token-56-14" morph="none" pos="word" start_char="5499">who</TOKEN>
<TOKEN end_char="5505" id="token-56-15" morph="none" pos="word" start_char="5503">are</TOKEN>
<TOKEN end_char="5510" id="token-56-16" morph="none" pos="word" start_char="5507">weak</TOKEN>
<TOKEN end_char="5511" id="token-56-17" morph="none" pos="punct" start_char="5511">,</TOKEN>
<TOKEN end_char="5515" id="token-56-18" morph="none" pos="word" start_char="5513">ill</TOKEN>
<TOKEN end_char="5519" id="token-56-19" morph="none" pos="word" start_char="5517">and</TOKEN>
<TOKEN end_char="5523" id="token-56-20" morph="none" pos="word" start_char="5521">old</TOKEN>
<TOKEN end_char="5524" id="token-56-21" morph="none" pos="punct" start_char="5524">.</TOKEN>
</SEG>
<SEG end_char="5566" id="segment-57" start_char="5526">
<ORIGINAL_TEXT>Not all of which is yet fully understood.</ORIGINAL_TEXT>
<TOKEN end_char="5528" id="token-57-0" morph="none" pos="word" start_char="5526">Not</TOKEN>
<TOKEN end_char="5532" id="token-57-1" morph="none" pos="word" start_char="5530">all</TOKEN>
<TOKEN end_char="5535" id="token-57-2" morph="none" pos="word" start_char="5534">of</TOKEN>
<TOKEN end_char="5541" id="token-57-3" morph="none" pos="word" start_char="5537">which</TOKEN>
<TOKEN end_char="5544" id="token-57-4" morph="none" pos="word" start_char="5543">is</TOKEN>
<TOKEN end_char="5548" id="token-57-5" morph="none" pos="word" start_char="5546">yet</TOKEN>
<TOKEN end_char="5554" id="token-57-6" morph="none" pos="word" start_char="5550">fully</TOKEN>
<TOKEN end_char="5565" id="token-57-7" morph="none" pos="word" start_char="5556">understood</TOKEN>
<TOKEN end_char="5566" id="token-57-8" morph="none" pos="punct" start_char="5566">.</TOKEN>
</SEG>
<SEG end_char="5667" id="segment-58" start_char="5568">
<ORIGINAL_TEXT>Its almost perfect as a depop BW which smacks of intelligent design rather than natural coincidence!</ORIGINAL_TEXT>
<TOKEN end_char="5570" id="token-58-0" morph="none" pos="word" start_char="5568">Its</TOKEN>
<TOKEN end_char="5577" id="token-58-1" morph="none" pos="word" start_char="5572">almost</TOKEN>
<TOKEN end_char="5585" id="token-58-2" morph="none" pos="word" start_char="5579">perfect</TOKEN>
<TOKEN end_char="5588" id="token-58-3" morph="none" pos="word" start_char="5587">as</TOKEN>
<TOKEN end_char="5590" id="token-58-4" morph="none" pos="word" start_char="5590">a</TOKEN>
<TOKEN end_char="5596" id="token-58-5" morph="none" pos="word" start_char="5592">depop</TOKEN>
<TOKEN end_char="5599" id="token-58-6" morph="none" pos="word" start_char="5598">BW</TOKEN>
<TOKEN end_char="5605" id="token-58-7" morph="none" pos="word" start_char="5601">which</TOKEN>
<TOKEN end_char="5612" id="token-58-8" morph="none" pos="word" start_char="5607">smacks</TOKEN>
<TOKEN end_char="5615" id="token-58-9" morph="none" pos="word" start_char="5614">of</TOKEN>
<TOKEN end_char="5627" id="token-58-10" morph="none" pos="word" start_char="5617">intelligent</TOKEN>
<TOKEN end_char="5634" id="token-58-11" morph="none" pos="word" start_char="5629">design</TOKEN>
<TOKEN end_char="5641" id="token-58-12" morph="none" pos="word" start_char="5636">rather</TOKEN>
<TOKEN end_char="5646" id="token-58-13" morph="none" pos="word" start_char="5643">than</TOKEN>
<TOKEN end_char="5654" id="token-58-14" morph="none" pos="word" start_char="5648">natural</TOKEN>
<TOKEN end_char="5666" id="token-58-15" morph="none" pos="word" start_char="5656">coincidence</TOKEN>
<TOKEN end_char="5667" id="token-58-16" morph="none" pos="punct" start_char="5667">!</TOKEN>
</SEG>
<SEG end_char="5733" id="segment-59" start_char="5669">
<ORIGINAL_TEXT>The question is, was it an accident or deliberate by the Chinese?</ORIGINAL_TEXT>
<TOKEN end_char="5671" id="token-59-0" morph="none" pos="word" start_char="5669">The</TOKEN>
<TOKEN end_char="5680" id="token-59-1" morph="none" pos="word" start_char="5673">question</TOKEN>
<TOKEN end_char="5683" id="token-59-2" morph="none" pos="word" start_char="5682">is</TOKEN>
<TOKEN end_char="5684" id="token-59-3" morph="none" pos="punct" start_char="5684">,</TOKEN>
<TOKEN end_char="5688" id="token-59-4" morph="none" pos="word" start_char="5686">was</TOKEN>
<TOKEN end_char="5691" id="token-59-5" morph="none" pos="word" start_char="5690">it</TOKEN>
<TOKEN end_char="5694" id="token-59-6" morph="none" pos="word" start_char="5693">an</TOKEN>
<TOKEN end_char="5703" id="token-59-7" morph="none" pos="word" start_char="5696">accident</TOKEN>
<TOKEN end_char="5706" id="token-59-8" morph="none" pos="word" start_char="5705">or</TOKEN>
<TOKEN end_char="5717" id="token-59-9" morph="none" pos="word" start_char="5708">deliberate</TOKEN>
<TOKEN end_char="5720" id="token-59-10" morph="none" pos="word" start_char="5719">by</TOKEN>
<TOKEN end_char="5724" id="token-59-11" morph="none" pos="word" start_char="5722">the</TOKEN>
<TOKEN end_char="5732" id="token-59-12" morph="none" pos="word" start_char="5726">Chinese</TOKEN>
<TOKEN end_char="5733" id="token-59-13" morph="none" pos="punct" start_char="5733">?</TOKEN>
</SEG>
<SEG end_char="5765" id="segment-60" start_char="5735">
<ORIGINAL_TEXT>do they already have a vaccine?</ORIGINAL_TEXT>
<TOKEN end_char="5736" id="token-60-0" morph="none" pos="word" start_char="5735">do</TOKEN>
<TOKEN end_char="5741" id="token-60-1" morph="none" pos="word" start_char="5738">they</TOKEN>
<TOKEN end_char="5749" id="token-60-2" morph="none" pos="word" start_char="5743">already</TOKEN>
<TOKEN end_char="5754" id="token-60-3" morph="none" pos="word" start_char="5751">have</TOKEN>
<TOKEN end_char="5756" id="token-60-4" morph="none" pos="word" start_char="5756">a</TOKEN>
<TOKEN end_char="5764" id="token-60-5" morph="none" pos="word" start_char="5758">vaccine</TOKEN>
<TOKEN end_char="5765" id="token-60-6" morph="none" pos="punct" start_char="5765">?</TOKEN>
</SEG>
<SEG end_char="5840" id="segment-61" start_char="5767">
<ORIGINAL_TEXT>Or was it done deliberately by another and do they already have a vaccine.</ORIGINAL_TEXT>
<TOKEN end_char="5768" id="token-61-0" morph="none" pos="word" start_char="5767">Or</TOKEN>
<TOKEN end_char="5772" id="token-61-1" morph="none" pos="word" start_char="5770">was</TOKEN>
<TOKEN end_char="5775" id="token-61-2" morph="none" pos="word" start_char="5774">it</TOKEN>
<TOKEN end_char="5780" id="token-61-3" morph="none" pos="word" start_char="5777">done</TOKEN>
<TOKEN end_char="5793" id="token-61-4" morph="none" pos="word" start_char="5782">deliberately</TOKEN>
<TOKEN end_char="5796" id="token-61-5" morph="none" pos="word" start_char="5795">by</TOKEN>
<TOKEN end_char="5804" id="token-61-6" morph="none" pos="word" start_char="5798">another</TOKEN>
<TOKEN end_char="5808" id="token-61-7" morph="none" pos="word" start_char="5806">and</TOKEN>
<TOKEN end_char="5811" id="token-61-8" morph="none" pos="word" start_char="5810">do</TOKEN>
<TOKEN end_char="5816" id="token-61-9" morph="none" pos="word" start_char="5813">they</TOKEN>
<TOKEN end_char="5824" id="token-61-10" morph="none" pos="word" start_char="5818">already</TOKEN>
<TOKEN end_char="5829" id="token-61-11" morph="none" pos="word" start_char="5826">have</TOKEN>
<TOKEN end_char="5831" id="token-61-12" morph="none" pos="word" start_char="5831">a</TOKEN>
<TOKEN end_char="5839" id="token-61-13" morph="none" pos="word" start_char="5833">vaccine</TOKEN>
<TOKEN end_char="5840" id="token-61-14" morph="none" pos="punct" start_char="5840">.</TOKEN>
</SEG>
<SEG end_char="5890" id="segment-62" start_char="5843">
<ORIGINAL_TEXT>This TOOL of a virus is worse than people think!</ORIGINAL_TEXT>
<TOKEN end_char="5846" id="token-62-0" morph="none" pos="word" start_char="5843">This</TOKEN>
<TOKEN end_char="5851" id="token-62-1" morph="none" pos="word" start_char="5848">TOOL</TOKEN>
<TOKEN end_char="5854" id="token-62-2" morph="none" pos="word" start_char="5853">of</TOKEN>
<TOKEN end_char="5856" id="token-62-3" morph="none" pos="word" start_char="5856">a</TOKEN>
<TOKEN end_char="5862" id="token-62-4" morph="none" pos="word" start_char="5858">virus</TOKEN>
<TOKEN end_char="5865" id="token-62-5" morph="none" pos="word" start_char="5864">is</TOKEN>
<TOKEN end_char="5871" id="token-62-6" morph="none" pos="word" start_char="5867">worse</TOKEN>
<TOKEN end_char="5876" id="token-62-7" morph="none" pos="word" start_char="5873">than</TOKEN>
<TOKEN end_char="5883" id="token-62-8" morph="none" pos="word" start_char="5878">people</TOKEN>
<TOKEN end_char="5889" id="token-62-9" morph="none" pos="word" start_char="5885">think</TOKEN>
<TOKEN end_char="5890" id="token-62-10" morph="none" pos="punct" start_char="5890">!</TOKEN>
</SEG>
<SEG end_char="5909" id="segment-63" start_char="5892">
<ORIGINAL_TEXT>Natural - hogwash!</ORIGINAL_TEXT>
<TOKEN end_char="5898" id="token-63-0" morph="none" pos="word" start_char="5892">Natural</TOKEN>
<TOKEN end_char="5900" id="token-63-1" morph="none" pos="punct" start_char="5900">-</TOKEN>
<TOKEN end_char="5908" id="token-63-2" morph="none" pos="word" start_char="5902">hogwash</TOKEN>
<TOKEN end_char="5909" id="token-63-3" morph="none" pos="punct" start_char="5909">!</TOKEN>
</SEG>
<SEG end_char="5982" id="segment-64" start_char="5915">
<ORIGINAL_TEXT>originally posted by: Miccey This strain was planted by you know who</ORIGINAL_TEXT>
<TOKEN end_char="5924" id="token-64-0" morph="none" pos="word" start_char="5915">originally</TOKEN>
<TOKEN end_char="5931" id="token-64-1" morph="none" pos="word" start_char="5926">posted</TOKEN>
<TOKEN end_char="5934" id="token-64-2" morph="none" pos="word" start_char="5933">by</TOKEN>
<TOKEN end_char="5935" id="token-64-3" morph="none" pos="punct" start_char="5935">:</TOKEN>
<TOKEN end_char="5942" id="token-64-4" morph="none" pos="word" start_char="5937">Miccey</TOKEN>
<TOKEN end_char="5947" id="token-64-5" morph="none" pos="word" start_char="5944">This</TOKEN>
<TOKEN end_char="5954" id="token-64-6" morph="none" pos="word" start_char="5949">strain</TOKEN>
<TOKEN end_char="5958" id="token-64-7" morph="none" pos="word" start_char="5956">was</TOKEN>
<TOKEN end_char="5966" id="token-64-8" morph="none" pos="word" start_char="5960">planted</TOKEN>
<TOKEN end_char="5969" id="token-64-9" morph="none" pos="word" start_char="5968">by</TOKEN>
<TOKEN end_char="5973" id="token-64-10" morph="none" pos="word" start_char="5971">you</TOKEN>
<TOKEN end_char="5978" id="token-64-11" morph="none" pos="word" start_char="5975">know</TOKEN>
<TOKEN end_char="5982" id="token-64-12" morph="none" pos="word" start_char="5980">who</TOKEN>
</SEG>
<SEG end_char="6000" id="segment-65" start_char="5985">
<ORIGINAL_TEXT>Hilery Clinton !</ORIGINAL_TEXT>
<TOKEN end_char="5990" id="token-65-0" morph="none" pos="word" start_char="5985">Hilery</TOKEN>
<TOKEN end_char="5998" id="token-65-1" morph="none" pos="word" start_char="5992">Clinton</TOKEN>
<TOKEN end_char="6000" id="token-65-2" morph="none" pos="punct" start_char="6000">!</TOKEN>
</SEG>
<SEG end_char="6037" id="segment-66" start_char="6002">
<ORIGINAL_TEXT>she just can not stop killing peope.</ORIGINAL_TEXT>
<TOKEN end_char="6004" id="token-66-0" morph="none" pos="word" start_char="6002">she</TOKEN>
<TOKEN end_char="6009" id="token-66-1" morph="none" pos="word" start_char="6006">just</TOKEN>
<TOKEN end_char="6013" id="token-66-2" morph="none" pos="word" start_char="6011">can</TOKEN>
<TOKEN end_char="6017" id="token-66-3" morph="none" pos="word" start_char="6015">not</TOKEN>
<TOKEN end_char="6022" id="token-66-4" morph="none" pos="word" start_char="6019">stop</TOKEN>
<TOKEN end_char="6030" id="token-66-5" morph="none" pos="word" start_char="6024">killing</TOKEN>
<TOKEN end_char="6036" id="token-66-6" morph="none" pos="word" start_char="6032">peope</TOKEN>
<TOKEN end_char="6037" id="token-66-7" morph="none" pos="punct" start_char="6037">.</TOKEN>
</SEG>
<SEG end_char="6069" id="segment-67" start_char="6042">
<ORIGINAL_TEXT>a reply to: ElectricUniverse</ORIGINAL_TEXT>
<TOKEN end_char="6042" id="token-67-0" morph="none" pos="word" start_char="6042">a</TOKEN>
<TOKEN end_char="6048" id="token-67-1" morph="none" pos="word" start_char="6044">reply</TOKEN>
<TOKEN end_char="6051" id="token-67-2" morph="none" pos="word" start_char="6050">to</TOKEN>
<TOKEN end_char="6052" id="token-67-3" morph="none" pos="punct" start_char="6052">:</TOKEN>
<TOKEN end_char="6069" id="token-67-4" morph="none" pos="word" start_char="6054">ElectricUniverse</TOKEN>
</SEG>
<SEG end_char="6152" id="segment-68" start_char="6072">
<ORIGINAL_TEXT>Notice the words "could have" and "possibility" reported in the original article.</ORIGINAL_TEXT>
<TOKEN end_char="6077" id="token-68-0" morph="none" pos="word" start_char="6072">Notice</TOKEN>
<TOKEN end_char="6081" id="token-68-1" morph="none" pos="word" start_char="6079">the</TOKEN>
<TOKEN end_char="6087" id="token-68-2" morph="none" pos="word" start_char="6083">words</TOKEN>
<TOKEN end_char="6089" id="token-68-3" morph="none" pos="punct" start_char="6089">"</TOKEN>
<TOKEN end_char="6094" id="token-68-4" morph="none" pos="word" start_char="6090">could</TOKEN>
<TOKEN end_char="6099" id="token-68-5" morph="none" pos="word" start_char="6096">have</TOKEN>
<TOKEN end_char="6100" id="token-68-6" morph="none" pos="punct" start_char="6100">"</TOKEN>
<TOKEN end_char="6104" id="token-68-7" morph="none" pos="word" start_char="6102">and</TOKEN>
<TOKEN end_char="6106" id="token-68-8" morph="none" pos="punct" start_char="6106">"</TOKEN>
<TOKEN end_char="6117" id="token-68-9" morph="none" pos="word" start_char="6107">possibility</TOKEN>
<TOKEN end_char="6118" id="token-68-10" morph="none" pos="punct" start_char="6118">"</TOKEN>
<TOKEN end_char="6127" id="token-68-11" morph="none" pos="word" start_char="6120">reported</TOKEN>
<TOKEN end_char="6130" id="token-68-12" morph="none" pos="word" start_char="6129">in</TOKEN>
<TOKEN end_char="6134" id="token-68-13" morph="none" pos="word" start_char="6132">the</TOKEN>
<TOKEN end_char="6143" id="token-68-14" morph="none" pos="word" start_char="6136">original</TOKEN>
<TOKEN end_char="6151" id="token-68-15" morph="none" pos="word" start_char="6145">article</TOKEN>
<TOKEN end_char="6152" id="token-68-16" morph="none" pos="punct" start_char="6152">.</TOKEN>
</SEG>
<SEG end_char="6194" id="segment-69" start_char="6154">
<ORIGINAL_TEXT>Nowhere does it say they "believe it did"</ORIGINAL_TEXT>
<TOKEN end_char="6160" id="token-69-0" morph="none" pos="word" start_char="6154">Nowhere</TOKEN>
<TOKEN end_char="6165" id="token-69-1" morph="none" pos="word" start_char="6162">does</TOKEN>
<TOKEN end_char="6168" id="token-69-2" morph="none" pos="word" start_char="6167">it</TOKEN>
<TOKEN end_char="6172" id="token-69-3" morph="none" pos="word" start_char="6170">say</TOKEN>
<TOKEN end_char="6177" id="token-69-4" morph="none" pos="word" start_char="6174">they</TOKEN>
<TOKEN end_char="6179" id="token-69-5" morph="none" pos="punct" start_char="6179">"</TOKEN>
<TOKEN end_char="6186" id="token-69-6" morph="none" pos="word" start_char="6180">believe</TOKEN>
<TOKEN end_char="6189" id="token-69-7" morph="none" pos="word" start_char="6188">it</TOKEN>
<TOKEN end_char="6193" id="token-69-8" morph="none" pos="word" start_char="6191">did</TOKEN>
<TOKEN end_char="6194" id="token-69-9" morph="none" pos="punct" start_char="6194">"</TOKEN>
</SEG>
<SEG end_char="6289" id="segment-70" start_char="6197">
<ORIGINAL_TEXT>And it is from the "Daily Mail" , which apparently is taking up the "Enquirer" brand of news.</ORIGINAL_TEXT>
<TOKEN end_char="6199" id="token-70-0" morph="none" pos="word" start_char="6197">And</TOKEN>
<TOKEN end_char="6202" id="token-70-1" morph="none" pos="word" start_char="6201">it</TOKEN>
<TOKEN end_char="6205" id="token-70-2" morph="none" pos="word" start_char="6204">is</TOKEN>
<TOKEN end_char="6210" id="token-70-3" morph="none" pos="word" start_char="6207">from</TOKEN>
<TOKEN end_char="6214" id="token-70-4" morph="none" pos="word" start_char="6212">the</TOKEN>
<TOKEN end_char="6216" id="token-70-5" morph="none" pos="punct" start_char="6216">"</TOKEN>
<TOKEN end_char="6221" id="token-70-6" morph="none" pos="word" start_char="6217">Daily</TOKEN>
<TOKEN end_char="6226" id="token-70-7" morph="none" pos="word" start_char="6223">Mail</TOKEN>
<TOKEN end_char="6227" id="token-70-8" morph="none" pos="punct" start_char="6227">"</TOKEN>
<TOKEN end_char="6229" id="token-70-9" morph="none" pos="punct" start_char="6229">,</TOKEN>
<TOKEN end_char="6235" id="token-70-10" morph="none" pos="word" start_char="6231">which</TOKEN>
<TOKEN end_char="6246" id="token-70-11" morph="none" pos="word" start_char="6237">apparently</TOKEN>
<TOKEN end_char="6249" id="token-70-12" morph="none" pos="word" start_char="6248">is</TOKEN>
<TOKEN end_char="6256" id="token-70-13" morph="none" pos="word" start_char="6251">taking</TOKEN>
<TOKEN end_char="6259" id="token-70-14" morph="none" pos="word" start_char="6258">up</TOKEN>
<TOKEN end_char="6263" id="token-70-15" morph="none" pos="word" start_char="6261">the</TOKEN>
<TOKEN end_char="6265" id="token-70-16" morph="none" pos="punct" start_char="6265">"</TOKEN>
<TOKEN end_char="6273" id="token-70-17" morph="none" pos="word" start_char="6266">Enquirer</TOKEN>
<TOKEN end_char="6274" id="token-70-18" morph="none" pos="punct" start_char="6274">"</TOKEN>
<TOKEN end_char="6280" id="token-70-19" morph="none" pos="word" start_char="6276">brand</TOKEN>
<TOKEN end_char="6283" id="token-70-20" morph="none" pos="word" start_char="6282">of</TOKEN>
<TOKEN end_char="6288" id="token-70-21" morph="none" pos="word" start_char="6285">news</TOKEN>
<TOKEN end_char="6289" id="token-70-22" morph="none" pos="punct" start_char="6289">.</TOKEN>
</SEG>
<SEG end_char="6344" id="segment-71" start_char="6292">
<ORIGINAL_TEXT>edit on 3/13/20 by Gothmog because: (no reason given)</ORIGINAL_TEXT>
<TOKEN end_char="6295" id="token-71-0" morph="none" pos="word" start_char="6292">edit</TOKEN>
<TOKEN end_char="6298" id="token-71-1" morph="none" pos="word" start_char="6297">on</TOKEN>
<TOKEN end_char="6306" id="token-71-2" morph="none" pos="unknown" start_char="6300">3/13/20</TOKEN>
<TOKEN end_char="6309" id="token-71-3" morph="none" pos="word" start_char="6308">by</TOKEN>
<TOKEN end_char="6317" id="token-71-4" morph="none" pos="word" start_char="6311">Gothmog</TOKEN>
<TOKEN end_char="6325" id="token-71-5" morph="none" pos="word" start_char="6319">because</TOKEN>
<TOKEN end_char="6326" id="token-71-6" morph="none" pos="punct" start_char="6326">:</TOKEN>
<TOKEN end_char="6328" id="token-71-7" morph="none" pos="punct" start_char="6328">(</TOKEN>
<TOKEN end_char="6330" id="token-71-8" morph="none" pos="word" start_char="6329">no</TOKEN>
<TOKEN end_char="6337" id="token-71-9" morph="none" pos="word" start_char="6332">reason</TOKEN>
<TOKEN end_char="6343" id="token-71-10" morph="none" pos="word" start_char="6339">given</TOKEN>
<TOKEN end_char="6344" id="token-71-11" morph="none" pos="punct" start_char="6344">)</TOKEN>
</SEG>
<SEG end_char="6420" id="segment-72" start_char="6348">
<ORIGINAL_TEXT>well i forgot that some people consider super market tabloids hot sheets.</ORIGINAL_TEXT>
<TOKEN end_char="6351" id="token-72-0" morph="none" pos="word" start_char="6348">well</TOKEN>
<TOKEN end_char="6353" id="token-72-1" morph="none" pos="word" start_char="6353">i</TOKEN>
<TOKEN end_char="6360" id="token-72-2" morph="none" pos="word" start_char="6355">forgot</TOKEN>
<TOKEN end_char="6365" id="token-72-3" morph="none" pos="word" start_char="6362">that</TOKEN>
<TOKEN end_char="6370" id="token-72-4" morph="none" pos="word" start_char="6367">some</TOKEN>
<TOKEN end_char="6377" id="token-72-5" morph="none" pos="word" start_char="6372">people</TOKEN>
<TOKEN end_char="6386" id="token-72-6" morph="none" pos="word" start_char="6379">consider</TOKEN>
<TOKEN end_char="6392" id="token-72-7" morph="none" pos="word" start_char="6388">super</TOKEN>
<TOKEN end_char="6399" id="token-72-8" morph="none" pos="word" start_char="6394">market</TOKEN>
<TOKEN end_char="6408" id="token-72-9" morph="none" pos="word" start_char="6401">tabloids</TOKEN>
<TOKEN end_char="6412" id="token-72-10" morph="none" pos="word" start_char="6410">hot</TOKEN>
<TOKEN end_char="6419" id="token-72-11" morph="none" pos="word" start_char="6414">sheets</TOKEN>
<TOKEN end_char="6420" id="token-72-12" morph="none" pos="punct" start_char="6420">.</TOKEN>
</SEG>
<SEG end_char="6451" id="segment-73" start_char="6424">
<ORIGINAL_TEXT>a reply to: ElectricUniverse</ORIGINAL_TEXT>
<TOKEN end_char="6424" id="token-73-0" morph="none" pos="word" start_char="6424">a</TOKEN>
<TOKEN end_char="6430" id="token-73-1" morph="none" pos="word" start_char="6426">reply</TOKEN>
<TOKEN end_char="6433" id="token-73-2" morph="none" pos="word" start_char="6432">to</TOKEN>
<TOKEN end_char="6434" id="token-73-3" morph="none" pos="punct" start_char="6434">:</TOKEN>
<TOKEN end_char="6451" id="token-73-4" morph="none" pos="word" start_char="6436">ElectricUniverse</TOKEN>
</SEG>
<SEG end_char="6470" id="segment-74" start_char="6454">
<ORIGINAL_TEXT>Of course it did.</ORIGINAL_TEXT>
<TOKEN end_char="6455" id="token-74-0" morph="none" pos="word" start_char="6454">Of</TOKEN>
<TOKEN end_char="6462" id="token-74-1" morph="none" pos="word" start_char="6457">course</TOKEN>
<TOKEN end_char="6465" id="token-74-2" morph="none" pos="word" start_char="6464">it</TOKEN>
<TOKEN end_char="6469" id="token-74-3" morph="none" pos="word" start_char="6467">did</TOKEN>
<TOKEN end_char="6470" id="token-74-4" morph="none" pos="punct" start_char="6470">.</TOKEN>
</SEG>
<SEG end_char="6543" id="segment-75" start_char="6472">
<ORIGINAL_TEXT>It started near a bioweapon facility and several bioresearch facilities.</ORIGINAL_TEXT>
<TOKEN end_char="6473" id="token-75-0" morph="none" pos="word" start_char="6472">It</TOKEN>
<TOKEN end_char="6481" id="token-75-1" morph="none" pos="word" start_char="6475">started</TOKEN>
<TOKEN end_char="6486" id="token-75-2" morph="none" pos="word" start_char="6483">near</TOKEN>
<TOKEN end_char="6488" id="token-75-3" morph="none" pos="word" start_char="6488">a</TOKEN>
<TOKEN end_char="6498" id="token-75-4" morph="none" pos="word" start_char="6490">bioweapon</TOKEN>
<TOKEN end_char="6507" id="token-75-5" morph="none" pos="word" start_char="6500">facility</TOKEN>
<TOKEN end_char="6511" id="token-75-6" morph="none" pos="word" start_char="6509">and</TOKEN>
<TOKEN end_char="6519" id="token-75-7" morph="none" pos="word" start_char="6513">several</TOKEN>
<TOKEN end_char="6531" id="token-75-8" morph="none" pos="word" start_char="6521">bioresearch</TOKEN>
<TOKEN end_char="6542" id="token-75-9" morph="none" pos="word" start_char="6533">facilities</TOKEN>
<TOKEN end_char="6543" id="token-75-10" morph="none" pos="punct" start_char="6543">.</TOKEN>
</SEG>
<SEG end_char="6578" id="segment-76" start_char="6545">
<ORIGINAL_TEXT>Too much a coincidence to dismiss.</ORIGINAL_TEXT>
<TOKEN end_char="6547" id="token-76-0" morph="none" pos="word" start_char="6545">Too</TOKEN>
<TOKEN end_char="6552" id="token-76-1" morph="none" pos="word" start_char="6549">much</TOKEN>
<TOKEN end_char="6554" id="token-76-2" morph="none" pos="word" start_char="6554">a</TOKEN>
<TOKEN end_char="6566" id="token-76-3" morph="none" pos="word" start_char="6556">coincidence</TOKEN>
<TOKEN end_char="6569" id="token-76-4" morph="none" pos="word" start_char="6568">to</TOKEN>
<TOKEN end_char="6577" id="token-76-5" morph="none" pos="word" start_char="6571">dismiss</TOKEN>
<TOKEN end_char="6578" id="token-76-6" morph="none" pos="punct" start_char="6578">.</TOKEN>
</SEG>
<SEG end_char="6656" id="segment-77" start_char="6580">
<ORIGINAL_TEXT>Especially since the virus is truly beneficial to Chinese society as a whole.</ORIGINAL_TEXT>
<TOKEN end_char="6589" id="token-77-0" morph="none" pos="word" start_char="6580">Especially</TOKEN>
<TOKEN end_char="6595" id="token-77-1" morph="none" pos="word" start_char="6591">since</TOKEN>
<TOKEN end_char="6599" id="token-77-2" morph="none" pos="word" start_char="6597">the</TOKEN>
<TOKEN end_char="6605" id="token-77-3" morph="none" pos="word" start_char="6601">virus</TOKEN>
<TOKEN end_char="6608" id="token-77-4" morph="none" pos="word" start_char="6607">is</TOKEN>
<TOKEN end_char="6614" id="token-77-5" morph="none" pos="word" start_char="6610">truly</TOKEN>
<TOKEN end_char="6625" id="token-77-6" morph="none" pos="word" start_char="6616">beneficial</TOKEN>
<TOKEN end_char="6628" id="token-77-7" morph="none" pos="word" start_char="6627">to</TOKEN>
<TOKEN end_char="6636" id="token-77-8" morph="none" pos="word" start_char="6630">Chinese</TOKEN>
<TOKEN end_char="6644" id="token-77-9" morph="none" pos="word" start_char="6638">society</TOKEN>
<TOKEN end_char="6647" id="token-77-10" morph="none" pos="word" start_char="6646">as</TOKEN>
<TOKEN end_char="6649" id="token-77-11" morph="none" pos="word" start_char="6649">a</TOKEN>
<TOKEN end_char="6655" id="token-77-12" morph="none" pos="word" start_char="6651">whole</TOKEN>
<TOKEN end_char="6656" id="token-77-13" morph="none" pos="punct" start_char="6656">.</TOKEN>
</SEG>
<SEG end_char="6713" id="segment-78" start_char="6659">
<ORIGINAL_TEXT>China is a communist country, individuals mean nothing.</ORIGINAL_TEXT>
<TOKEN end_char="6663" id="token-78-0" morph="none" pos="word" start_char="6659">China</TOKEN>
<TOKEN end_char="6666" id="token-78-1" morph="none" pos="word" start_char="6665">is</TOKEN>
<TOKEN end_char="6668" id="token-78-2" morph="none" pos="word" start_char="6668">a</TOKEN>
<TOKEN end_char="6678" id="token-78-3" morph="none" pos="word" start_char="6670">communist</TOKEN>
<TOKEN end_char="6686" id="token-78-4" morph="none" pos="word" start_char="6680">country</TOKEN>
<TOKEN end_char="6687" id="token-78-5" morph="none" pos="punct" start_char="6687">,</TOKEN>
<TOKEN end_char="6699" id="token-78-6" morph="none" pos="word" start_char="6689">individuals</TOKEN>
<TOKEN end_char="6704" id="token-78-7" morph="none" pos="word" start_char="6701">mean</TOKEN>
<TOKEN end_char="6712" id="token-78-8" morph="none" pos="word" start_char="6706">nothing</TOKEN>
<TOKEN end_char="6713" id="token-78-9" morph="none" pos="punct" start_char="6713">.</TOKEN>
</SEG>
<SEG end_char="6779" id="segment-79" start_char="6715">
<ORIGINAL_TEXT>Everything is done for the good of the whole, society as a whole.</ORIGINAL_TEXT>
<TOKEN end_char="6724" id="token-79-0" morph="none" pos="word" start_char="6715">Everything</TOKEN>
<TOKEN end_char="6727" id="token-79-1" morph="none" pos="word" start_char="6726">is</TOKEN>
<TOKEN end_char="6732" id="token-79-2" morph="none" pos="word" start_char="6729">done</TOKEN>
<TOKEN end_char="6736" id="token-79-3" morph="none" pos="word" start_char="6734">for</TOKEN>
<TOKEN end_char="6740" id="token-79-4" morph="none" pos="word" start_char="6738">the</TOKEN>
<TOKEN end_char="6745" id="token-79-5" morph="none" pos="word" start_char="6742">good</TOKEN>
<TOKEN end_char="6748" id="token-79-6" morph="none" pos="word" start_char="6747">of</TOKEN>
<TOKEN end_char="6752" id="token-79-7" morph="none" pos="word" start_char="6750">the</TOKEN>
<TOKEN end_char="6758" id="token-79-8" morph="none" pos="word" start_char="6754">whole</TOKEN>
<TOKEN end_char="6759" id="token-79-9" morph="none" pos="punct" start_char="6759">,</TOKEN>
<TOKEN end_char="6767" id="token-79-10" morph="none" pos="word" start_char="6761">society</TOKEN>
<TOKEN end_char="6770" id="token-79-11" morph="none" pos="word" start_char="6769">as</TOKEN>
<TOKEN end_char="6772" id="token-79-12" morph="none" pos="word" start_char="6772">a</TOKEN>
<TOKEN end_char="6778" id="token-79-13" morph="none" pos="word" start_char="6774">whole</TOKEN>
<TOKEN end_char="6779" id="token-79-14" morph="none" pos="punct" start_char="6779">.</TOKEN>
</SEG>
<SEG end_char="6832" id="segment-80" start_char="6782">
<ORIGINAL_TEXT>They have a enormous problem with too many elderly.</ORIGINAL_TEXT>
<TOKEN end_char="6785" id="token-80-0" morph="none" pos="word" start_char="6782">They</TOKEN>
<TOKEN end_char="6790" id="token-80-1" morph="none" pos="word" start_char="6787">have</TOKEN>
<TOKEN end_char="6792" id="token-80-2" morph="none" pos="word" start_char="6792">a</TOKEN>
<TOKEN end_char="6801" id="token-80-3" morph="none" pos="word" start_char="6794">enormous</TOKEN>
<TOKEN end_char="6809" id="token-80-4" morph="none" pos="word" start_char="6803">problem</TOKEN>
<TOKEN end_char="6814" id="token-80-5" morph="none" pos="word" start_char="6811">with</TOKEN>
<TOKEN end_char="6818" id="token-80-6" morph="none" pos="word" start_char="6816">too</TOKEN>
<TOKEN end_char="6823" id="token-80-7" morph="none" pos="word" start_char="6820">many</TOKEN>
<TOKEN end_char="6831" id="token-80-8" morph="none" pos="word" start_char="6825">elderly</TOKEN>
<TOKEN end_char="6832" id="token-80-9" morph="none" pos="punct" start_char="6832">.</TOKEN>
</SEG>
<SEG end_char="6868" id="segment-81" start_char="6834">
<ORIGINAL_TEXT>This is due their one child policy.</ORIGINAL_TEXT>
<TOKEN end_char="6837" id="token-81-0" morph="none" pos="word" start_char="6834">This</TOKEN>
<TOKEN end_char="6840" id="token-81-1" morph="none" pos="word" start_char="6839">is</TOKEN>
<TOKEN end_char="6844" id="token-81-2" morph="none" pos="word" start_char="6842">due</TOKEN>
<TOKEN end_char="6850" id="token-81-3" morph="none" pos="word" start_char="6846">their</TOKEN>
<TOKEN end_char="6854" id="token-81-4" morph="none" pos="word" start_char="6852">one</TOKEN>
<TOKEN end_char="6860" id="token-81-5" morph="none" pos="word" start_char="6856">child</TOKEN>
<TOKEN end_char="6867" id="token-81-6" morph="none" pos="word" start_char="6862">policy</TOKEN>
<TOKEN end_char="6868" id="token-81-7" morph="none" pos="punct" start_char="6868">.</TOKEN>
</SEG>
<SEG end_char="7025" id="segment-82" start_char="6870">
<ORIGINAL_TEXT>Right now on average a couple is supporting themselves, their child/ren, and FOUR other adults, this is their culture- no to few facilities for the elderly.</ORIGINAL_TEXT>
<TOKEN end_char="6874" id="token-82-0" morph="none" pos="word" start_char="6870">Right</TOKEN>
<TOKEN end_char="6878" id="token-82-1" morph="none" pos="word" start_char="6876">now</TOKEN>
<TOKEN end_char="6881" id="token-82-2" morph="none" pos="word" start_char="6880">on</TOKEN>
<TOKEN end_char="6889" id="token-82-3" morph="none" pos="word" start_char="6883">average</TOKEN>
<TOKEN end_char="6891" id="token-82-4" morph="none" pos="word" start_char="6891">a</TOKEN>
<TOKEN end_char="6898" id="token-82-5" morph="none" pos="word" start_char="6893">couple</TOKEN>
<TOKEN end_char="6901" id="token-82-6" morph="none" pos="word" start_char="6900">is</TOKEN>
<TOKEN end_char="6912" id="token-82-7" morph="none" pos="word" start_char="6903">supporting</TOKEN>
<TOKEN end_char="6923" id="token-82-8" morph="none" pos="word" start_char="6914">themselves</TOKEN>
<TOKEN end_char="6924" id="token-82-9" morph="none" pos="punct" start_char="6924">,</TOKEN>
<TOKEN end_char="6930" id="token-82-10" morph="none" pos="word" start_char="6926">their</TOKEN>
<TOKEN end_char="6940" id="token-82-11" morph="none" pos="unknown" start_char="6932">child/ren</TOKEN>
<TOKEN end_char="6941" id="token-82-12" morph="none" pos="punct" start_char="6941">,</TOKEN>
<TOKEN end_char="6945" id="token-82-13" morph="none" pos="word" start_char="6943">and</TOKEN>
<TOKEN end_char="6950" id="token-82-14" morph="none" pos="word" start_char="6947">FOUR</TOKEN>
<TOKEN end_char="6956" id="token-82-15" morph="none" pos="word" start_char="6952">other</TOKEN>
<TOKEN end_char="6963" id="token-82-16" morph="none" pos="word" start_char="6958">adults</TOKEN>
<TOKEN end_char="6964" id="token-82-17" morph="none" pos="punct" start_char="6964">,</TOKEN>
<TOKEN end_char="6969" id="token-82-18" morph="none" pos="word" start_char="6966">this</TOKEN>
<TOKEN end_char="6972" id="token-82-19" morph="none" pos="word" start_char="6971">is</TOKEN>
<TOKEN end_char="6978" id="token-82-20" morph="none" pos="word" start_char="6974">their</TOKEN>
<TOKEN end_char="6986" id="token-82-21" morph="none" pos="word" start_char="6980">culture</TOKEN>
<TOKEN end_char="6987" id="token-82-22" morph="none" pos="punct" start_char="6987">-</TOKEN>
<TOKEN end_char="6990" id="token-82-23" morph="none" pos="word" start_char="6989">no</TOKEN>
<TOKEN end_char="6993" id="token-82-24" morph="none" pos="word" start_char="6992">to</TOKEN>
<TOKEN end_char="6997" id="token-82-25" morph="none" pos="word" start_char="6995">few</TOKEN>
<TOKEN end_char="7008" id="token-82-26" morph="none" pos="word" start_char="6999">facilities</TOKEN>
<TOKEN end_char="7012" id="token-82-27" morph="none" pos="word" start_char="7010">for</TOKEN>
<TOKEN end_char="7016" id="token-82-28" morph="none" pos="word" start_char="7014">the</TOKEN>
<TOKEN end_char="7024" id="token-82-29" morph="none" pos="word" start_char="7018">elderly</TOKEN>
<TOKEN end_char="7025" id="token-82-30" morph="none" pos="punct" start_char="7025">.</TOKEN>
</SEG>
<SEG end_char="7109" id="segment-83" start_char="7028">
<ORIGINAL_TEXT>This virus is specifically designed to kill the elderly and not harm young people.</ORIGINAL_TEXT>
<TOKEN end_char="7031" id="token-83-0" morph="none" pos="word" start_char="7028">This</TOKEN>
<TOKEN end_char="7037" id="token-83-1" morph="none" pos="word" start_char="7033">virus</TOKEN>
<TOKEN end_char="7040" id="token-83-2" morph="none" pos="word" start_char="7039">is</TOKEN>
<TOKEN end_char="7053" id="token-83-3" morph="none" pos="word" start_char="7042">specifically</TOKEN>
<TOKEN end_char="7062" id="token-83-4" morph="none" pos="word" start_char="7055">designed</TOKEN>
<TOKEN end_char="7065" id="token-83-5" morph="none" pos="word" start_char="7064">to</TOKEN>
<TOKEN end_char="7070" id="token-83-6" morph="none" pos="word" start_char="7067">kill</TOKEN>
<TOKEN end_char="7074" id="token-83-7" morph="none" pos="word" start_char="7072">the</TOKEN>
<TOKEN end_char="7082" id="token-83-8" morph="none" pos="word" start_char="7076">elderly</TOKEN>
<TOKEN end_char="7086" id="token-83-9" morph="none" pos="word" start_char="7084">and</TOKEN>
<TOKEN end_char="7090" id="token-83-10" morph="none" pos="word" start_char="7088">not</TOKEN>
<TOKEN end_char="7095" id="token-83-11" morph="none" pos="word" start_char="7092">harm</TOKEN>
<TOKEN end_char="7101" id="token-83-12" morph="none" pos="word" start_char="7097">young</TOKEN>
<TOKEN end_char="7108" id="token-83-13" morph="none" pos="word" start_char="7103">people</TOKEN>
<TOKEN end_char="7109" id="token-83-14" morph="none" pos="punct" start_char="7109">.</TOKEN>
</SEG>
<SEG end_char="7181" id="segment-84" start_char="7111">
<ORIGINAL_TEXT>An excellent way to genocide the elderly without looking like they did.</ORIGINAL_TEXT>
<TOKEN end_char="7112" id="token-84-0" morph="none" pos="word" start_char="7111">An</TOKEN>
<TOKEN end_char="7122" id="token-84-1" morph="none" pos="word" start_char="7114">excellent</TOKEN>
<TOKEN end_char="7126" id="token-84-2" morph="none" pos="word" start_char="7124">way</TOKEN>
<TOKEN end_char="7129" id="token-84-3" morph="none" pos="word" start_char="7128">to</TOKEN>
<TOKEN end_char="7138" id="token-84-4" morph="none" pos="word" start_char="7131">genocide</TOKEN>
<TOKEN end_char="7142" id="token-84-5" morph="none" pos="word" start_char="7140">the</TOKEN>
<TOKEN end_char="7150" id="token-84-6" morph="none" pos="word" start_char="7144">elderly</TOKEN>
<TOKEN end_char="7158" id="token-84-7" morph="none" pos="word" start_char="7152">without</TOKEN>
<TOKEN end_char="7166" id="token-84-8" morph="none" pos="word" start_char="7160">looking</TOKEN>
<TOKEN end_char="7171" id="token-84-9" morph="none" pos="word" start_char="7168">like</TOKEN>
<TOKEN end_char="7176" id="token-84-10" morph="none" pos="word" start_char="7173">they</TOKEN>
<TOKEN end_char="7180" id="token-84-11" morph="none" pos="word" start_char="7178">did</TOKEN>
<TOKEN end_char="7181" id="token-84-12" morph="none" pos="punct" start_char="7181">.</TOKEN>
</SEG>
<SEG end_char="7337" id="segment-85" start_char="7184">
<ORIGINAL_TEXT>There are always outliers who die from any virus, like health workers forced by the government to work 24/7 without rest or minimal rest for weeks on end.</ORIGINAL_TEXT>
<TOKEN end_char="7188" id="token-85-0" morph="none" pos="word" start_char="7184">There</TOKEN>
<TOKEN end_char="7192" id="token-85-1" morph="none" pos="word" start_char="7190">are</TOKEN>
<TOKEN end_char="7199" id="token-85-2" morph="none" pos="word" start_char="7194">always</TOKEN>
<TOKEN end_char="7208" id="token-85-3" morph="none" pos="word" start_char="7201">outliers</TOKEN>
<TOKEN end_char="7212" id="token-85-4" morph="none" pos="word" start_char="7210">who</TOKEN>
<TOKEN end_char="7216" id="token-85-5" morph="none" pos="word" start_char="7214">die</TOKEN>
<TOKEN end_char="7221" id="token-85-6" morph="none" pos="word" start_char="7218">from</TOKEN>
<TOKEN end_char="7225" id="token-85-7" morph="none" pos="word" start_char="7223">any</TOKEN>
<TOKEN end_char="7231" id="token-85-8" morph="none" pos="word" start_char="7227">virus</TOKEN>
<TOKEN end_char="7232" id="token-85-9" morph="none" pos="punct" start_char="7232">,</TOKEN>
<TOKEN end_char="7237" id="token-85-10" morph="none" pos="word" start_char="7234">like</TOKEN>
<TOKEN end_char="7244" id="token-85-11" morph="none" pos="word" start_char="7239">health</TOKEN>
<TOKEN end_char="7252" id="token-85-12" morph="none" pos="word" start_char="7246">workers</TOKEN>
<TOKEN end_char="7259" id="token-85-13" morph="none" pos="word" start_char="7254">forced</TOKEN>
<TOKEN end_char="7262" id="token-85-14" morph="none" pos="word" start_char="7261">by</TOKEN>
<TOKEN end_char="7266" id="token-85-15" morph="none" pos="word" start_char="7264">the</TOKEN>
<TOKEN end_char="7277" id="token-85-16" morph="none" pos="word" start_char="7268">government</TOKEN>
<TOKEN end_char="7280" id="token-85-17" morph="none" pos="word" start_char="7279">to</TOKEN>
<TOKEN end_char="7285" id="token-85-18" morph="none" pos="word" start_char="7282">work</TOKEN>
<TOKEN end_char="7290" id="token-85-19" morph="none" pos="unknown" start_char="7287">24/7</TOKEN>
<TOKEN end_char="7298" id="token-85-20" morph="none" pos="word" start_char="7292">without</TOKEN>
<TOKEN end_char="7303" id="token-85-21" morph="none" pos="word" start_char="7300">rest</TOKEN>
<TOKEN end_char="7306" id="token-85-22" morph="none" pos="word" start_char="7305">or</TOKEN>
<TOKEN end_char="7314" id="token-85-23" morph="none" pos="word" start_char="7308">minimal</TOKEN>
<TOKEN end_char="7319" id="token-85-24" morph="none" pos="word" start_char="7316">rest</TOKEN>
<TOKEN end_char="7323" id="token-85-25" morph="none" pos="word" start_char="7321">for</TOKEN>
<TOKEN end_char="7329" id="token-85-26" morph="none" pos="word" start_char="7325">weeks</TOKEN>
<TOKEN end_char="7332" id="token-85-27" morph="none" pos="word" start_char="7331">on</TOKEN>
<TOKEN end_char="7336" id="token-85-28" morph="none" pos="word" start_char="7334">end</TOKEN>
<TOKEN end_char="7337" id="token-85-29" morph="none" pos="punct" start_char="7337">.</TOKEN>
</SEG>
<SEG end_char="7434" id="segment-86" start_char="7340">
<ORIGINAL_TEXT>In a socialist/communist country the resource drain from the elderly is reaching crises levels.</ORIGINAL_TEXT>
<TOKEN end_char="7341" id="token-86-0" morph="none" pos="word" start_char="7340">In</TOKEN>
<TOKEN end_char="7343" id="token-86-1" morph="none" pos="word" start_char="7343">a</TOKEN>
<TOKEN end_char="7363" id="token-86-2" morph="none" pos="unknown" start_char="7345">socialist/communist</TOKEN>
<TOKEN end_char="7371" id="token-86-3" morph="none" pos="word" start_char="7365">country</TOKEN>
<TOKEN end_char="7375" id="token-86-4" morph="none" pos="word" start_char="7373">the</TOKEN>
<TOKEN end_char="7384" id="token-86-5" morph="none" pos="word" start_char="7377">resource</TOKEN>
<TOKEN end_char="7390" id="token-86-6" morph="none" pos="word" start_char="7386">drain</TOKEN>
<TOKEN end_char="7395" id="token-86-7" morph="none" pos="word" start_char="7392">from</TOKEN>
<TOKEN end_char="7399" id="token-86-8" morph="none" pos="word" start_char="7397">the</TOKEN>
<TOKEN end_char="7407" id="token-86-9" morph="none" pos="word" start_char="7401">elderly</TOKEN>
<TOKEN end_char="7410" id="token-86-10" morph="none" pos="word" start_char="7409">is</TOKEN>
<TOKEN end_char="7419" id="token-86-11" morph="none" pos="word" start_char="7412">reaching</TOKEN>
<TOKEN end_char="7426" id="token-86-12" morph="none" pos="word" start_char="7421">crises</TOKEN>
<TOKEN end_char="7433" id="token-86-13" morph="none" pos="word" start_char="7428">levels</TOKEN>
<TOKEN end_char="7434" id="token-86-14" morph="none" pos="punct" start_char="7434">.</TOKEN>
</SEG>
<SEG end_char="7509" id="segment-87" start_char="7436">
<ORIGINAL_TEXT>Aside from China, China may see itself as doing good for the entire world.</ORIGINAL_TEXT>
<TOKEN end_char="7440" id="token-87-0" morph="none" pos="word" start_char="7436">Aside</TOKEN>
<TOKEN end_char="7445" id="token-87-1" morph="none" pos="word" start_char="7442">from</TOKEN>
<TOKEN end_char="7451" id="token-87-2" morph="none" pos="word" start_char="7447">China</TOKEN>
<TOKEN end_char="7452" id="token-87-3" morph="none" pos="punct" start_char="7452">,</TOKEN>
<TOKEN end_char="7458" id="token-87-4" morph="none" pos="word" start_char="7454">China</TOKEN>
<TOKEN end_char="7462" id="token-87-5" morph="none" pos="word" start_char="7460">may</TOKEN>
<TOKEN end_char="7466" id="token-87-6" morph="none" pos="word" start_char="7464">see</TOKEN>
<TOKEN end_char="7473" id="token-87-7" morph="none" pos="word" start_char="7468">itself</TOKEN>
<TOKEN end_char="7476" id="token-87-8" morph="none" pos="word" start_char="7475">as</TOKEN>
<TOKEN end_char="7482" id="token-87-9" morph="none" pos="word" start_char="7478">doing</TOKEN>
<TOKEN end_char="7487" id="token-87-10" morph="none" pos="word" start_char="7484">good</TOKEN>
<TOKEN end_char="7491" id="token-87-11" morph="none" pos="word" start_char="7489">for</TOKEN>
<TOKEN end_char="7495" id="token-87-12" morph="none" pos="word" start_char="7493">the</TOKEN>
<TOKEN end_char="7502" id="token-87-13" morph="none" pos="word" start_char="7497">entire</TOKEN>
<TOKEN end_char="7508" id="token-87-14" morph="none" pos="word" start_char="7504">world</TOKEN>
<TOKEN end_char="7509" id="token-87-15" morph="none" pos="punct" start_char="7509">.</TOKEN>
</SEG>
<SEG end_char="7581" id="segment-88" start_char="7511">
<ORIGINAL_TEXT>There are an excess of elderly in every developed country in the world.</ORIGINAL_TEXT>
<TOKEN end_char="7515" id="token-88-0" morph="none" pos="word" start_char="7511">There</TOKEN>
<TOKEN end_char="7519" id="token-88-1" morph="none" pos="word" start_char="7517">are</TOKEN>
<TOKEN end_char="7522" id="token-88-2" morph="none" pos="word" start_char="7521">an</TOKEN>
<TOKEN end_char="7529" id="token-88-3" morph="none" pos="word" start_char="7524">excess</TOKEN>
<TOKEN end_char="7532" id="token-88-4" morph="none" pos="word" start_char="7531">of</TOKEN>
<TOKEN end_char="7540" id="token-88-5" morph="none" pos="word" start_char="7534">elderly</TOKEN>
<TOKEN end_char="7543" id="token-88-6" morph="none" pos="word" start_char="7542">in</TOKEN>
<TOKEN end_char="7549" id="token-88-7" morph="none" pos="word" start_char="7545">every</TOKEN>
<TOKEN end_char="7559" id="token-88-8" morph="none" pos="word" start_char="7551">developed</TOKEN>
<TOKEN end_char="7567" id="token-88-9" morph="none" pos="word" start_char="7561">country</TOKEN>
<TOKEN end_char="7570" id="token-88-10" morph="none" pos="word" start_char="7569">in</TOKEN>
<TOKEN end_char="7574" id="token-88-11" morph="none" pos="word" start_char="7572">the</TOKEN>
<TOKEN end_char="7580" id="token-88-12" morph="none" pos="word" start_char="7576">world</TOKEN>
<TOKEN end_char="7581" id="token-88-13" morph="none" pos="punct" start_char="7581">.</TOKEN>
</SEG>
<SEG end_char="7705" id="segment-89" start_char="7584">
<ORIGINAL_TEXT>To deny or dismiss it being a designer virus to kill the excess elderly population is like sticking your head in the sand.</ORIGINAL_TEXT>
<TOKEN end_char="7585" id="token-89-0" morph="none" pos="word" start_char="7584">To</TOKEN>
<TOKEN end_char="7590" id="token-89-1" morph="none" pos="word" start_char="7587">deny</TOKEN>
<TOKEN end_char="7593" id="token-89-2" morph="none" pos="word" start_char="7592">or</TOKEN>
<TOKEN end_char="7601" id="token-89-3" morph="none" pos="word" start_char="7595">dismiss</TOKEN>
<TOKEN end_char="7604" id="token-89-4" morph="none" pos="word" start_char="7603">it</TOKEN>
<TOKEN end_char="7610" id="token-89-5" morph="none" pos="word" start_char="7606">being</TOKEN>
<TOKEN end_char="7612" id="token-89-6" morph="none" pos="word" start_char="7612">a</TOKEN>
<TOKEN end_char="7621" id="token-89-7" morph="none" pos="word" start_char="7614">designer</TOKEN>
<TOKEN end_char="7627" id="token-89-8" morph="none" pos="word" start_char="7623">virus</TOKEN>
<TOKEN end_char="7630" id="token-89-9" morph="none" pos="word" start_char="7629">to</TOKEN>
<TOKEN end_char="7635" id="token-89-10" morph="none" pos="word" start_char="7632">kill</TOKEN>
<TOKEN end_char="7639" id="token-89-11" morph="none" pos="word" start_char="7637">the</TOKEN>
<TOKEN end_char="7646" id="token-89-12" morph="none" pos="word" start_char="7641">excess</TOKEN>
<TOKEN end_char="7654" id="token-89-13" morph="none" pos="word" start_char="7648">elderly</TOKEN>
<TOKEN end_char="7665" id="token-89-14" morph="none" pos="word" start_char="7656">population</TOKEN>
<TOKEN end_char="7668" id="token-89-15" morph="none" pos="word" start_char="7667">is</TOKEN>
<TOKEN end_char="7673" id="token-89-16" morph="none" pos="word" start_char="7670">like</TOKEN>
<TOKEN end_char="7682" id="token-89-17" morph="none" pos="word" start_char="7675">sticking</TOKEN>
<TOKEN end_char="7687" id="token-89-18" morph="none" pos="word" start_char="7684">your</TOKEN>
<TOKEN end_char="7692" id="token-89-19" morph="none" pos="word" start_char="7689">head</TOKEN>
<TOKEN end_char="7695" id="token-89-20" morph="none" pos="word" start_char="7694">in</TOKEN>
<TOKEN end_char="7699" id="token-89-21" morph="none" pos="word" start_char="7697">the</TOKEN>
<TOKEN end_char="7704" id="token-89-22" morph="none" pos="word" start_char="7701">sand</TOKEN>
<TOKEN end_char="7705" id="token-89-23" morph="none" pos="punct" start_char="7705">.</TOKEN>
</SEG>
<SEG end_char="7893" id="segment-90" start_char="7708">
<ORIGINAL_TEXT>I have seen several people doing that and wonder if they are Chinese paid operatives who are doing their best to make this highly logical conclusion sound like a weird conspiracy theory.</ORIGINAL_TEXT>
<TOKEN end_char="7708" id="token-90-0" morph="none" pos="word" start_char="7708">I</TOKEN>
<TOKEN end_char="7713" id="token-90-1" morph="none" pos="word" start_char="7710">have</TOKEN>
<TOKEN end_char="7718" id="token-90-2" morph="none" pos="word" start_char="7715">seen</TOKEN>
<TOKEN end_char="7726" id="token-90-3" morph="none" pos="word" start_char="7720">several</TOKEN>
<TOKEN end_char="7733" id="token-90-4" morph="none" pos="word" start_char="7728">people</TOKEN>
<TOKEN end_char="7739" id="token-90-5" morph="none" pos="word" start_char="7735">doing</TOKEN>
<TOKEN end_char="7744" id="token-90-6" morph="none" pos="word" start_char="7741">that</TOKEN>
<TOKEN end_char="7748" id="token-90-7" morph="none" pos="word" start_char="7746">and</TOKEN>
<TOKEN end_char="7755" id="token-90-8" morph="none" pos="word" start_char="7750">wonder</TOKEN>
<TOKEN end_char="7758" id="token-90-9" morph="none" pos="word" start_char="7757">if</TOKEN>
<TOKEN end_char="7763" id="token-90-10" morph="none" pos="word" start_char="7760">they</TOKEN>
<TOKEN end_char="7767" id="token-90-11" morph="none" pos="word" start_char="7765">are</TOKEN>
<TOKEN end_char="7775" id="token-90-12" morph="none" pos="word" start_char="7769">Chinese</TOKEN>
<TOKEN end_char="7780" id="token-90-13" morph="none" pos="word" start_char="7777">paid</TOKEN>
<TOKEN end_char="7791" id="token-90-14" morph="none" pos="word" start_char="7782">operatives</TOKEN>
<TOKEN end_char="7795" id="token-90-15" morph="none" pos="word" start_char="7793">who</TOKEN>
<TOKEN end_char="7799" id="token-90-16" morph="none" pos="word" start_char="7797">are</TOKEN>
<TOKEN end_char="7805" id="token-90-17" morph="none" pos="word" start_char="7801">doing</TOKEN>
<TOKEN end_char="7811" id="token-90-18" morph="none" pos="word" start_char="7807">their</TOKEN>
<TOKEN end_char="7816" id="token-90-19" morph="none" pos="word" start_char="7813">best</TOKEN>
<TOKEN end_char="7819" id="token-90-20" morph="none" pos="word" start_char="7818">to</TOKEN>
<TOKEN end_char="7824" id="token-90-21" morph="none" pos="word" start_char="7821">make</TOKEN>
<TOKEN end_char="7829" id="token-90-22" morph="none" pos="word" start_char="7826">this</TOKEN>
<TOKEN end_char="7836" id="token-90-23" morph="none" pos="word" start_char="7831">highly</TOKEN>
<TOKEN end_char="7844" id="token-90-24" morph="none" pos="word" start_char="7838">logical</TOKEN>
<TOKEN end_char="7855" id="token-90-25" morph="none" pos="word" start_char="7846">conclusion</TOKEN>
<TOKEN end_char="7861" id="token-90-26" morph="none" pos="word" start_char="7857">sound</TOKEN>
<TOKEN end_char="7866" id="token-90-27" morph="none" pos="word" start_char="7863">like</TOKEN>
<TOKEN end_char="7868" id="token-90-28" morph="none" pos="word" start_char="7868">a</TOKEN>
<TOKEN end_char="7874" id="token-90-29" morph="none" pos="word" start_char="7870">weird</TOKEN>
<TOKEN end_char="7885" id="token-90-30" morph="none" pos="word" start_char="7876">conspiracy</TOKEN>
<TOKEN end_char="7892" id="token-90-31" morph="none" pos="word" start_char="7887">theory</TOKEN>
<TOKEN end_char="7893" id="token-90-32" morph="none" pos="punct" start_char="7893">.</TOKEN>
</SEG>
<SEG end_char="8051" id="segment-91" start_char="7896">
<ORIGINAL_TEXT>Someone with 2 masters degrees, and a very steady person asked me the other day if I thought the Chinese designed this and it got loose from their facility.</ORIGINAL_TEXT>
<TOKEN end_char="7902" id="token-91-0" morph="none" pos="word" start_char="7896">Someone</TOKEN>
<TOKEN end_char="7907" id="token-91-1" morph="none" pos="word" start_char="7904">with</TOKEN>
<TOKEN end_char="7909" id="token-91-2" morph="none" pos="word" start_char="7909">2</TOKEN>
<TOKEN end_char="7917" id="token-91-3" morph="none" pos="word" start_char="7911">masters</TOKEN>
<TOKEN end_char="7925" id="token-91-4" morph="none" pos="word" start_char="7919">degrees</TOKEN>
<TOKEN end_char="7926" id="token-91-5" morph="none" pos="punct" start_char="7926">,</TOKEN>
<TOKEN end_char="7930" id="token-91-6" morph="none" pos="word" start_char="7928">and</TOKEN>
<TOKEN end_char="7932" id="token-91-7" morph="none" pos="word" start_char="7932">a</TOKEN>
<TOKEN end_char="7937" id="token-91-8" morph="none" pos="word" start_char="7934">very</TOKEN>
<TOKEN end_char="7944" id="token-91-9" morph="none" pos="word" start_char="7939">steady</TOKEN>
<TOKEN end_char="7951" id="token-91-10" morph="none" pos="word" start_char="7946">person</TOKEN>
<TOKEN end_char="7957" id="token-91-11" morph="none" pos="word" start_char="7953">asked</TOKEN>
<TOKEN end_char="7960" id="token-91-12" morph="none" pos="word" start_char="7959">me</TOKEN>
<TOKEN end_char="7964" id="token-91-13" morph="none" pos="word" start_char="7962">the</TOKEN>
<TOKEN end_char="7970" id="token-91-14" morph="none" pos="word" start_char="7966">other</TOKEN>
<TOKEN end_char="7974" id="token-91-15" morph="none" pos="word" start_char="7972">day</TOKEN>
<TOKEN end_char="7977" id="token-91-16" morph="none" pos="word" start_char="7976">if</TOKEN>
<TOKEN end_char="7979" id="token-91-17" morph="none" pos="word" start_char="7979">I</TOKEN>
<TOKEN end_char="7987" id="token-91-18" morph="none" pos="word" start_char="7981">thought</TOKEN>
<TOKEN end_char="7991" id="token-91-19" morph="none" pos="word" start_char="7989">the</TOKEN>
<TOKEN end_char="7999" id="token-91-20" morph="none" pos="word" start_char="7993">Chinese</TOKEN>
<TOKEN end_char="8008" id="token-91-21" morph="none" pos="word" start_char="8001">designed</TOKEN>
<TOKEN end_char="8013" id="token-91-22" morph="none" pos="word" start_char="8010">this</TOKEN>
<TOKEN end_char="8017" id="token-91-23" morph="none" pos="word" start_char="8015">and</TOKEN>
<TOKEN end_char="8020" id="token-91-24" morph="none" pos="word" start_char="8019">it</TOKEN>
<TOKEN end_char="8024" id="token-91-25" morph="none" pos="word" start_char="8022">got</TOKEN>
<TOKEN end_char="8030" id="token-91-26" morph="none" pos="word" start_char="8026">loose</TOKEN>
<TOKEN end_char="8035" id="token-91-27" morph="none" pos="word" start_char="8032">from</TOKEN>
<TOKEN end_char="8041" id="token-91-28" morph="none" pos="word" start_char="8037">their</TOKEN>
<TOKEN end_char="8050" id="token-91-29" morph="none" pos="word" start_char="8043">facility</TOKEN>
<TOKEN end_char="8051" id="token-91-30" morph="none" pos="punct" start_char="8051">.</TOKEN>
</SEG>
<SEG end_char="8105" id="segment-92" start_char="8053">
<ORIGINAL_TEXT>I said a cautious yes, and the person said, I do too.</ORIGINAL_TEXT>
<TOKEN end_char="8053" id="token-92-0" morph="none" pos="word" start_char="8053">I</TOKEN>
<TOKEN end_char="8058" id="token-92-1" morph="none" pos="word" start_char="8055">said</TOKEN>
<TOKEN end_char="8060" id="token-92-2" morph="none" pos="word" start_char="8060">a</TOKEN>
<TOKEN end_char="8069" id="token-92-3" morph="none" pos="word" start_char="8062">cautious</TOKEN>
<TOKEN end_char="8073" id="token-92-4" morph="none" pos="word" start_char="8071">yes</TOKEN>
<TOKEN end_char="8074" id="token-92-5" morph="none" pos="punct" start_char="8074">,</TOKEN>
<TOKEN end_char="8078" id="token-92-6" morph="none" pos="word" start_char="8076">and</TOKEN>
<TOKEN end_char="8082" id="token-92-7" morph="none" pos="word" start_char="8080">the</TOKEN>
<TOKEN end_char="8089" id="token-92-8" morph="none" pos="word" start_char="8084">person</TOKEN>
<TOKEN end_char="8094" id="token-92-9" morph="none" pos="word" start_char="8091">said</TOKEN>
<TOKEN end_char="8095" id="token-92-10" morph="none" pos="punct" start_char="8095">,</TOKEN>
<TOKEN end_char="8097" id="token-92-11" morph="none" pos="word" start_char="8097">I</TOKEN>
<TOKEN end_char="8100" id="token-92-12" morph="none" pos="word" start_char="8099">do</TOKEN>
<TOKEN end_char="8104" id="token-92-13" morph="none" pos="word" start_char="8102">too</TOKEN>
<TOKEN end_char="8105" id="token-92-14" morph="none" pos="punct" start_char="8105">.</TOKEN>
</SEG>
<SEG end_char="8211" id="segment-93" start_char="8107">
<ORIGINAL_TEXT>This shows that even people who aren't into "the new" the way ATS people are have seen the obvious truth.</ORIGINAL_TEXT>
<TOKEN end_char="8110" id="token-93-0" morph="none" pos="word" start_char="8107">This</TOKEN>
<TOKEN end_char="8116" id="token-93-1" morph="none" pos="word" start_char="8112">shows</TOKEN>
<TOKEN end_char="8121" id="token-93-2" morph="none" pos="word" start_char="8118">that</TOKEN>
<TOKEN end_char="8126" id="token-93-3" morph="none" pos="word" start_char="8123">even</TOKEN>
<TOKEN end_char="8133" id="token-93-4" morph="none" pos="word" start_char="8128">people</TOKEN>
<TOKEN end_char="8137" id="token-93-5" morph="none" pos="word" start_char="8135">who</TOKEN>
<TOKEN end_char="8144" id="token-93-6" morph="none" pos="word" start_char="8139">aren't</TOKEN>
<TOKEN end_char="8149" id="token-93-7" morph="none" pos="word" start_char="8146">into</TOKEN>
<TOKEN end_char="8151" id="token-93-8" morph="none" pos="punct" start_char="8151">"</TOKEN>
<TOKEN end_char="8154" id="token-93-9" morph="none" pos="word" start_char="8152">the</TOKEN>
<TOKEN end_char="8158" id="token-93-10" morph="none" pos="word" start_char="8156">new</TOKEN>
<TOKEN end_char="8159" id="token-93-11" morph="none" pos="punct" start_char="8159">"</TOKEN>
<TOKEN end_char="8163" id="token-93-12" morph="none" pos="word" start_char="8161">the</TOKEN>
<TOKEN end_char="8167" id="token-93-13" morph="none" pos="word" start_char="8165">way</TOKEN>
<TOKEN end_char="8171" id="token-93-14" morph="none" pos="word" start_char="8169">ATS</TOKEN>
<TOKEN end_char="8178" id="token-93-15" morph="none" pos="word" start_char="8173">people</TOKEN>
<TOKEN end_char="8182" id="token-93-16" morph="none" pos="word" start_char="8180">are</TOKEN>
<TOKEN end_char="8187" id="token-93-17" morph="none" pos="word" start_char="8184">have</TOKEN>
<TOKEN end_char="8192" id="token-93-18" morph="none" pos="word" start_char="8189">seen</TOKEN>
<TOKEN end_char="8196" id="token-93-19" morph="none" pos="word" start_char="8194">the</TOKEN>
<TOKEN end_char="8204" id="token-93-20" morph="none" pos="word" start_char="8198">obvious</TOKEN>
<TOKEN end_char="8210" id="token-93-21" morph="none" pos="word" start_char="8206">truth</TOKEN>
<TOKEN end_char="8211" id="token-93-22" morph="none" pos="punct" start_char="8211">.</TOKEN>
</SEG>
<SEG end_char="8259" id="segment-94" start_char="8214">
<ORIGINAL_TEXT>edit on 3/13/20 by The2Billies because: format</ORIGINAL_TEXT>
<TOKEN end_char="8217" id="token-94-0" morph="none" pos="word" start_char="8214">edit</TOKEN>
<TOKEN end_char="8220" id="token-94-1" morph="none" pos="word" start_char="8219">on</TOKEN>
<TOKEN end_char="8228" id="token-94-2" morph="none" pos="unknown" start_char="8222">3/13/20</TOKEN>
<TOKEN end_char="8231" id="token-94-3" morph="none" pos="word" start_char="8230">by</TOKEN>
<TOKEN end_char="8243" id="token-94-4" morph="none" pos="word" start_char="8233">The2Billies</TOKEN>
<TOKEN end_char="8251" id="token-94-5" morph="none" pos="word" start_char="8245">because</TOKEN>
<TOKEN end_char="8252" id="token-94-6" morph="none" pos="punct" start_char="8252">:</TOKEN>
<TOKEN end_char="8259" id="token-94-7" morph="none" pos="word" start_char="8254">format</TOKEN>
</SEG>
<SEG end_char="8282" id="segment-95" start_char="8263">
<ORIGINAL_TEXT>"What Are The Odds?"</ORIGINAL_TEXT>
<TOKEN end_char="8263" id="token-95-0" morph="none" pos="punct" start_char="8263">"</TOKEN>
<TOKEN end_char="8267" id="token-95-1" morph="none" pos="word" start_char="8264">What</TOKEN>
<TOKEN end_char="8271" id="token-95-2" morph="none" pos="word" start_char="8269">Are</TOKEN>
<TOKEN end_char="8275" id="token-95-3" morph="none" pos="word" start_char="8273">The</TOKEN>
<TOKEN end_char="8280" id="token-95-4" morph="none" pos="word" start_char="8277">Odds</TOKEN>
<TOKEN end_char="8282" id="token-95-5" morph="none" pos="punct" start_char="8281">?"</TOKEN>
</SEG>
<SEG end_char="8371" id="segment-96" start_char="8284">
<ORIGINAL_TEXT>- A Timeline Of Facts Linking Covid-19, HIV, Wuhan's Secret Bio-Lab www.zerohedge.com...</ORIGINAL_TEXT>
<TOKEN end_char="8284" id="token-96-0" morph="none" pos="punct" start_char="8284">-</TOKEN>
<TOKEN end_char="8286" id="token-96-1" morph="none" pos="word" start_char="8286">A</TOKEN>
<TOKEN end_char="8295" id="token-96-2" morph="none" pos="word" start_char="8288">Timeline</TOKEN>
<TOKEN end_char="8298" id="token-96-3" morph="none" pos="word" start_char="8297">Of</TOKEN>
<TOKEN end_char="8304" id="token-96-4" morph="none" pos="word" start_char="8300">Facts</TOKEN>
<TOKEN end_char="8312" id="token-96-5" morph="none" pos="word" start_char="8306">Linking</TOKEN>
<TOKEN end_char="8321" id="token-96-6" morph="none" pos="unknown" start_char="8314">Covid-19</TOKEN>
<TOKEN end_char="8322" id="token-96-7" morph="none" pos="punct" start_char="8322">,</TOKEN>
<TOKEN end_char="8326" id="token-96-8" morph="none" pos="word" start_char="8324">HIV</TOKEN>
<TOKEN end_char="8327" id="token-96-9" morph="none" pos="punct" start_char="8327">,</TOKEN>
<TOKEN end_char="8335" id="token-96-10" morph="none" pos="word" start_char="8329">Wuhan's</TOKEN>
<TOKEN end_char="8342" id="token-96-11" morph="none" pos="word" start_char="8337">Secret</TOKEN>
<TOKEN end_char="8350" id="token-96-12" morph="none" pos="unknown" start_char="8344">Bio-Lab</TOKEN>
<TOKEN end_char="8371" id="token-96-13" morph="none" pos="url" start_char="8352">www.zerohedge.com...</TOKEN>
</SEG>
<SEG end_char="8430" id="segment-97" start_char="8374">
<ORIGINAL_TEXT>So theres original SARS, which is a type of coronavirus.</ORIGINAL_TEXT>
<TOKEN end_char="8375" id="token-97-0" morph="none" pos="word" start_char="8374">So</TOKEN>
<TOKEN end_char="8383" id="token-97-1" morph="none" pos="word" start_char="8377">theres</TOKEN>
<TOKEN end_char="8392" id="token-97-2" morph="none" pos="word" start_char="8385">original</TOKEN>
<TOKEN end_char="8397" id="token-97-3" morph="none" pos="word" start_char="8394">SARS</TOKEN>
<TOKEN end_char="8398" id="token-97-4" morph="none" pos="punct" start_char="8398">,</TOKEN>
<TOKEN end_char="8404" id="token-97-5" morph="none" pos="word" start_char="8400">which</TOKEN>
<TOKEN end_char="8407" id="token-97-6" morph="none" pos="word" start_char="8406">is</TOKEN>
<TOKEN end_char="8409" id="token-97-7" morph="none" pos="word" start_char="8409">a</TOKEN>
<TOKEN end_char="8414" id="token-97-8" morph="none" pos="word" start_char="8411">type</TOKEN>
<TOKEN end_char="8417" id="token-97-9" morph="none" pos="word" start_char="8416">of</TOKEN>
<TOKEN end_char="8429" id="token-97-10" morph="none" pos="word" start_char="8419">coronavirus</TOKEN>
<TOKEN end_char="8430" id="token-97-11" morph="none" pos="punct" start_char="8430">.</TOKEN>
</SEG>
<SEG end_char="8485" id="segment-98" start_char="8432">
<ORIGINAL_TEXT>SARS infects cells through the ACE2 receptor in hosts.</ORIGINAL_TEXT>
<TOKEN end_char="8435" id="token-98-0" morph="none" pos="word" start_char="8432">SARS</TOKEN>
<TOKEN end_char="8443" id="token-98-1" morph="none" pos="word" start_char="8437">infects</TOKEN>
<TOKEN end_char="8449" id="token-98-2" morph="none" pos="word" start_char="8445">cells</TOKEN>
<TOKEN end_char="8457" id="token-98-3" morph="none" pos="word" start_char="8451">through</TOKEN>
<TOKEN end_char="8461" id="token-98-4" morph="none" pos="word" start_char="8459">the</TOKEN>
<TOKEN end_char="8466" id="token-98-5" morph="none" pos="word" start_char="8463">ACE2</TOKEN>
<TOKEN end_char="8475" id="token-98-6" morph="none" pos="word" start_char="8468">receptor</TOKEN>
<TOKEN end_char="8478" id="token-98-7" morph="none" pos="word" start_char="8477">in</TOKEN>
<TOKEN end_char="8484" id="token-98-8" morph="none" pos="word" start_char="8480">hosts</TOKEN>
<TOKEN end_char="8485" id="token-98-9" morph="none" pos="punct" start_char="8485">.</TOKEN>
</SEG>
<SEG end_char="8554" id="segment-99" start_char="8487">
<ORIGINAL_TEXT>The S spike protein plays a key role in how the virus infects cells.</ORIGINAL_TEXT>
<TOKEN end_char="8489" id="token-99-0" morph="none" pos="word" start_char="8487">The</TOKEN>
<TOKEN end_char="8491" id="token-99-1" morph="none" pos="word" start_char="8491">S</TOKEN>
<TOKEN end_char="8497" id="token-99-2" morph="none" pos="word" start_char="8493">spike</TOKEN>
<TOKEN end_char="8505" id="token-99-3" morph="none" pos="word" start_char="8499">protein</TOKEN>
<TOKEN end_char="8511" id="token-99-4" morph="none" pos="word" start_char="8507">plays</TOKEN>
<TOKEN end_char="8513" id="token-99-5" morph="none" pos="word" start_char="8513">a</TOKEN>
<TOKEN end_char="8517" id="token-99-6" morph="none" pos="word" start_char="8515">key</TOKEN>
<TOKEN end_char="8522" id="token-99-7" morph="none" pos="word" start_char="8519">role</TOKEN>
<TOKEN end_char="8525" id="token-99-8" morph="none" pos="word" start_char="8524">in</TOKEN>
<TOKEN end_char="8529" id="token-99-9" morph="none" pos="word" start_char="8527">how</TOKEN>
<TOKEN end_char="8533" id="token-99-10" morph="none" pos="word" start_char="8531">the</TOKEN>
<TOKEN end_char="8539" id="token-99-11" morph="none" pos="word" start_char="8535">virus</TOKEN>
<TOKEN end_char="8547" id="token-99-12" morph="none" pos="word" start_char="8541">infects</TOKEN>
<TOKEN end_char="8553" id="token-99-13" morph="none" pos="word" start_char="8549">cells</TOKEN>
<TOKEN end_char="8554" id="token-99-14" morph="none" pos="punct" start_char="8554">.</TOKEN>
</SEG>
<SEG end_char="8645" id="segment-100" start_char="8556">
<ORIGINAL_TEXT>Each of the little spikes that surround the coronavirus is a spike protein (or S protein).</ORIGINAL_TEXT>
<TOKEN end_char="8559" id="token-100-0" morph="none" pos="word" start_char="8556">Each</TOKEN>
<TOKEN end_char="8562" id="token-100-1" morph="none" pos="word" start_char="8561">of</TOKEN>
<TOKEN end_char="8566" id="token-100-2" morph="none" pos="word" start_char="8564">the</TOKEN>
<TOKEN end_char="8573" id="token-100-3" morph="none" pos="word" start_char="8568">little</TOKEN>
<TOKEN end_char="8580" id="token-100-4" morph="none" pos="word" start_char="8575">spikes</TOKEN>
<TOKEN end_char="8585" id="token-100-5" morph="none" pos="word" start_char="8582">that</TOKEN>
<TOKEN end_char="8594" id="token-100-6" morph="none" pos="word" start_char="8587">surround</TOKEN>
<TOKEN end_char="8598" id="token-100-7" morph="none" pos="word" start_char="8596">the</TOKEN>
<TOKEN end_char="8610" id="token-100-8" morph="none" pos="word" start_char="8600">coronavirus</TOKEN>
<TOKEN end_char="8613" id="token-100-9" morph="none" pos="word" start_char="8612">is</TOKEN>
<TOKEN end_char="8615" id="token-100-10" morph="none" pos="word" start_char="8615">a</TOKEN>
<TOKEN end_char="8621" id="token-100-11" morph="none" pos="word" start_char="8617">spike</TOKEN>
<TOKEN end_char="8629" id="token-100-12" morph="none" pos="word" start_char="8623">protein</TOKEN>
<TOKEN end_char="8631" id="token-100-13" morph="none" pos="punct" start_char="8631">(</TOKEN>
<TOKEN end_char="8633" id="token-100-14" morph="none" pos="word" start_char="8632">or</TOKEN>
<TOKEN end_char="8635" id="token-100-15" morph="none" pos="word" start_char="8635">S</TOKEN>
<TOKEN end_char="8643" id="token-100-16" morph="none" pos="word" start_char="8637">protein</TOKEN>
<TOKEN end_char="8645" id="token-100-17" morph="none" pos="punct" start_char="8644">).</TOKEN>
</SEG>
<SEG end_char="8721" id="segment-101" start_char="8647">
<ORIGINAL_TEXT>Thats what gives the coronavirus its name - its "crown" of these spikes.</ORIGINAL_TEXT>
<TOKEN end_char="8652" id="token-101-0" morph="none" pos="word" start_char="8647">Thats</TOKEN>
<TOKEN end_char="8657" id="token-101-1" morph="none" pos="word" start_char="8654">what</TOKEN>
<TOKEN end_char="8663" id="token-101-2" morph="none" pos="word" start_char="8659">gives</TOKEN>
<TOKEN end_char="8667" id="token-101-3" morph="none" pos="word" start_char="8665">the</TOKEN>
<TOKEN end_char="8679" id="token-101-4" morph="none" pos="word" start_char="8669">coronavirus</TOKEN>
<TOKEN end_char="8684" id="token-101-5" morph="none" pos="word" start_char="8681">its</TOKEN>
<TOKEN end_char="8689" id="token-101-6" morph="none" pos="word" start_char="8686">name</TOKEN>
<TOKEN end_char="8691" id="token-101-7" morph="none" pos="punct" start_char="8691">-</TOKEN>
<TOKEN end_char="8696" id="token-101-8" morph="none" pos="word" start_char="8693">its</TOKEN>
<TOKEN end_char="8698" id="token-101-9" morph="none" pos="punct" start_char="8698">"</TOKEN>
<TOKEN end_char="8703" id="token-101-10" morph="none" pos="word" start_char="8699">crown</TOKEN>
<TOKEN end_char="8704" id="token-101-11" morph="none" pos="punct" start_char="8704">"</TOKEN>
<TOKEN end_char="8707" id="token-101-12" morph="none" pos="word" start_char="8706">of</TOKEN>
<TOKEN end_char="8713" id="token-101-13" morph="none" pos="word" start_char="8709">these</TOKEN>
<TOKEN end_char="8720" id="token-101-14" morph="none" pos="word" start_char="8715">spikes</TOKEN>
<TOKEN end_char="8721" id="token-101-15" morph="none" pos="punct" start_char="8721">.</TOKEN>
</SEG>
<SEG end_char="8806" id="segment-102" start_char="8724">
<ORIGINAL_TEXT>After the first SARS outbreak, there was a "land rush" to find other coronaviruses.</ORIGINAL_TEXT>
<TOKEN end_char="8728" id="token-102-0" morph="none" pos="word" start_char="8724">After</TOKEN>
<TOKEN end_char="8732" id="token-102-1" morph="none" pos="word" start_char="8730">the</TOKEN>
<TOKEN end_char="8738" id="token-102-2" morph="none" pos="word" start_char="8734">first</TOKEN>
<TOKEN end_char="8743" id="token-102-3" morph="none" pos="word" start_char="8740">SARS</TOKEN>
<TOKEN end_char="8752" id="token-102-4" morph="none" pos="word" start_char="8745">outbreak</TOKEN>
<TOKEN end_char="8753" id="token-102-5" morph="none" pos="punct" start_char="8753">,</TOKEN>
<TOKEN end_char="8759" id="token-102-6" morph="none" pos="word" start_char="8755">there</TOKEN>
<TOKEN end_char="8763" id="token-102-7" morph="none" pos="word" start_char="8761">was</TOKEN>
<TOKEN end_char="8765" id="token-102-8" morph="none" pos="word" start_char="8765">a</TOKEN>
<TOKEN end_char="8767" id="token-102-9" morph="none" pos="punct" start_char="8767">"</TOKEN>
<TOKEN end_char="8771" id="token-102-10" morph="none" pos="word" start_char="8768">land</TOKEN>
<TOKEN end_char="8776" id="token-102-11" morph="none" pos="word" start_char="8773">rush</TOKEN>
<TOKEN end_char="8777" id="token-102-12" morph="none" pos="punct" start_char="8777">"</TOKEN>
<TOKEN end_char="8780" id="token-102-13" morph="none" pos="word" start_char="8779">to</TOKEN>
<TOKEN end_char="8785" id="token-102-14" morph="none" pos="word" start_char="8782">find</TOKEN>
<TOKEN end_char="8791" id="token-102-15" morph="none" pos="word" start_char="8787">other</TOKEN>
<TOKEN end_char="8805" id="token-102-16" morph="none" pos="word" start_char="8793">coronaviruses</TOKEN>
<TOKEN end_char="8806" id="token-102-17" morph="none" pos="punct" start_char="8806">.</TOKEN>
</SEG>
<SEG end_char="8948" id="segment-103" start_char="8808">
<ORIGINAL_TEXT>A collection of SARS-*like* coronaviruses was isolated in several horseshoe bat species over 10 years ago, called SARS-like CoVs, or SL-CoVs.</ORIGINAL_TEXT>
<TOKEN end_char="8808" id="token-103-0" morph="none" pos="word" start_char="8808">A</TOKEN>
<TOKEN end_char="8819" id="token-103-1" morph="none" pos="word" start_char="8810">collection</TOKEN>
<TOKEN end_char="8822" id="token-103-2" morph="none" pos="word" start_char="8821">of</TOKEN>
<TOKEN end_char="8833" id="token-103-3" morph="none" pos="unknown" start_char="8824">SARS-*like</TOKEN>
<TOKEN end_char="8834" id="token-103-4" morph="none" pos="punct" start_char="8834">*</TOKEN>
<TOKEN end_char="8848" id="token-103-5" morph="none" pos="word" start_char="8836">coronaviruses</TOKEN>
<TOKEN end_char="8852" id="token-103-6" morph="none" pos="word" start_char="8850">was</TOKEN>
<TOKEN end_char="8861" id="token-103-7" morph="none" pos="word" start_char="8854">isolated</TOKEN>
<TOKEN end_char="8864" id="token-103-8" morph="none" pos="word" start_char="8863">in</TOKEN>
<TOKEN end_char="8872" id="token-103-9" morph="none" pos="word" start_char="8866">several</TOKEN>
<TOKEN end_char="8882" id="token-103-10" morph="none" pos="word" start_char="8874">horseshoe</TOKEN>
<TOKEN end_char="8886" id="token-103-11" morph="none" pos="word" start_char="8884">bat</TOKEN>
<TOKEN end_char="8894" id="token-103-12" morph="none" pos="word" start_char="8888">species</TOKEN>
<TOKEN end_char="8899" id="token-103-13" morph="none" pos="word" start_char="8896">over</TOKEN>
<TOKEN end_char="8902" id="token-103-14" morph="none" pos="word" start_char="8901">10</TOKEN>
<TOKEN end_char="8908" id="token-103-15" morph="none" pos="word" start_char="8904">years</TOKEN>
<TOKEN end_char="8912" id="token-103-16" morph="none" pos="word" start_char="8910">ago</TOKEN>
<TOKEN end_char="8913" id="token-103-17" morph="none" pos="punct" start_char="8913">,</TOKEN>
<TOKEN end_char="8920" id="token-103-18" morph="none" pos="word" start_char="8915">called</TOKEN>
<TOKEN end_char="8930" id="token-103-19" morph="none" pos="unknown" start_char="8922">SARS-like</TOKEN>
<TOKEN end_char="8935" id="token-103-20" morph="none" pos="word" start_char="8932">CoVs</TOKEN>
<TOKEN end_char="8936" id="token-103-21" morph="none" pos="punct" start_char="8936">,</TOKEN>
<TOKEN end_char="8939" id="token-103-22" morph="none" pos="word" start_char="8938">or</TOKEN>
<TOKEN end_char="8947" id="token-103-23" morph="none" pos="unknown" start_char="8941">SL-CoVs</TOKEN>
<TOKEN end_char="8948" id="token-103-24" morph="none" pos="punct" start_char="8948">.</TOKEN>
</SEG>
<SEG end_char="9001" id="segment-104" start_char="8950">
<ORIGINAL_TEXT>Not SARS exactly, but coronaviruses similar to SARS.</ORIGINAL_TEXT>
<TOKEN end_char="8952" id="token-104-0" morph="none" pos="word" start_char="8950">Not</TOKEN>
<TOKEN end_char="8957" id="token-104-1" morph="none" pos="word" start_char="8954">SARS</TOKEN>
<TOKEN end_char="8965" id="token-104-2" morph="none" pos="word" start_char="8959">exactly</TOKEN>
<TOKEN end_char="8966" id="token-104-3" morph="none" pos="punct" start_char="8966">,</TOKEN>
<TOKEN end_char="8970" id="token-104-4" morph="none" pos="word" start_char="8968">but</TOKEN>
<TOKEN end_char="8984" id="token-104-5" morph="none" pos="word" start_char="8972">coronaviruses</TOKEN>
<TOKEN end_char="8992" id="token-104-6" morph="none" pos="word" start_char="8986">similar</TOKEN>
<TOKEN end_char="8995" id="token-104-7" morph="none" pos="word" start_char="8994">to</TOKEN>
<TOKEN end_char="9000" id="token-104-8" morph="none" pos="word" start_char="8997">SARS</TOKEN>
<TOKEN end_char="9001" id="token-104-9" morph="none" pos="punct" start_char="9001">.</TOKEN>
</SEG>
<SEG end_char="9159" id="segment-105" start_char="9003">
<ORIGINAL_TEXT>In 2007, a team of researchers based in Wuhan, in conjunction with an Australian laboratory, conducted a study with SARS, a SARS-like coronavirus, and HIV-1.</ORIGINAL_TEXT>
<TOKEN end_char="9004" id="token-105-0" morph="none" pos="word" start_char="9003">In</TOKEN>
<TOKEN end_char="9009" id="token-105-1" morph="none" pos="word" start_char="9006">2007</TOKEN>
<TOKEN end_char="9010" id="token-105-2" morph="none" pos="punct" start_char="9010">,</TOKEN>
<TOKEN end_char="9012" id="token-105-3" morph="none" pos="word" start_char="9012">a</TOKEN>
<TOKEN end_char="9017" id="token-105-4" morph="none" pos="word" start_char="9014">team</TOKEN>
<TOKEN end_char="9020" id="token-105-5" morph="none" pos="word" start_char="9019">of</TOKEN>
<TOKEN end_char="9032" id="token-105-6" morph="none" pos="word" start_char="9022">researchers</TOKEN>
<TOKEN end_char="9038" id="token-105-7" morph="none" pos="word" start_char="9034">based</TOKEN>
<TOKEN end_char="9041" id="token-105-8" morph="none" pos="word" start_char="9040">in</TOKEN>
<TOKEN end_char="9047" id="token-105-9" morph="none" pos="word" start_char="9043">Wuhan</TOKEN>
<TOKEN end_char="9048" id="token-105-10" morph="none" pos="punct" start_char="9048">,</TOKEN>
<TOKEN end_char="9051" id="token-105-11" morph="none" pos="word" start_char="9050">in</TOKEN>
<TOKEN end_char="9063" id="token-105-12" morph="none" pos="word" start_char="9053">conjunction</TOKEN>
<TOKEN end_char="9068" id="token-105-13" morph="none" pos="word" start_char="9065">with</TOKEN>
<TOKEN end_char="9071" id="token-105-14" morph="none" pos="word" start_char="9070">an</TOKEN>
<TOKEN end_char="9082" id="token-105-15" morph="none" pos="word" start_char="9073">Australian</TOKEN>
<TOKEN end_char="9093" id="token-105-16" morph="none" pos="word" start_char="9084">laboratory</TOKEN>
<TOKEN end_char="9094" id="token-105-17" morph="none" pos="punct" start_char="9094">,</TOKEN>
<TOKEN end_char="9104" id="token-105-18" morph="none" pos="word" start_char="9096">conducted</TOKEN>
<TOKEN end_char="9106" id="token-105-19" morph="none" pos="word" start_char="9106">a</TOKEN>
<TOKEN end_char="9112" id="token-105-20" morph="none" pos="word" start_char="9108">study</TOKEN>
<TOKEN end_char="9117" id="token-105-21" morph="none" pos="word" start_char="9114">with</TOKEN>
<TOKEN end_char="9122" id="token-105-22" morph="none" pos="word" start_char="9119">SARS</TOKEN>
<TOKEN end_char="9123" id="token-105-23" morph="none" pos="punct" start_char="9123">,</TOKEN>
<TOKEN end_char="9125" id="token-105-24" morph="none" pos="word" start_char="9125">a</TOKEN>
<TOKEN end_char="9135" id="token-105-25" morph="none" pos="unknown" start_char="9127">SARS-like</TOKEN>
<TOKEN end_char="9147" id="token-105-26" morph="none" pos="word" start_char="9137">coronavirus</TOKEN>
<TOKEN end_char="9148" id="token-105-27" morph="none" pos="punct" start_char="9148">,</TOKEN>
<TOKEN end_char="9152" id="token-105-28" morph="none" pos="word" start_char="9150">and</TOKEN>
<TOKEN end_char="9158" id="token-105-29" morph="none" pos="unknown" start_char="9154">HIV-1</TOKEN>
<TOKEN end_char="9159" id="token-105-30" morph="none" pos="punct" start_char="9159">.</TOKEN>
</SEG>
<SEG end_char="9302" id="segment-106" start_char="9162">
<ORIGINAL_TEXT>They also predicted based on the S-ACE2 binding structure, that SARS-like CoVs were not able to use this same attack method (ACE2 mediation).</ORIGINAL_TEXT>
<TOKEN end_char="9165" id="token-106-0" morph="none" pos="word" start_char="9162">They</TOKEN>
<TOKEN end_char="9170" id="token-106-1" morph="none" pos="word" start_char="9167">also</TOKEN>
<TOKEN end_char="9180" id="token-106-2" morph="none" pos="word" start_char="9172">predicted</TOKEN>
<TOKEN end_char="9186" id="token-106-3" morph="none" pos="word" start_char="9182">based</TOKEN>
<TOKEN end_char="9189" id="token-106-4" morph="none" pos="word" start_char="9188">on</TOKEN>
<TOKEN end_char="9193" id="token-106-5" morph="none" pos="word" start_char="9191">the</TOKEN>
<TOKEN end_char="9200" id="token-106-6" morph="none" pos="unknown" start_char="9195">S-ACE2</TOKEN>
<TOKEN end_char="9208" id="token-106-7" morph="none" pos="word" start_char="9202">binding</TOKEN>
<TOKEN end_char="9218" id="token-106-8" morph="none" pos="word" start_char="9210">structure</TOKEN>
<TOKEN end_char="9219" id="token-106-9" morph="none" pos="punct" start_char="9219">,</TOKEN>
<TOKEN end_char="9224" id="token-106-10" morph="none" pos="word" start_char="9221">that</TOKEN>
<TOKEN end_char="9234" id="token-106-11" morph="none" pos="unknown" start_char="9226">SARS-like</TOKEN>
<TOKEN end_char="9239" id="token-106-12" morph="none" pos="word" start_char="9236">CoVs</TOKEN>
<TOKEN end_char="9244" id="token-106-13" morph="none" pos="word" start_char="9241">were</TOKEN>
<TOKEN end_char="9248" id="token-106-14" morph="none" pos="word" start_char="9246">not</TOKEN>
<TOKEN end_char="9253" id="token-106-15" morph="none" pos="word" start_char="9250">able</TOKEN>
<TOKEN end_char="9256" id="token-106-16" morph="none" pos="word" start_char="9255">to</TOKEN>
<TOKEN end_char="9260" id="token-106-17" morph="none" pos="word" start_char="9258">use</TOKEN>
<TOKEN end_char="9265" id="token-106-18" morph="none" pos="word" start_char="9262">this</TOKEN>
<TOKEN end_char="9270" id="token-106-19" morph="none" pos="word" start_char="9267">same</TOKEN>
<TOKEN end_char="9277" id="token-106-20" morph="none" pos="word" start_char="9272">attack</TOKEN>
<TOKEN end_char="9284" id="token-106-21" morph="none" pos="word" start_char="9279">method</TOKEN>
<TOKEN end_char="9286" id="token-106-22" morph="none" pos="punct" start_char="9286">(</TOKEN>
<TOKEN end_char="9290" id="token-106-23" morph="none" pos="word" start_char="9287">ACE2</TOKEN>
<TOKEN end_char="9300" id="token-106-24" morph="none" pos="word" start_char="9292">mediation</TOKEN>
<TOKEN end_char="9302" id="token-106-25" morph="none" pos="punct" start_char="9301">).</TOKEN>
</SEG>
<SEG end_char="9401" id="segment-107" start_char="9304">
<ORIGINAL_TEXT>They decided to create a pseudovirus where they essentially put a SARS-like CoV in a HIV envelope.</ORIGINAL_TEXT>
<TOKEN end_char="9307" id="token-107-0" morph="none" pos="word" start_char="9304">They</TOKEN>
<TOKEN end_char="9315" id="token-107-1" morph="none" pos="word" start_char="9309">decided</TOKEN>
<TOKEN end_char="9318" id="token-107-2" morph="none" pos="word" start_char="9317">to</TOKEN>
<TOKEN end_char="9325" id="token-107-3" morph="none" pos="word" start_char="9320">create</TOKEN>
<TOKEN end_char="9327" id="token-107-4" morph="none" pos="word" start_char="9327">a</TOKEN>
<TOKEN end_char="9339" id="token-107-5" morph="none" pos="word" start_char="9329">pseudovirus</TOKEN>
<TOKEN end_char="9345" id="token-107-6" morph="none" pos="word" start_char="9341">where</TOKEN>
<TOKEN end_char="9350" id="token-107-7" morph="none" pos="word" start_char="9347">they</TOKEN>
<TOKEN end_char="9362" id="token-107-8" morph="none" pos="word" start_char="9352">essentially</TOKEN>
<TOKEN end_char="9366" id="token-107-9" morph="none" pos="word" start_char="9364">put</TOKEN>
<TOKEN end_char="9368" id="token-107-10" morph="none" pos="word" start_char="9368">a</TOKEN>
<TOKEN end_char="9378" id="token-107-11" morph="none" pos="unknown" start_char="9370">SARS-like</TOKEN>
<TOKEN end_char="9382" id="token-107-12" morph="none" pos="word" start_char="9380">CoV</TOKEN>
<TOKEN end_char="9385" id="token-107-13" morph="none" pos="word" start_char="9384">in</TOKEN>
<TOKEN end_char="9387" id="token-107-14" morph="none" pos="word" start_char="9387">a</TOKEN>
<TOKEN end_char="9391" id="token-107-15" morph="none" pos="word" start_char="9389">HIV</TOKEN>
<TOKEN end_char="9400" id="token-107-16" morph="none" pos="word" start_char="9393">envelope</TOKEN>
<TOKEN end_char="9401" id="token-107-17" morph="none" pos="punct" start_char="9401">.</TOKEN>
</SEG>
<SEG end_char="9412" id="segment-108" start_char="9403">
<ORIGINAL_TEXT>It worked.</ORIGINAL_TEXT>
<TOKEN end_char="9404" id="token-108-0" morph="none" pos="word" start_char="9403">It</TOKEN>
<TOKEN end_char="9411" id="token-108-1" morph="none" pos="word" start_char="9406">worked</TOKEN>
<TOKEN end_char="9412" id="token-108-2" morph="none" pos="punct" start_char="9412">.</TOKEN>
</SEG>
<SEG end_char="9580" id="segment-109" start_char="9414">
<ORIGINAL_TEXT>Using an HIV envelope, they replaced the RBD (receptor binding domain) of SL-CoV with that of SARS-CoV, and used it to successfully infect bats through ACE2 mediation.</ORIGINAL_TEXT>
<TOKEN end_char="9418" id="token-109-0" morph="none" pos="word" start_char="9414">Using</TOKEN>
<TOKEN end_char="9421" id="token-109-1" morph="none" pos="word" start_char="9420">an</TOKEN>
<TOKEN end_char="9425" id="token-109-2" morph="none" pos="word" start_char="9423">HIV</TOKEN>
<TOKEN end_char="9434" id="token-109-3" morph="none" pos="word" start_char="9427">envelope</TOKEN>
<TOKEN end_char="9435" id="token-109-4" morph="none" pos="punct" start_char="9435">,</TOKEN>
<TOKEN end_char="9440" id="token-109-5" morph="none" pos="word" start_char="9437">they</TOKEN>
<TOKEN end_char="9449" id="token-109-6" morph="none" pos="word" start_char="9442">replaced</TOKEN>
<TOKEN end_char="9453" id="token-109-7" morph="none" pos="word" start_char="9451">the</TOKEN>
<TOKEN end_char="9457" id="token-109-8" morph="none" pos="word" start_char="9455">RBD</TOKEN>
<TOKEN end_char="9459" id="token-109-9" morph="none" pos="punct" start_char="9459">(</TOKEN>
<TOKEN end_char="9467" id="token-109-10" morph="none" pos="word" start_char="9460">receptor</TOKEN>
<TOKEN end_char="9475" id="token-109-11" morph="none" pos="word" start_char="9469">binding</TOKEN>
<TOKEN end_char="9482" id="token-109-12" morph="none" pos="word" start_char="9477">domain</TOKEN>
<TOKEN end_char="9483" id="token-109-13" morph="none" pos="punct" start_char="9483">)</TOKEN>
<TOKEN end_char="9486" id="token-109-14" morph="none" pos="word" start_char="9485">of</TOKEN>
<TOKEN end_char="9493" id="token-109-15" morph="none" pos="unknown" start_char="9488">SL-CoV</TOKEN>
<TOKEN end_char="9498" id="token-109-16" morph="none" pos="word" start_char="9495">with</TOKEN>
<TOKEN end_char="9503" id="token-109-17" morph="none" pos="word" start_char="9500">that</TOKEN>
<TOKEN end_char="9506" id="token-109-18" morph="none" pos="word" start_char="9505">of</TOKEN>
<TOKEN end_char="9515" id="token-109-19" morph="none" pos="unknown" start_char="9508">SARS-CoV</TOKEN>
<TOKEN end_char="9516" id="token-109-20" morph="none" pos="punct" start_char="9516">,</TOKEN>
<TOKEN end_char="9520" id="token-109-21" morph="none" pos="word" start_char="9518">and</TOKEN>
<TOKEN end_char="9525" id="token-109-22" morph="none" pos="word" start_char="9522">used</TOKEN>
<TOKEN end_char="9528" id="token-109-23" morph="none" pos="word" start_char="9527">it</TOKEN>
<TOKEN end_char="9531" id="token-109-24" morph="none" pos="word" start_char="9530">to</TOKEN>
<TOKEN end_char="9544" id="token-109-25" morph="none" pos="word" start_char="9533">successfully</TOKEN>
<TOKEN end_char="9551" id="token-109-26" morph="none" pos="word" start_char="9546">infect</TOKEN>
<TOKEN end_char="9556" id="token-109-27" morph="none" pos="word" start_char="9553">bats</TOKEN>
<TOKEN end_char="9564" id="token-109-28" morph="none" pos="word" start_char="9558">through</TOKEN>
<TOKEN end_char="9569" id="token-109-29" morph="none" pos="word" start_char="9566">ACE2</TOKEN>
<TOKEN end_char="9579" id="token-109-30" morph="none" pos="word" start_char="9571">mediation</TOKEN>
<TOKEN end_char="9580" id="token-109-31" morph="none" pos="punct" start_char="9580">.</TOKEN>
</SEG>
<SEG end_char="9639" id="segment-110" start_char="9583">
<ORIGINAL_TEXT>The Indian scientific paper that Chinese got angry about.</ORIGINAL_TEXT>
<TOKEN end_char="9585" id="token-110-0" morph="none" pos="word" start_char="9583">The</TOKEN>
<TOKEN end_char="9592" id="token-110-1" morph="none" pos="word" start_char="9587">Indian</TOKEN>
<TOKEN end_char="9603" id="token-110-2" morph="none" pos="word" start_char="9594">scientific</TOKEN>
<TOKEN end_char="9609" id="token-110-3" morph="none" pos="word" start_char="9605">paper</TOKEN>
<TOKEN end_char="9614" id="token-110-4" morph="none" pos="word" start_char="9611">that</TOKEN>
<TOKEN end_char="9622" id="token-110-5" morph="none" pos="word" start_char="9616">Chinese</TOKEN>
<TOKEN end_char="9626" id="token-110-6" morph="none" pos="word" start_char="9624">got</TOKEN>
<TOKEN end_char="9632" id="token-110-7" morph="none" pos="word" start_char="9628">angry</TOKEN>
<TOKEN end_char="9638" id="token-110-8" morph="none" pos="word" start_char="9634">about</TOKEN>
<TOKEN end_char="9639" id="token-110-9" morph="none" pos="punct" start_char="9639">.</TOKEN>
</SEG>
<SEG end_char="9731" id="segment-111" start_char="9642">
<ORIGINAL_TEXT>Uncanny similarity of unique inserts in the 2019-nCoV spike protein to HIV-1 gp120 and Gag</ORIGINAL_TEXT>
<TOKEN end_char="9648" id="token-111-0" morph="none" pos="word" start_char="9642">Uncanny</TOKEN>
<TOKEN end_char="9659" id="token-111-1" morph="none" pos="word" start_char="9650">similarity</TOKEN>
<TOKEN end_char="9662" id="token-111-2" morph="none" pos="word" start_char="9661">of</TOKEN>
<TOKEN end_char="9669" id="token-111-3" morph="none" pos="word" start_char="9664">unique</TOKEN>
<TOKEN end_char="9677" id="token-111-4" morph="none" pos="word" start_char="9671">inserts</TOKEN>
<TOKEN end_char="9680" id="token-111-5" morph="none" pos="word" start_char="9679">in</TOKEN>
<TOKEN end_char="9684" id="token-111-6" morph="none" pos="word" start_char="9682">the</TOKEN>
<TOKEN end_char="9694" id="token-111-7" morph="none" pos="unknown" start_char="9686">2019-nCoV</TOKEN>
<TOKEN end_char="9700" id="token-111-8" morph="none" pos="word" start_char="9696">spike</TOKEN>
<TOKEN end_char="9708" id="token-111-9" morph="none" pos="word" start_char="9702">protein</TOKEN>
<TOKEN end_char="9711" id="token-111-10" morph="none" pos="word" start_char="9710">to</TOKEN>
<TOKEN end_char="9717" id="token-111-11" morph="none" pos="unknown" start_char="9713">HIV-1</TOKEN>
<TOKEN end_char="9723" id="token-111-12" morph="none" pos="word" start_char="9719">gp120</TOKEN>
<TOKEN end_char="9727" id="token-111-13" morph="none" pos="word" start_char="9725">and</TOKEN>
<TOKEN end_char="9731" id="token-111-14" morph="none" pos="word" start_char="9729">Gag</TOKEN>
</SEG>
<SEG end_char="9849" id="segment-112" start_char="9734">
<ORIGINAL_TEXT>And then we have the articles on people working at the lab selling animals at food market instead of cremating them.</ORIGINAL_TEXT>
<TOKEN end_char="9736" id="token-112-0" morph="none" pos="word" start_char="9734">And</TOKEN>
<TOKEN end_char="9741" id="token-112-1" morph="none" pos="word" start_char="9738">then</TOKEN>
<TOKEN end_char="9744" id="token-112-2" morph="none" pos="word" start_char="9743">we</TOKEN>
<TOKEN end_char="9749" id="token-112-3" morph="none" pos="word" start_char="9746">have</TOKEN>
<TOKEN end_char="9753" id="token-112-4" morph="none" pos="word" start_char="9751">the</TOKEN>
<TOKEN end_char="9762" id="token-112-5" morph="none" pos="word" start_char="9755">articles</TOKEN>
<TOKEN end_char="9765" id="token-112-6" morph="none" pos="word" start_char="9764">on</TOKEN>
<TOKEN end_char="9772" id="token-112-7" morph="none" pos="word" start_char="9767">people</TOKEN>
<TOKEN end_char="9780" id="token-112-8" morph="none" pos="word" start_char="9774">working</TOKEN>
<TOKEN end_char="9783" id="token-112-9" morph="none" pos="word" start_char="9782">at</TOKEN>
<TOKEN end_char="9787" id="token-112-10" morph="none" pos="word" start_char="9785">the</TOKEN>
<TOKEN end_char="9791" id="token-112-11" morph="none" pos="word" start_char="9789">lab</TOKEN>
<TOKEN end_char="9799" id="token-112-12" morph="none" pos="word" start_char="9793">selling</TOKEN>
<TOKEN end_char="9807" id="token-112-13" morph="none" pos="word" start_char="9801">animals</TOKEN>
<TOKEN end_char="9810" id="token-112-14" morph="none" pos="word" start_char="9809">at</TOKEN>
<TOKEN end_char="9815" id="token-112-15" morph="none" pos="word" start_char="9812">food</TOKEN>
<TOKEN end_char="9822" id="token-112-16" morph="none" pos="word" start_char="9817">market</TOKEN>
<TOKEN end_char="9830" id="token-112-17" morph="none" pos="word" start_char="9824">instead</TOKEN>
<TOKEN end_char="9833" id="token-112-18" morph="none" pos="word" start_char="9832">of</TOKEN>
<TOKEN end_char="9843" id="token-112-19" morph="none" pos="word" start_char="9835">cremating</TOKEN>
<TOKEN end_char="9848" id="token-112-20" morph="none" pos="word" start_char="9845">them</TOKEN>
<TOKEN end_char="9849" id="token-112-21" morph="none" pos="punct" start_char="9849">.</TOKEN>
</SEG>
<SEG end_char="9870" id="segment-113" start_char="9851">
<ORIGINAL_TEXT>www.breitbart.com...</ORIGINAL_TEXT>
<TOKEN end_char="9870" id="token-113-0" morph="none" pos="url" start_char="9851">www.breitbart.com...</TOKEN>
</SEG>
<SEG end_char="9944" id="segment-114" start_char="9875">
<ORIGINAL_TEXT>originally posted by: hounddoghowlie please, a super market tabloid???</ORIGINAL_TEXT>
<TOKEN end_char="9884" id="token-114-0" morph="none" pos="word" start_char="9875">originally</TOKEN>
<TOKEN end_char="9891" id="token-114-1" morph="none" pos="word" start_char="9886">posted</TOKEN>
<TOKEN end_char="9894" id="token-114-2" morph="none" pos="word" start_char="9893">by</TOKEN>
<TOKEN end_char="9895" id="token-114-3" morph="none" pos="punct" start_char="9895">:</TOKEN>
<TOKEN end_char="9910" id="token-114-4" morph="none" pos="word" start_char="9897">hounddoghowlie</TOKEN>
<TOKEN end_char="9917" id="token-114-5" morph="none" pos="word" start_char="9912">please</TOKEN>
<TOKEN end_char="9918" id="token-114-6" morph="none" pos="punct" start_char="9918">,</TOKEN>
<TOKEN end_char="9920" id="token-114-7" morph="none" pos="word" start_char="9920">a</TOKEN>
<TOKEN end_char="9926" id="token-114-8" morph="none" pos="word" start_char="9922">super</TOKEN>
<TOKEN end_char="9933" id="token-114-9" morph="none" pos="word" start_char="9928">market</TOKEN>
<TOKEN end_char="9941" id="token-114-10" morph="none" pos="word" start_char="9935">tabloid</TOKEN>
<TOKEN end_char="9944" id="token-114-11" morph="none" pos="punct" start_char="9942">???</TOKEN>
</SEG>
<SEG end_char="10174" id="segment-115" start_char="9947">
<ORIGINAL_TEXT>To me it seems ironic how certain people seem to espouse the CCP propaganda about this story not being real when the article mentions the names of the Chinese scientists whom wrote this report, and a story the CCP tried to bury.</ORIGINAL_TEXT>
<TOKEN end_char="9948" id="token-115-0" morph="none" pos="word" start_char="9947">To</TOKEN>
<TOKEN end_char="9951" id="token-115-1" morph="none" pos="word" start_char="9950">me</TOKEN>
<TOKEN end_char="9954" id="token-115-2" morph="none" pos="word" start_char="9953">it</TOKEN>
<TOKEN end_char="9960" id="token-115-3" morph="none" pos="word" start_char="9956">seems</TOKEN>
<TOKEN end_char="9967" id="token-115-4" morph="none" pos="word" start_char="9962">ironic</TOKEN>
<TOKEN end_char="9971" id="token-115-5" morph="none" pos="word" start_char="9969">how</TOKEN>
<TOKEN end_char="9979" id="token-115-6" morph="none" pos="word" start_char="9973">certain</TOKEN>
<TOKEN end_char="9986" id="token-115-7" morph="none" pos="word" start_char="9981">people</TOKEN>
<TOKEN end_char="9991" id="token-115-8" morph="none" pos="word" start_char="9988">seem</TOKEN>
<TOKEN end_char="9994" id="token-115-9" morph="none" pos="word" start_char="9993">to</TOKEN>
<TOKEN end_char="10002" id="token-115-10" morph="none" pos="word" start_char="9996">espouse</TOKEN>
<TOKEN end_char="10006" id="token-115-11" morph="none" pos="word" start_char="10004">the</TOKEN>
<TOKEN end_char="10010" id="token-115-12" morph="none" pos="word" start_char="10008">CCP</TOKEN>
<TOKEN end_char="10021" id="token-115-13" morph="none" pos="word" start_char="10012">propaganda</TOKEN>
<TOKEN end_char="10027" id="token-115-14" morph="none" pos="word" start_char="10023">about</TOKEN>
<TOKEN end_char="10032" id="token-115-15" morph="none" pos="word" start_char="10029">this</TOKEN>
<TOKEN end_char="10038" id="token-115-16" morph="none" pos="word" start_char="10034">story</TOKEN>
<TOKEN end_char="10042" id="token-115-17" morph="none" pos="word" start_char="10040">not</TOKEN>
<TOKEN end_char="10048" id="token-115-18" morph="none" pos="word" start_char="10044">being</TOKEN>
<TOKEN end_char="10053" id="token-115-19" morph="none" pos="word" start_char="10050">real</TOKEN>
<TOKEN end_char="10058" id="token-115-20" morph="none" pos="word" start_char="10055">when</TOKEN>
<TOKEN end_char="10062" id="token-115-21" morph="none" pos="word" start_char="10060">the</TOKEN>
<TOKEN end_char="10070" id="token-115-22" morph="none" pos="word" start_char="10064">article</TOKEN>
<TOKEN end_char="10079" id="token-115-23" morph="none" pos="word" start_char="10072">mentions</TOKEN>
<TOKEN end_char="10083" id="token-115-24" morph="none" pos="word" start_char="10081">the</TOKEN>
<TOKEN end_char="10089" id="token-115-25" morph="none" pos="word" start_char="10085">names</TOKEN>
<TOKEN end_char="10092" id="token-115-26" morph="none" pos="word" start_char="10091">of</TOKEN>
<TOKEN end_char="10096" id="token-115-27" morph="none" pos="word" start_char="10094">the</TOKEN>
<TOKEN end_char="10104" id="token-115-28" morph="none" pos="word" start_char="10098">Chinese</TOKEN>
<TOKEN end_char="10115" id="token-115-29" morph="none" pos="word" start_char="10106">scientists</TOKEN>
<TOKEN end_char="10120" id="token-115-30" morph="none" pos="word" start_char="10117">whom</TOKEN>
<TOKEN end_char="10126" id="token-115-31" morph="none" pos="word" start_char="10122">wrote</TOKEN>
<TOKEN end_char="10131" id="token-115-32" morph="none" pos="word" start_char="10128">this</TOKEN>
<TOKEN end_char="10138" id="token-115-33" morph="none" pos="word" start_char="10133">report</TOKEN>
<TOKEN end_char="10139" id="token-115-34" morph="none" pos="punct" start_char="10139">,</TOKEN>
<TOKEN end_char="10143" id="token-115-35" morph="none" pos="word" start_char="10141">and</TOKEN>
<TOKEN end_char="10145" id="token-115-36" morph="none" pos="word" start_char="10145">a</TOKEN>
<TOKEN end_char="10151" id="token-115-37" morph="none" pos="word" start_char="10147">story</TOKEN>
<TOKEN end_char="10155" id="token-115-38" morph="none" pos="word" start_char="10153">the</TOKEN>
<TOKEN end_char="10159" id="token-115-39" morph="none" pos="word" start_char="10157">CCP</TOKEN>
<TOKEN end_char="10165" id="token-115-40" morph="none" pos="word" start_char="10161">tried</TOKEN>
<TOKEN end_char="10168" id="token-115-41" morph="none" pos="word" start_char="10167">to</TOKEN>
<TOKEN end_char="10173" id="token-115-42" morph="none" pos="word" start_char="10170">bury</TOKEN>
<TOKEN end_char="10174" id="token-115-43" morph="none" pos="punct" start_char="10174">.</TOKEN>
</SEG>
<SEG end_char="10328" id="segment-116" start_char="10177">
<ORIGINAL_TEXT>But anyways, here is an excerpt and link to the paper, which took me a while to find and wasn't possible for me to post last night for personal reasons.</ORIGINAL_TEXT>
<TOKEN end_char="10179" id="token-116-0" morph="none" pos="word" start_char="10177">But</TOKEN>
<TOKEN end_char="10187" id="token-116-1" morph="none" pos="word" start_char="10181">anyways</TOKEN>
<TOKEN end_char="10188" id="token-116-2" morph="none" pos="punct" start_char="10188">,</TOKEN>
<TOKEN end_char="10193" id="token-116-3" morph="none" pos="word" start_char="10190">here</TOKEN>
<TOKEN end_char="10196" id="token-116-4" morph="none" pos="word" start_char="10195">is</TOKEN>
<TOKEN end_char="10199" id="token-116-5" morph="none" pos="word" start_char="10198">an</TOKEN>
<TOKEN end_char="10207" id="token-116-6" morph="none" pos="word" start_char="10201">excerpt</TOKEN>
<TOKEN end_char="10211" id="token-116-7" morph="none" pos="word" start_char="10209">and</TOKEN>
<TOKEN end_char="10216" id="token-116-8" morph="none" pos="word" start_char="10213">link</TOKEN>
<TOKEN end_char="10219" id="token-116-9" morph="none" pos="word" start_char="10218">to</TOKEN>
<TOKEN end_char="10223" id="token-116-10" morph="none" pos="word" start_char="10221">the</TOKEN>
<TOKEN end_char="10229" id="token-116-11" morph="none" pos="word" start_char="10225">paper</TOKEN>
<TOKEN end_char="10230" id="token-116-12" morph="none" pos="punct" start_char="10230">,</TOKEN>
<TOKEN end_char="10236" id="token-116-13" morph="none" pos="word" start_char="10232">which</TOKEN>
<TOKEN end_char="10241" id="token-116-14" morph="none" pos="word" start_char="10238">took</TOKEN>
<TOKEN end_char="10244" id="token-116-15" morph="none" pos="word" start_char="10243">me</TOKEN>
<TOKEN end_char="10246" id="token-116-16" morph="none" pos="word" start_char="10246">a</TOKEN>
<TOKEN end_char="10252" id="token-116-17" morph="none" pos="word" start_char="10248">while</TOKEN>
<TOKEN end_char="10255" id="token-116-18" morph="none" pos="word" start_char="10254">to</TOKEN>
<TOKEN end_char="10260" id="token-116-19" morph="none" pos="word" start_char="10257">find</TOKEN>
<TOKEN end_char="10264" id="token-116-20" morph="none" pos="word" start_char="10262">and</TOKEN>
<TOKEN end_char="10271" id="token-116-21" morph="none" pos="word" start_char="10266">wasn't</TOKEN>
<TOKEN end_char="10280" id="token-116-22" morph="none" pos="word" start_char="10273">possible</TOKEN>
<TOKEN end_char="10284" id="token-116-23" morph="none" pos="word" start_char="10282">for</TOKEN>
<TOKEN end_char="10287" id="token-116-24" morph="none" pos="word" start_char="10286">me</TOKEN>
<TOKEN end_char="10290" id="token-116-25" morph="none" pos="word" start_char="10289">to</TOKEN>
<TOKEN end_char="10295" id="token-116-26" morph="none" pos="word" start_char="10292">post</TOKEN>
<TOKEN end_char="10300" id="token-116-27" morph="none" pos="word" start_char="10297">last</TOKEN>
<TOKEN end_char="10306" id="token-116-28" morph="none" pos="word" start_char="10302">night</TOKEN>
<TOKEN end_char="10310" id="token-116-29" morph="none" pos="word" start_char="10308">for</TOKEN>
<TOKEN end_char="10319" id="token-116-30" morph="none" pos="word" start_char="10312">personal</TOKEN>
<TOKEN end_char="10327" id="token-116-31" morph="none" pos="word" start_char="10321">reasons</TOKEN>
<TOKEN end_char="10328" id="token-116-32" morph="none" pos="punct" start_char="10328">.</TOKEN>
</SEG>
<SEG end_char="10585" id="segment-117" start_char="10331">
<ORIGINAL_TEXT>The article even states that the CCP buried this story when it came out, but thankfully we have archives that shine the truth about stories, and the attempts of dictatorships like China, in doing everything they can to stop the truth from ever coming out.</ORIGINAL_TEXT>
<TOKEN end_char="10333" id="token-117-0" morph="none" pos="word" start_char="10331">The</TOKEN>
<TOKEN end_char="10341" id="token-117-1" morph="none" pos="word" start_char="10335">article</TOKEN>
<TOKEN end_char="10346" id="token-117-2" morph="none" pos="word" start_char="10343">even</TOKEN>
<TOKEN end_char="10353" id="token-117-3" morph="none" pos="word" start_char="10348">states</TOKEN>
<TOKEN end_char="10358" id="token-117-4" morph="none" pos="word" start_char="10355">that</TOKEN>
<TOKEN end_char="10362" id="token-117-5" morph="none" pos="word" start_char="10360">the</TOKEN>
<TOKEN end_char="10366" id="token-117-6" morph="none" pos="word" start_char="10364">CCP</TOKEN>
<TOKEN end_char="10373" id="token-117-7" morph="none" pos="word" start_char="10368">buried</TOKEN>
<TOKEN end_char="10378" id="token-117-8" morph="none" pos="word" start_char="10375">this</TOKEN>
<TOKEN end_char="10384" id="token-117-9" morph="none" pos="word" start_char="10380">story</TOKEN>
<TOKEN end_char="10389" id="token-117-10" morph="none" pos="word" start_char="10386">when</TOKEN>
<TOKEN end_char="10392" id="token-117-11" morph="none" pos="word" start_char="10391">it</TOKEN>
<TOKEN end_char="10397" id="token-117-12" morph="none" pos="word" start_char="10394">came</TOKEN>
<TOKEN end_char="10401" id="token-117-13" morph="none" pos="word" start_char="10399">out</TOKEN>
<TOKEN end_char="10402" id="token-117-14" morph="none" pos="punct" start_char="10402">,</TOKEN>
<TOKEN end_char="10406" id="token-117-15" morph="none" pos="word" start_char="10404">but</TOKEN>
<TOKEN end_char="10417" id="token-117-16" morph="none" pos="word" start_char="10408">thankfully</TOKEN>
<TOKEN end_char="10420" id="token-117-17" morph="none" pos="word" start_char="10419">we</TOKEN>
<TOKEN end_char="10425" id="token-117-18" morph="none" pos="word" start_char="10422">have</TOKEN>
<TOKEN end_char="10434" id="token-117-19" morph="none" pos="word" start_char="10427">archives</TOKEN>
<TOKEN end_char="10439" id="token-117-20" morph="none" pos="word" start_char="10436">that</TOKEN>
<TOKEN end_char="10445" id="token-117-21" morph="none" pos="word" start_char="10441">shine</TOKEN>
<TOKEN end_char="10449" id="token-117-22" morph="none" pos="word" start_char="10447">the</TOKEN>
<TOKEN end_char="10455" id="token-117-23" morph="none" pos="word" start_char="10451">truth</TOKEN>
<TOKEN end_char="10461" id="token-117-24" morph="none" pos="word" start_char="10457">about</TOKEN>
<TOKEN end_char="10469" id="token-117-25" morph="none" pos="word" start_char="10463">stories</TOKEN>
<TOKEN end_char="10470" id="token-117-26" morph="none" pos="punct" start_char="10470">,</TOKEN>
<TOKEN end_char="10474" id="token-117-27" morph="none" pos="word" start_char="10472">and</TOKEN>
<TOKEN end_char="10478" id="token-117-28" morph="none" pos="word" start_char="10476">the</TOKEN>
<TOKEN end_char="10487" id="token-117-29" morph="none" pos="word" start_char="10480">attempts</TOKEN>
<TOKEN end_char="10490" id="token-117-30" morph="none" pos="word" start_char="10489">of</TOKEN>
<TOKEN end_char="10504" id="token-117-31" morph="none" pos="word" start_char="10492">dictatorships</TOKEN>
<TOKEN end_char="10509" id="token-117-32" morph="none" pos="word" start_char="10506">like</TOKEN>
<TOKEN end_char="10515" id="token-117-33" morph="none" pos="word" start_char="10511">China</TOKEN>
<TOKEN end_char="10516" id="token-117-34" morph="none" pos="punct" start_char="10516">,</TOKEN>
<TOKEN end_char="10519" id="token-117-35" morph="none" pos="word" start_char="10518">in</TOKEN>
<TOKEN end_char="10525" id="token-117-36" morph="none" pos="word" start_char="10521">doing</TOKEN>
<TOKEN end_char="10536" id="token-117-37" morph="none" pos="word" start_char="10527">everything</TOKEN>
<TOKEN end_char="10541" id="token-117-38" morph="none" pos="word" start_char="10538">they</TOKEN>
<TOKEN end_char="10545" id="token-117-39" morph="none" pos="word" start_char="10543">can</TOKEN>
<TOKEN end_char="10548" id="token-117-40" morph="none" pos="word" start_char="10547">to</TOKEN>
<TOKEN end_char="10553" id="token-117-41" morph="none" pos="word" start_char="10550">stop</TOKEN>
<TOKEN end_char="10557" id="token-117-42" morph="none" pos="word" start_char="10555">the</TOKEN>
<TOKEN end_char="10563" id="token-117-43" morph="none" pos="word" start_char="10559">truth</TOKEN>
<TOKEN end_char="10568" id="token-117-44" morph="none" pos="word" start_char="10565">from</TOKEN>
<TOKEN end_char="10573" id="token-117-45" morph="none" pos="word" start_char="10570">ever</TOKEN>
<TOKEN end_char="10580" id="token-117-46" morph="none" pos="word" start_char="10575">coming</TOKEN>
<TOKEN end_char="10584" id="token-117-47" morph="none" pos="word" start_char="10582">out</TOKEN>
<TOKEN end_char="10585" id="token-117-48" morph="none" pos="punct" start_char="10585">.</TOKEN>
</SEG>
<SEG end_char="10882" id="segment-118" start_char="10588">
<ORIGINAL_TEXT>The possible origins of 2019-nCoV coronavirus Preprint (PDF Available)  February 2020 with 547 Reads DOI: 10.13140/RG.2.2.21799.29601 Cite this publication The 2019-nCoV has caused an epidemic of 28,060 laboratory-confirmed infections in human including 564 deaths in China by February 6, 2020.</ORIGINAL_TEXT>
<TOKEN end_char="10590" id="token-118-0" morph="none" pos="word" start_char="10588">The</TOKEN>
<TOKEN end_char="10599" id="token-118-1" morph="none" pos="word" start_char="10592">possible</TOKEN>
<TOKEN end_char="10607" id="token-118-2" morph="none" pos="word" start_char="10601">origins</TOKEN>
<TOKEN end_char="10610" id="token-118-3" morph="none" pos="word" start_char="10609">of</TOKEN>
<TOKEN end_char="10620" id="token-118-4" morph="none" pos="unknown" start_char="10612">2019-nCoV</TOKEN>
<TOKEN end_char="10632" id="token-118-5" morph="none" pos="word" start_char="10622">coronavirus</TOKEN>
<TOKEN end_char="10641" id="token-118-6" morph="none" pos="word" start_char="10634">Preprint</TOKEN>
<TOKEN end_char="10643" id="token-118-7" morph="none" pos="punct" start_char="10643">(</TOKEN>
<TOKEN end_char="10646" id="token-118-8" morph="none" pos="word" start_char="10644">PDF</TOKEN>
<TOKEN end_char="10656" id="token-118-9" morph="none" pos="word" start_char="10648">Available</TOKEN>
<TOKEN end_char="10657" id="token-118-10" morph="none" pos="punct" start_char="10657">)</TOKEN>
<TOKEN end_char="10659" id="token-118-11" morph="none" pos="punct" start_char="10659"></TOKEN>
<TOKEN end_char="10668" id="token-118-12" morph="none" pos="word" start_char="10661">February</TOKEN>
<TOKEN end_char="10673" id="token-118-13" morph="none" pos="word" start_char="10670">2020</TOKEN>
<TOKEN end_char="10678" id="token-118-14" morph="none" pos="word" start_char="10675">with</TOKEN>
<TOKEN end_char="10682" id="token-118-15" morph="none" pos="word" start_char="10680">547</TOKEN>
<TOKEN end_char="10688" id="token-118-16" morph="none" pos="word" start_char="10684">Reads</TOKEN>
<TOKEN end_char="10692" id="token-118-17" morph="none" pos="word" start_char="10690">DOI</TOKEN>
<TOKEN end_char="10693" id="token-118-18" morph="none" pos="punct" start_char="10693">:</TOKEN>
<TOKEN end_char="10721" id="token-118-19" morph="none" pos="unknown" start_char="10695">10.13140/RG.2.2.21799.29601</TOKEN>
<TOKEN end_char="10726" id="token-118-20" morph="none" pos="word" start_char="10723">Cite</TOKEN>
<TOKEN end_char="10731" id="token-118-21" morph="none" pos="word" start_char="10728">this</TOKEN>
<TOKEN end_char="10743" id="token-118-22" morph="none" pos="word" start_char="10733">publication</TOKEN>
<TOKEN end_char="10747" id="token-118-23" morph="none" pos="word" start_char="10745">The</TOKEN>
<TOKEN end_char="10757" id="token-118-24" morph="none" pos="unknown" start_char="10749">2019-nCoV</TOKEN>
<TOKEN end_char="10761" id="token-118-25" morph="none" pos="word" start_char="10759">has</TOKEN>
<TOKEN end_char="10768" id="token-118-26" morph="none" pos="word" start_char="10763">caused</TOKEN>
<TOKEN end_char="10771" id="token-118-27" morph="none" pos="word" start_char="10770">an</TOKEN>
<TOKEN end_char="10780" id="token-118-28" morph="none" pos="word" start_char="10773">epidemic</TOKEN>
<TOKEN end_char="10783" id="token-118-29" morph="none" pos="word" start_char="10782">of</TOKEN>
<TOKEN end_char="10790" id="token-118-30" morph="none" pos="unknown" start_char="10785">28,060</TOKEN>
<TOKEN end_char="10811" id="token-118-31" morph="none" pos="unknown" start_char="10792">laboratory-confirmed</TOKEN>
<TOKEN end_char="10822" id="token-118-32" morph="none" pos="word" start_char="10813">infections</TOKEN>
<TOKEN end_char="10825" id="token-118-33" morph="none" pos="word" start_char="10824">in</TOKEN>
<TOKEN end_char="10831" id="token-118-34" morph="none" pos="word" start_char="10827">human</TOKEN>
<TOKEN end_char="10841" id="token-118-35" morph="none" pos="word" start_char="10833">including</TOKEN>
<TOKEN end_char="10845" id="token-118-36" morph="none" pos="word" start_char="10843">564</TOKEN>
<TOKEN end_char="10852" id="token-118-37" morph="none" pos="word" start_char="10847">deaths</TOKEN>
<TOKEN end_char="10855" id="token-118-38" morph="none" pos="word" start_char="10854">in</TOKEN>
<TOKEN end_char="10861" id="token-118-39" morph="none" pos="word" start_char="10857">China</TOKEN>
<TOKEN end_char="10864" id="token-118-40" morph="none" pos="word" start_char="10863">by</TOKEN>
<TOKEN end_char="10873" id="token-118-41" morph="none" pos="word" start_char="10866">February</TOKEN>
<TOKEN end_char="10875" id="token-118-42" morph="none" pos="word" start_char="10875">6</TOKEN>
<TOKEN end_char="10876" id="token-118-43" morph="none" pos="punct" start_char="10876">,</TOKEN>
<TOKEN end_char="10881" id="token-118-44" morph="none" pos="word" start_char="10878">2020</TOKEN>
<TOKEN end_char="10882" id="token-118-45" morph="none" pos="punct" start_char="10882">.</TOKEN>
</SEG>
<SEG end_char="11047" id="segment-119" start_char="10884">
<ORIGINAL_TEXT>Two descriptions of the virus published on Nature this week indicated that the genome sequences from patients were almost identical to the Bat CoV ZC45 coronavirus.</ORIGINAL_TEXT>
<TOKEN end_char="10886" id="token-119-0" morph="none" pos="word" start_char="10884">Two</TOKEN>
<TOKEN end_char="10899" id="token-119-1" morph="none" pos="word" start_char="10888">descriptions</TOKEN>
<TOKEN end_char="10902" id="token-119-2" morph="none" pos="word" start_char="10901">of</TOKEN>
<TOKEN end_char="10906" id="token-119-3" morph="none" pos="word" start_char="10904">the</TOKEN>
<TOKEN end_char="10912" id="token-119-4" morph="none" pos="word" start_char="10908">virus</TOKEN>
<TOKEN end_char="10922" id="token-119-5" morph="none" pos="word" start_char="10914">published</TOKEN>
<TOKEN end_char="10925" id="token-119-6" morph="none" pos="word" start_char="10924">on</TOKEN>
<TOKEN end_char="10932" id="token-119-7" morph="none" pos="word" start_char="10927">Nature</TOKEN>
<TOKEN end_char="10937" id="token-119-8" morph="none" pos="word" start_char="10934">this</TOKEN>
<TOKEN end_char="10942" id="token-119-9" morph="none" pos="word" start_char="10939">week</TOKEN>
<TOKEN end_char="10952" id="token-119-10" morph="none" pos="word" start_char="10944">indicated</TOKEN>
<TOKEN end_char="10957" id="token-119-11" morph="none" pos="word" start_char="10954">that</TOKEN>
<TOKEN end_char="10961" id="token-119-12" morph="none" pos="word" start_char="10959">the</TOKEN>
<TOKEN end_char="10968" id="token-119-13" morph="none" pos="word" start_char="10963">genome</TOKEN>
<TOKEN end_char="10978" id="token-119-14" morph="none" pos="word" start_char="10970">sequences</TOKEN>
<TOKEN end_char="10983" id="token-119-15" morph="none" pos="word" start_char="10980">from</TOKEN>
<TOKEN end_char="10992" id="token-119-16" morph="none" pos="word" start_char="10985">patients</TOKEN>
<TOKEN end_char="10997" id="token-119-17" morph="none" pos="word" start_char="10994">were</TOKEN>
<TOKEN end_char="11004" id="token-119-18" morph="none" pos="word" start_char="10999">almost</TOKEN>
<TOKEN end_char="11014" id="token-119-19" morph="none" pos="word" start_char="11006">identical</TOKEN>
<TOKEN end_char="11017" id="token-119-20" morph="none" pos="word" start_char="11016">to</TOKEN>
<TOKEN end_char="11021" id="token-119-21" morph="none" pos="word" start_char="11019">the</TOKEN>
<TOKEN end_char="11025" id="token-119-22" morph="none" pos="word" start_char="11023">Bat</TOKEN>
<TOKEN end_char="11029" id="token-119-23" morph="none" pos="word" start_char="11027">CoV</TOKEN>
<TOKEN end_char="11034" id="token-119-24" morph="none" pos="word" start_char="11031">ZC45</TOKEN>
<TOKEN end_char="11046" id="token-119-25" morph="none" pos="word" start_char="11036">coronavirus</TOKEN>
<TOKEN end_char="11047" id="token-119-26" morph="none" pos="punct" start_char="11047">.</TOKEN>
</SEG>
<SEG end_char="11131" id="segment-120" start_char="11049">
<ORIGINAL_TEXT>It was critical to study where the pathogen came from and how it passed onto human.</ORIGINAL_TEXT>
<TOKEN end_char="11050" id="token-120-0" morph="none" pos="word" start_char="11049">It</TOKEN>
<TOKEN end_char="11054" id="token-120-1" morph="none" pos="word" start_char="11052">was</TOKEN>
<TOKEN end_char="11063" id="token-120-2" morph="none" pos="word" start_char="11056">critical</TOKEN>
<TOKEN end_char="11066" id="token-120-3" morph="none" pos="word" start_char="11065">to</TOKEN>
<TOKEN end_char="11072" id="token-120-4" morph="none" pos="word" start_char="11068">study</TOKEN>
<TOKEN end_char="11078" id="token-120-5" morph="none" pos="word" start_char="11074">where</TOKEN>
<TOKEN end_char="11082" id="token-120-6" morph="none" pos="word" start_char="11080">the</TOKEN>
<TOKEN end_char="11091" id="token-120-7" morph="none" pos="word" start_char="11084">pathogen</TOKEN>
<TOKEN end_char="11096" id="token-120-8" morph="none" pos="word" start_char="11093">came</TOKEN>
<TOKEN end_char="11101" id="token-120-9" morph="none" pos="word" start_char="11098">from</TOKEN>
<TOKEN end_char="11105" id="token-120-10" morph="none" pos="word" start_char="11103">and</TOKEN>
<TOKEN end_char="11109" id="token-120-11" morph="none" pos="word" start_char="11107">how</TOKEN>
<TOKEN end_char="11112" id="token-120-12" morph="none" pos="word" start_char="11111">it</TOKEN>
<TOKEN end_char="11119" id="token-120-13" morph="none" pos="word" start_char="11114">passed</TOKEN>
<TOKEN end_char="11124" id="token-120-14" morph="none" pos="word" start_char="11121">onto</TOKEN>
<TOKEN end_char="11130" id="token-120-15" morph="none" pos="word" start_char="11126">human</TOKEN>
<TOKEN end_char="11131" id="token-120-16" morph="none" pos="punct" start_char="11131">.</TOKEN>
</SEG>
<SEG end_char="11275" id="segment-121" start_char="11133">
<ORIGINAL_TEXT>An article published on The Lancet reported that 27 of 41 infected patients were found to have contact with the Huanan Seafood Market in Wuhan.</ORIGINAL_TEXT>
<TOKEN end_char="11134" id="token-121-0" morph="none" pos="word" start_char="11133">An</TOKEN>
<TOKEN end_char="11142" id="token-121-1" morph="none" pos="word" start_char="11136">article</TOKEN>
<TOKEN end_char="11152" id="token-121-2" morph="none" pos="word" start_char="11144">published</TOKEN>
<TOKEN end_char="11155" id="token-121-3" morph="none" pos="word" start_char="11154">on</TOKEN>
<TOKEN end_char="11159" id="token-121-4" morph="none" pos="word" start_char="11157">The</TOKEN>
<TOKEN end_char="11166" id="token-121-5" morph="none" pos="word" start_char="11161">Lancet</TOKEN>
<TOKEN end_char="11175" id="token-121-6" morph="none" pos="word" start_char="11168">reported</TOKEN>
<TOKEN end_char="11180" id="token-121-7" morph="none" pos="word" start_char="11177">that</TOKEN>
<TOKEN end_char="11183" id="token-121-8" morph="none" pos="word" start_char="11182">27</TOKEN>
<TOKEN end_char="11186" id="token-121-9" morph="none" pos="word" start_char="11185">of</TOKEN>
<TOKEN end_char="11189" id="token-121-10" morph="none" pos="word" start_char="11188">41</TOKEN>
<TOKEN end_char="11198" id="token-121-11" morph="none" pos="word" start_char="11191">infected</TOKEN>
<TOKEN end_char="11207" id="token-121-12" morph="none" pos="word" start_char="11200">patients</TOKEN>
<TOKEN end_char="11212" id="token-121-13" morph="none" pos="word" start_char="11209">were</TOKEN>
<TOKEN end_char="11218" id="token-121-14" morph="none" pos="word" start_char="11214">found</TOKEN>
<TOKEN end_char="11221" id="token-121-15" morph="none" pos="word" start_char="11220">to</TOKEN>
<TOKEN end_char="11226" id="token-121-16" morph="none" pos="word" start_char="11223">have</TOKEN>
<TOKEN end_char="11234" id="token-121-17" morph="none" pos="word" start_char="11228">contact</TOKEN>
<TOKEN end_char="11239" id="token-121-18" morph="none" pos="word" start_char="11236">with</TOKEN>
<TOKEN end_char="11243" id="token-121-19" morph="none" pos="word" start_char="11241">the</TOKEN>
<TOKEN end_char="11250" id="token-121-20" morph="none" pos="word" start_char="11245">Huanan</TOKEN>
<TOKEN end_char="11258" id="token-121-21" morph="none" pos="word" start_char="11252">Seafood</TOKEN>
<TOKEN end_char="11265" id="token-121-22" morph="none" pos="word" start_char="11260">Market</TOKEN>
<TOKEN end_char="11268" id="token-121-23" morph="none" pos="word" start_char="11267">in</TOKEN>
<TOKEN end_char="11274" id="token-121-24" morph="none" pos="word" start_char="11270">Wuhan</TOKEN>
<TOKEN end_char="11275" id="token-121-25" morph="none" pos="punct" start_char="11275">.</TOKEN>
</SEG>
<SEG end_char="11408" id="segment-122" start_char="11277">
<ORIGINAL_TEXT>We noted two laboratories conducting research on bat coronavirus in Wuhan, one of which was only 280 meters from the seafood market.</ORIGINAL_TEXT>
<TOKEN end_char="11278" id="token-122-0" morph="none" pos="word" start_char="11277">We</TOKEN>
<TOKEN end_char="11284" id="token-122-1" morph="none" pos="word" start_char="11280">noted</TOKEN>
<TOKEN end_char="11288" id="token-122-2" morph="none" pos="word" start_char="11286">two</TOKEN>
<TOKEN end_char="11301" id="token-122-3" morph="none" pos="word" start_char="11290">laboratories</TOKEN>
<TOKEN end_char="11312" id="token-122-4" morph="none" pos="word" start_char="11303">conducting</TOKEN>
<TOKEN end_char="11321" id="token-122-5" morph="none" pos="word" start_char="11314">research</TOKEN>
<TOKEN end_char="11324" id="token-122-6" morph="none" pos="word" start_char="11323">on</TOKEN>
<TOKEN end_char="11328" id="token-122-7" morph="none" pos="word" start_char="11326">bat</TOKEN>
<TOKEN end_char="11340" id="token-122-8" morph="none" pos="word" start_char="11330">coronavirus</TOKEN>
<TOKEN end_char="11343" id="token-122-9" morph="none" pos="word" start_char="11342">in</TOKEN>
<TOKEN end_char="11349" id="token-122-10" morph="none" pos="word" start_char="11345">Wuhan</TOKEN>
<TOKEN end_char="11350" id="token-122-11" morph="none" pos="punct" start_char="11350">,</TOKEN>
<TOKEN end_char="11354" id="token-122-12" morph="none" pos="word" start_char="11352">one</TOKEN>
<TOKEN end_char="11357" id="token-122-13" morph="none" pos="word" start_char="11356">of</TOKEN>
<TOKEN end_char="11363" id="token-122-14" morph="none" pos="word" start_char="11359">which</TOKEN>
<TOKEN end_char="11367" id="token-122-15" morph="none" pos="word" start_char="11365">was</TOKEN>
<TOKEN end_char="11372" id="token-122-16" morph="none" pos="word" start_char="11369">only</TOKEN>
<TOKEN end_char="11376" id="token-122-17" morph="none" pos="word" start_char="11374">280</TOKEN>
<TOKEN end_char="11383" id="token-122-18" morph="none" pos="word" start_char="11378">meters</TOKEN>
<TOKEN end_char="11388" id="token-122-19" morph="none" pos="word" start_char="11385">from</TOKEN>
<TOKEN end_char="11392" id="token-122-20" morph="none" pos="word" start_char="11390">the</TOKEN>
<TOKEN end_char="11400" id="token-122-21" morph="none" pos="word" start_char="11394">seafood</TOKEN>
<TOKEN end_char="11407" id="token-122-22" morph="none" pos="word" start_char="11402">market</TOKEN>
<TOKEN end_char="11408" id="token-122-23" morph="none" pos="punct" start_char="11408">.</TOKEN>
</SEG>
<SEG end_char="11535" id="segment-123" start_char="11410">
<ORIGINAL_TEXT>We briefly examined the histories of the laboratories and proposed that the coronavirus probably originated from a laboratory.</ORIGINAL_TEXT>
<TOKEN end_char="11411" id="token-123-0" morph="none" pos="word" start_char="11410">We</TOKEN>
<TOKEN end_char="11419" id="token-123-1" morph="none" pos="word" start_char="11413">briefly</TOKEN>
<TOKEN end_char="11428" id="token-123-2" morph="none" pos="word" start_char="11421">examined</TOKEN>
<TOKEN end_char="11432" id="token-123-3" morph="none" pos="word" start_char="11430">the</TOKEN>
<TOKEN end_char="11442" id="token-123-4" morph="none" pos="word" start_char="11434">histories</TOKEN>
<TOKEN end_char="11445" id="token-123-5" morph="none" pos="word" start_char="11444">of</TOKEN>
<TOKEN end_char="11449" id="token-123-6" morph="none" pos="word" start_char="11447">the</TOKEN>
<TOKEN end_char="11462" id="token-123-7" morph="none" pos="word" start_char="11451">laboratories</TOKEN>
<TOKEN end_char="11466" id="token-123-8" morph="none" pos="word" start_char="11464">and</TOKEN>
<TOKEN end_char="11475" id="token-123-9" morph="none" pos="word" start_char="11468">proposed</TOKEN>
<TOKEN end_char="11480" id="token-123-10" morph="none" pos="word" start_char="11477">that</TOKEN>
<TOKEN end_char="11484" id="token-123-11" morph="none" pos="word" start_char="11482">the</TOKEN>
<TOKEN end_char="11496" id="token-123-12" morph="none" pos="word" start_char="11486">coronavirus</TOKEN>
<TOKEN end_char="11505" id="token-123-13" morph="none" pos="word" start_char="11498">probably</TOKEN>
<TOKEN end_char="11516" id="token-123-14" morph="none" pos="word" start_char="11507">originated</TOKEN>
<TOKEN end_char="11521" id="token-123-15" morph="none" pos="word" start_char="11518">from</TOKEN>
<TOKEN end_char="11523" id="token-123-16" morph="none" pos="word" start_char="11523">a</TOKEN>
<TOKEN end_char="11534" id="token-123-17" morph="none" pos="word" start_char="11525">laboratory</TOKEN>
<TOKEN end_char="11535" id="token-123-18" morph="none" pos="punct" start_char="11535">.</TOKEN>
</SEG>
<SEG end_char="11658" id="segment-124" start_char="11537">
<ORIGINAL_TEXT>Our proposal provided an alternative origin of the coronavirus in addition to natural recombination and intermediate host.</ORIGINAL_TEXT>
<TOKEN end_char="11539" id="token-124-0" morph="none" pos="word" start_char="11537">Our</TOKEN>
<TOKEN end_char="11548" id="token-124-1" morph="none" pos="word" start_char="11541">proposal</TOKEN>
<TOKEN end_char="11557" id="token-124-2" morph="none" pos="word" start_char="11550">provided</TOKEN>
<TOKEN end_char="11560" id="token-124-3" morph="none" pos="word" start_char="11559">an</TOKEN>
<TOKEN end_char="11572" id="token-124-4" morph="none" pos="word" start_char="11562">alternative</TOKEN>
<TOKEN end_char="11579" id="token-124-5" morph="none" pos="word" start_char="11574">origin</TOKEN>
<TOKEN end_char="11582" id="token-124-6" morph="none" pos="word" start_char="11581">of</TOKEN>
<TOKEN end_char="11586" id="token-124-7" morph="none" pos="word" start_char="11584">the</TOKEN>
<TOKEN end_char="11598" id="token-124-8" morph="none" pos="word" start_char="11588">coronavirus</TOKEN>
<TOKEN end_char="11601" id="token-124-9" morph="none" pos="word" start_char="11600">in</TOKEN>
<TOKEN end_char="11610" id="token-124-10" morph="none" pos="word" start_char="11603">addition</TOKEN>
<TOKEN end_char="11613" id="token-124-11" morph="none" pos="word" start_char="11612">to</TOKEN>
<TOKEN end_char="11621" id="token-124-12" morph="none" pos="word" start_char="11615">natural</TOKEN>
<TOKEN end_char="11635" id="token-124-13" morph="none" pos="word" start_char="11623">recombination</TOKEN>
<TOKEN end_char="11639" id="token-124-14" morph="none" pos="word" start_char="11637">and</TOKEN>
<TOKEN end_char="11652" id="token-124-15" morph="none" pos="word" start_char="11641">intermediate</TOKEN>
<TOKEN end_char="11657" id="token-124-16" morph="none" pos="word" start_char="11654">host</TOKEN>
<TOKEN end_char="11658" id="token-124-17" morph="none" pos="punct" start_char="11658">.</TOKEN>
</SEG>
<SEG end_char="11769" id="segment-125" start_char="11661">
<ORIGINAL_TEXT>web.archive.org...://www.researchgate.net/publication/339070128_The_possible_origins_of_2019-nCoV_coronavirus</ORIGINAL_TEXT>
<TOKEN end_char="11769" id="token-125-0" morph="none" pos="unknown" start_char="11661">web.archive.org...://www.researchgate.net/publication/339070128_The_possible_origins_of_2019-nCoV_coronavirus</TOKEN>
</SEG>
<SEG end_char="11809" id="segment-126" start_char="11772">
<ORIGINAL_TEXT>(For some reason i can't fix the link.</ORIGINAL_TEXT>
<TOKEN end_char="11772" id="token-126-0" morph="none" pos="punct" start_char="11772">(</TOKEN>
<TOKEN end_char="11775" id="token-126-1" morph="none" pos="word" start_char="11773">For</TOKEN>
<TOKEN end_char="11780" id="token-126-2" morph="none" pos="word" start_char="11777">some</TOKEN>
<TOKEN end_char="11787" id="token-126-3" morph="none" pos="word" start_char="11782">reason</TOKEN>
<TOKEN end_char="11789" id="token-126-4" morph="none" pos="word" start_char="11789">i</TOKEN>
<TOKEN end_char="11795" id="token-126-5" morph="none" pos="word" start_char="11791">can't</TOKEN>
<TOKEN end_char="11799" id="token-126-6" morph="none" pos="word" start_char="11797">fix</TOKEN>
<TOKEN end_char="11803" id="token-126-7" morph="none" pos="word" start_char="11801">the</TOKEN>
<TOKEN end_char="11808" id="token-126-8" morph="none" pos="word" start_char="11805">link</TOKEN>
<TOKEN end_char="11809" id="token-126-9" morph="none" pos="punct" start_char="11809">.</TOKEN>
</SEG>
<SEG end_char="11920" id="segment-127" start_char="11811">
<ORIGINAL_TEXT>To find the link, which has another link to the entire paper, just copy the url and paste it in a new window.)</ORIGINAL_TEXT>
<TOKEN end_char="11812" id="token-127-0" morph="none" pos="word" start_char="11811">To</TOKEN>
<TOKEN end_char="11817" id="token-127-1" morph="none" pos="word" start_char="11814">find</TOKEN>
<TOKEN end_char="11821" id="token-127-2" morph="none" pos="word" start_char="11819">the</TOKEN>
<TOKEN end_char="11826" id="token-127-3" morph="none" pos="word" start_char="11823">link</TOKEN>
<TOKEN end_char="11827" id="token-127-4" morph="none" pos="punct" start_char="11827">,</TOKEN>
<TOKEN end_char="11833" id="token-127-5" morph="none" pos="word" start_char="11829">which</TOKEN>
<TOKEN end_char="11837" id="token-127-6" morph="none" pos="word" start_char="11835">has</TOKEN>
<TOKEN end_char="11845" id="token-127-7" morph="none" pos="word" start_char="11839">another</TOKEN>
<TOKEN end_char="11850" id="token-127-8" morph="none" pos="word" start_char="11847">link</TOKEN>
<TOKEN end_char="11853" id="token-127-9" morph="none" pos="word" start_char="11852">to</TOKEN>
<TOKEN end_char="11857" id="token-127-10" morph="none" pos="word" start_char="11855">the</TOKEN>
<TOKEN end_char="11864" id="token-127-11" morph="none" pos="word" start_char="11859">entire</TOKEN>
<TOKEN end_char="11870" id="token-127-12" morph="none" pos="word" start_char="11866">paper</TOKEN>
<TOKEN end_char="11871" id="token-127-13" morph="none" pos="punct" start_char="11871">,</TOKEN>
<TOKEN end_char="11876" id="token-127-14" morph="none" pos="word" start_char="11873">just</TOKEN>
<TOKEN end_char="11881" id="token-127-15" morph="none" pos="word" start_char="11878">copy</TOKEN>
<TOKEN end_char="11885" id="token-127-16" morph="none" pos="word" start_char="11883">the</TOKEN>
<TOKEN end_char="11889" id="token-127-17" morph="none" pos="word" start_char="11887">url</TOKEN>
<TOKEN end_char="11893" id="token-127-18" morph="none" pos="word" start_char="11891">and</TOKEN>
<TOKEN end_char="11899" id="token-127-19" morph="none" pos="word" start_char="11895">paste</TOKEN>
<TOKEN end_char="11902" id="token-127-20" morph="none" pos="word" start_char="11901">it</TOKEN>
<TOKEN end_char="11905" id="token-127-21" morph="none" pos="word" start_char="11904">in</TOKEN>
<TOKEN end_char="11907" id="token-127-22" morph="none" pos="word" start_char="11907">a</TOKEN>
<TOKEN end_char="11911" id="token-127-23" morph="none" pos="word" start_char="11909">new</TOKEN>
<TOKEN end_char="11918" id="token-127-24" morph="none" pos="word" start_char="11913">window</TOKEN>
<TOKEN end_char="11920" id="token-127-25" morph="none" pos="punct" start_char="11919">.)</TOKEN>
</SEG>
<SEG end_char="12048" id="segment-128" start_char="11923">
<ORIGINAL_TEXT>BTW, the Chinese government attempted to claim that the "U.S. military released this virus in Wuhan," which of course it's BS.</ORIGINAL_TEXT>
<TOKEN end_char="11925" id="token-128-0" morph="none" pos="word" start_char="11923">BTW</TOKEN>
<TOKEN end_char="11926" id="token-128-1" morph="none" pos="punct" start_char="11926">,</TOKEN>
<TOKEN end_char="11930" id="token-128-2" morph="none" pos="word" start_char="11928">the</TOKEN>
<TOKEN end_char="11938" id="token-128-3" morph="none" pos="word" start_char="11932">Chinese</TOKEN>
<TOKEN end_char="11949" id="token-128-4" morph="none" pos="word" start_char="11940">government</TOKEN>
<TOKEN end_char="11959" id="token-128-5" morph="none" pos="word" start_char="11951">attempted</TOKEN>
<TOKEN end_char="11962" id="token-128-6" morph="none" pos="word" start_char="11961">to</TOKEN>
<TOKEN end_char="11968" id="token-128-7" morph="none" pos="word" start_char="11964">claim</TOKEN>
<TOKEN end_char="11973" id="token-128-8" morph="none" pos="word" start_char="11970">that</TOKEN>
<TOKEN end_char="11977" id="token-128-9" morph="none" pos="word" start_char="11975">the</TOKEN>
<TOKEN end_char="11979" id="token-128-10" morph="none" pos="punct" start_char="11979">"</TOKEN>
<TOKEN end_char="11982" id="token-128-11" morph="none" pos="unknown" start_char="11980">U.S</TOKEN>
<TOKEN end_char="11983" id="token-128-12" morph="none" pos="punct" start_char="11983">.</TOKEN>
<TOKEN end_char="11992" id="token-128-13" morph="none" pos="word" start_char="11985">military</TOKEN>
<TOKEN end_char="12001" id="token-128-14" morph="none" pos="word" start_char="11994">released</TOKEN>
<TOKEN end_char="12006" id="token-128-15" morph="none" pos="word" start_char="12003">this</TOKEN>
<TOKEN end_char="12012" id="token-128-16" morph="none" pos="word" start_char="12008">virus</TOKEN>
<TOKEN end_char="12015" id="token-128-17" morph="none" pos="word" start_char="12014">in</TOKEN>
<TOKEN end_char="12021" id="token-128-18" morph="none" pos="word" start_char="12017">Wuhan</TOKEN>
<TOKEN end_char="12023" id="token-128-19" morph="none" pos="punct" start_char="12022">,"</TOKEN>
<TOKEN end_char="12029" id="token-128-20" morph="none" pos="word" start_char="12025">which</TOKEN>
<TOKEN end_char="12032" id="token-128-21" morph="none" pos="word" start_char="12031">of</TOKEN>
<TOKEN end_char="12039" id="token-128-22" morph="none" pos="word" start_char="12034">course</TOKEN>
<TOKEN end_char="12044" id="token-128-23" morph="none" pos="word" start_char="12041">it's</TOKEN>
<TOKEN end_char="12047" id="token-128-24" morph="none" pos="word" start_char="12046">BS</TOKEN>
<TOKEN end_char="12048" id="token-128-25" morph="none" pos="punct" start_char="12048">.</TOKEN>
</SEG>
<SEG end_char="12141" id="segment-129" start_char="12051">
<ORIGINAL_TEXT>edit on 13-3-2020 by ElectricUniverse because: correct comment and attempt to correct link.</ORIGINAL_TEXT>
<TOKEN end_char="12054" id="token-129-0" morph="none" pos="word" start_char="12051">edit</TOKEN>
<TOKEN end_char="12057" id="token-129-1" morph="none" pos="word" start_char="12056">on</TOKEN>
<TOKEN end_char="12067" id="token-129-2" morph="none" pos="unknown" start_char="12059">13-3-2020</TOKEN>
<TOKEN end_char="12070" id="token-129-3" morph="none" pos="word" start_char="12069">by</TOKEN>
<TOKEN end_char="12087" id="token-129-4" morph="none" pos="word" start_char="12072">ElectricUniverse</TOKEN>
<TOKEN end_char="12095" id="token-129-5" morph="none" pos="word" start_char="12089">because</TOKEN>
<TOKEN end_char="12096" id="token-129-6" morph="none" pos="punct" start_char="12096">:</TOKEN>
<TOKEN end_char="12104" id="token-129-7" morph="none" pos="word" start_char="12098">correct</TOKEN>
<TOKEN end_char="12112" id="token-129-8" morph="none" pos="word" start_char="12106">comment</TOKEN>
<TOKEN end_char="12116" id="token-129-9" morph="none" pos="word" start_char="12114">and</TOKEN>
<TOKEN end_char="12124" id="token-129-10" morph="none" pos="word" start_char="12118">attempt</TOKEN>
<TOKEN end_char="12127" id="token-129-11" morph="none" pos="word" start_char="12126">to</TOKEN>
<TOKEN end_char="12135" id="token-129-12" morph="none" pos="word" start_char="12129">correct</TOKEN>
<TOKEN end_char="12140" id="token-129-13" morph="none" pos="word" start_char="12137">link</TOKEN>
<TOKEN end_char="12141" id="token-129-14" morph="none" pos="punct" start_char="12141">.</TOKEN>
</SEG>
<SEG end_char="12173" id="segment-130" start_char="12146">
<ORIGINAL_TEXT>a reply to: ElectricUniverse</ORIGINAL_TEXT>
<TOKEN end_char="12146" id="token-130-0" morph="none" pos="word" start_char="12146">a</TOKEN>
<TOKEN end_char="12152" id="token-130-1" morph="none" pos="word" start_char="12148">reply</TOKEN>
<TOKEN end_char="12155" id="token-130-2" morph="none" pos="word" start_char="12154">to</TOKEN>
<TOKEN end_char="12156" id="token-130-3" morph="none" pos="punct" start_char="12156">:</TOKEN>
<TOKEN end_char="12173" id="token-130-4" morph="none" pos="word" start_char="12158">ElectricUniverse</TOKEN>
</SEG>
<SEG end_char="12277" id="segment-131" start_char="12176">
<ORIGINAL_TEXT>This virus has been sequenced and deconstructed in multiple state and private labs all over the world.</ORIGINAL_TEXT>
<TOKEN end_char="12179" id="token-131-0" morph="none" pos="word" start_char="12176">This</TOKEN>
<TOKEN end_char="12185" id="token-131-1" morph="none" pos="word" start_char="12181">virus</TOKEN>
<TOKEN end_char="12189" id="token-131-2" morph="none" pos="word" start_char="12187">has</TOKEN>
<TOKEN end_char="12194" id="token-131-3" morph="none" pos="word" start_char="12191">been</TOKEN>
<TOKEN end_char="12204" id="token-131-4" morph="none" pos="word" start_char="12196">sequenced</TOKEN>
<TOKEN end_char="12208" id="token-131-5" morph="none" pos="word" start_char="12206">and</TOKEN>
<TOKEN end_char="12222" id="token-131-6" morph="none" pos="word" start_char="12210">deconstructed</TOKEN>
<TOKEN end_char="12225" id="token-131-7" morph="none" pos="word" start_char="12224">in</TOKEN>
<TOKEN end_char="12234" id="token-131-8" morph="none" pos="word" start_char="12227">multiple</TOKEN>
<TOKEN end_char="12240" id="token-131-9" morph="none" pos="word" start_char="12236">state</TOKEN>
<TOKEN end_char="12244" id="token-131-10" morph="none" pos="word" start_char="12242">and</TOKEN>
<TOKEN end_char="12252" id="token-131-11" morph="none" pos="word" start_char="12246">private</TOKEN>
<TOKEN end_char="12257" id="token-131-12" morph="none" pos="word" start_char="12254">labs</TOKEN>
<TOKEN end_char="12261" id="token-131-13" morph="none" pos="word" start_char="12259">all</TOKEN>
<TOKEN end_char="12266" id="token-131-14" morph="none" pos="word" start_char="12263">over</TOKEN>
<TOKEN end_char="12270" id="token-131-15" morph="none" pos="word" start_char="12268">the</TOKEN>
<TOKEN end_char="12276" id="token-131-16" morph="none" pos="word" start_char="12272">world</TOKEN>
<TOKEN end_char="12277" id="token-131-17" morph="none" pos="punct" start_char="12277">.</TOKEN>
</SEG>
<SEG end_char="12303" id="segment-132" start_char="12279">
<ORIGINAL_TEXT>Including many in the US.</ORIGINAL_TEXT>
<TOKEN end_char="12287" id="token-132-0" morph="none" pos="word" start_char="12279">Including</TOKEN>
<TOKEN end_char="12292" id="token-132-1" morph="none" pos="word" start_char="12289">many</TOKEN>
<TOKEN end_char="12295" id="token-132-2" morph="none" pos="word" start_char="12294">in</TOKEN>
<TOKEN end_char="12299" id="token-132-3" morph="none" pos="word" start_char="12297">the</TOKEN>
<TOKEN end_char="12302" id="token-132-4" morph="none" pos="word" start_char="12301">US</TOKEN>
<TOKEN end_char="12303" id="token-132-5" morph="none" pos="punct" start_char="12303">.</TOKEN>
</SEG>
<SEG end_char="12415" id="segment-133" start_char="12306">
<ORIGINAL_TEXT>So far, nobody has found any trace that might indicate that it was genetically engineered, or even hybridised.</ORIGINAL_TEXT>
<TOKEN end_char="12307" id="token-133-0" morph="none" pos="word" start_char="12306">So</TOKEN>
<TOKEN end_char="12311" id="token-133-1" morph="none" pos="word" start_char="12309">far</TOKEN>
<TOKEN end_char="12312" id="token-133-2" morph="none" pos="punct" start_char="12312">,</TOKEN>
<TOKEN end_char="12319" id="token-133-3" morph="none" pos="word" start_char="12314">nobody</TOKEN>
<TOKEN end_char="12323" id="token-133-4" morph="none" pos="word" start_char="12321">has</TOKEN>
<TOKEN end_char="12329" id="token-133-5" morph="none" pos="word" start_char="12325">found</TOKEN>
<TOKEN end_char="12333" id="token-133-6" morph="none" pos="word" start_char="12331">any</TOKEN>
<TOKEN end_char="12339" id="token-133-7" morph="none" pos="word" start_char="12335">trace</TOKEN>
<TOKEN end_char="12344" id="token-133-8" morph="none" pos="word" start_char="12341">that</TOKEN>
<TOKEN end_char="12350" id="token-133-9" morph="none" pos="word" start_char="12346">might</TOKEN>
<TOKEN end_char="12359" id="token-133-10" morph="none" pos="word" start_char="12352">indicate</TOKEN>
<TOKEN end_char="12364" id="token-133-11" morph="none" pos="word" start_char="12361">that</TOKEN>
<TOKEN end_char="12367" id="token-133-12" morph="none" pos="word" start_char="12366">it</TOKEN>
<TOKEN end_char="12371" id="token-133-13" morph="none" pos="word" start_char="12369">was</TOKEN>
<TOKEN end_char="12383" id="token-133-14" morph="none" pos="word" start_char="12373">genetically</TOKEN>
<TOKEN end_char="12394" id="token-133-15" morph="none" pos="word" start_char="12385">engineered</TOKEN>
<TOKEN end_char="12395" id="token-133-16" morph="none" pos="punct" start_char="12395">,</TOKEN>
<TOKEN end_char="12398" id="token-133-17" morph="none" pos="word" start_char="12397">or</TOKEN>
<TOKEN end_char="12403" id="token-133-18" morph="none" pos="word" start_char="12400">even</TOKEN>
<TOKEN end_char="12414" id="token-133-19" morph="none" pos="word" start_char="12405">hybridised</TOKEN>
<TOKEN end_char="12415" id="token-133-20" morph="none" pos="punct" start_char="12415">.</TOKEN>
</SEG>
<SEG end_char="12568" id="segment-134" start_char="12418">
<ORIGINAL_TEXT>The technology for gene editing is well known, and it leaves marks on the subject that would stand out to any expert where parts were added or removed.</ORIGINAL_TEXT>
<TOKEN end_char="12420" id="token-134-0" morph="none" pos="word" start_char="12418">The</TOKEN>
<TOKEN end_char="12431" id="token-134-1" morph="none" pos="word" start_char="12422">technology</TOKEN>
<TOKEN end_char="12435" id="token-134-2" morph="none" pos="word" start_char="12433">for</TOKEN>
<TOKEN end_char="12440" id="token-134-3" morph="none" pos="word" start_char="12437">gene</TOKEN>
<TOKEN end_char="12448" id="token-134-4" morph="none" pos="word" start_char="12442">editing</TOKEN>
<TOKEN end_char="12451" id="token-134-5" morph="none" pos="word" start_char="12450">is</TOKEN>
<TOKEN end_char="12456" id="token-134-6" morph="none" pos="word" start_char="12453">well</TOKEN>
<TOKEN end_char="12462" id="token-134-7" morph="none" pos="word" start_char="12458">known</TOKEN>
<TOKEN end_char="12463" id="token-134-8" morph="none" pos="punct" start_char="12463">,</TOKEN>
<TOKEN end_char="12467" id="token-134-9" morph="none" pos="word" start_char="12465">and</TOKEN>
<TOKEN end_char="12470" id="token-134-10" morph="none" pos="word" start_char="12469">it</TOKEN>
<TOKEN end_char="12477" id="token-134-11" morph="none" pos="word" start_char="12472">leaves</TOKEN>
<TOKEN end_char="12483" id="token-134-12" morph="none" pos="word" start_char="12479">marks</TOKEN>
<TOKEN end_char="12486" id="token-134-13" morph="none" pos="word" start_char="12485">on</TOKEN>
<TOKEN end_char="12490" id="token-134-14" morph="none" pos="word" start_char="12488">the</TOKEN>
<TOKEN end_char="12498" id="token-134-15" morph="none" pos="word" start_char="12492">subject</TOKEN>
<TOKEN end_char="12503" id="token-134-16" morph="none" pos="word" start_char="12500">that</TOKEN>
<TOKEN end_char="12509" id="token-134-17" morph="none" pos="word" start_char="12505">would</TOKEN>
<TOKEN end_char="12515" id="token-134-18" morph="none" pos="word" start_char="12511">stand</TOKEN>
<TOKEN end_char="12519" id="token-134-19" morph="none" pos="word" start_char="12517">out</TOKEN>
<TOKEN end_char="12522" id="token-134-20" morph="none" pos="word" start_char="12521">to</TOKEN>
<TOKEN end_char="12526" id="token-134-21" morph="none" pos="word" start_char="12524">any</TOKEN>
<TOKEN end_char="12533" id="token-134-22" morph="none" pos="word" start_char="12528">expert</TOKEN>
<TOKEN end_char="12539" id="token-134-23" morph="none" pos="word" start_char="12535">where</TOKEN>
<TOKEN end_char="12545" id="token-134-24" morph="none" pos="word" start_char="12541">parts</TOKEN>
<TOKEN end_char="12550" id="token-134-25" morph="none" pos="word" start_char="12547">were</TOKEN>
<TOKEN end_char="12556" id="token-134-26" morph="none" pos="word" start_char="12552">added</TOKEN>
<TOKEN end_char="12559" id="token-134-27" morph="none" pos="word" start_char="12558">or</TOKEN>
<TOKEN end_char="12567" id="token-134-28" morph="none" pos="word" start_char="12561">removed</TOKEN>
<TOKEN end_char="12568" id="token-134-29" morph="none" pos="punct" start_char="12568">.</TOKEN>
</SEG>
<SEG end_char="12712" id="segment-135" start_char="12571">
<ORIGINAL_TEXT>If this virus is man made the it's been made using a technology that is completely unknown to science, and which leaves no recognizable trace.</ORIGINAL_TEXT>
<TOKEN end_char="12572" id="token-135-0" morph="none" pos="word" start_char="12571">If</TOKEN>
<TOKEN end_char="12577" id="token-135-1" morph="none" pos="word" start_char="12574">this</TOKEN>
<TOKEN end_char="12583" id="token-135-2" morph="none" pos="word" start_char="12579">virus</TOKEN>
<TOKEN end_char="12586" id="token-135-3" morph="none" pos="word" start_char="12585">is</TOKEN>
<TOKEN end_char="12590" id="token-135-4" morph="none" pos="word" start_char="12588">man</TOKEN>
<TOKEN end_char="12595" id="token-135-5" morph="none" pos="word" start_char="12592">made</TOKEN>
<TOKEN end_char="12599" id="token-135-6" morph="none" pos="word" start_char="12597">the</TOKEN>
<TOKEN end_char="12604" id="token-135-7" morph="none" pos="word" start_char="12601">it's</TOKEN>
<TOKEN end_char="12609" id="token-135-8" morph="none" pos="word" start_char="12606">been</TOKEN>
<TOKEN end_char="12614" id="token-135-9" morph="none" pos="word" start_char="12611">made</TOKEN>
<TOKEN end_char="12620" id="token-135-10" morph="none" pos="word" start_char="12616">using</TOKEN>
<TOKEN end_char="12622" id="token-135-11" morph="none" pos="word" start_char="12622">a</TOKEN>
<TOKEN end_char="12633" id="token-135-12" morph="none" pos="word" start_char="12624">technology</TOKEN>
<TOKEN end_char="12638" id="token-135-13" morph="none" pos="word" start_char="12635">that</TOKEN>
<TOKEN end_char="12641" id="token-135-14" morph="none" pos="word" start_char="12640">is</TOKEN>
<TOKEN end_char="12652" id="token-135-15" morph="none" pos="word" start_char="12643">completely</TOKEN>
<TOKEN end_char="12660" id="token-135-16" morph="none" pos="word" start_char="12654">unknown</TOKEN>
<TOKEN end_char="12663" id="token-135-17" morph="none" pos="word" start_char="12662">to</TOKEN>
<TOKEN end_char="12671" id="token-135-18" morph="none" pos="word" start_char="12665">science</TOKEN>
<TOKEN end_char="12672" id="token-135-19" morph="none" pos="punct" start_char="12672">,</TOKEN>
<TOKEN end_char="12676" id="token-135-20" morph="none" pos="word" start_char="12674">and</TOKEN>
<TOKEN end_char="12682" id="token-135-21" morph="none" pos="word" start_char="12678">which</TOKEN>
<TOKEN end_char="12689" id="token-135-22" morph="none" pos="word" start_char="12684">leaves</TOKEN>
<TOKEN end_char="12692" id="token-135-23" morph="none" pos="word" start_char="12691">no</TOKEN>
<TOKEN end_char="12705" id="token-135-24" morph="none" pos="word" start_char="12694">recognizable</TOKEN>
<TOKEN end_char="12711" id="token-135-25" morph="none" pos="word" start_char="12707">trace</TOKEN>
<TOKEN end_char="12712" id="token-135-26" morph="none" pos="punct" start_char="12712">.</TOKEN>
</SEG>
<SEG end_char="12786" id="segment-136" start_char="12714">
<ORIGINAL_TEXT>So, I'm going to go for it being a natural organizm and not a bio-weapon.</ORIGINAL_TEXT>
<TOKEN end_char="12715" id="token-136-0" morph="none" pos="word" start_char="12714">So</TOKEN>
<TOKEN end_char="12716" id="token-136-1" morph="none" pos="punct" start_char="12716">,</TOKEN>
<TOKEN end_char="12720" id="token-136-2" morph="none" pos="word" start_char="12718">I'm</TOKEN>
<TOKEN end_char="12726" id="token-136-3" morph="none" pos="word" start_char="12722">going</TOKEN>
<TOKEN end_char="12729" id="token-136-4" morph="none" pos="word" start_char="12728">to</TOKEN>
<TOKEN end_char="12732" id="token-136-5" morph="none" pos="word" start_char="12731">go</TOKEN>
<TOKEN end_char="12736" id="token-136-6" morph="none" pos="word" start_char="12734">for</TOKEN>
<TOKEN end_char="12739" id="token-136-7" morph="none" pos="word" start_char="12738">it</TOKEN>
<TOKEN end_char="12745" id="token-136-8" morph="none" pos="word" start_char="12741">being</TOKEN>
<TOKEN end_char="12747" id="token-136-9" morph="none" pos="word" start_char="12747">a</TOKEN>
<TOKEN end_char="12755" id="token-136-10" morph="none" pos="word" start_char="12749">natural</TOKEN>
<TOKEN end_char="12764" id="token-136-11" morph="none" pos="word" start_char="12757">organizm</TOKEN>
<TOKEN end_char="12768" id="token-136-12" morph="none" pos="word" start_char="12766">and</TOKEN>
<TOKEN end_char="12772" id="token-136-13" morph="none" pos="word" start_char="12770">not</TOKEN>
<TOKEN end_char="12774" id="token-136-14" morph="none" pos="word" start_char="12774">a</TOKEN>
<TOKEN end_char="12785" id="token-136-15" morph="none" pos="unknown" start_char="12776">bio-weapon</TOKEN>
<TOKEN end_char="12786" id="token-136-16" morph="none" pos="punct" start_char="12786">.</TOKEN>
</SEG>
<SEG end_char="12870" id="segment-137" start_char="12791">
<ORIGINAL_TEXT>originally posted by: The2Billies a reply to: ElectricUniverse Of course it did.</ORIGINAL_TEXT>
<TOKEN end_char="12800" id="token-137-0" morph="none" pos="word" start_char="12791">originally</TOKEN>
<TOKEN end_char="12807" id="token-137-1" morph="none" pos="word" start_char="12802">posted</TOKEN>
<TOKEN end_char="12810" id="token-137-2" morph="none" pos="word" start_char="12809">by</TOKEN>
<TOKEN end_char="12811" id="token-137-3" morph="none" pos="punct" start_char="12811">:</TOKEN>
<TOKEN end_char="12823" id="token-137-4" morph="none" pos="word" start_char="12813">The2Billies</TOKEN>
<TOKEN end_char="12825" id="token-137-5" morph="none" pos="word" start_char="12825">a</TOKEN>
<TOKEN end_char="12831" id="token-137-6" morph="none" pos="word" start_char="12827">reply</TOKEN>
<TOKEN end_char="12834" id="token-137-7" morph="none" pos="word" start_char="12833">to</TOKEN>
<TOKEN end_char="12835" id="token-137-8" morph="none" pos="punct" start_char="12835">:</TOKEN>
<TOKEN end_char="12852" id="token-137-9" morph="none" pos="word" start_char="12837">ElectricUniverse</TOKEN>
<TOKEN end_char="12855" id="token-137-10" morph="none" pos="word" start_char="12854">Of</TOKEN>
<TOKEN end_char="12862" id="token-137-11" morph="none" pos="word" start_char="12857">course</TOKEN>
<TOKEN end_char="12865" id="token-137-12" morph="none" pos="word" start_char="12864">it</TOKEN>
<TOKEN end_char="12869" id="token-137-13" morph="none" pos="word" start_char="12867">did</TOKEN>
<TOKEN end_char="12870" id="token-137-14" morph="none" pos="punct" start_char="12870">.</TOKEN>
</SEG>
<SEG end_char="12943" id="segment-138" start_char="12872">
<ORIGINAL_TEXT>It started near a bioweapon facility and several bioresearch facilities.</ORIGINAL_TEXT>
<TOKEN end_char="12873" id="token-138-0" morph="none" pos="word" start_char="12872">It</TOKEN>
<TOKEN end_char="12881" id="token-138-1" morph="none" pos="word" start_char="12875">started</TOKEN>
<TOKEN end_char="12886" id="token-138-2" morph="none" pos="word" start_char="12883">near</TOKEN>
<TOKEN end_char="12888" id="token-138-3" morph="none" pos="word" start_char="12888">a</TOKEN>
<TOKEN end_char="12898" id="token-138-4" morph="none" pos="word" start_char="12890">bioweapon</TOKEN>
<TOKEN end_char="12907" id="token-138-5" morph="none" pos="word" start_char="12900">facility</TOKEN>
<TOKEN end_char="12911" id="token-138-6" morph="none" pos="word" start_char="12909">and</TOKEN>
<TOKEN end_char="12919" id="token-138-7" morph="none" pos="word" start_char="12913">several</TOKEN>
<TOKEN end_char="12931" id="token-138-8" morph="none" pos="word" start_char="12921">bioresearch</TOKEN>
<TOKEN end_char="12942" id="token-138-9" morph="none" pos="word" start_char="12933">facilities</TOKEN>
<TOKEN end_char="12943" id="token-138-10" morph="none" pos="punct" start_char="12943">.</TOKEN>
</SEG>
<SEG end_char="12978" id="segment-139" start_char="12945">
<ORIGINAL_TEXT>Too much a coincidence to dismiss.</ORIGINAL_TEXT>
<TOKEN end_char="12947" id="token-139-0" morph="none" pos="word" start_char="12945">Too</TOKEN>
<TOKEN end_char="12952" id="token-139-1" morph="none" pos="word" start_char="12949">much</TOKEN>
<TOKEN end_char="12954" id="token-139-2" morph="none" pos="word" start_char="12954">a</TOKEN>
<TOKEN end_char="12966" id="token-139-3" morph="none" pos="word" start_char="12956">coincidence</TOKEN>
<TOKEN end_char="12969" id="token-139-4" morph="none" pos="word" start_char="12968">to</TOKEN>
<TOKEN end_char="12977" id="token-139-5" morph="none" pos="word" start_char="12971">dismiss</TOKEN>
<TOKEN end_char="12978" id="token-139-6" morph="none" pos="punct" start_char="12978">.</TOKEN>
</SEG>
<SEG end_char="13056" id="segment-140" start_char="12980">
<ORIGINAL_TEXT>Especially since the virus is truly beneficial to Chinese society as a whole.</ORIGINAL_TEXT>
<TOKEN end_char="12989" id="token-140-0" morph="none" pos="word" start_char="12980">Especially</TOKEN>
<TOKEN end_char="12995" id="token-140-1" morph="none" pos="word" start_char="12991">since</TOKEN>
<TOKEN end_char="12999" id="token-140-2" morph="none" pos="word" start_char="12997">the</TOKEN>
<TOKEN end_char="13005" id="token-140-3" morph="none" pos="word" start_char="13001">virus</TOKEN>
<TOKEN end_char="13008" id="token-140-4" morph="none" pos="word" start_char="13007">is</TOKEN>
<TOKEN end_char="13014" id="token-140-5" morph="none" pos="word" start_char="13010">truly</TOKEN>
<TOKEN end_char="13025" id="token-140-6" morph="none" pos="word" start_char="13016">beneficial</TOKEN>
<TOKEN end_char="13028" id="token-140-7" morph="none" pos="word" start_char="13027">to</TOKEN>
<TOKEN end_char="13036" id="token-140-8" morph="none" pos="word" start_char="13030">Chinese</TOKEN>
<TOKEN end_char="13044" id="token-140-9" morph="none" pos="word" start_char="13038">society</TOKEN>
<TOKEN end_char="13047" id="token-140-10" morph="none" pos="word" start_char="13046">as</TOKEN>
<TOKEN end_char="13049" id="token-140-11" morph="none" pos="word" start_char="13049">a</TOKEN>
<TOKEN end_char="13055" id="token-140-12" morph="none" pos="word" start_char="13051">whole</TOKEN>
<TOKEN end_char="13056" id="token-140-13" morph="none" pos="punct" start_char="13056">.</TOKEN>
</SEG>
<SEG end_char="13112" id="segment-141" start_char="13058">
<ORIGINAL_TEXT>China is a communist country, individuals mean nothing.</ORIGINAL_TEXT>
<TOKEN end_char="13062" id="token-141-0" morph="none" pos="word" start_char="13058">China</TOKEN>
<TOKEN end_char="13065" id="token-141-1" morph="none" pos="word" start_char="13064">is</TOKEN>
<TOKEN end_char="13067" id="token-141-2" morph="none" pos="word" start_char="13067">a</TOKEN>
<TOKEN end_char="13077" id="token-141-3" morph="none" pos="word" start_char="13069">communist</TOKEN>
<TOKEN end_char="13085" id="token-141-4" morph="none" pos="word" start_char="13079">country</TOKEN>
<TOKEN end_char="13086" id="token-141-5" morph="none" pos="punct" start_char="13086">,</TOKEN>
<TOKEN end_char="13098" id="token-141-6" morph="none" pos="word" start_char="13088">individuals</TOKEN>
<TOKEN end_char="13103" id="token-141-7" morph="none" pos="word" start_char="13100">mean</TOKEN>
<TOKEN end_char="13111" id="token-141-8" morph="none" pos="word" start_char="13105">nothing</TOKEN>
<TOKEN end_char="13112" id="token-141-9" morph="none" pos="punct" start_char="13112">.</TOKEN>
</SEG>
<SEG end_char="13178" id="segment-142" start_char="13114">
<ORIGINAL_TEXT>Everything is done for the good of the whole, society as a whole.</ORIGINAL_TEXT>
<TOKEN end_char="13123" id="token-142-0" morph="none" pos="word" start_char="13114">Everything</TOKEN>
<TOKEN end_char="13126" id="token-142-1" morph="none" pos="word" start_char="13125">is</TOKEN>
<TOKEN end_char="13131" id="token-142-2" morph="none" pos="word" start_char="13128">done</TOKEN>
<TOKEN end_char="13135" id="token-142-3" morph="none" pos="word" start_char="13133">for</TOKEN>
<TOKEN end_char="13139" id="token-142-4" morph="none" pos="word" start_char="13137">the</TOKEN>
<TOKEN end_char="13144" id="token-142-5" morph="none" pos="word" start_char="13141">good</TOKEN>
<TOKEN end_char="13147" id="token-142-6" morph="none" pos="word" start_char="13146">of</TOKEN>
<TOKEN end_char="13151" id="token-142-7" morph="none" pos="word" start_char="13149">the</TOKEN>
<TOKEN end_char="13157" id="token-142-8" morph="none" pos="word" start_char="13153">whole</TOKEN>
<TOKEN end_char="13158" id="token-142-9" morph="none" pos="punct" start_char="13158">,</TOKEN>
<TOKEN end_char="13166" id="token-142-10" morph="none" pos="word" start_char="13160">society</TOKEN>
<TOKEN end_char="13169" id="token-142-11" morph="none" pos="word" start_char="13168">as</TOKEN>
<TOKEN end_char="13171" id="token-142-12" morph="none" pos="word" start_char="13171">a</TOKEN>
<TOKEN end_char="13177" id="token-142-13" morph="none" pos="word" start_char="13173">whole</TOKEN>
<TOKEN end_char="13178" id="token-142-14" morph="none" pos="punct" start_char="13178">.</TOKEN>
</SEG>
<SEG end_char="13230" id="segment-143" start_char="13180">
<ORIGINAL_TEXT>They have a enormous problem with too many elderly.</ORIGINAL_TEXT>
<TOKEN end_char="13183" id="token-143-0" morph="none" pos="word" start_char="13180">They</TOKEN>
<TOKEN end_char="13188" id="token-143-1" morph="none" pos="word" start_char="13185">have</TOKEN>
<TOKEN end_char="13190" id="token-143-2" morph="none" pos="word" start_char="13190">a</TOKEN>
<TOKEN end_char="13199" id="token-143-3" morph="none" pos="word" start_char="13192">enormous</TOKEN>
<TOKEN end_char="13207" id="token-143-4" morph="none" pos="word" start_char="13201">problem</TOKEN>
<TOKEN end_char="13212" id="token-143-5" morph="none" pos="word" start_char="13209">with</TOKEN>
<TOKEN end_char="13216" id="token-143-6" morph="none" pos="word" start_char="13214">too</TOKEN>
<TOKEN end_char="13221" id="token-143-7" morph="none" pos="word" start_char="13218">many</TOKEN>
<TOKEN end_char="13229" id="token-143-8" morph="none" pos="word" start_char="13223">elderly</TOKEN>
<TOKEN end_char="13230" id="token-143-9" morph="none" pos="punct" start_char="13230">.</TOKEN>
</SEG>
<SEG end_char="13266" id="segment-144" start_char="13232">
<ORIGINAL_TEXT>This is due their one child policy.</ORIGINAL_TEXT>
<TOKEN end_char="13235" id="token-144-0" morph="none" pos="word" start_char="13232">This</TOKEN>
<TOKEN end_char="13238" id="token-144-1" morph="none" pos="word" start_char="13237">is</TOKEN>
<TOKEN end_char="13242" id="token-144-2" morph="none" pos="word" start_char="13240">due</TOKEN>
<TOKEN end_char="13248" id="token-144-3" morph="none" pos="word" start_char="13244">their</TOKEN>
<TOKEN end_char="13252" id="token-144-4" morph="none" pos="word" start_char="13250">one</TOKEN>
<TOKEN end_char="13258" id="token-144-5" morph="none" pos="word" start_char="13254">child</TOKEN>
<TOKEN end_char="13265" id="token-144-6" morph="none" pos="word" start_char="13260">policy</TOKEN>
<TOKEN end_char="13266" id="token-144-7" morph="none" pos="punct" start_char="13266">.</TOKEN>
</SEG>
<SEG end_char="13423" id="segment-145" start_char="13268">
<ORIGINAL_TEXT>Right now on average a couple is supporting themselves, their child/ren, and FOUR other adults, this is their culture- no to few facilities for the elderly.</ORIGINAL_TEXT>
<TOKEN end_char="13272" id="token-145-0" morph="none" pos="word" start_char="13268">Right</TOKEN>
<TOKEN end_char="13276" id="token-145-1" morph="none" pos="word" start_char="13274">now</TOKEN>
<TOKEN end_char="13279" id="token-145-2" morph="none" pos="word" start_char="13278">on</TOKEN>
<TOKEN end_char="13287" id="token-145-3" morph="none" pos="word" start_char="13281">average</TOKEN>
<TOKEN end_char="13289" id="token-145-4" morph="none" pos="word" start_char="13289">a</TOKEN>
<TOKEN end_char="13296" id="token-145-5" morph="none" pos="word" start_char="13291">couple</TOKEN>
<TOKEN end_char="13299" id="token-145-6" morph="none" pos="word" start_char="13298">is</TOKEN>
<TOKEN end_char="13310" id="token-145-7" morph="none" pos="word" start_char="13301">supporting</TOKEN>
<TOKEN end_char="13321" id="token-145-8" morph="none" pos="word" start_char="13312">themselves</TOKEN>
<TOKEN end_char="13322" id="token-145-9" morph="none" pos="punct" start_char="13322">,</TOKEN>
<TOKEN end_char="13328" id="token-145-10" morph="none" pos="word" start_char="13324">their</TOKEN>
<TOKEN end_char="13338" id="token-145-11" morph="none" pos="unknown" start_char="13330">child/ren</TOKEN>
<TOKEN end_char="13339" id="token-145-12" morph="none" pos="punct" start_char="13339">,</TOKEN>
<TOKEN end_char="13343" id="token-145-13" morph="none" pos="word" start_char="13341">and</TOKEN>
<TOKEN end_char="13348" id="token-145-14" morph="none" pos="word" start_char="13345">FOUR</TOKEN>
<TOKEN end_char="13354" id="token-145-15" morph="none" pos="word" start_char="13350">other</TOKEN>
<TOKEN end_char="13361" id="token-145-16" morph="none" pos="word" start_char="13356">adults</TOKEN>
<TOKEN end_char="13362" id="token-145-17" morph="none" pos="punct" start_char="13362">,</TOKEN>
<TOKEN end_char="13367" id="token-145-18" morph="none" pos="word" start_char="13364">this</TOKEN>
<TOKEN end_char="13370" id="token-145-19" morph="none" pos="word" start_char="13369">is</TOKEN>
<TOKEN end_char="13376" id="token-145-20" morph="none" pos="word" start_char="13372">their</TOKEN>
<TOKEN end_char="13384" id="token-145-21" morph="none" pos="word" start_char="13378">culture</TOKEN>
<TOKEN end_char="13385" id="token-145-22" morph="none" pos="punct" start_char="13385">-</TOKEN>
<TOKEN end_char="13388" id="token-145-23" morph="none" pos="word" start_char="13387">no</TOKEN>
<TOKEN end_char="13391" id="token-145-24" morph="none" pos="word" start_char="13390">to</TOKEN>
<TOKEN end_char="13395" id="token-145-25" morph="none" pos="word" start_char="13393">few</TOKEN>
<TOKEN end_char="13406" id="token-145-26" morph="none" pos="word" start_char="13397">facilities</TOKEN>
<TOKEN end_char="13410" id="token-145-27" morph="none" pos="word" start_char="13408">for</TOKEN>
<TOKEN end_char="13414" id="token-145-28" morph="none" pos="word" start_char="13412">the</TOKEN>
<TOKEN end_char="13422" id="token-145-29" morph="none" pos="word" start_char="13416">elderly</TOKEN>
<TOKEN end_char="13423" id="token-145-30" morph="none" pos="punct" start_char="13423">.</TOKEN>
</SEG>
<SEG end_char="13506" id="segment-146" start_char="13425">
<ORIGINAL_TEXT>This virus is specifically designed to kill the elderly and not harm young people.</ORIGINAL_TEXT>
<TOKEN end_char="13428" id="token-146-0" morph="none" pos="word" start_char="13425">This</TOKEN>
<TOKEN end_char="13434" id="token-146-1" morph="none" pos="word" start_char="13430">virus</TOKEN>
<TOKEN end_char="13437" id="token-146-2" morph="none" pos="word" start_char="13436">is</TOKEN>
<TOKEN end_char="13450" id="token-146-3" morph="none" pos="word" start_char="13439">specifically</TOKEN>
<TOKEN end_char="13459" id="token-146-4" morph="none" pos="word" start_char="13452">designed</TOKEN>
<TOKEN end_char="13462" id="token-146-5" morph="none" pos="word" start_char="13461">to</TOKEN>
<TOKEN end_char="13467" id="token-146-6" morph="none" pos="word" start_char="13464">kill</TOKEN>
<TOKEN end_char="13471" id="token-146-7" morph="none" pos="word" start_char="13469">the</TOKEN>
<TOKEN end_char="13479" id="token-146-8" morph="none" pos="word" start_char="13473">elderly</TOKEN>
<TOKEN end_char="13483" id="token-146-9" morph="none" pos="word" start_char="13481">and</TOKEN>
<TOKEN end_char="13487" id="token-146-10" morph="none" pos="word" start_char="13485">not</TOKEN>
<TOKEN end_char="13492" id="token-146-11" morph="none" pos="word" start_char="13489">harm</TOKEN>
<TOKEN end_char="13498" id="token-146-12" morph="none" pos="word" start_char="13494">young</TOKEN>
<TOKEN end_char="13505" id="token-146-13" morph="none" pos="word" start_char="13500">people</TOKEN>
<TOKEN end_char="13506" id="token-146-14" morph="none" pos="punct" start_char="13506">.</TOKEN>
</SEG>
<SEG end_char="13578" id="segment-147" start_char="13508">
<ORIGINAL_TEXT>An excellent way to genocide the elderly without looking like they did.</ORIGINAL_TEXT>
<TOKEN end_char="13509" id="token-147-0" morph="none" pos="word" start_char="13508">An</TOKEN>
<TOKEN end_char="13519" id="token-147-1" morph="none" pos="word" start_char="13511">excellent</TOKEN>
<TOKEN end_char="13523" id="token-147-2" morph="none" pos="word" start_char="13521">way</TOKEN>
<TOKEN end_char="13526" id="token-147-3" morph="none" pos="word" start_char="13525">to</TOKEN>
<TOKEN end_char="13535" id="token-147-4" morph="none" pos="word" start_char="13528">genocide</TOKEN>
<TOKEN end_char="13539" id="token-147-5" morph="none" pos="word" start_char="13537">the</TOKEN>
<TOKEN end_char="13547" id="token-147-6" morph="none" pos="word" start_char="13541">elderly</TOKEN>
<TOKEN end_char="13555" id="token-147-7" morph="none" pos="word" start_char="13549">without</TOKEN>
<TOKEN end_char="13563" id="token-147-8" morph="none" pos="word" start_char="13557">looking</TOKEN>
<TOKEN end_char="13568" id="token-147-9" morph="none" pos="word" start_char="13565">like</TOKEN>
<TOKEN end_char="13573" id="token-147-10" morph="none" pos="word" start_char="13570">they</TOKEN>
<TOKEN end_char="13577" id="token-147-11" morph="none" pos="word" start_char="13575">did</TOKEN>
<TOKEN end_char="13578" id="token-147-12" morph="none" pos="punct" start_char="13578">.</TOKEN>
</SEG>
<SEG end_char="13733" id="segment-148" start_char="13580">
<ORIGINAL_TEXT>There are always outliers who die from any virus, like health workers forced by the government to work 24/7 without rest or minimal rest for weeks on end.</ORIGINAL_TEXT>
<TOKEN end_char="13584" id="token-148-0" morph="none" pos="word" start_char="13580">There</TOKEN>
<TOKEN end_char="13588" id="token-148-1" morph="none" pos="word" start_char="13586">are</TOKEN>
<TOKEN end_char="13595" id="token-148-2" morph="none" pos="word" start_char="13590">always</TOKEN>
<TOKEN end_char="13604" id="token-148-3" morph="none" pos="word" start_char="13597">outliers</TOKEN>
<TOKEN end_char="13608" id="token-148-4" morph="none" pos="word" start_char="13606">who</TOKEN>
<TOKEN end_char="13612" id="token-148-5" morph="none" pos="word" start_char="13610">die</TOKEN>
<TOKEN end_char="13617" id="token-148-6" morph="none" pos="word" start_char="13614">from</TOKEN>
<TOKEN end_char="13621" id="token-148-7" morph="none" pos="word" start_char="13619">any</TOKEN>
<TOKEN end_char="13627" id="token-148-8" morph="none" pos="word" start_char="13623">virus</TOKEN>
<TOKEN end_char="13628" id="token-148-9" morph="none" pos="punct" start_char="13628">,</TOKEN>
<TOKEN end_char="13633" id="token-148-10" morph="none" pos="word" start_char="13630">like</TOKEN>
<TOKEN end_char="13640" id="token-148-11" morph="none" pos="word" start_char="13635">health</TOKEN>
<TOKEN end_char="13648" id="token-148-12" morph="none" pos="word" start_char="13642">workers</TOKEN>
<TOKEN end_char="13655" id="token-148-13" morph="none" pos="word" start_char="13650">forced</TOKEN>
<TOKEN end_char="13658" id="token-148-14" morph="none" pos="word" start_char="13657">by</TOKEN>
<TOKEN end_char="13662" id="token-148-15" morph="none" pos="word" start_char="13660">the</TOKEN>
<TOKEN end_char="13673" id="token-148-16" morph="none" pos="word" start_char="13664">government</TOKEN>
<TOKEN end_char="13676" id="token-148-17" morph="none" pos="word" start_char="13675">to</TOKEN>
<TOKEN end_char="13681" id="token-148-18" morph="none" pos="word" start_char="13678">work</TOKEN>
<TOKEN end_char="13686" id="token-148-19" morph="none" pos="unknown" start_char="13683">24/7</TOKEN>
<TOKEN end_char="13694" id="token-148-20" morph="none" pos="word" start_char="13688">without</TOKEN>
<TOKEN end_char="13699" id="token-148-21" morph="none" pos="word" start_char="13696">rest</TOKEN>
<TOKEN end_char="13702" id="token-148-22" morph="none" pos="word" start_char="13701">or</TOKEN>
<TOKEN end_char="13710" id="token-148-23" morph="none" pos="word" start_char="13704">minimal</TOKEN>
<TOKEN end_char="13715" id="token-148-24" morph="none" pos="word" start_char="13712">rest</TOKEN>
<TOKEN end_char="13719" id="token-148-25" morph="none" pos="word" start_char="13717">for</TOKEN>
<TOKEN end_char="13725" id="token-148-26" morph="none" pos="word" start_char="13721">weeks</TOKEN>
<TOKEN end_char="13728" id="token-148-27" morph="none" pos="word" start_char="13727">on</TOKEN>
<TOKEN end_char="13732" id="token-148-28" morph="none" pos="word" start_char="13730">end</TOKEN>
<TOKEN end_char="13733" id="token-148-29" morph="none" pos="punct" start_char="13733">.</TOKEN>
</SEG>
<SEG end_char="13829" id="segment-149" start_char="13735">
<ORIGINAL_TEXT>In a socialist/communist country the resource drain from the elderly is reaching crises levels.</ORIGINAL_TEXT>
<TOKEN end_char="13736" id="token-149-0" morph="none" pos="word" start_char="13735">In</TOKEN>
<TOKEN end_char="13738" id="token-149-1" morph="none" pos="word" start_char="13738">a</TOKEN>
<TOKEN end_char="13758" id="token-149-2" morph="none" pos="unknown" start_char="13740">socialist/communist</TOKEN>
<TOKEN end_char="13766" id="token-149-3" morph="none" pos="word" start_char="13760">country</TOKEN>
<TOKEN end_char="13770" id="token-149-4" morph="none" pos="word" start_char="13768">the</TOKEN>
<TOKEN end_char="13779" id="token-149-5" morph="none" pos="word" start_char="13772">resource</TOKEN>
<TOKEN end_char="13785" id="token-149-6" morph="none" pos="word" start_char="13781">drain</TOKEN>
<TOKEN end_char="13790" id="token-149-7" morph="none" pos="word" start_char="13787">from</TOKEN>
<TOKEN end_char="13794" id="token-149-8" morph="none" pos="word" start_char="13792">the</TOKEN>
<TOKEN end_char="13802" id="token-149-9" morph="none" pos="word" start_char="13796">elderly</TOKEN>
<TOKEN end_char="13805" id="token-149-10" morph="none" pos="word" start_char="13804">is</TOKEN>
<TOKEN end_char="13814" id="token-149-11" morph="none" pos="word" start_char="13807">reaching</TOKEN>
<TOKEN end_char="13821" id="token-149-12" morph="none" pos="word" start_char="13816">crises</TOKEN>
<TOKEN end_char="13828" id="token-149-13" morph="none" pos="word" start_char="13823">levels</TOKEN>
<TOKEN end_char="13829" id="token-149-14" morph="none" pos="punct" start_char="13829">.</TOKEN>
</SEG>
<SEG end_char="13904" id="segment-150" start_char="13831">
<ORIGINAL_TEXT>Aside from China, China may see itself as doing good for the entire world.</ORIGINAL_TEXT>
<TOKEN end_char="13835" id="token-150-0" morph="none" pos="word" start_char="13831">Aside</TOKEN>
<TOKEN end_char="13840" id="token-150-1" morph="none" pos="word" start_char="13837">from</TOKEN>
<TOKEN end_char="13846" id="token-150-2" morph="none" pos="word" start_char="13842">China</TOKEN>
<TOKEN end_char="13847" id="token-150-3" morph="none" pos="punct" start_char="13847">,</TOKEN>
<TOKEN end_char="13853" id="token-150-4" morph="none" pos="word" start_char="13849">China</TOKEN>
<TOKEN end_char="13857" id="token-150-5" morph="none" pos="word" start_char="13855">may</TOKEN>
<TOKEN end_char="13861" id="token-150-6" morph="none" pos="word" start_char="13859">see</TOKEN>
<TOKEN end_char="13868" id="token-150-7" morph="none" pos="word" start_char="13863">itself</TOKEN>
<TOKEN end_char="13871" id="token-150-8" morph="none" pos="word" start_char="13870">as</TOKEN>
<TOKEN end_char="13877" id="token-150-9" morph="none" pos="word" start_char="13873">doing</TOKEN>
<TOKEN end_char="13882" id="token-150-10" morph="none" pos="word" start_char="13879">good</TOKEN>
<TOKEN end_char="13886" id="token-150-11" morph="none" pos="word" start_char="13884">for</TOKEN>
<TOKEN end_char="13890" id="token-150-12" morph="none" pos="word" start_char="13888">the</TOKEN>
<TOKEN end_char="13897" id="token-150-13" morph="none" pos="word" start_char="13892">entire</TOKEN>
<TOKEN end_char="13903" id="token-150-14" morph="none" pos="word" start_char="13899">world</TOKEN>
<TOKEN end_char="13904" id="token-150-15" morph="none" pos="punct" start_char="13904">.</TOKEN>
</SEG>
<SEG end_char="13976" id="segment-151" start_char="13906">
<ORIGINAL_TEXT>There are an excess of elderly in every developed country in the world.</ORIGINAL_TEXT>
<TOKEN end_char="13910" id="token-151-0" morph="none" pos="word" start_char="13906">There</TOKEN>
<TOKEN end_char="13914" id="token-151-1" morph="none" pos="word" start_char="13912">are</TOKEN>
<TOKEN end_char="13917" id="token-151-2" morph="none" pos="word" start_char="13916">an</TOKEN>
<TOKEN end_char="13924" id="token-151-3" morph="none" pos="word" start_char="13919">excess</TOKEN>
<TOKEN end_char="13927" id="token-151-4" morph="none" pos="word" start_char="13926">of</TOKEN>
<TOKEN end_char="13935" id="token-151-5" morph="none" pos="word" start_char="13929">elderly</TOKEN>
<TOKEN end_char="13938" id="token-151-6" morph="none" pos="word" start_char="13937">in</TOKEN>
<TOKEN end_char="13944" id="token-151-7" morph="none" pos="word" start_char="13940">every</TOKEN>
<TOKEN end_char="13954" id="token-151-8" morph="none" pos="word" start_char="13946">developed</TOKEN>
<TOKEN end_char="13962" id="token-151-9" morph="none" pos="word" start_char="13956">country</TOKEN>
<TOKEN end_char="13965" id="token-151-10" morph="none" pos="word" start_char="13964">in</TOKEN>
<TOKEN end_char="13969" id="token-151-11" morph="none" pos="word" start_char="13967">the</TOKEN>
<TOKEN end_char="13975" id="token-151-12" morph="none" pos="word" start_char="13971">world</TOKEN>
<TOKEN end_char="13976" id="token-151-13" morph="none" pos="punct" start_char="13976">.</TOKEN>
</SEG>
<SEG end_char="14099" id="segment-152" start_char="13978">
<ORIGINAL_TEXT>To deny or dismiss it being a designer virus to kill the excess elderly population is like sticking your head in the sand.</ORIGINAL_TEXT>
<TOKEN end_char="13979" id="token-152-0" morph="none" pos="word" start_char="13978">To</TOKEN>
<TOKEN end_char="13984" id="token-152-1" morph="none" pos="word" start_char="13981">deny</TOKEN>
<TOKEN end_char="13987" id="token-152-2" morph="none" pos="word" start_char="13986">or</TOKEN>
<TOKEN end_char="13995" id="token-152-3" morph="none" pos="word" start_char="13989">dismiss</TOKEN>
<TOKEN end_char="13998" id="token-152-4" morph="none" pos="word" start_char="13997">it</TOKEN>
<TOKEN end_char="14004" id="token-152-5" morph="none" pos="word" start_char="14000">being</TOKEN>
<TOKEN end_char="14006" id="token-152-6" morph="none" pos="word" start_char="14006">a</TOKEN>
<TOKEN end_char="14015" id="token-152-7" morph="none" pos="word" start_char="14008">designer</TOKEN>
<TOKEN end_char="14021" id="token-152-8" morph="none" pos="word" start_char="14017">virus</TOKEN>
<TOKEN end_char="14024" id="token-152-9" morph="none" pos="word" start_char="14023">to</TOKEN>
<TOKEN end_char="14029" id="token-152-10" morph="none" pos="word" start_char="14026">kill</TOKEN>
<TOKEN end_char="14033" id="token-152-11" morph="none" pos="word" start_char="14031">the</TOKEN>
<TOKEN end_char="14040" id="token-152-12" morph="none" pos="word" start_char="14035">excess</TOKEN>
<TOKEN end_char="14048" id="token-152-13" morph="none" pos="word" start_char="14042">elderly</TOKEN>
<TOKEN end_char="14059" id="token-152-14" morph="none" pos="word" start_char="14050">population</TOKEN>
<TOKEN end_char="14062" id="token-152-15" morph="none" pos="word" start_char="14061">is</TOKEN>
<TOKEN end_char="14067" id="token-152-16" morph="none" pos="word" start_char="14064">like</TOKEN>
<TOKEN end_char="14076" id="token-152-17" morph="none" pos="word" start_char="14069">sticking</TOKEN>
<TOKEN end_char="14081" id="token-152-18" morph="none" pos="word" start_char="14078">your</TOKEN>
<TOKEN end_char="14086" id="token-152-19" morph="none" pos="word" start_char="14083">head</TOKEN>
<TOKEN end_char="14089" id="token-152-20" morph="none" pos="word" start_char="14088">in</TOKEN>
<TOKEN end_char="14093" id="token-152-21" morph="none" pos="word" start_char="14091">the</TOKEN>
<TOKEN end_char="14098" id="token-152-22" morph="none" pos="word" start_char="14095">sand</TOKEN>
<TOKEN end_char="14099" id="token-152-23" morph="none" pos="punct" start_char="14099">.</TOKEN>
</SEG>
<SEG end_char="14286" id="segment-153" start_char="14101">
<ORIGINAL_TEXT>I have seen several people doing that and wonder if they are Chinese paid operatives who are doing their best to make this highly logical conclusion sound like a weird conspiracy theory.</ORIGINAL_TEXT>
<TOKEN end_char="14101" id="token-153-0" morph="none" pos="word" start_char="14101">I</TOKEN>
<TOKEN end_char="14106" id="token-153-1" morph="none" pos="word" start_char="14103">have</TOKEN>
<TOKEN end_char="14111" id="token-153-2" morph="none" pos="word" start_char="14108">seen</TOKEN>
<TOKEN end_char="14119" id="token-153-3" morph="none" pos="word" start_char="14113">several</TOKEN>
<TOKEN end_char="14126" id="token-153-4" morph="none" pos="word" start_char="14121">people</TOKEN>
<TOKEN end_char="14132" id="token-153-5" morph="none" pos="word" start_char="14128">doing</TOKEN>
<TOKEN end_char="14137" id="token-153-6" morph="none" pos="word" start_char="14134">that</TOKEN>
<TOKEN end_char="14141" id="token-153-7" morph="none" pos="word" start_char="14139">and</TOKEN>
<TOKEN end_char="14148" id="token-153-8" morph="none" pos="word" start_char="14143">wonder</TOKEN>
<TOKEN end_char="14151" id="token-153-9" morph="none" pos="word" start_char="14150">if</TOKEN>
<TOKEN end_char="14156" id="token-153-10" morph="none" pos="word" start_char="14153">they</TOKEN>
<TOKEN end_char="14160" id="token-153-11" morph="none" pos="word" start_char="14158">are</TOKEN>
<TOKEN end_char="14168" id="token-153-12" morph="none" pos="word" start_char="14162">Chinese</TOKEN>
<TOKEN end_char="14173" id="token-153-13" morph="none" pos="word" start_char="14170">paid</TOKEN>
<TOKEN end_char="14184" id="token-153-14" morph="none" pos="word" start_char="14175">operatives</TOKEN>
<TOKEN end_char="14188" id="token-153-15" morph="none" pos="word" start_char="14186">who</TOKEN>
<TOKEN end_char="14192" id="token-153-16" morph="none" pos="word" start_char="14190">are</TOKEN>
<TOKEN end_char="14198" id="token-153-17" morph="none" pos="word" start_char="14194">doing</TOKEN>
<TOKEN end_char="14204" id="token-153-18" morph="none" pos="word" start_char="14200">their</TOKEN>
<TOKEN end_char="14209" id="token-153-19" morph="none" pos="word" start_char="14206">best</TOKEN>
<TOKEN end_char="14212" id="token-153-20" morph="none" pos="word" start_char="14211">to</TOKEN>
<TOKEN end_char="14217" id="token-153-21" morph="none" pos="word" start_char="14214">make</TOKEN>
<TOKEN end_char="14222" id="token-153-22" morph="none" pos="word" start_char="14219">this</TOKEN>
<TOKEN end_char="14229" id="token-153-23" morph="none" pos="word" start_char="14224">highly</TOKEN>
<TOKEN end_char="14237" id="token-153-24" morph="none" pos="word" start_char="14231">logical</TOKEN>
<TOKEN end_char="14248" id="token-153-25" morph="none" pos="word" start_char="14239">conclusion</TOKEN>
<TOKEN end_char="14254" id="token-153-26" morph="none" pos="word" start_char="14250">sound</TOKEN>
<TOKEN end_char="14259" id="token-153-27" morph="none" pos="word" start_char="14256">like</TOKEN>
<TOKEN end_char="14261" id="token-153-28" morph="none" pos="word" start_char="14261">a</TOKEN>
<TOKEN end_char="14267" id="token-153-29" morph="none" pos="word" start_char="14263">weird</TOKEN>
<TOKEN end_char="14278" id="token-153-30" morph="none" pos="word" start_char="14269">conspiracy</TOKEN>
<TOKEN end_char="14285" id="token-153-31" morph="none" pos="word" start_char="14280">theory</TOKEN>
<TOKEN end_char="14286" id="token-153-32" morph="none" pos="punct" start_char="14286">.</TOKEN>
</SEG>
<SEG end_char="14443" id="segment-154" start_char="14288">
<ORIGINAL_TEXT>Someone with 2 masters degrees, and a very steady person asked me the other day if I thought the Chinese designed this and it got loose from their facility.</ORIGINAL_TEXT>
<TOKEN end_char="14294" id="token-154-0" morph="none" pos="word" start_char="14288">Someone</TOKEN>
<TOKEN end_char="14299" id="token-154-1" morph="none" pos="word" start_char="14296">with</TOKEN>
<TOKEN end_char="14301" id="token-154-2" morph="none" pos="word" start_char="14301">2</TOKEN>
<TOKEN end_char="14309" id="token-154-3" morph="none" pos="word" start_char="14303">masters</TOKEN>
<TOKEN end_char="14317" id="token-154-4" morph="none" pos="word" start_char="14311">degrees</TOKEN>
<TOKEN end_char="14318" id="token-154-5" morph="none" pos="punct" start_char="14318">,</TOKEN>
<TOKEN end_char="14322" id="token-154-6" morph="none" pos="word" start_char="14320">and</TOKEN>
<TOKEN end_char="14324" id="token-154-7" morph="none" pos="word" start_char="14324">a</TOKEN>
<TOKEN end_char="14329" id="token-154-8" morph="none" pos="word" start_char="14326">very</TOKEN>
<TOKEN end_char="14336" id="token-154-9" morph="none" pos="word" start_char="14331">steady</TOKEN>
<TOKEN end_char="14343" id="token-154-10" morph="none" pos="word" start_char="14338">person</TOKEN>
<TOKEN end_char="14349" id="token-154-11" morph="none" pos="word" start_char="14345">asked</TOKEN>
<TOKEN end_char="14352" id="token-154-12" morph="none" pos="word" start_char="14351">me</TOKEN>
<TOKEN end_char="14356" id="token-154-13" morph="none" pos="word" start_char="14354">the</TOKEN>
<TOKEN end_char="14362" id="token-154-14" morph="none" pos="word" start_char="14358">other</TOKEN>
<TOKEN end_char="14366" id="token-154-15" morph="none" pos="word" start_char="14364">day</TOKEN>
<TOKEN end_char="14369" id="token-154-16" morph="none" pos="word" start_char="14368">if</TOKEN>
<TOKEN end_char="14371" id="token-154-17" morph="none" pos="word" start_char="14371">I</TOKEN>
<TOKEN end_char="14379" id="token-154-18" morph="none" pos="word" start_char="14373">thought</TOKEN>
<TOKEN end_char="14383" id="token-154-19" morph="none" pos="word" start_char="14381">the</TOKEN>
<TOKEN end_char="14391" id="token-154-20" morph="none" pos="word" start_char="14385">Chinese</TOKEN>
<TOKEN end_char="14400" id="token-154-21" morph="none" pos="word" start_char="14393">designed</TOKEN>
<TOKEN end_char="14405" id="token-154-22" morph="none" pos="word" start_char="14402">this</TOKEN>
<TOKEN end_char="14409" id="token-154-23" morph="none" pos="word" start_char="14407">and</TOKEN>
<TOKEN end_char="14412" id="token-154-24" morph="none" pos="word" start_char="14411">it</TOKEN>
<TOKEN end_char="14416" id="token-154-25" morph="none" pos="word" start_char="14414">got</TOKEN>
<TOKEN end_char="14422" id="token-154-26" morph="none" pos="word" start_char="14418">loose</TOKEN>
<TOKEN end_char="14427" id="token-154-27" morph="none" pos="word" start_char="14424">from</TOKEN>
<TOKEN end_char="14433" id="token-154-28" morph="none" pos="word" start_char="14429">their</TOKEN>
<TOKEN end_char="14442" id="token-154-29" morph="none" pos="word" start_char="14435">facility</TOKEN>
<TOKEN end_char="14443" id="token-154-30" morph="none" pos="punct" start_char="14443">.</TOKEN>
</SEG>
<SEG end_char="14497" id="segment-155" start_char="14445">
<ORIGINAL_TEXT>I said a cautious yes, and the person said, I do too.</ORIGINAL_TEXT>
<TOKEN end_char="14445" id="token-155-0" morph="none" pos="word" start_char="14445">I</TOKEN>
<TOKEN end_char="14450" id="token-155-1" morph="none" pos="word" start_char="14447">said</TOKEN>
<TOKEN end_char="14452" id="token-155-2" morph="none" pos="word" start_char="14452">a</TOKEN>
<TOKEN end_char="14461" id="token-155-3" morph="none" pos="word" start_char="14454">cautious</TOKEN>
<TOKEN end_char="14465" id="token-155-4" morph="none" pos="word" start_char="14463">yes</TOKEN>
<TOKEN end_char="14466" id="token-155-5" morph="none" pos="punct" start_char="14466">,</TOKEN>
<TOKEN end_char="14470" id="token-155-6" morph="none" pos="word" start_char="14468">and</TOKEN>
<TOKEN end_char="14474" id="token-155-7" morph="none" pos="word" start_char="14472">the</TOKEN>
<TOKEN end_char="14481" id="token-155-8" morph="none" pos="word" start_char="14476">person</TOKEN>
<TOKEN end_char="14486" id="token-155-9" morph="none" pos="word" start_char="14483">said</TOKEN>
<TOKEN end_char="14487" id="token-155-10" morph="none" pos="punct" start_char="14487">,</TOKEN>
<TOKEN end_char="14489" id="token-155-11" morph="none" pos="word" start_char="14489">I</TOKEN>
<TOKEN end_char="14492" id="token-155-12" morph="none" pos="word" start_char="14491">do</TOKEN>
<TOKEN end_char="14496" id="token-155-13" morph="none" pos="word" start_char="14494">too</TOKEN>
<TOKEN end_char="14497" id="token-155-14" morph="none" pos="punct" start_char="14497">.</TOKEN>
</SEG>
<SEG end_char="14603" id="segment-156" start_char="14499">
<ORIGINAL_TEXT>This shows that even people who aren't into "the new" the way ATS people are have seen the obvious truth.</ORIGINAL_TEXT>
<TOKEN end_char="14502" id="token-156-0" morph="none" pos="word" start_char="14499">This</TOKEN>
<TOKEN end_char="14508" id="token-156-1" morph="none" pos="word" start_char="14504">shows</TOKEN>
<TOKEN end_char="14513" id="token-156-2" morph="none" pos="word" start_char="14510">that</TOKEN>
<TOKEN end_char="14518" id="token-156-3" morph="none" pos="word" start_char="14515">even</TOKEN>
<TOKEN end_char="14525" id="token-156-4" morph="none" pos="word" start_char="14520">people</TOKEN>
<TOKEN end_char="14529" id="token-156-5" morph="none" pos="word" start_char="14527">who</TOKEN>
<TOKEN end_char="14536" id="token-156-6" morph="none" pos="word" start_char="14531">aren't</TOKEN>
<TOKEN end_char="14541" id="token-156-7" morph="none" pos="word" start_char="14538">into</TOKEN>
<TOKEN end_char="14543" id="token-156-8" morph="none" pos="punct" start_char="14543">"</TOKEN>
<TOKEN end_char="14546" id="token-156-9" morph="none" pos="word" start_char="14544">the</TOKEN>
<TOKEN end_char="14550" id="token-156-10" morph="none" pos="word" start_char="14548">new</TOKEN>
<TOKEN end_char="14551" id="token-156-11" morph="none" pos="punct" start_char="14551">"</TOKEN>
<TOKEN end_char="14555" id="token-156-12" morph="none" pos="word" start_char="14553">the</TOKEN>
<TOKEN end_char="14559" id="token-156-13" morph="none" pos="word" start_char="14557">way</TOKEN>
<TOKEN end_char="14563" id="token-156-14" morph="none" pos="word" start_char="14561">ATS</TOKEN>
<TOKEN end_char="14570" id="token-156-15" morph="none" pos="word" start_char="14565">people</TOKEN>
<TOKEN end_char="14574" id="token-156-16" morph="none" pos="word" start_char="14572">are</TOKEN>
<TOKEN end_char="14579" id="token-156-17" morph="none" pos="word" start_char="14576">have</TOKEN>
<TOKEN end_char="14584" id="token-156-18" morph="none" pos="word" start_char="14581">seen</TOKEN>
<TOKEN end_char="14588" id="token-156-19" morph="none" pos="word" start_char="14586">the</TOKEN>
<TOKEN end_char="14596" id="token-156-20" morph="none" pos="word" start_char="14590">obvious</TOKEN>
<TOKEN end_char="14602" id="token-156-21" morph="none" pos="word" start_char="14598">truth</TOKEN>
<TOKEN end_char="14603" id="token-156-22" morph="none" pos="punct" start_char="14603">.</TOKEN>
</SEG>
<SEG end_char="14634" id="segment-157" start_char="14606">
<ORIGINAL_TEXT>You're argument has one flaw.</ORIGINAL_TEXT>
<TOKEN end_char="14611" id="token-157-0" morph="none" pos="word" start_char="14606">You're</TOKEN>
<TOKEN end_char="14620" id="token-157-1" morph="none" pos="word" start_char="14613">argument</TOKEN>
<TOKEN end_char="14624" id="token-157-2" morph="none" pos="word" start_char="14622">has</TOKEN>
<TOKEN end_char="14628" id="token-157-3" morph="none" pos="word" start_char="14626">one</TOKEN>
<TOKEN end_char="14633" id="token-157-4" morph="none" pos="word" start_char="14630">flaw</TOKEN>
<TOKEN end_char="14634" id="token-157-5" morph="none" pos="punct" start_char="14634">.</TOKEN>
</SEG>
<SEG end_char="14702" id="segment-158" start_char="14637">
<ORIGINAL_TEXT>The elderly in China are one of the primary sources of child care.</ORIGINAL_TEXT>
<TOKEN end_char="14639" id="token-158-0" morph="none" pos="word" start_char="14637">The</TOKEN>
<TOKEN end_char="14647" id="token-158-1" morph="none" pos="word" start_char="14641">elderly</TOKEN>
<TOKEN end_char="14650" id="token-158-2" morph="none" pos="word" start_char="14649">in</TOKEN>
<TOKEN end_char="14656" id="token-158-3" morph="none" pos="word" start_char="14652">China</TOKEN>
<TOKEN end_char="14660" id="token-158-4" morph="none" pos="word" start_char="14658">are</TOKEN>
<TOKEN end_char="14664" id="token-158-5" morph="none" pos="word" start_char="14662">one</TOKEN>
<TOKEN end_char="14667" id="token-158-6" morph="none" pos="word" start_char="14666">of</TOKEN>
<TOKEN end_char="14671" id="token-158-7" morph="none" pos="word" start_char="14669">the</TOKEN>
<TOKEN end_char="14679" id="token-158-8" morph="none" pos="word" start_char="14673">primary</TOKEN>
<TOKEN end_char="14687" id="token-158-9" morph="none" pos="word" start_char="14681">sources</TOKEN>
<TOKEN end_char="14690" id="token-158-10" morph="none" pos="word" start_char="14689">of</TOKEN>
<TOKEN end_char="14696" id="token-158-11" morph="none" pos="word" start_char="14692">child</TOKEN>
<TOKEN end_char="14701" id="token-158-12" morph="none" pos="word" start_char="14698">care</TOKEN>
<TOKEN end_char="14702" id="token-158-13" morph="none" pos="punct" start_char="14702">.</TOKEN>
</SEG>
<SEG end_char="14933" id="segment-159" start_char="14704">
<ORIGINAL_TEXT>Particularly with internal migrants (Mostly people who were born in rural areas and moved to urban areas, leaving their children behind as the Chinese system makes it difficult for them to go to school outside of their home area).</ORIGINAL_TEXT>
<TOKEN end_char="14715" id="token-159-0" morph="none" pos="word" start_char="14704">Particularly</TOKEN>
<TOKEN end_char="14720" id="token-159-1" morph="none" pos="word" start_char="14717">with</TOKEN>
<TOKEN end_char="14729" id="token-159-2" morph="none" pos="word" start_char="14722">internal</TOKEN>
<TOKEN end_char="14738" id="token-159-3" morph="none" pos="word" start_char="14731">migrants</TOKEN>
<TOKEN end_char="14740" id="token-159-4" morph="none" pos="punct" start_char="14740">(</TOKEN>
<TOKEN end_char="14746" id="token-159-5" morph="none" pos="word" start_char="14741">Mostly</TOKEN>
<TOKEN end_char="14753" id="token-159-6" morph="none" pos="word" start_char="14748">people</TOKEN>
<TOKEN end_char="14757" id="token-159-7" morph="none" pos="word" start_char="14755">who</TOKEN>
<TOKEN end_char="14762" id="token-159-8" morph="none" pos="word" start_char="14759">were</TOKEN>
<TOKEN end_char="14767" id="token-159-9" morph="none" pos="word" start_char="14764">born</TOKEN>
<TOKEN end_char="14770" id="token-159-10" morph="none" pos="word" start_char="14769">in</TOKEN>
<TOKEN end_char="14776" id="token-159-11" morph="none" pos="word" start_char="14772">rural</TOKEN>
<TOKEN end_char="14782" id="token-159-12" morph="none" pos="word" start_char="14778">areas</TOKEN>
<TOKEN end_char="14786" id="token-159-13" morph="none" pos="word" start_char="14784">and</TOKEN>
<TOKEN end_char="14792" id="token-159-14" morph="none" pos="word" start_char="14788">moved</TOKEN>
<TOKEN end_char="14795" id="token-159-15" morph="none" pos="word" start_char="14794">to</TOKEN>
<TOKEN end_char="14801" id="token-159-16" morph="none" pos="word" start_char="14797">urban</TOKEN>
<TOKEN end_char="14807" id="token-159-17" morph="none" pos="word" start_char="14803">areas</TOKEN>
<TOKEN end_char="14808" id="token-159-18" morph="none" pos="punct" start_char="14808">,</TOKEN>
<TOKEN end_char="14816" id="token-159-19" morph="none" pos="word" start_char="14810">leaving</TOKEN>
<TOKEN end_char="14822" id="token-159-20" morph="none" pos="word" start_char="14818">their</TOKEN>
<TOKEN end_char="14831" id="token-159-21" morph="none" pos="word" start_char="14824">children</TOKEN>
<TOKEN end_char="14838" id="token-159-22" morph="none" pos="word" start_char="14833">behind</TOKEN>
<TOKEN end_char="14841" id="token-159-23" morph="none" pos="word" start_char="14840">as</TOKEN>
<TOKEN end_char="14845" id="token-159-24" morph="none" pos="word" start_char="14843">the</TOKEN>
<TOKEN end_char="14853" id="token-159-25" morph="none" pos="word" start_char="14847">Chinese</TOKEN>
<TOKEN end_char="14860" id="token-159-26" morph="none" pos="word" start_char="14855">system</TOKEN>
<TOKEN end_char="14866" id="token-159-27" morph="none" pos="word" start_char="14862">makes</TOKEN>
<TOKEN end_char="14869" id="token-159-28" morph="none" pos="word" start_char="14868">it</TOKEN>
<TOKEN end_char="14879" id="token-159-29" morph="none" pos="word" start_char="14871">difficult</TOKEN>
<TOKEN end_char="14883" id="token-159-30" morph="none" pos="word" start_char="14881">for</TOKEN>
<TOKEN end_char="14888" id="token-159-31" morph="none" pos="word" start_char="14885">them</TOKEN>
<TOKEN end_char="14891" id="token-159-32" morph="none" pos="word" start_char="14890">to</TOKEN>
<TOKEN end_char="14894" id="token-159-33" morph="none" pos="word" start_char="14893">go</TOKEN>
<TOKEN end_char="14897" id="token-159-34" morph="none" pos="word" start_char="14896">to</TOKEN>
<TOKEN end_char="14904" id="token-159-35" morph="none" pos="word" start_char="14899">school</TOKEN>
<TOKEN end_char="14912" id="token-159-36" morph="none" pos="word" start_char="14906">outside</TOKEN>
<TOKEN end_char="14915" id="token-159-37" morph="none" pos="word" start_char="14914">of</TOKEN>
<TOKEN end_char="14921" id="token-159-38" morph="none" pos="word" start_char="14917">their</TOKEN>
<TOKEN end_char="14926" id="token-159-39" morph="none" pos="word" start_char="14923">home</TOKEN>
<TOKEN end_char="14931" id="token-159-40" morph="none" pos="word" start_char="14928">area</TOKEN>
<TOKEN end_char="14933" id="token-159-41" morph="none" pos="punct" start_char="14932">).</TOKEN>
</SEG>
<SEG end_char="14979" id="segment-160" start_char="14936">
<ORIGINAL_TEXT>Kill the elderly, cause a child care crisis.</ORIGINAL_TEXT>
<TOKEN end_char="14939" id="token-160-0" morph="none" pos="word" start_char="14936">Kill</TOKEN>
<TOKEN end_char="14943" id="token-160-1" morph="none" pos="word" start_char="14941">the</TOKEN>
<TOKEN end_char="14951" id="token-160-2" morph="none" pos="word" start_char="14945">elderly</TOKEN>
<TOKEN end_char="14952" id="token-160-3" morph="none" pos="punct" start_char="14952">,</TOKEN>
<TOKEN end_char="14958" id="token-160-4" morph="none" pos="word" start_char="14954">cause</TOKEN>
<TOKEN end_char="14960" id="token-160-5" morph="none" pos="word" start_char="14960">a</TOKEN>
<TOKEN end_char="14966" id="token-160-6" morph="none" pos="word" start_char="14962">child</TOKEN>
<TOKEN end_char="14971" id="token-160-7" morph="none" pos="word" start_char="14968">care</TOKEN>
<TOKEN end_char="14978" id="token-160-8" morph="none" pos="word" start_char="14973">crisis</TOKEN>
<TOKEN end_char="14979" id="token-160-9" morph="none" pos="punct" start_char="14979">.</TOKEN>
</SEG>
<SEG end_char="15117" id="segment-161" start_char="14982">
<ORIGINAL_TEXT>This virus hits the lungs, and China has a huge amount of middle aged male smokers (And Chinese cigarettes can be NASTY in the extreme).</ORIGINAL_TEXT>
<TOKEN end_char="14985" id="token-161-0" morph="none" pos="word" start_char="14982">This</TOKEN>
<TOKEN end_char="14991" id="token-161-1" morph="none" pos="word" start_char="14987">virus</TOKEN>
<TOKEN end_char="14996" id="token-161-2" morph="none" pos="word" start_char="14993">hits</TOKEN>
<TOKEN end_char="15000" id="token-161-3" morph="none" pos="word" start_char="14998">the</TOKEN>
<TOKEN end_char="15006" id="token-161-4" morph="none" pos="word" start_char="15002">lungs</TOKEN>
<TOKEN end_char="15007" id="token-161-5" morph="none" pos="punct" start_char="15007">,</TOKEN>
<TOKEN end_char="15011" id="token-161-6" morph="none" pos="word" start_char="15009">and</TOKEN>
<TOKEN end_char="15017" id="token-161-7" morph="none" pos="word" start_char="15013">China</TOKEN>
<TOKEN end_char="15021" id="token-161-8" morph="none" pos="word" start_char="15019">has</TOKEN>
<TOKEN end_char="15023" id="token-161-9" morph="none" pos="word" start_char="15023">a</TOKEN>
<TOKEN end_char="15028" id="token-161-10" morph="none" pos="word" start_char="15025">huge</TOKEN>
<TOKEN end_char="15035" id="token-161-11" morph="none" pos="word" start_char="15030">amount</TOKEN>
<TOKEN end_char="15038" id="token-161-12" morph="none" pos="word" start_char="15037">of</TOKEN>
<TOKEN end_char="15045" id="token-161-13" morph="none" pos="word" start_char="15040">middle</TOKEN>
<TOKEN end_char="15050" id="token-161-14" morph="none" pos="word" start_char="15047">aged</TOKEN>
<TOKEN end_char="15055" id="token-161-15" morph="none" pos="word" start_char="15052">male</TOKEN>
<TOKEN end_char="15063" id="token-161-16" morph="none" pos="word" start_char="15057">smokers</TOKEN>
<TOKEN end_char="15065" id="token-161-17" morph="none" pos="punct" start_char="15065">(</TOKEN>
<TOKEN end_char="15068" id="token-161-18" morph="none" pos="word" start_char="15066">And</TOKEN>
<TOKEN end_char="15076" id="token-161-19" morph="none" pos="word" start_char="15070">Chinese</TOKEN>
<TOKEN end_char="15087" id="token-161-20" morph="none" pos="word" start_char="15078">cigarettes</TOKEN>
<TOKEN end_char="15091" id="token-161-21" morph="none" pos="word" start_char="15089">can</TOKEN>
<TOKEN end_char="15094" id="token-161-22" morph="none" pos="word" start_char="15093">be</TOKEN>
<TOKEN end_char="15100" id="token-161-23" morph="none" pos="word" start_char="15096">NASTY</TOKEN>
<TOKEN end_char="15103" id="token-161-24" morph="none" pos="word" start_char="15102">in</TOKEN>
<TOKEN end_char="15107" id="token-161-25" morph="none" pos="word" start_char="15105">the</TOKEN>
<TOKEN end_char="15115" id="token-161-26" morph="none" pos="word" start_char="15109">extreme</TOKEN>
<TOKEN end_char="15117" id="token-161-27" morph="none" pos="punct" start_char="15116">).</TOKEN>
</SEG>
<SEG end_char="15191" id="segment-162" start_char="15119">
<ORIGINAL_TEXT>These people are some of the most economically productive in the country.</ORIGINAL_TEXT>
<TOKEN end_char="15123" id="token-162-0" morph="none" pos="word" start_char="15119">These</TOKEN>
<TOKEN end_char="15130" id="token-162-1" morph="none" pos="word" start_char="15125">people</TOKEN>
<TOKEN end_char="15134" id="token-162-2" morph="none" pos="word" start_char="15132">are</TOKEN>
<TOKEN end_char="15139" id="token-162-3" morph="none" pos="word" start_char="15136">some</TOKEN>
<TOKEN end_char="15142" id="token-162-4" morph="none" pos="word" start_char="15141">of</TOKEN>
<TOKEN end_char="15146" id="token-162-5" morph="none" pos="word" start_char="15144">the</TOKEN>
<TOKEN end_char="15151" id="token-162-6" morph="none" pos="word" start_char="15148">most</TOKEN>
<TOKEN end_char="15164" id="token-162-7" morph="none" pos="word" start_char="15153">economically</TOKEN>
<TOKEN end_char="15175" id="token-162-8" morph="none" pos="word" start_char="15166">productive</TOKEN>
<TOKEN end_char="15178" id="token-162-9" morph="none" pos="word" start_char="15177">in</TOKEN>
<TOKEN end_char="15182" id="token-162-10" morph="none" pos="word" start_char="15180">the</TOKEN>
<TOKEN end_char="15190" id="token-162-11" morph="none" pos="word" start_char="15184">country</TOKEN>
<TOKEN end_char="15191" id="token-162-12" morph="none" pos="punct" start_char="15191">.</TOKEN>
</SEG>
<SEG end_char="15296" id="segment-163" start_char="15193">
<ORIGINAL_TEXT>Creating a virus like this is going to hit a productive sector of the population as well as the elderly.</ORIGINAL_TEXT>
<TOKEN end_char="15200" id="token-163-0" morph="none" pos="word" start_char="15193">Creating</TOKEN>
<TOKEN end_char="15202" id="token-163-1" morph="none" pos="word" start_char="15202">a</TOKEN>
<TOKEN end_char="15208" id="token-163-2" morph="none" pos="word" start_char="15204">virus</TOKEN>
<TOKEN end_char="15213" id="token-163-3" morph="none" pos="word" start_char="15210">like</TOKEN>
<TOKEN end_char="15218" id="token-163-4" morph="none" pos="word" start_char="15215">this</TOKEN>
<TOKEN end_char="15221" id="token-163-5" morph="none" pos="word" start_char="15220">is</TOKEN>
<TOKEN end_char="15227" id="token-163-6" morph="none" pos="word" start_char="15223">going</TOKEN>
<TOKEN end_char="15230" id="token-163-7" morph="none" pos="word" start_char="15229">to</TOKEN>
<TOKEN end_char="15234" id="token-163-8" morph="none" pos="word" start_char="15232">hit</TOKEN>
<TOKEN end_char="15236" id="token-163-9" morph="none" pos="word" start_char="15236">a</TOKEN>
<TOKEN end_char="15247" id="token-163-10" morph="none" pos="word" start_char="15238">productive</TOKEN>
<TOKEN end_char="15254" id="token-163-11" morph="none" pos="word" start_char="15249">sector</TOKEN>
<TOKEN end_char="15257" id="token-163-12" morph="none" pos="word" start_char="15256">of</TOKEN>
<TOKEN end_char="15261" id="token-163-13" morph="none" pos="word" start_char="15259">the</TOKEN>
<TOKEN end_char="15272" id="token-163-14" morph="none" pos="word" start_char="15263">population</TOKEN>
<TOKEN end_char="15275" id="token-163-15" morph="none" pos="word" start_char="15274">as</TOKEN>
<TOKEN end_char="15280" id="token-163-16" morph="none" pos="word" start_char="15277">well</TOKEN>
<TOKEN end_char="15283" id="token-163-17" morph="none" pos="word" start_char="15282">as</TOKEN>
<TOKEN end_char="15287" id="token-163-18" morph="none" pos="word" start_char="15285">the</TOKEN>
<TOKEN end_char="15295" id="token-163-19" morph="none" pos="word" start_char="15289">elderly</TOKEN>
<TOKEN end_char="15296" id="token-163-20" morph="none" pos="punct" start_char="15296">.</TOKEN>
</SEG>
<SEG end_char="15328" id="segment-164" start_char="15301">
<ORIGINAL_TEXT>a reply to: ElectricUniverse</ORIGINAL_TEXT>
<TOKEN end_char="15301" id="token-164-0" morph="none" pos="word" start_char="15301">a</TOKEN>
<TOKEN end_char="15307" id="token-164-1" morph="none" pos="word" start_char="15303">reply</TOKEN>
<TOKEN end_char="15310" id="token-164-2" morph="none" pos="word" start_char="15309">to</TOKEN>
<TOKEN end_char="15311" id="token-164-3" morph="none" pos="punct" start_char="15311">:</TOKEN>
<TOKEN end_char="15328" id="token-164-4" morph="none" pos="word" start_char="15313">ElectricUniverse</TOKEN>
</SEG>
<SEG end_char="15441" id="segment-165" start_char="15331">
<ORIGINAL_TEXT>to me it's laughable how certain people always reach for a far fetched reason to find a conspiracy or cover up.</ORIGINAL_TEXT>
<TOKEN end_char="15332" id="token-165-0" morph="none" pos="word" start_char="15331">to</TOKEN>
<TOKEN end_char="15335" id="token-165-1" morph="none" pos="word" start_char="15334">me</TOKEN>
<TOKEN end_char="15340" id="token-165-2" morph="none" pos="word" start_char="15337">it's</TOKEN>
<TOKEN end_char="15350" id="token-165-3" morph="none" pos="word" start_char="15342">laughable</TOKEN>
<TOKEN end_char="15354" id="token-165-4" morph="none" pos="word" start_char="15352">how</TOKEN>
<TOKEN end_char="15362" id="token-165-5" morph="none" pos="word" start_char="15356">certain</TOKEN>
<TOKEN end_char="15369" id="token-165-6" morph="none" pos="word" start_char="15364">people</TOKEN>
<TOKEN end_char="15376" id="token-165-7" morph="none" pos="word" start_char="15371">always</TOKEN>
<TOKEN end_char="15382" id="token-165-8" morph="none" pos="word" start_char="15378">reach</TOKEN>
<TOKEN end_char="15386" id="token-165-9" morph="none" pos="word" start_char="15384">for</TOKEN>
<TOKEN end_char="15388" id="token-165-10" morph="none" pos="word" start_char="15388">a</TOKEN>
<TOKEN end_char="15392" id="token-165-11" morph="none" pos="word" start_char="15390">far</TOKEN>
<TOKEN end_char="15400" id="token-165-12" morph="none" pos="word" start_char="15394">fetched</TOKEN>
<TOKEN end_char="15407" id="token-165-13" morph="none" pos="word" start_char="15402">reason</TOKEN>
<TOKEN end_char="15410" id="token-165-14" morph="none" pos="word" start_char="15409">to</TOKEN>
<TOKEN end_char="15415" id="token-165-15" morph="none" pos="word" start_char="15412">find</TOKEN>
<TOKEN end_char="15417" id="token-165-16" morph="none" pos="word" start_char="15417">a</TOKEN>
<TOKEN end_char="15428" id="token-165-17" morph="none" pos="word" start_char="15419">conspiracy</TOKEN>
<TOKEN end_char="15431" id="token-165-18" morph="none" pos="word" start_char="15430">or</TOKEN>
<TOKEN end_char="15437" id="token-165-19" morph="none" pos="word" start_char="15433">cover</TOKEN>
<TOKEN end_char="15440" id="token-165-20" morph="none" pos="word" start_char="15439">up</TOKEN>
<TOKEN end_char="15441" id="token-165-21" morph="none" pos="punct" start_char="15441">.</TOKEN>
</SEG>
<SEG end_char="15496" id="segment-166" start_char="15444">
<ORIGINAL_TEXT>you do know what preprint means on a paper don't you?</ORIGINAL_TEXT>
<TOKEN end_char="15446" id="token-166-0" morph="none" pos="word" start_char="15444">you</TOKEN>
<TOKEN end_char="15449" id="token-166-1" morph="none" pos="word" start_char="15448">do</TOKEN>
<TOKEN end_char="15454" id="token-166-2" morph="none" pos="word" start_char="15451">know</TOKEN>
<TOKEN end_char="15459" id="token-166-3" morph="none" pos="word" start_char="15456">what</TOKEN>
<TOKEN end_char="15468" id="token-166-4" morph="none" pos="word" start_char="15461">preprint</TOKEN>
<TOKEN end_char="15474" id="token-166-5" morph="none" pos="word" start_char="15470">means</TOKEN>
<TOKEN end_char="15477" id="token-166-6" morph="none" pos="word" start_char="15476">on</TOKEN>
<TOKEN end_char="15479" id="token-166-7" morph="none" pos="word" start_char="15479">a</TOKEN>
<TOKEN end_char="15485" id="token-166-8" morph="none" pos="word" start_char="15481">paper</TOKEN>
<TOKEN end_char="15491" id="token-166-9" morph="none" pos="word" start_char="15487">don't</TOKEN>
<TOKEN end_char="15495" id="token-166-10" morph="none" pos="word" start_char="15493">you</TOKEN>
<TOKEN end_char="15496" id="token-166-11" morph="none" pos="punct" start_char="15496">?</TOKEN>
</SEG>
<SEG end_char="15578" id="segment-167" start_char="15498">
<ORIGINAL_TEXT>it means that it has not been peer reviewed or published in a scientific journal.</ORIGINAL_TEXT>
<TOKEN end_char="15499" id="token-167-0" morph="none" pos="word" start_char="15498">it</TOKEN>
<TOKEN end_char="15505" id="token-167-1" morph="none" pos="word" start_char="15501">means</TOKEN>
<TOKEN end_char="15510" id="token-167-2" morph="none" pos="word" start_char="15507">that</TOKEN>
<TOKEN end_char="15513" id="token-167-3" morph="none" pos="word" start_char="15512">it</TOKEN>
<TOKEN end_char="15517" id="token-167-4" morph="none" pos="word" start_char="15515">has</TOKEN>
<TOKEN end_char="15521" id="token-167-5" morph="none" pos="word" start_char="15519">not</TOKEN>
<TOKEN end_char="15526" id="token-167-6" morph="none" pos="word" start_char="15523">been</TOKEN>
<TOKEN end_char="15531" id="token-167-7" morph="none" pos="word" start_char="15528">peer</TOKEN>
<TOKEN end_char="15540" id="token-167-8" morph="none" pos="word" start_char="15533">reviewed</TOKEN>
<TOKEN end_char="15543" id="token-167-9" morph="none" pos="word" start_char="15542">or</TOKEN>
<TOKEN end_char="15553" id="token-167-10" morph="none" pos="word" start_char="15545">published</TOKEN>
<TOKEN end_char="15556" id="token-167-11" morph="none" pos="word" start_char="15555">in</TOKEN>
<TOKEN end_char="15558" id="token-167-12" morph="none" pos="word" start_char="15558">a</TOKEN>
<TOKEN end_char="15569" id="token-167-13" morph="none" pos="word" start_char="15560">scientific</TOKEN>
<TOKEN end_char="15577" id="token-167-14" morph="none" pos="word" start_char="15571">journal</TOKEN>
<TOKEN end_char="15578" id="token-167-15" morph="none" pos="punct" start_char="15578">.</TOKEN>
</SEG>
<SEG end_char="15651" id="segment-168" start_char="15581">
<ORIGINAL_TEXT>here i found this while trying to find a good link for your broken one.</ORIGINAL_TEXT>
<TOKEN end_char="15584" id="token-168-0" morph="none" pos="word" start_char="15581">here</TOKEN>
<TOKEN end_char="15586" id="token-168-1" morph="none" pos="word" start_char="15586">i</TOKEN>
<TOKEN end_char="15592" id="token-168-2" morph="none" pos="word" start_char="15588">found</TOKEN>
<TOKEN end_char="15597" id="token-168-3" morph="none" pos="word" start_char="15594">this</TOKEN>
<TOKEN end_char="15603" id="token-168-4" morph="none" pos="word" start_char="15599">while</TOKEN>
<TOKEN end_char="15610" id="token-168-5" morph="none" pos="word" start_char="15605">trying</TOKEN>
<TOKEN end_char="15613" id="token-168-6" morph="none" pos="word" start_char="15612">to</TOKEN>
<TOKEN end_char="15618" id="token-168-7" morph="none" pos="word" start_char="15615">find</TOKEN>
<TOKEN end_char="15620" id="token-168-8" morph="none" pos="word" start_char="15620">a</TOKEN>
<TOKEN end_char="15625" id="token-168-9" morph="none" pos="word" start_char="15622">good</TOKEN>
<TOKEN end_char="15630" id="token-168-10" morph="none" pos="word" start_char="15627">link</TOKEN>
<TOKEN end_char="15634" id="token-168-11" morph="none" pos="word" start_char="15632">for</TOKEN>
<TOKEN end_char="15639" id="token-168-12" morph="none" pos="word" start_char="15636">your</TOKEN>
<TOKEN end_char="15646" id="token-168-13" morph="none" pos="word" start_char="15641">broken</TOKEN>
<TOKEN end_char="15650" id="token-168-14" morph="none" pos="word" start_char="15648">one</TOKEN>
<TOKEN end_char="15651" id="token-168-15" morph="none" pos="punct" start_char="15651">.</TOKEN>
</SEG>
<SEG end_char="15810" id="segment-169" start_char="15654">
<ORIGINAL_TEXT>While the two authors do not provide any evidence that the novel coronavirus (SARS-CoV-2) was created in the lab, they build their case based on assumptions.</ORIGINAL_TEXT>
<TOKEN end_char="15658" id="token-169-0" morph="none" pos="word" start_char="15654">While</TOKEN>
<TOKEN end_char="15662" id="token-169-1" morph="none" pos="word" start_char="15660">the</TOKEN>
<TOKEN end_char="15666" id="token-169-2" morph="none" pos="word" start_char="15664">two</TOKEN>
<TOKEN end_char="15674" id="token-169-3" morph="none" pos="word" start_char="15668">authors</TOKEN>
<TOKEN end_char="15677" id="token-169-4" morph="none" pos="word" start_char="15676">do</TOKEN>
<TOKEN end_char="15681" id="token-169-5" morph="none" pos="word" start_char="15679">not</TOKEN>
<TOKEN end_char="15689" id="token-169-6" morph="none" pos="word" start_char="15683">provide</TOKEN>
<TOKEN end_char="15693" id="token-169-7" morph="none" pos="word" start_char="15691">any</TOKEN>
<TOKEN end_char="15702" id="token-169-8" morph="none" pos="word" start_char="15695">evidence</TOKEN>
<TOKEN end_char="15707" id="token-169-9" morph="none" pos="word" start_char="15704">that</TOKEN>
<TOKEN end_char="15711" id="token-169-10" morph="none" pos="word" start_char="15709">the</TOKEN>
<TOKEN end_char="15717" id="token-169-11" morph="none" pos="word" start_char="15713">novel</TOKEN>
<TOKEN end_char="15729" id="token-169-12" morph="none" pos="word" start_char="15719">coronavirus</TOKEN>
<TOKEN end_char="15731" id="token-169-13" morph="none" pos="punct" start_char="15731">(</TOKEN>
<TOKEN end_char="15741" id="token-169-14" morph="none" pos="unknown" start_char="15732">SARS-CoV-2</TOKEN>
<TOKEN end_char="15742" id="token-169-15" morph="none" pos="punct" start_char="15742">)</TOKEN>
<TOKEN end_char="15746" id="token-169-16" morph="none" pos="word" start_char="15744">was</TOKEN>
<TOKEN end_char="15754" id="token-169-17" morph="none" pos="word" start_char="15748">created</TOKEN>
<TOKEN end_char="15757" id="token-169-18" morph="none" pos="word" start_char="15756">in</TOKEN>
<TOKEN end_char="15761" id="token-169-19" morph="none" pos="word" start_char="15759">the</TOKEN>
<TOKEN end_char="15765" id="token-169-20" morph="none" pos="word" start_char="15763">lab</TOKEN>
<TOKEN end_char="15766" id="token-169-21" morph="none" pos="punct" start_char="15766">,</TOKEN>
<TOKEN end_char="15771" id="token-169-22" morph="none" pos="word" start_char="15768">they</TOKEN>
<TOKEN end_char="15777" id="token-169-23" morph="none" pos="word" start_char="15773">build</TOKEN>
<TOKEN end_char="15783" id="token-169-24" morph="none" pos="word" start_char="15779">their</TOKEN>
<TOKEN end_char="15788" id="token-169-25" morph="none" pos="word" start_char="15785">case</TOKEN>
<TOKEN end_char="15794" id="token-169-26" morph="none" pos="word" start_char="15790">based</TOKEN>
<TOKEN end_char="15797" id="token-169-27" morph="none" pos="word" start_char="15796">on</TOKEN>
<TOKEN end_char="15809" id="token-169-28" morph="none" pos="word" start_char="15799">assumptions</TOKEN>
<TOKEN end_char="15810" id="token-169-29" morph="none" pos="punct" start_char="15810">.</TOKEN>
</SEG>
<SEG end_char="16025" id="segment-170" start_char="15812">
<ORIGINAL_TEXT>They begin by saying that bats carrying the novel coronavirus are originally found in Yunnan or Zhejiang province, which is more than 900 km from the seafood market at the centre of the investigation on the source.</ORIGINAL_TEXT>
<TOKEN end_char="15815" id="token-170-0" morph="none" pos="word" start_char="15812">They</TOKEN>
<TOKEN end_char="15821" id="token-170-1" morph="none" pos="word" start_char="15817">begin</TOKEN>
<TOKEN end_char="15824" id="token-170-2" morph="none" pos="word" start_char="15823">by</TOKEN>
<TOKEN end_char="15831" id="token-170-3" morph="none" pos="word" start_char="15826">saying</TOKEN>
<TOKEN end_char="15836" id="token-170-4" morph="none" pos="word" start_char="15833">that</TOKEN>
<TOKEN end_char="15841" id="token-170-5" morph="none" pos="word" start_char="15838">bats</TOKEN>
<TOKEN end_char="15850" id="token-170-6" morph="none" pos="word" start_char="15843">carrying</TOKEN>
<TOKEN end_char="15854" id="token-170-7" morph="none" pos="word" start_char="15852">the</TOKEN>
<TOKEN end_char="15860" id="token-170-8" morph="none" pos="word" start_char="15856">novel</TOKEN>
<TOKEN end_char="15872" id="token-170-9" morph="none" pos="word" start_char="15862">coronavirus</TOKEN>
<TOKEN end_char="15876" id="token-170-10" morph="none" pos="word" start_char="15874">are</TOKEN>
<TOKEN end_char="15887" id="token-170-11" morph="none" pos="word" start_char="15878">originally</TOKEN>
<TOKEN end_char="15893" id="token-170-12" morph="none" pos="word" start_char="15889">found</TOKEN>
<TOKEN end_char="15896" id="token-170-13" morph="none" pos="word" start_char="15895">in</TOKEN>
<TOKEN end_char="15903" id="token-170-14" morph="none" pos="word" start_char="15898">Yunnan</TOKEN>
<TOKEN end_char="15906" id="token-170-15" morph="none" pos="word" start_char="15905">or</TOKEN>
<TOKEN end_char="15915" id="token-170-16" morph="none" pos="word" start_char="15908">Zhejiang</TOKEN>
<TOKEN end_char="15924" id="token-170-17" morph="none" pos="word" start_char="15917">province</TOKEN>
<TOKEN end_char="15925" id="token-170-18" morph="none" pos="punct" start_char="15925">,</TOKEN>
<TOKEN end_char="15931" id="token-170-19" morph="none" pos="word" start_char="15927">which</TOKEN>
<TOKEN end_char="15934" id="token-170-20" morph="none" pos="word" start_char="15933">is</TOKEN>
<TOKEN end_char="15939" id="token-170-21" morph="none" pos="word" start_char="15936">more</TOKEN>
<TOKEN end_char="15944" id="token-170-22" morph="none" pos="word" start_char="15941">than</TOKEN>
<TOKEN end_char="15948" id="token-170-23" morph="none" pos="word" start_char="15946">900</TOKEN>
<TOKEN end_char="15951" id="token-170-24" morph="none" pos="word" start_char="15950">km</TOKEN>
<TOKEN end_char="15956" id="token-170-25" morph="none" pos="word" start_char="15953">from</TOKEN>
<TOKEN end_char="15960" id="token-170-26" morph="none" pos="word" start_char="15958">the</TOKEN>
<TOKEN end_char="15968" id="token-170-27" morph="none" pos="word" start_char="15962">seafood</TOKEN>
<TOKEN end_char="15975" id="token-170-28" morph="none" pos="word" start_char="15970">market</TOKEN>
<TOKEN end_char="15978" id="token-170-29" morph="none" pos="word" start_char="15977">at</TOKEN>
<TOKEN end_char="15982" id="token-170-30" morph="none" pos="word" start_char="15980">the</TOKEN>
<TOKEN end_char="15989" id="token-170-31" morph="none" pos="word" start_char="15984">centre</TOKEN>
<TOKEN end_char="15992" id="token-170-32" morph="none" pos="word" start_char="15991">of</TOKEN>
<TOKEN end_char="15996" id="token-170-33" morph="none" pos="word" start_char="15994">the</TOKEN>
<TOKEN end_char="16010" id="token-170-34" morph="none" pos="word" start_char="15998">investigation</TOKEN>
<TOKEN end_char="16013" id="token-170-35" morph="none" pos="word" start_char="16012">on</TOKEN>
<TOKEN end_char="16017" id="token-170-36" morph="none" pos="word" start_char="16015">the</TOKEN>
<TOKEN end_char="16024" id="token-170-37" morph="none" pos="word" start_char="16019">source</TOKEN>
<TOKEN end_char="16025" id="token-170-38" morph="none" pos="punct" start_char="16025">.</TOKEN>
</SEG>
<SEG end_char="16085" id="segment-171" start_char="16027">
<ORIGINAL_TEXT>Hence, the chances of bats "flying to the market" are slim.</ORIGINAL_TEXT>
<TOKEN end_char="16031" id="token-171-0" morph="none" pos="word" start_char="16027">Hence</TOKEN>
<TOKEN end_char="16032" id="token-171-1" morph="none" pos="punct" start_char="16032">,</TOKEN>
<TOKEN end_char="16036" id="token-171-2" morph="none" pos="word" start_char="16034">the</TOKEN>
<TOKEN end_char="16044" id="token-171-3" morph="none" pos="word" start_char="16038">chances</TOKEN>
<TOKEN end_char="16047" id="token-171-4" morph="none" pos="word" start_char="16046">of</TOKEN>
<TOKEN end_char="16052" id="token-171-5" morph="none" pos="word" start_char="16049">bats</TOKEN>
<TOKEN end_char="16054" id="token-171-6" morph="none" pos="punct" start_char="16054">"</TOKEN>
<TOKEN end_char="16060" id="token-171-7" morph="none" pos="word" start_char="16055">flying</TOKEN>
<TOKEN end_char="16063" id="token-171-8" morph="none" pos="word" start_char="16062">to</TOKEN>
<TOKEN end_char="16067" id="token-171-9" morph="none" pos="word" start_char="16065">the</TOKEN>
<TOKEN end_char="16074" id="token-171-10" morph="none" pos="word" start_char="16069">market</TOKEN>
<TOKEN end_char="16075" id="token-171-11" morph="none" pos="punct" start_char="16075">"</TOKEN>
<TOKEN end_char="16079" id="token-171-12" morph="none" pos="word" start_char="16077">are</TOKEN>
<TOKEN end_char="16084" id="token-171-13" morph="none" pos="word" start_char="16081">slim</TOKEN>
<TOKEN end_char="16085" id="token-171-14" morph="none" pos="punct" start_char="16085">.</TOKEN>
</SEG>
<SEG end_char="16173" id="segment-172" start_char="16087">
<ORIGINAL_TEXT>Opinion | A preprint provides ammunition to conspiracy theories about SARS-CoV-2 origin</ORIGINAL_TEXT>
<TOKEN end_char="16093" id="token-172-0" morph="none" pos="word" start_char="16087">Opinion</TOKEN>
<TOKEN end_char="16095" id="token-172-1" morph="none" pos="unknown" start_char="16095">|</TOKEN>
<TOKEN end_char="16097" id="token-172-2" morph="none" pos="word" start_char="16097">A</TOKEN>
<TOKEN end_char="16106" id="token-172-3" morph="none" pos="word" start_char="16099">preprint</TOKEN>
<TOKEN end_char="16115" id="token-172-4" morph="none" pos="word" start_char="16108">provides</TOKEN>
<TOKEN end_char="16126" id="token-172-5" morph="none" pos="word" start_char="16117">ammunition</TOKEN>
<TOKEN end_char="16129" id="token-172-6" morph="none" pos="word" start_char="16128">to</TOKEN>
<TOKEN end_char="16140" id="token-172-7" morph="none" pos="word" start_char="16131">conspiracy</TOKEN>
<TOKEN end_char="16149" id="token-172-8" morph="none" pos="word" start_char="16142">theories</TOKEN>
<TOKEN end_char="16155" id="token-172-9" morph="none" pos="word" start_char="16151">about</TOKEN>
<TOKEN end_char="16166" id="token-172-10" morph="none" pos="unknown" start_char="16157">SARS-CoV-2</TOKEN>
<TOKEN end_char="16173" id="token-172-11" morph="none" pos="word" start_char="16168">origin</TOKEN>
</SEG>
<SEG end_char="16211" id="segment-173" start_char="16176">
<ORIGINAL_TEXT>now granted this is a Opinion piece.</ORIGINAL_TEXT>
<TOKEN end_char="16178" id="token-173-0" morph="none" pos="word" start_char="16176">now</TOKEN>
<TOKEN end_char="16186" id="token-173-1" morph="none" pos="word" start_char="16180">granted</TOKEN>
<TOKEN end_char="16191" id="token-173-2" morph="none" pos="word" start_char="16188">this</TOKEN>
<TOKEN end_char="16194" id="token-173-3" morph="none" pos="word" start_char="16193">is</TOKEN>
<TOKEN end_char="16196" id="token-173-4" morph="none" pos="word" start_char="16196">a</TOKEN>
<TOKEN end_char="16204" id="token-173-5" morph="none" pos="word" start_char="16198">Opinion</TOKEN>
<TOKEN end_char="16210" id="token-173-6" morph="none" pos="word" start_char="16206">piece</TOKEN>
<TOKEN end_char="16211" id="token-173-7" morph="none" pos="punct" start_char="16211">.</TOKEN>
</SEG>
<SEG end_char="16280" id="segment-174" start_char="16213">
<ORIGINAL_TEXT>but The Hindu is rated high for factual reporting and their sources.</ORIGINAL_TEXT>
<TOKEN end_char="16215" id="token-174-0" morph="none" pos="word" start_char="16213">but</TOKEN>
<TOKEN end_char="16219" id="token-174-1" morph="none" pos="word" start_char="16217">The</TOKEN>
<TOKEN end_char="16225" id="token-174-2" morph="none" pos="word" start_char="16221">Hindu</TOKEN>
<TOKEN end_char="16228" id="token-174-3" morph="none" pos="word" start_char="16227">is</TOKEN>
<TOKEN end_char="16234" id="token-174-4" morph="none" pos="word" start_char="16230">rated</TOKEN>
<TOKEN end_char="16239" id="token-174-5" morph="none" pos="word" start_char="16236">high</TOKEN>
<TOKEN end_char="16243" id="token-174-6" morph="none" pos="word" start_char="16241">for</TOKEN>
<TOKEN end_char="16251" id="token-174-7" morph="none" pos="word" start_char="16245">factual</TOKEN>
<TOKEN end_char="16261" id="token-174-8" morph="none" pos="word" start_char="16253">reporting</TOKEN>
<TOKEN end_char="16265" id="token-174-9" morph="none" pos="word" start_char="16263">and</TOKEN>
<TOKEN end_char="16271" id="token-174-10" morph="none" pos="word" start_char="16267">their</TOKEN>
<TOKEN end_char="16279" id="token-174-11" morph="none" pos="word" start_char="16273">sources</TOKEN>
<TOKEN end_char="16280" id="token-174-12" morph="none" pos="punct" start_char="16280">.</TOKEN>
</SEG>
<SEG end_char="16341" id="segment-175" start_char="16283">
<ORIGINAL_TEXT>These media sources have a slight to moderate liberal bias.</ORIGINAL_TEXT>
<TOKEN end_char="16287" id="token-175-0" morph="none" pos="word" start_char="16283">These</TOKEN>
<TOKEN end_char="16293" id="token-175-1" morph="none" pos="word" start_char="16289">media</TOKEN>
<TOKEN end_char="16301" id="token-175-2" morph="none" pos="word" start_char="16295">sources</TOKEN>
<TOKEN end_char="16306" id="token-175-3" morph="none" pos="word" start_char="16303">have</TOKEN>
<TOKEN end_char="16308" id="token-175-4" morph="none" pos="word" start_char="16308">a</TOKEN>
<TOKEN end_char="16315" id="token-175-5" morph="none" pos="word" start_char="16310">slight</TOKEN>
<TOKEN end_char="16318" id="token-175-6" morph="none" pos="word" start_char="16317">to</TOKEN>
<TOKEN end_char="16327" id="token-175-7" morph="none" pos="word" start_char="16320">moderate</TOKEN>
<TOKEN end_char="16335" id="token-175-8" morph="none" pos="word" start_char="16329">liberal</TOKEN>
<TOKEN end_char="16340" id="token-175-9" morph="none" pos="word" start_char="16337">bias</TOKEN>
<TOKEN end_char="16341" id="token-175-10" morph="none" pos="punct" start_char="16341">.</TOKEN>
</SEG>
<SEG end_char="16523" id="segment-176" start_char="16343">
<ORIGINAL_TEXT>They often publish factual information that utilizes loaded words (wording that attempts to influence an audience by using appeal to emotion or stereotypes) to favor liberal causes.</ORIGINAL_TEXT>
<TOKEN end_char="16346" id="token-176-0" morph="none" pos="word" start_char="16343">They</TOKEN>
<TOKEN end_char="16352" id="token-176-1" morph="none" pos="word" start_char="16348">often</TOKEN>
<TOKEN end_char="16360" id="token-176-2" morph="none" pos="word" start_char="16354">publish</TOKEN>
<TOKEN end_char="16368" id="token-176-3" morph="none" pos="word" start_char="16362">factual</TOKEN>
<TOKEN end_char="16380" id="token-176-4" morph="none" pos="word" start_char="16370">information</TOKEN>
<TOKEN end_char="16385" id="token-176-5" morph="none" pos="word" start_char="16382">that</TOKEN>
<TOKEN end_char="16394" id="token-176-6" morph="none" pos="word" start_char="16387">utilizes</TOKEN>
<TOKEN end_char="16401" id="token-176-7" morph="none" pos="word" start_char="16396">loaded</TOKEN>
<TOKEN end_char="16407" id="token-176-8" morph="none" pos="word" start_char="16403">words</TOKEN>
<TOKEN end_char="16409" id="token-176-9" morph="none" pos="punct" start_char="16409">(</TOKEN>
<TOKEN end_char="16416" id="token-176-10" morph="none" pos="word" start_char="16410">wording</TOKEN>
<TOKEN end_char="16421" id="token-176-11" morph="none" pos="word" start_char="16418">that</TOKEN>
<TOKEN end_char="16430" id="token-176-12" morph="none" pos="word" start_char="16423">attempts</TOKEN>
<TOKEN end_char="16433" id="token-176-13" morph="none" pos="word" start_char="16432">to</TOKEN>
<TOKEN end_char="16443" id="token-176-14" morph="none" pos="word" start_char="16435">influence</TOKEN>
<TOKEN end_char="16446" id="token-176-15" morph="none" pos="word" start_char="16445">an</TOKEN>
<TOKEN end_char="16455" id="token-176-16" morph="none" pos="word" start_char="16448">audience</TOKEN>
<TOKEN end_char="16458" id="token-176-17" morph="none" pos="word" start_char="16457">by</TOKEN>
<TOKEN end_char="16464" id="token-176-18" morph="none" pos="word" start_char="16460">using</TOKEN>
<TOKEN end_char="16471" id="token-176-19" morph="none" pos="word" start_char="16466">appeal</TOKEN>
<TOKEN end_char="16474" id="token-176-20" morph="none" pos="word" start_char="16473">to</TOKEN>
<TOKEN end_char="16482" id="token-176-21" morph="none" pos="word" start_char="16476">emotion</TOKEN>
<TOKEN end_char="16485" id="token-176-22" morph="none" pos="word" start_char="16484">or</TOKEN>
<TOKEN end_char="16497" id="token-176-23" morph="none" pos="word" start_char="16487">stereotypes</TOKEN>
<TOKEN end_char="16498" id="token-176-24" morph="none" pos="punct" start_char="16498">)</TOKEN>
<TOKEN end_char="16501" id="token-176-25" morph="none" pos="word" start_char="16500">to</TOKEN>
<TOKEN end_char="16507" id="token-176-26" morph="none" pos="word" start_char="16503">favor</TOKEN>
<TOKEN end_char="16515" id="token-176-27" morph="none" pos="word" start_char="16509">liberal</TOKEN>
<TOKEN end_char="16522" id="token-176-28" morph="none" pos="word" start_char="16517">causes</TOKEN>
<TOKEN end_char="16523" id="token-176-29" morph="none" pos="punct" start_char="16523">.</TOKEN>
</SEG>
<SEG end_char="16619" id="segment-177" start_char="16525">
<ORIGINAL_TEXT>These sources are generally trustworthy for information, but may require further investigation.</ORIGINAL_TEXT>
<TOKEN end_char="16529" id="token-177-0" morph="none" pos="word" start_char="16525">These</TOKEN>
<TOKEN end_char="16537" id="token-177-1" morph="none" pos="word" start_char="16531">sources</TOKEN>
<TOKEN end_char="16541" id="token-177-2" morph="none" pos="word" start_char="16539">are</TOKEN>
<TOKEN end_char="16551" id="token-177-3" morph="none" pos="word" start_char="16543">generally</TOKEN>
<TOKEN end_char="16563" id="token-177-4" morph="none" pos="word" start_char="16553">trustworthy</TOKEN>
<TOKEN end_char="16567" id="token-177-5" morph="none" pos="word" start_char="16565">for</TOKEN>
<TOKEN end_char="16579" id="token-177-6" morph="none" pos="word" start_char="16569">information</TOKEN>
<TOKEN end_char="16580" id="token-177-7" morph="none" pos="punct" start_char="16580">,</TOKEN>
<TOKEN end_char="16584" id="token-177-8" morph="none" pos="word" start_char="16582">but</TOKEN>
<TOKEN end_char="16588" id="token-177-9" morph="none" pos="word" start_char="16586">may</TOKEN>
<TOKEN end_char="16596" id="token-177-10" morph="none" pos="word" start_char="16590">require</TOKEN>
<TOKEN end_char="16604" id="token-177-11" morph="none" pos="word" start_char="16598">further</TOKEN>
<TOKEN end_char="16618" id="token-177-12" morph="none" pos="word" start_char="16606">investigation</TOKEN>
<TOKEN end_char="16619" id="token-177-13" morph="none" pos="punct" start_char="16619">.</TOKEN>
</SEG>
<SEG end_char="16648" id="segment-178" start_char="16621">
<ORIGINAL_TEXT>See all Left-Center sources.</ORIGINAL_TEXT>
<TOKEN end_char="16623" id="token-178-0" morph="none" pos="word" start_char="16621">See</TOKEN>
<TOKEN end_char="16627" id="token-178-1" morph="none" pos="word" start_char="16625">all</TOKEN>
<TOKEN end_char="16639" id="token-178-2" morph="none" pos="unknown" start_char="16629">Left-Center</TOKEN>
<TOKEN end_char="16647" id="token-178-3" morph="none" pos="word" start_char="16641">sources</TOKEN>
<TOKEN end_char="16648" id="token-178-4" morph="none" pos="punct" start_char="16648">.</TOKEN>
</SEG>
<SEG end_char="16736" id="segment-179" start_char="16650">
<ORIGINAL_TEXT>Factual Reporting: HIGH Notes: The Hindu is an English-language Indian daily newspaper.</ORIGINAL_TEXT>
<TOKEN end_char="16656" id="token-179-0" morph="none" pos="word" start_char="16650">Factual</TOKEN>
<TOKEN end_char="16666" id="token-179-1" morph="none" pos="word" start_char="16658">Reporting</TOKEN>
<TOKEN end_char="16667" id="token-179-2" morph="none" pos="punct" start_char="16667">:</TOKEN>
<TOKEN end_char="16672" id="token-179-3" morph="none" pos="word" start_char="16669">HIGH</TOKEN>
<TOKEN end_char="16678" id="token-179-4" morph="none" pos="word" start_char="16674">Notes</TOKEN>
<TOKEN end_char="16679" id="token-179-5" morph="none" pos="punct" start_char="16679">:</TOKEN>
<TOKEN end_char="16683" id="token-179-6" morph="none" pos="word" start_char="16681">The</TOKEN>
<TOKEN end_char="16689" id="token-179-7" morph="none" pos="word" start_char="16685">Hindu</TOKEN>
<TOKEN end_char="16692" id="token-179-8" morph="none" pos="word" start_char="16691">is</TOKEN>
<TOKEN end_char="16695" id="token-179-9" morph="none" pos="word" start_char="16694">an</TOKEN>
<TOKEN end_char="16712" id="token-179-10" morph="none" pos="unknown" start_char="16697">English-language</TOKEN>
<TOKEN end_char="16719" id="token-179-11" morph="none" pos="word" start_char="16714">Indian</TOKEN>
<TOKEN end_char="16725" id="token-179-12" morph="none" pos="word" start_char="16721">daily</TOKEN>
<TOKEN end_char="16735" id="token-179-13" morph="none" pos="word" start_char="16727">newspaper</TOKEN>
<TOKEN end_char="16736" id="token-179-14" morph="none" pos="punct" start_char="16736">.</TOKEN>
</SEG>
<SEG end_char="16865" id="segment-180" start_char="16738">
<ORIGINAL_TEXT>The Hindu has been accused of left-wing bias with its articles and editorials, but covers the USA with a more centrist approach.</ORIGINAL_TEXT>
<TOKEN end_char="16740" id="token-180-0" morph="none" pos="word" start_char="16738">The</TOKEN>
<TOKEN end_char="16746" id="token-180-1" morph="none" pos="word" start_char="16742">Hindu</TOKEN>
<TOKEN end_char="16750" id="token-180-2" morph="none" pos="word" start_char="16748">has</TOKEN>
<TOKEN end_char="16755" id="token-180-3" morph="none" pos="word" start_char="16752">been</TOKEN>
<TOKEN end_char="16763" id="token-180-4" morph="none" pos="word" start_char="16757">accused</TOKEN>
<TOKEN end_char="16766" id="token-180-5" morph="none" pos="word" start_char="16765">of</TOKEN>
<TOKEN end_char="16776" id="token-180-6" morph="none" pos="unknown" start_char="16768">left-wing</TOKEN>
<TOKEN end_char="16781" id="token-180-7" morph="none" pos="word" start_char="16778">bias</TOKEN>
<TOKEN end_char="16786" id="token-180-8" morph="none" pos="word" start_char="16783">with</TOKEN>
<TOKEN end_char="16790" id="token-180-9" morph="none" pos="word" start_char="16788">its</TOKEN>
<TOKEN end_char="16799" id="token-180-10" morph="none" pos="word" start_char="16792">articles</TOKEN>
<TOKEN end_char="16803" id="token-180-11" morph="none" pos="word" start_char="16801">and</TOKEN>
<TOKEN end_char="16814" id="token-180-12" morph="none" pos="word" start_char="16805">editorials</TOKEN>
<TOKEN end_char="16815" id="token-180-13" morph="none" pos="punct" start_char="16815">,</TOKEN>
<TOKEN end_char="16819" id="token-180-14" morph="none" pos="word" start_char="16817">but</TOKEN>
<TOKEN end_char="16826" id="token-180-15" morph="none" pos="word" start_char="16821">covers</TOKEN>
<TOKEN end_char="16830" id="token-180-16" morph="none" pos="word" start_char="16828">the</TOKEN>
<TOKEN end_char="16834" id="token-180-17" morph="none" pos="word" start_char="16832">USA</TOKEN>
<TOKEN end_char="16839" id="token-180-18" morph="none" pos="word" start_char="16836">with</TOKEN>
<TOKEN end_char="16841" id="token-180-19" morph="none" pos="word" start_char="16841">a</TOKEN>
<TOKEN end_char="16846" id="token-180-20" morph="none" pos="word" start_char="16843">more</TOKEN>
<TOKEN end_char="16855" id="token-180-21" morph="none" pos="word" start_char="16848">centrist</TOKEN>
<TOKEN end_char="16864" id="token-180-22" morph="none" pos="word" start_char="16857">approach</TOKEN>
<TOKEN end_char="16865" id="token-180-23" morph="none" pos="punct" start_char="16865">.</TOKEN>
</SEG>
<SEG end_char="16869" id="segment-181" start_char="16867">
<ORIGINAL_TEXT>(D.</ORIGINAL_TEXT>
<TOKEN end_char="16867" id="token-181-0" morph="none" pos="punct" start_char="16867">(</TOKEN>
<TOKEN end_char="16868" id="token-181-1" morph="none" pos="word" start_char="16868">D</TOKEN>
<TOKEN end_char="16869" id="token-181-2" morph="none" pos="punct" start_char="16869">.</TOKEN>
</SEG>
<SEG end_char="16901" id="segment-182" start_char="16871">
<ORIGINAL_TEXT>Van Zandt 10/27/2016) The Hindu</ORIGINAL_TEXT>
<TOKEN end_char="16873" id="token-182-0" morph="none" pos="word" start_char="16871">Van</TOKEN>
<TOKEN end_char="16879" id="token-182-1" morph="none" pos="word" start_char="16875">Zandt</TOKEN>
<TOKEN end_char="16890" id="token-182-2" morph="none" pos="unknown" start_char="16881">10/27/2016</TOKEN>
<TOKEN end_char="16891" id="token-182-3" morph="none" pos="punct" start_char="16891">)</TOKEN>
<TOKEN end_char="16895" id="token-182-4" morph="none" pos="word" start_char="16893">The</TOKEN>
<TOKEN end_char="16901" id="token-182-5" morph="none" pos="word" start_char="16897">Hindu</TOKEN>
<TRANSLATED_TEXT>Van Zandt 10 / 27 / 2016) The Hindu</TRANSLATED_TEXT><DETECTED_LANGUAGE>de</DETECTED_LANGUAGE></SEG>
<SEG end_char="17040" id="segment-183" start_char="16904">
<ORIGINAL_TEXT>so i guess i'm one of those certain people that would take the word of a left leaning, opinion piece over a super market tabloid any day.</ORIGINAL_TEXT>
<TOKEN end_char="16905" id="token-183-0" morph="none" pos="word" start_char="16904">so</TOKEN>
<TOKEN end_char="16907" id="token-183-1" morph="none" pos="word" start_char="16907">i</TOKEN>
<TOKEN end_char="16913" id="token-183-2" morph="none" pos="word" start_char="16909">guess</TOKEN>
<TOKEN end_char="16917" id="token-183-3" morph="none" pos="word" start_char="16915">i'm</TOKEN>
<TOKEN end_char="16921" id="token-183-4" morph="none" pos="word" start_char="16919">one</TOKEN>
<TOKEN end_char="16924" id="token-183-5" morph="none" pos="word" start_char="16923">of</TOKEN>
<TOKEN end_char="16930" id="token-183-6" morph="none" pos="word" start_char="16926">those</TOKEN>
<TOKEN end_char="16938" id="token-183-7" morph="none" pos="word" start_char="16932">certain</TOKEN>
<TOKEN end_char="16945" id="token-183-8" morph="none" pos="word" start_char="16940">people</TOKEN>
<TOKEN end_char="16950" id="token-183-9" morph="none" pos="word" start_char="16947">that</TOKEN>
<TOKEN end_char="16956" id="token-183-10" morph="none" pos="word" start_char="16952">would</TOKEN>
<TOKEN end_char="16961" id="token-183-11" morph="none" pos="word" start_char="16958">take</TOKEN>
<TOKEN end_char="16965" id="token-183-12" morph="none" pos="word" start_char="16963">the</TOKEN>
<TOKEN end_char="16970" id="token-183-13" morph="none" pos="word" start_char="16967">word</TOKEN>
<TOKEN end_char="16973" id="token-183-14" morph="none" pos="word" start_char="16972">of</TOKEN>
<TOKEN end_char="16975" id="token-183-15" morph="none" pos="word" start_char="16975">a</TOKEN>
<TOKEN end_char="16980" id="token-183-16" morph="none" pos="word" start_char="16977">left</TOKEN>
<TOKEN end_char="16988" id="token-183-17" morph="none" pos="word" start_char="16982">leaning</TOKEN>
<TOKEN end_char="16989" id="token-183-18" morph="none" pos="punct" start_char="16989">,</TOKEN>
<TOKEN end_char="16997" id="token-183-19" morph="none" pos="word" start_char="16991">opinion</TOKEN>
<TOKEN end_char="17003" id="token-183-20" morph="none" pos="word" start_char="16999">piece</TOKEN>
<TOKEN end_char="17008" id="token-183-21" morph="none" pos="word" start_char="17005">over</TOKEN>
<TOKEN end_char="17010" id="token-183-22" morph="none" pos="word" start_char="17010">a</TOKEN>
<TOKEN end_char="17016" id="token-183-23" morph="none" pos="word" start_char="17012">super</TOKEN>
<TOKEN end_char="17023" id="token-183-24" morph="none" pos="word" start_char="17018">market</TOKEN>
<TOKEN end_char="17031" id="token-183-25" morph="none" pos="word" start_char="17025">tabloid</TOKEN>
<TOKEN end_char="17035" id="token-183-26" morph="none" pos="word" start_char="17033">any</TOKEN>
<TOKEN end_char="17039" id="token-183-27" morph="none" pos="word" start_char="17037">day</TOKEN>
<TOKEN end_char="17040" id="token-183-28" morph="none" pos="punct" start_char="17040">.</TOKEN>
</SEG>
<SEG end_char="17121" id="segment-184" start_char="17042">
<ORIGINAL_TEXT>plus, did you notice that your external source has the word preprint at the top.</ORIGINAL_TEXT>
<TOKEN end_char="17045" id="token-184-0" morph="none" pos="word" start_char="17042">plus</TOKEN>
<TOKEN end_char="17046" id="token-184-1" morph="none" pos="punct" start_char="17046">,</TOKEN>
<TOKEN end_char="17050" id="token-184-2" morph="none" pos="word" start_char="17048">did</TOKEN>
<TOKEN end_char="17054" id="token-184-3" morph="none" pos="word" start_char="17052">you</TOKEN>
<TOKEN end_char="17061" id="token-184-4" morph="none" pos="word" start_char="17056">notice</TOKEN>
<TOKEN end_char="17066" id="token-184-5" morph="none" pos="word" start_char="17063">that</TOKEN>
<TOKEN end_char="17071" id="token-184-6" morph="none" pos="word" start_char="17068">your</TOKEN>
<TOKEN end_char="17080" id="token-184-7" morph="none" pos="word" start_char="17073">external</TOKEN>
<TOKEN end_char="17087" id="token-184-8" morph="none" pos="word" start_char="17082">source</TOKEN>
<TOKEN end_char="17091" id="token-184-9" morph="none" pos="word" start_char="17089">has</TOKEN>
<TOKEN end_char="17095" id="token-184-10" morph="none" pos="word" start_char="17093">the</TOKEN>
<TOKEN end_char="17100" id="token-184-11" morph="none" pos="word" start_char="17097">word</TOKEN>
<TOKEN end_char="17109" id="token-184-12" morph="none" pos="word" start_char="17102">preprint</TOKEN>
<TOKEN end_char="17112" id="token-184-13" morph="none" pos="word" start_char="17111">at</TOKEN>
<TOKEN end_char="17116" id="token-184-14" morph="none" pos="word" start_char="17114">the</TOKEN>
<TOKEN end_char="17120" id="token-184-15" morph="none" pos="word" start_char="17118">top</TOKEN>
<TOKEN end_char="17121" id="token-184-16" morph="none" pos="punct" start_char="17121">.</TOKEN>
</SEG>
<SEG end_char="17229" id="segment-185" start_char="17124">
<ORIGINAL_TEXT>also do you really believe that the WHO would back China in this so called BIO weapon escape/ or accident.</ORIGINAL_TEXT>
<TOKEN end_char="17127" id="token-185-0" morph="none" pos="word" start_char="17124">also</TOKEN>
<TOKEN end_char="17130" id="token-185-1" morph="none" pos="word" start_char="17129">do</TOKEN>
<TOKEN end_char="17134" id="token-185-2" morph="none" pos="word" start_char="17132">you</TOKEN>
<TOKEN end_char="17141" id="token-185-3" morph="none" pos="word" start_char="17136">really</TOKEN>
<TOKEN end_char="17149" id="token-185-4" morph="none" pos="word" start_char="17143">believe</TOKEN>
<TOKEN end_char="17154" id="token-185-5" morph="none" pos="word" start_char="17151">that</TOKEN>
<TOKEN end_char="17158" id="token-185-6" morph="none" pos="word" start_char="17156">the</TOKEN>
<TOKEN end_char="17162" id="token-185-7" morph="none" pos="word" start_char="17160">WHO</TOKEN>
<TOKEN end_char="17168" id="token-185-8" morph="none" pos="word" start_char="17164">would</TOKEN>
<TOKEN end_char="17173" id="token-185-9" morph="none" pos="word" start_char="17170">back</TOKEN>
<TOKEN end_char="17179" id="token-185-10" morph="none" pos="word" start_char="17175">China</TOKEN>
<TOKEN end_char="17182" id="token-185-11" morph="none" pos="word" start_char="17181">in</TOKEN>
<TOKEN end_char="17187" id="token-185-12" morph="none" pos="word" start_char="17184">this</TOKEN>
<TOKEN end_char="17190" id="token-185-13" morph="none" pos="word" start_char="17189">so</TOKEN>
<TOKEN end_char="17197" id="token-185-14" morph="none" pos="word" start_char="17192">called</TOKEN>
<TOKEN end_char="17201" id="token-185-15" morph="none" pos="word" start_char="17199">BIO</TOKEN>
<TOKEN end_char="17208" id="token-185-16" morph="none" pos="word" start_char="17203">weapon</TOKEN>
<TOKEN end_char="17215" id="token-185-17" morph="none" pos="word" start_char="17210">escape</TOKEN>
<TOKEN end_char="17216" id="token-185-18" morph="none" pos="punct" start_char="17216">/</TOKEN>
<TOKEN end_char="17219" id="token-185-19" morph="none" pos="word" start_char="17218">or</TOKEN>
<TOKEN end_char="17228" id="token-185-20" morph="none" pos="word" start_char="17221">accident</TOKEN>
<TOKEN end_char="17229" id="token-185-21" morph="none" pos="punct" start_char="17229">.</TOKEN>
</SEG>
<SEG end_char="17337" id="segment-186" start_char="17231">
<ORIGINAL_TEXT>to do that and if any evidence came out that it did cover it up their credibility would be shot completely.</ORIGINAL_TEXT>
<TOKEN end_char="17232" id="token-186-0" morph="none" pos="word" start_char="17231">to</TOKEN>
<TOKEN end_char="17235" id="token-186-1" morph="none" pos="word" start_char="17234">do</TOKEN>
<TOKEN end_char="17240" id="token-186-2" morph="none" pos="word" start_char="17237">that</TOKEN>
<TOKEN end_char="17244" id="token-186-3" morph="none" pos="word" start_char="17242">and</TOKEN>
<TOKEN end_char="17247" id="token-186-4" morph="none" pos="word" start_char="17246">if</TOKEN>
<TOKEN end_char="17251" id="token-186-5" morph="none" pos="word" start_char="17249">any</TOKEN>
<TOKEN end_char="17260" id="token-186-6" morph="none" pos="word" start_char="17253">evidence</TOKEN>
<TOKEN end_char="17265" id="token-186-7" morph="none" pos="word" start_char="17262">came</TOKEN>
<TOKEN end_char="17269" id="token-186-8" morph="none" pos="word" start_char="17267">out</TOKEN>
<TOKEN end_char="17274" id="token-186-9" morph="none" pos="word" start_char="17271">that</TOKEN>
<TOKEN end_char="17277" id="token-186-10" morph="none" pos="word" start_char="17276">it</TOKEN>
<TOKEN end_char="17281" id="token-186-11" morph="none" pos="word" start_char="17279">did</TOKEN>
<TOKEN end_char="17287" id="token-186-12" morph="none" pos="word" start_char="17283">cover</TOKEN>
<TOKEN end_char="17290" id="token-186-13" morph="none" pos="word" start_char="17289">it</TOKEN>
<TOKEN end_char="17293" id="token-186-14" morph="none" pos="word" start_char="17292">up</TOKEN>
<TOKEN end_char="17299" id="token-186-15" morph="none" pos="word" start_char="17295">their</TOKEN>
<TOKEN end_char="17311" id="token-186-16" morph="none" pos="word" start_char="17301">credibility</TOKEN>
<TOKEN end_char="17317" id="token-186-17" morph="none" pos="word" start_char="17313">would</TOKEN>
<TOKEN end_char="17320" id="token-186-18" morph="none" pos="word" start_char="17319">be</TOKEN>
<TOKEN end_char="17325" id="token-186-19" morph="none" pos="word" start_char="17322">shot</TOKEN>
<TOKEN end_char="17336" id="token-186-20" morph="none" pos="word" start_char="17327">completely</TOKEN>
<TOKEN end_char="17337" id="token-186-21" morph="none" pos="punct" start_char="17337">.</TOKEN>
</SEG>
<SEG end_char="17380" id="segment-187" start_char="17339">
<ORIGINAL_TEXT>they don't have a high degree of that now.</ORIGINAL_TEXT>
<TOKEN end_char="17342" id="token-187-0" morph="none" pos="word" start_char="17339">they</TOKEN>
<TOKEN end_char="17348" id="token-187-1" morph="none" pos="word" start_char="17344">don't</TOKEN>
<TOKEN end_char="17353" id="token-187-2" morph="none" pos="word" start_char="17350">have</TOKEN>
<TOKEN end_char="17355" id="token-187-3" morph="none" pos="word" start_char="17355">a</TOKEN>
<TOKEN end_char="17360" id="token-187-4" morph="none" pos="word" start_char="17357">high</TOKEN>
<TOKEN end_char="17367" id="token-187-5" morph="none" pos="word" start_char="17362">degree</TOKEN>
<TOKEN end_char="17370" id="token-187-6" morph="none" pos="word" start_char="17369">of</TOKEN>
<TOKEN end_char="17375" id="token-187-7" morph="none" pos="word" start_char="17372">that</TOKEN>
<TOKEN end_char="17379" id="token-187-8" morph="none" pos="word" start_char="17377">now</TOKEN>
<TOKEN end_char="17380" id="token-187-9" morph="none" pos="punct" start_char="17380">.</TOKEN>
</SEG>
<SEG end_char="17444" id="segment-188" start_char="17383">
<ORIGINAL_TEXT>edit on 14-3-2020 by hounddoghowlie because: (no reason given)</ORIGINAL_TEXT>
<TOKEN end_char="17386" id="token-188-0" morph="none" pos="word" start_char="17383">edit</TOKEN>
<TOKEN end_char="17389" id="token-188-1" morph="none" pos="word" start_char="17388">on</TOKEN>
<TOKEN end_char="17399" id="token-188-2" morph="none" pos="unknown" start_char="17391">14-3-2020</TOKEN>
<TOKEN end_char="17402" id="token-188-3" morph="none" pos="word" start_char="17401">by</TOKEN>
<TOKEN end_char="17417" id="token-188-4" morph="none" pos="word" start_char="17404">hounddoghowlie</TOKEN>
<TOKEN end_char="17425" id="token-188-5" morph="none" pos="word" start_char="17419">because</TOKEN>
<TOKEN end_char="17426" id="token-188-6" morph="none" pos="punct" start_char="17426">:</TOKEN>
<TOKEN end_char="17428" id="token-188-7" morph="none" pos="punct" start_char="17428">(</TOKEN>
<TOKEN end_char="17430" id="token-188-8" morph="none" pos="word" start_char="17429">no</TOKEN>
<TOKEN end_char="17437" id="token-188-9" morph="none" pos="word" start_char="17432">reason</TOKEN>
<TOKEN end_char="17443" id="token-188-10" morph="none" pos="word" start_char="17439">given</TOKEN>
<TOKEN end_char="17444" id="token-188-11" morph="none" pos="punct" start_char="17444">)</TOKEN>
</SEG>
<SEG end_char="17546" id="segment-189" start_char="17447">
<ORIGINAL_TEXT>oh and i forgot to mention that there is a link to your so called research paper in The Hindu piece.</ORIGINAL_TEXT>
<TOKEN end_char="17448" id="token-189-0" morph="none" pos="word" start_char="17447">oh</TOKEN>
<TOKEN end_char="17452" id="token-189-1" morph="none" pos="word" start_char="17450">and</TOKEN>
<TOKEN end_char="17454" id="token-189-2" morph="none" pos="word" start_char="17454">i</TOKEN>
<TOKEN end_char="17461" id="token-189-3" morph="none" pos="word" start_char="17456">forgot</TOKEN>
<TOKEN end_char="17464" id="token-189-4" morph="none" pos="word" start_char="17463">to</TOKEN>
<TOKEN end_char="17472" id="token-189-5" morph="none" pos="word" start_char="17466">mention</TOKEN>
<TOKEN end_char="17477" id="token-189-6" morph="none" pos="word" start_char="17474">that</TOKEN>
<TOKEN end_char="17483" id="token-189-7" morph="none" pos="word" start_char="17479">there</TOKEN>
<TOKEN end_char="17486" id="token-189-8" morph="none" pos="word" start_char="17485">is</TOKEN>
<TOKEN end_char="17488" id="token-189-9" morph="none" pos="word" start_char="17488">a</TOKEN>
<TOKEN end_char="17493" id="token-189-10" morph="none" pos="word" start_char="17490">link</TOKEN>
<TOKEN end_char="17496" id="token-189-11" morph="none" pos="word" start_char="17495">to</TOKEN>
<TOKEN end_char="17501" id="token-189-12" morph="none" pos="word" start_char="17498">your</TOKEN>
<TOKEN end_char="17504" id="token-189-13" morph="none" pos="word" start_char="17503">so</TOKEN>
<TOKEN end_char="17511" id="token-189-14" morph="none" pos="word" start_char="17506">called</TOKEN>
<TOKEN end_char="17520" id="token-189-15" morph="none" pos="word" start_char="17513">research</TOKEN>
<TOKEN end_char="17526" id="token-189-16" morph="none" pos="word" start_char="17522">paper</TOKEN>
<TOKEN end_char="17529" id="token-189-17" morph="none" pos="word" start_char="17528">in</TOKEN>
<TOKEN end_char="17533" id="token-189-18" morph="none" pos="word" start_char="17531">The</TOKEN>
<TOKEN end_char="17539" id="token-189-19" morph="none" pos="word" start_char="17535">Hindu</TOKEN>
<TOKEN end_char="17545" id="token-189-20" morph="none" pos="word" start_char="17541">piece</TOKEN>
<TOKEN end_char="17546" id="token-189-21" morph="none" pos="punct" start_char="17546">.</TOKEN>
</SEG>
<SEG end_char="17566" id="segment-190" start_char="17548">
<ORIGINAL_TEXT>it's only one page.</ORIGINAL_TEXT>
<TOKEN end_char="17551" id="token-190-0" morph="none" pos="word" start_char="17548">it's</TOKEN>
<TOKEN end_char="17556" id="token-190-1" morph="none" pos="word" start_char="17553">only</TOKEN>
<TOKEN end_char="17560" id="token-190-2" morph="none" pos="word" start_char="17558">one</TOKEN>
<TOKEN end_char="17565" id="token-190-3" morph="none" pos="word" start_char="17562">page</TOKEN>
<TOKEN end_char="17566" id="token-190-4" morph="none" pos="punct" start_char="17566">.</TOKEN>
</SEG>
<SEG end_char="17660" id="segment-191" start_char="17568">
<ORIGINAL_TEXT>what kind of self respecting researcher is going to write a paper that is only one page long.</ORIGINAL_TEXT>
<TOKEN end_char="17571" id="token-191-0" morph="none" pos="word" start_char="17568">what</TOKEN>
<TOKEN end_char="17576" id="token-191-1" morph="none" pos="word" start_char="17573">kind</TOKEN>
<TOKEN end_char="17579" id="token-191-2" morph="none" pos="word" start_char="17578">of</TOKEN>
<TOKEN end_char="17584" id="token-191-3" morph="none" pos="word" start_char="17581">self</TOKEN>
<TOKEN end_char="17595" id="token-191-4" morph="none" pos="word" start_char="17586">respecting</TOKEN>
<TOKEN end_char="17606" id="token-191-5" morph="none" pos="word" start_char="17597">researcher</TOKEN>
<TOKEN end_char="17609" id="token-191-6" morph="none" pos="word" start_char="17608">is</TOKEN>
<TOKEN end_char="17615" id="token-191-7" morph="none" pos="word" start_char="17611">going</TOKEN>
<TOKEN end_char="17618" id="token-191-8" morph="none" pos="word" start_char="17617">to</TOKEN>
<TOKEN end_char="17624" id="token-191-9" morph="none" pos="word" start_char="17620">write</TOKEN>
<TOKEN end_char="17626" id="token-191-10" morph="none" pos="word" start_char="17626">a</TOKEN>
<TOKEN end_char="17632" id="token-191-11" morph="none" pos="word" start_char="17628">paper</TOKEN>
<TOKEN end_char="17637" id="token-191-12" morph="none" pos="word" start_char="17634">that</TOKEN>
<TOKEN end_char="17640" id="token-191-13" morph="none" pos="word" start_char="17639">is</TOKEN>
<TOKEN end_char="17645" id="token-191-14" morph="none" pos="word" start_char="17642">only</TOKEN>
<TOKEN end_char="17649" id="token-191-15" morph="none" pos="word" start_char="17647">one</TOKEN>
<TOKEN end_char="17654" id="token-191-16" morph="none" pos="word" start_char="17651">page</TOKEN>
<TOKEN end_char="17659" id="token-191-17" morph="none" pos="word" start_char="17656">long</TOKEN>
<TOKEN end_char="17660" id="token-191-18" morph="none" pos="punct" start_char="17660">.</TOKEN>
</SEG>
<SEG end_char="17703" id="segment-192" start_char="17662">
<ORIGINAL_TEXT>plus he also says possible not that it is.</ORIGINAL_TEXT>
<TOKEN end_char="17665" id="token-192-0" morph="none" pos="word" start_char="17662">plus</TOKEN>
<TOKEN end_char="17668" id="token-192-1" morph="none" pos="word" start_char="17667">he</TOKEN>
<TOKEN end_char="17673" id="token-192-2" morph="none" pos="word" start_char="17670">also</TOKEN>
<TOKEN end_char="17678" id="token-192-3" morph="none" pos="word" start_char="17675">says</TOKEN>
<TOKEN end_char="17687" id="token-192-4" morph="none" pos="word" start_char="17680">possible</TOKEN>
<TOKEN end_char="17691" id="token-192-5" morph="none" pos="word" start_char="17689">not</TOKEN>
<TOKEN end_char="17696" id="token-192-6" morph="none" pos="word" start_char="17693">that</TOKEN>
<TOKEN end_char="17699" id="token-192-7" morph="none" pos="word" start_char="17698">it</TOKEN>
<TOKEN end_char="17702" id="token-192-8" morph="none" pos="word" start_char="17701">is</TOKEN>
<TOKEN end_char="17703" id="token-192-9" morph="none" pos="punct" start_char="17703">.</TOKEN>
</SEG>
<SEG end_char="17856" id="segment-193" start_char="17705">
<ORIGINAL_TEXT>it's possible that if a grass hopper could fire a .45 the birds wouldn't blank with him, or if a frog had wings he wouldn't bump his azz when he hopped.</ORIGINAL_TEXT>
<TOKEN end_char="17708" id="token-193-0" morph="none" pos="word" start_char="17705">it's</TOKEN>
<TOKEN end_char="17717" id="token-193-1" morph="none" pos="word" start_char="17710">possible</TOKEN>
<TOKEN end_char="17722" id="token-193-2" morph="none" pos="word" start_char="17719">that</TOKEN>
<TOKEN end_char="17725" id="token-193-3" morph="none" pos="word" start_char="17724">if</TOKEN>
<TOKEN end_char="17727" id="token-193-4" morph="none" pos="word" start_char="17727">a</TOKEN>
<TOKEN end_char="17733" id="token-193-5" morph="none" pos="word" start_char="17729">grass</TOKEN>
<TOKEN end_char="17740" id="token-193-6" morph="none" pos="word" start_char="17735">hopper</TOKEN>
<TOKEN end_char="17746" id="token-193-7" morph="none" pos="word" start_char="17742">could</TOKEN>
<TOKEN end_char="17751" id="token-193-8" morph="none" pos="word" start_char="17748">fire</TOKEN>
<TOKEN end_char="17753" id="token-193-9" morph="none" pos="word" start_char="17753">a</TOKEN>
<TOKEN end_char="17757" id="token-193-10" morph="none" pos="word" start_char="17755">.45</TOKEN>
<TOKEN end_char="17761" id="token-193-11" morph="none" pos="word" start_char="17759">the</TOKEN>
<TOKEN end_char="17767" id="token-193-12" morph="none" pos="word" start_char="17763">birds</TOKEN>
<TOKEN end_char="17776" id="token-193-13" morph="none" pos="word" start_char="17769">wouldn't</TOKEN>
<TOKEN end_char="17782" id="token-193-14" morph="none" pos="word" start_char="17778">blank</TOKEN>
<TOKEN end_char="17787" id="token-193-15" morph="none" pos="word" start_char="17784">with</TOKEN>
<TOKEN end_char="17791" id="token-193-16" morph="none" pos="word" start_char="17789">him</TOKEN>
<TOKEN end_char="17792" id="token-193-17" morph="none" pos="punct" start_char="17792">,</TOKEN>
<TOKEN end_char="17795" id="token-193-18" morph="none" pos="word" start_char="17794">or</TOKEN>
<TOKEN end_char="17798" id="token-193-19" morph="none" pos="word" start_char="17797">if</TOKEN>
<TOKEN end_char="17800" id="token-193-20" morph="none" pos="word" start_char="17800">a</TOKEN>
<TOKEN end_char="17805" id="token-193-21" morph="none" pos="word" start_char="17802">frog</TOKEN>
<TOKEN end_char="17809" id="token-193-22" morph="none" pos="word" start_char="17807">had</TOKEN>
<TOKEN end_char="17815" id="token-193-23" morph="none" pos="word" start_char="17811">wings</TOKEN>
<TOKEN end_char="17818" id="token-193-24" morph="none" pos="word" start_char="17817">he</TOKEN>
<TOKEN end_char="17827" id="token-193-25" morph="none" pos="word" start_char="17820">wouldn't</TOKEN>
<TOKEN end_char="17832" id="token-193-26" morph="none" pos="word" start_char="17829">bump</TOKEN>
<TOKEN end_char="17836" id="token-193-27" morph="none" pos="word" start_char="17834">his</TOKEN>
<TOKEN end_char="17840" id="token-193-28" morph="none" pos="word" start_char="17838">azz</TOKEN>
<TOKEN end_char="17845" id="token-193-29" morph="none" pos="word" start_char="17842">when</TOKEN>
<TOKEN end_char="17848" id="token-193-30" morph="none" pos="word" start_char="17847">he</TOKEN>
<TOKEN end_char="17855" id="token-193-31" morph="none" pos="word" start_char="17850">hopped</TOKEN>
<TOKEN end_char="17856" id="token-193-32" morph="none" pos="punct" start_char="17856">.</TOKEN>
</SEG>
<SEG end_char="17919" id="segment-194" start_char="17859">
<ORIGINAL_TEXT>here the paper, The possible origins of 2019-nCoV coronavirus</ORIGINAL_TEXT>
<TOKEN end_char="17862" id="token-194-0" morph="none" pos="word" start_char="17859">here</TOKEN>
<TOKEN end_char="17866" id="token-194-1" morph="none" pos="word" start_char="17864">the</TOKEN>
<TOKEN end_char="17872" id="token-194-2" morph="none" pos="word" start_char="17868">paper</TOKEN>
<TOKEN end_char="17873" id="token-194-3" morph="none" pos="punct" start_char="17873">,</TOKEN>
<TOKEN end_char="17877" id="token-194-4" morph="none" pos="word" start_char="17875">The</TOKEN>
<TOKEN end_char="17886" id="token-194-5" morph="none" pos="word" start_char="17879">possible</TOKEN>
<TOKEN end_char="17894" id="token-194-6" morph="none" pos="word" start_char="17888">origins</TOKEN>
<TOKEN end_char="17897" id="token-194-7" morph="none" pos="word" start_char="17896">of</TOKEN>
<TOKEN end_char="17907" id="token-194-8" morph="none" pos="unknown" start_char="17899">2019-nCoV</TOKEN>
<TOKEN end_char="17919" id="token-194-9" morph="none" pos="word" start_char="17909">coronavirus</TOKEN>
</SEG>
<SEG end_char="17983" id="segment-195" start_char="17922">
<ORIGINAL_TEXT>edit on 14-3-2020 by hounddoghowlie because: (no reason given)</ORIGINAL_TEXT>
<TOKEN end_char="17925" id="token-195-0" morph="none" pos="word" start_char="17922">edit</TOKEN>
<TOKEN end_char="17928" id="token-195-1" morph="none" pos="word" start_char="17927">on</TOKEN>
<TOKEN end_char="17938" id="token-195-2" morph="none" pos="unknown" start_char="17930">14-3-2020</TOKEN>
<TOKEN end_char="17941" id="token-195-3" morph="none" pos="word" start_char="17940">by</TOKEN>
<TOKEN end_char="17956" id="token-195-4" morph="none" pos="word" start_char="17943">hounddoghowlie</TOKEN>
<TOKEN end_char="17964" id="token-195-5" morph="none" pos="word" start_char="17958">because</TOKEN>
<TOKEN end_char="17965" id="token-195-6" morph="none" pos="punct" start_char="17965">:</TOKEN>
<TOKEN end_char="17967" id="token-195-7" morph="none" pos="punct" start_char="17967">(</TOKEN>
<TOKEN end_char="17969" id="token-195-8" morph="none" pos="word" start_char="17968">no</TOKEN>
<TOKEN end_char="17976" id="token-195-9" morph="none" pos="word" start_char="17971">reason</TOKEN>
<TOKEN end_char="17982" id="token-195-10" morph="none" pos="word" start_char="17978">given</TOKEN>
<TOKEN end_char="17983" id="token-195-11" morph="none" pos="punct" start_char="17983">)</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>